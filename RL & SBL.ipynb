{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"ed62cb7529aa4b91bd363f2564f4f378","deepnote_cell_type":"text-cell-h1","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":29,"type":"marks"}]},"source":["# Gymnasium With stablebaseline"]},{"cell_type":"markdown","metadata":{"cell_id":"052d0e2696ff48988f491b86ff0e441c","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":0,"type":"marks"}]},"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"e47b7d85ecb749dd8e9dc6d862009782","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":5814,"execution_start":1728985559790,"source_hash":"d8f7f6ba"},"outputs":[],"source":["from time import time\n","from enum import Enum\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import gymnasium as gym\n","from gymnasium.envs.registration import register\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from stable_baselines3 import PPO, A2C,DQN,TD3\n","from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n","from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback, CallbackList\n","from stable_baselines3.common.monitor import Monitor\n","from gymnasium import spaces\n","from gymnasium.utils import seeding\n","from sklearn.preprocessing import MinMaxScaler\n","import ta\n","import logging\n","from sklearn.impute import SimpleImputer\n","from datetime import datetime, timedelta\n","from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n","from stable_baselines3.common.noise import NormalActionNoise\n","from stable_baselines3.common.callbacks import BaseCallback\n","import sys\n","from typing import Any, Dict, Tuple, Union\n","# import mlflow\n","\n","from stable_baselines3.common.logger import HumanOutputFormat, KVWriter, Logger\n","# lets hide the warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"9019a622bd904d51b92c9c82786f1513","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":1,"execution_start":1728985565646,"source_hash":"cad0266c"},"outputs":[],"source":["#look out for this like for simulator to MT5 https://github.com/AminHP/gym-mtsim/tree/main/gym_mtsim\n","# https://github.com/TomatoFT/Forex-Trading-Automation-with-Deep-Reinforcement-Learning/tree/main"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"f8b3f00dd301408f87db12e60bca3428","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":1,"execution_start":1728985565698,"source_hash":"4d2e6f32"},"outputs":[],"source":["class Actions(Enum):\n","    Sell = 0\n","    Buy = 1\n","    Hold = 2\n","\n","    def __int__(self):\n","        return self.value\n","\n","\n","class Positions(Enum):\n","    Short = 0\n","    Long = 1\n","\n","    def __int__(self):\n","        return self.value\n","\n","    def opposite(self):\n","        return Positions.Short if self == Positions.Long else Positions.Long"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class TradingEnv(gym.Env):\n","\n","    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 3}\n","\n","    def __init__(self, df, window_size, render_mode=None):\n","        assert df.ndim == 2\n","        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n","\n","        self.render_mode = render_mode\n","\n","        self.df = df\n","        self.window_size = window_size\n","        self.prices, self.signal_features = self._process_data()\n","        self.shape = (window_size, self.signal_features.shape[1])\n","\n","        # spaces\n","        self.action_space = gym.spaces.Discrete(len(Actions))\n","        INF = 1e10\n","        self.observation_space = gym.spaces.Box(\n","            low=-INF,\n","            high=INF,\n","            shape=self.shape,\n","            dtype=np.float32,\n","        )\n","\n","        # episode\n","        self._start_tick = self.window_size\n","        self._end_tick = len(self.prices) - 1\n","        self._truncated = None\n","        self._current_tick = None\n","        self._last_trade_tick = None\n","        self._position = None\n","        self._position_history = None\n","        self._total_reward = None\n","        self._total_profit = None\n","        self._first_rendering = None\n","\n","        # Initialize plot for rendering\n","        self.fig, self.ax = plt.subplots()\n","        (self.price_line,) = self.ax.plot(self.prices)  # Store the plot line object\n","        self.position_scatter = None\n","        self._first_rendering = True\n","        self.history = {}\n","\n","    def reset(self, seed=None, options=None):\n","        super().reset(seed=seed, options=options)\n","        self.action_space.seed(\n","            int((self.np_random.uniform(0, seed if seed is not None else 1)))\n","        )\n","\n","        self._truncated = False\n","        self._current_tick = self._start_tick\n","        self._last_trade_tick = self._current_tick - 1\n","        self._position = Positions.Short\n","        self._position_history = (self.window_size * [None]) + [self._position]\n","        self._total_reward = 0.0\n","        self._total_profit = 1.0  # unit\n","        self._first_rendering = True\n","        self.history = {}\n","        # Clear the plot on reset\n","        self.ax.cla()\n","        (self.price_line,) = self.ax.plot(self.prices)\n","        self.position_scatter = None\n","\n","        observation = self._get_observation()\n","        info = self._get_info()\n","\n","        if self.render_mode == \"human\":\n","            self._render_frame()\n","\n","        return observation, info\n","\n","    def step(self, action):\n","        self._truncated = False\n","        self._current_tick += 1\n","\n","        if self._current_tick == self._end_tick:\n","            self._truncated = True\n","\n","        step_reward = self._calculate_reward(action)\n","        self._total_reward += step_reward\n","\n","        self._update_profit(action)\n","\n","        trade = False\n","        if (action == Actions.Buy.value and self._position == Positions.Short) or (\n","            action == Actions.Sell.value and self._position == Positions.Long\n","        ):\n","            trade = True\n","\n","        if trade:\n","            self._position = self._position.opposite()\n","            self._last_trade_tick = self._current_tick\n","\n","        self._position_history.append(self._position)\n","        observation = self._get_observation()\n","        info = self._get_info()\n","        self._update_history(info)\n","\n","        if self.render_mode == \"human\":\n","            self._render_frame()\n","\n","        return observation, step_reward, False, self._truncated, info\n","\n","    def _get_info(self):\n","        return dict(\n","            total_reward=self._total_reward,\n","            total_profit=self._total_profit,\n","            position=self._position,\n","        )\n","\n","    def _get_observation(self):\n","        return self.signal_features[\n","            (self._current_tick - self.window_size + 1) : self._current_tick + 1\n","        ]\n","\n","    def _update_history(self, info):\n","        if not self.history:\n","            self.history = {key: [] for key in info.keys()}\n","\n","        for key, value in info.items():\n","            self.history[key].append(value)\n","\n","    def _render_frame(self):\n","        self.render()\n","\n","    def render(self, mode=\"human\"):\n","        start_time = time()\n","\n","        # Update price plot\n","        self.price_line.set_data(np.arange(len(self.prices)), self.prices)\n","        self.ax.set_xlim(0, len(self.prices))  # Set x-axis limits\n","        self.ax.set_ylim(min(self.prices), max(self.prices))  # Set y-axis limits\n","\n","        # Update position markers\n","        if self.position_scatter is not None:\n","            self.position_scatter.remove()\n","\n","        short_ticks = []\n","        long_ticks = []\n","        for i, tick in enumerate(np.arange(len(self._position_history))):\n","            if self._position_history[i] == Positions.Short:\n","                short_ticks.append(tick)\n","            elif self._position_history[i] == Positions.Long:\n","                long_ticks.append(tick)\n","\n","        self.position_scatter = self.ax.scatter(\n","            short_ticks, self.prices[short_ticks], color=\"red\", marker=\"o\"\n","        )\n","        self.position_scatter = self.ax.scatter(\n","            long_ticks, self.prices[long_ticks], color=\"green\", marker=\"o\"\n","        )\n","\n","        # Update plot title\n","        self.ax.set_title(\n","            \"Total Reward: %.6f\" % self._total_reward\n","            + \" ~ \"\n","            + \"Total Profit: %.6f\" % self._total_profit\n","        )\n","\n","        # Update the plot\n","        self.fig.canvas.draw()\n","        self.fig.canvas.flush_events()\n","\n","        end_time = time()\n","        process_time = end_time - start_time\n","\n","        pause_time = (1 / self.metadata[\"render_fps\"]) - process_time\n","        assert pause_time > 0.0, \"High FPS! Try to reduce the 'render_fps' value.\"\n","\n","        plt.pause(pause_time)\n","\n","    def render_all(self, title=None):\n","        window_ticks = np.arange(len(self._position_history))\n","        plt.plot(self.prices)\n","\n","        short_ticks = []\n","        long_ticks = []\n","        for i, tick in enumerate(window_ticks):\n","            if self._position_history[i] == Positions.Short:\n","                short_ticks.append(tick)\n","            elif self._position_history[i] == Positions.Long:\n","                long_ticks.append(tick)\n","\n","        plt.plot(short_ticks, self.prices[short_ticks], \"ro\")\n","        plt.plot(long_ticks, self.prices[long_ticks], \"go\")\n","\n","        if title:\n","            plt.title(title)\n","\n","        plt.suptitle(\n","            \"Total Reward: %.6f\" % self._total_reward\n","            + \" ~ \"\n","            + \"Total Profit: %.6f\" % self._total_profit\n","        )\n","\n","    def close(self):\n","        plt.close()\n","\n","    def save_rendering(self, filepath):\n","        plt.savefig(filepath)\n","\n","    def pause_rendering(self):\n","        plt.show()\n","\n","    def _process_data(self):\n","        raise NotImplementedError\n","\n","    def _calculate_reward(self, action):\n","        raise NotImplementedError\n","\n","    def _update_profit(self, action):\n","        raise NotImplementedError\n","        "]},{"cell_type":"code","execution_count":17,"metadata":{"cell_id":"f1e26d2b9aab4bd18f790772c79f2f59","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":1,"execution_start":1728985565774,"source_hash":"81cf1ba7"},"outputs":[],"source":["# class TradingEnv(gym.Env):\n","\n","#     metadata = {'render_modes': ['human', 'rgb_array'], 'render_fps': 3}\n","\n","#     def __init__(self, df, window_size, render_mode=None):\n","#         assert df.ndim == 2\n","#         assert render_mode is None or render_mode in self.metadata['render_modes']\n","\n","#         self.render_mode = render_mode\n","\n","#         self.df = df\n","#         self.window_size = window_size\n","#         self.prices, self.signal_features = self._process_data()\n","#         self.shape = (window_size, self.signal_features.shape[1])\n","\n","#         # spaces\n","#         self.action_space = gym.spaces.Discrete(len(Actions))\n","#         INF = 1e10\n","#         self.observation_space = gym.spaces.Box(\n","#             low=-INF, high=INF, shape=self.shape, dtype=np.float32,\n","#         )\n","\n","#         # episode\n","#         self._start_tick = self.window_size\n","#         self._end_tick = len(self.prices) - 1\n","#         self._truncated = None\n","#         self._current_tick = None\n","#         self._last_trade_tick = None\n","#         self._position = None\n","#         self._position_history = None\n","#         self._total_reward = None\n","#         self._total_profit = None\n","#         self._first_rendering = None\n","\n","#         # Initialize plot for rendering\n","#         self.fig, self.ax = plt.subplots()\n","#         self.price_line, = self.ax.plot(self.prices)  # Store the plot line object\n","#         self.position_scatter = None\n","#         self._first_rendering = True\n","#         self.history = {}\n","\n","#     def reset(self, seed=None, options=None):\n","#         super().reset(seed=seed, options=options)\n","#         self.action_space.seed(int((self.np_random.uniform(0, seed if seed is not None else 1))))\n","\n","#         self._truncated = False\n","#         self._current_tick = self._start_tick\n","#         self._last_trade_tick = self._current_tick - 1\n","#         self._position = Positions.Short\n","#         self._position_history = (self.window_size * [None]) + [self._position]\n","#         self._total_reward = 0.\n","#         self._total_profit = 1.  # unit\n","#         self._first_rendering = True\n","#         self.history = {}\n","#         # Clear the plot on reset\n","#         self.ax.cla()\n","#         self.price_line, = self.ax.plot(self.prices)\n","#         self.position_scatter = None\n","\n","#         observation = self._get_observation()\n","#         info = self._get_info()\n","\n","#         if self.render_mode == 'human':\n","#             self._render_frame()\n","\n","#         return observation, info\n","\n","#     def step(self, action):\n","#         self._truncated = False\n","#         self._current_tick += 1\n","\n","#         if self._current_tick == self._end_tick:\n","#             self._truncated = True\n","\n","#         step_reward = self._calculate_reward(action)\n","#         self._total_reward += step_reward\n","\n","#         self._update_profit(action)\n","\n","#         trade = False\n","#         if (\n","#             (action == Actions.Buy.value and self._position == Positions.Short) or\n","#             (action == Actions.Sell.value and self._position == Positions.Long)\n","#         ):\n","#             trade = True\n","\n","#         if trade:\n","#             self._position = self._position.opposite()\n","#             self._last_trade_tick = self._current_tick\n","\n","#         self._position_history.append(self._position)\n","#         observation = self._get_observation()\n","#         info = self._get_info()\n","#         self._update_history(info)\n","\n","#         if self.render_mode == 'human':\n","#             self._render_frame()\n","\n","#         return observation, step_reward, False, self._truncated, info\n","\n","#     def _get_info(self):\n","#         return dict(\n","#             total_reward=self._total_reward,\n","#             total_profit=self._total_profit,\n","#             position=self._position\n","#         )\n","\n","#     def _get_observation(self):\n","#         return self.signal_features[(self._current_tick-self.window_size+1):self._current_tick+1]\n","\n","#     def _update_history(self, info):\n","#         if not self.history:\n","#             self.history = {key: [] for key in info.keys()}\n","\n","#         for key, value in info.items():\n","#             self.history[key].append(value)\n","\n","#     def _render_frame(self):\n","#         self.render()\n","\n","#     def render(self, mode='human'):\n","#         start_time = time()\n","\n","#         # Update price plot\n","#         self.price_line.set_data(np.arange(len(self.prices)), self.prices)\n","#         self.ax.set_xlim(0, len(self.prices))  # Set x-axis limits\n","#         self.ax.set_ylim(min(self.prices), max(self.prices))  # Set y-axis limits\n","\n","#         # Update position markers\n","#         if self.position_scatter is not None:\n","#             self.position_scatter.remove()\n","\n","#         short_ticks = []\n","#         long_ticks = []\n","#         for i, tick in enumerate(np.arange(len(self._position_history))):\n","#             if self._position_history[i] == Positions.Short:\n","#                 short_ticks.append(tick)\n","#             elif self._position_history[i] == Positions.Long:\n","#                 long_ticks.append(tick)\n","\n","#         self.position_scatter = self.ax.scatter(short_ticks, self.prices[short_ticks], color='red', marker='o')\n","#         self.position_scatter = self.ax.scatter(long_ticks, self.prices[long_ticks], color='green', marker='o')\n","\n","#         # Update plot title\n","#         self.ax.set_title(\n","#             \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n","#             \"Total Profit: %.6f\" % self._total_profit\n","#         )\n","\n","#         # Update the plot\n","#         self.fig.canvas.draw()\n","#         self.fig.canvas.flush_events()\n","\n","#         end_time = time()\n","#         process_time = end_time - start_time\n","\n","#         pause_time = (1 / self.metadata['render_fps']) - process_time\n","#         assert pause_time > 0., \"High FPS! Try to reduce the 'render_fps' value.\"\n","\n","#         plt.pause(pause_time)\n","\n","#     def render_all(self, title=None):\n","#         window_ticks = np.arange(len(self._position_history))\n","#         plt.plot(self.prices)\n","\n","#         short_ticks = []\n","#         long_ticks = []\n","#         for i, tick in enumerate(window_ticks):\n","#             if self._position_history[i] == Positions.Short:\n","#                 short_ticks.append(tick)\n","#             elif self._position_history[i] == Positions.Long:\n","#                 long_ticks.append(tick)\n","\n","#         plt.plot(short_ticks, self.prices[short_ticks], 'ro')\n","#         plt.plot(long_ticks, self.prices[long_ticks], 'go')\n","\n","#         if title:\n","#             plt.title(title)\n","\n","#         plt.suptitle(\n","#             \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n","#             \"Total Profit: %.6f\" % self._total_profit\n","#         )\n","\n","#     def close(self):\n","#         plt.close()\n","\n","#     def save_rendering(self, filepath):\n","#         plt.savefig(filepath)\n","\n","#     def pause_rendering(self):\n","#         plt.show()\n","\n","#     def _process_data(self):\n","#         raise NotImplementedError\n","\n","#     def _calculate_reward(self, action):\n","#         raise NotImplementedError\n","\n","#     def _update_profit(self, action):\n","#         raise NotImplementedError\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# class ForexEnv(gym.Env):\n","#     metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 3}\n","\n","#     def __init__(\n","#         self,\n","#         df,\n","#         window_size,\n","#         frame_bound,\n","#         unit_side=\"left\",\n","#         render_mode=None,\n","#         trade_fee=0.0003,\n","#         spread=0.0001,\n","#         lot_size=0.01,\n","#         leverage=50,\n","#         stop_loss=0.001,\n","#         take_profit=0.002,\n","#         slippage=0.0001,\n","#         risk_per_trade=0.02,\n","#     ):\n","#         assert len(frame_bound) == 2\n","#         assert unit_side.lower() in [\"left\", \"right\"]\n","\n","#         self.df = df\n","#         self.window_size = window_size\n","#         self.frame_bound = frame_bound\n","#         self.unit_side = unit_side.lower()\n","#         self.render_mode = render_mode\n","\n","#         self.lot_size = lot_size\n","#         self.leverage = leverage\n","#         self.spread = spread\n","#         self.trade_fee = trade_fee\n","#         self.stop_loss = stop_loss\n","#         self.take_profit = take_profit\n","#         self.slippage = slippage\n","#         self.risk_per_trade = risk_per_trade\n","\n","#         self.prices, self.signal_features = self._process_data()\n","#         self.shape = (window_size, self.signal_features.shape[1])\n","\n","#         # spaces\n","#         self.action_space = spaces.Discrete(len(Actions))\n","#         self.observation_space = spaces.Box(\n","#             low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float32\n","#         )\n","\n","#         # episode\n","#         self._start_tick = self.window_size\n","#         self._end_tick = len(self.prices) - 1\n","#         self._truncated = False\n","#         self._current_tick = None\n","#         self._last_trade_tick = None\n","#         self._position = None\n","#         self._position_history = None\n","#         self._total_reward = None\n","#         self._total_profit = None\n","#         self._first_rendering = None\n","#         self.history = {}\n","\n","#         # Logging\n","#         logging.basicConfig(level=logging.INFO)\n","#         self.logger = logging.getLogger(__name__)\n","\n","#     def reset(self):\n","#         self._truncated = False\n","#         self._current_tick = self._start_tick\n","#         self._last_trade_tick = self._current_tick - 1\n","#         self._position = Positions.Short\n","#         self._position_history = (self.window_size * [None]) + [self._position]\n","#         self._total_reward = 0.0\n","#         self._total_profit = 1.0  # unit\n","#         self._first_rendering = True\n","#         self.history = {}\n","\n","#         observation = self._get_observation()\n","#         info = self._get_info()\n","\n","#         return observation, info\n","\n","#     def step(self, action):\n","#         self._truncated = False\n","#         self._current_tick += 1\n","\n","#         if self._current_tick == self._end_tick:\n","#             self._truncated = True\n","\n","#         step_reward = self._calculate_reward(action)\n","#         self._total_reward += step_reward\n","\n","#         self._update_profit(action)\n","\n","#         trade = False\n","#         if (action == Actions.Buy.value and self._position == Positions.Short) or (\n","#             action == Actions.Sell.value and self._position == Positions.Long\n","#         ):\n","#             trade = True\n","\n","#         if trade:\n","#             self._position = self._position.opposite()\n","#             self._last_trade_tick = self._current_tick\n","#             self.lot_size = self._calculate_position_size()\n","\n","#         self._position_history.append(self._position)\n","#         observation = self._get_observation()\n","#         info = self._get_info()\n","#         self._update_history(info)\n","\n","#         return observation, step_reward, False, self._truncated, info\n","\n","#     def _get_info(self):\n","#         return {\n","#             \"total_reward\": self._total_reward,\n","#             \"total_profit\": self._total_profit,\n","#             \"position\": self._position.value,\n","#         }\n","\n","#     def _get_observation(self):\n","#         return self.signal_features[\n","#             (self._current_tick - self.window_size + 1) : self._current_tick + 1\n","#         ]\n","\n","#     def _update_history(self, info):\n","#         if not self.history:\n","#             self.history = {key: [] for key in info.keys()}\n","\n","#         for key, value in info.items():\n","#             self.history[key].append(value)\n","\n","#     def _process_data(self):\n","#             prices = self.df.loc[:, \"Close\"].to_numpy()\n","#             prices = prices[self.frame_bound[0] - self.window_size : self.frame_bound[1]]\n","\n","#             def calculate_sma(data, window):\n","#                 return np.convolve(data, np.ones(window), 'valid') / window\n","\n","#             diff = np.insert(np.diff(prices), 0, 0)\n","#             sma_50 = calculate_sma(prices, 50)\n","#             sma_200 = calculate_sma(prices, 200)\n","\n","#             # Pad the SMAs to match the length of prices\n","#             sma_50 = np.pad(sma_50, (49, 0), mode='edge')\n","#             sma_200 = np.pad(sma_200, (199, 0), mode='edge')\n","\n","#             # Calculate other indicators using ta library\n","#             df = self.df.iloc[self.frame_bound[0] - self.window_size : self.frame_bound[1]]\n","#             rsi = ta.momentum.rsi(df[\"Close\"]).to_numpy()\n","#             bb_high = ta.volatility.bollinger_hband(df[\"Close\"]).to_numpy()\n","#             bb_low = ta.volatility.bollinger_lband(df[\"Close\"]).to_numpy()\n","#             macd = ta.trend.macd(df[\"Close\"]).to_numpy()\n","#             atr = ta.volatility.average_true_range(df[\"High\"], df[\"Low\"], df[\"Close\"]).to_numpy()\n","#             cci = ta.trend.cci(df[\"High\"], df[\"Low\"], df[\"Close\"]).to_numpy()\n","#             obv = ta.volume.on_balance_volume(df[\"Close\"], df[\"Volume\"]).to_numpy()\n","\n","#             signal_features = np.column_stack((\n","#                 prices,\n","#                 diff,\n","#                 sma_50,\n","#                 sma_200,\n","#                 rsi,\n","#                 bb_high,\n","#                 bb_low,\n","#                 macd,\n","#                 atr,\n","#                 cci,\n","#                 obv\n","#             ))\n","\n","#             # Normalize signal features\n","#             mean_features = np.nanmean(signal_features, axis=0)\n","#             std_features = np.nanstd(signal_features, axis=0)\n","#             signal_features = (signal_features - mean_features) / std_features\n","\n","#             # Replace NaNs with zeros\n","#             signal_features = np.nan_to_num(signal_features)\n","\n","#             return prices.astype(np.float32), signal_features.astype(np.float32)\n","\n","     \n","#     def _calculate_reward(self, action):\n","#         step_reward = 0\n","#         trade = False\n","\n","#         if ((action == Actions.Buy.value and self._position == Positions.Short) or\n","#             (action == Actions.Sell.value and self._position == Positions.Long)):\n","#             trade = True\n","\n","#         if trade:\n","#             current_price = self.prices[self._current_tick]\n","#             last_trade_price = self.prices[self._last_trade_tick]\n","#             price_diff = current_price - last_trade_price\n","\n","#             # Calculate pip profit (adjust for lot size, leverage, spread, and fee)\n","#             if self._position == Positions.Short:\n","#                 step_reward += -price_diff * self.lot_size * self.leverage * 10000\n","#                 step_reward -= self.spread * self.lot_size * self.leverage * 10000  # Spread\n","#             elif self._position == Positions.Long:\n","#                 step_reward += price_diff * self.lot_size * self.leverage * 10000\n","#                 step_reward -= self.spread * self.lot_size * self.leverage * 10000  # Spread\n","\n","#             step_reward -= self.trade_fee * self.lot_size * self.leverage * 10000  # Fee\n","\n","#             # Add slippage cost\n","#             slippage_cost = abs(current_price - last_trade_price) * self.slippage\n","#             step_reward -= slippage_cost * self.lot_size * self.leverage * 10000\n","\n","#             # Check for stop-loss and take-profit\n","#             if self._position == Positions.Long:\n","#                 if current_price <= last_trade_price * (1 - self.stop_loss):\n","#                     step_reward = -self.stop_loss * self.lot_size * self.leverage * 10000\n","#                     self._position = Positions.Short  # Force position close\n","#                 elif current_price >= last_trade_price * (1 + self.take_profit):\n","#                     step_reward = self.take_profit * self.lot_size * self.leverage * 10000\n","#                     self._position = Positions.Short  # Force position close\n","#             elif self._position == Positions.Short:\n","#                 if current_price >= last_trade_price * (1 + self.stop_loss):\n","#                     step_reward = -self.stop_loss * self.lot_size * self.leverage * 10000\n","#                     self._position = Positions.Long  # Force position close\n","#                 elif current_price <= last_trade_price * (1 - self.take_profit):\n","#                     step_reward = self.take_profit * self.lot_size * self.leverage * 10000\n","#                     self._position = Positions.Long  # Force position close\n","\n","#         # Calculate Sharpe ratio-like reward\n","#         if len(self.history.get('total_profit', [])) > 30:\n","#             profits = np.array(self.history['total_profit'][-30:])\n","#             returns = (profits[1:] - profits[:-1]) / profits[:-1]\n","#             if len(returns) > 1:  # Ensure we have at least 2 returns to calculate std\n","#                 sharpe = np.sqrt(252) * returns.mean() / returns.std()\n","                \n","#                 # Combine profit-based reward with risk-adjusted reward\n","#                 step_reward = 0.7 * step_reward + 0.3 * sharpe\n","#             else:\n","#                 self.logger.warning(\"Not enough data to calculate Sharpe ratio\")\n","\n","#         return step_reward\n","\n","#     def _update_profit(self, action):\n","#         trade = False\n","#         if (action == Actions.Buy.value and self._position == Positions.Short) or (\n","#             action == Actions.Sell.value and self._position == Positions.Long\n","#         ):\n","#             trade = True\n","\n","#         if trade or self._truncated:\n","#             current_price = self.prices[self._current_tick]\n","#             last_trade_price = self.prices[self._last_trade_tick]\n","\n","#             if self.unit_side == \"left\":\n","#                 if self._position == Positions.Short:\n","#                     quantity = self._total_profit * (last_trade_price - self.trade_fee)\n","#                     self._total_profit = quantity / current_price\n","#             elif self.unit_side == \"right\":\n","#                 if self._position == Positions.Long:\n","#                     quantity = self._total_profit / last_trade_price\n","#                     self._total_profit = quantity * (current_price - self.trade_fee)\n","\n","#             self.logger.info(\n","#                 f\"Tick: {self._current_tick}, Action: {action}, Position: {self._position}, Profit: {self._total_profit}\"\n","#             )\n","\n","#     def _calculate_position_size(self):\n","#         account_balance = self._total_profit\n","#         risk_amount = account_balance * self.risk_per_trade\n","#         pip_value = self.lot_size * 10  # Assuming 1 pip = 0.0001 for most forex pairs\n","#         stop_loss_pips = self.stop_loss * 10000\n","#         return risk_amount / (pip_value * stop_loss_pips)\n","\n","#     def calculate_sharpe_ratio(self):\n","#         if len(self.history.get(\"total_profit\", [])) > 1:\n","#             returns = (\n","#                 np.diff(self.history[\"total_profit\"])\n","#                 / self.history[\"total_profit\"][:-1]\n","#             )\n","#             return np.sqrt(252) * returns.mean() / returns.std()\n","#         return 0\n","\n","#     def calculate_max_drawdown(self):\n","#         if len(self.history.get(\"total_profit\", [])) > 0:\n","#             peak = self.history[\"total_profit\"][0]\n","#             max_dd = 0\n","#             for profit in self.history[\"total_profit\"]:\n","#                 if profit > peak:\n","#                     peak = profit\n","#                 dd = (peak - profit) / peak\n","#                 if dd > max_dd:\n","#                     max_dd = dd\n","#             return max_dd\n","#         return 0\n","\n","#     def render(self, mode='human'):\n","#             \"\"\"Render the environment.\"\"\"\n","#             if self._first_rendering:\n","#                 self._first_rendering = False\n","#                 plt.cla()\n","#                 plt.ion()\n","\n","#             plt.clf()\n","#             plt.subplot(3, 1, 1)\n","#             plt.plot(self.prices)\n","#             plt.title('Forex Price')\n","#             plt.xlabel('Time')\n","#             plt.ylabel('Price')\n","\n","#             plt.subplot(3, 1, 2)\n","#             plt.plot(self.history['total_profit'])\n","#             plt.title('Total Profit')\n","#             plt.xlabel('Time')\n","#             plt.ylabel('Profit')\n","\n","#             plt.subplot(3, 1, 3)\n","#             plt.plot(self.history['total_reward'])\n","#             plt.title('Total Reward')\n","#             plt.xlabel('Time')\n","#             plt.ylabel('Reward')\n","\n","#             plt.tight_layout()\n","\n","#             if mode == 'human':\n","#                 plt.pause(0.1)\n","#                 return None\n","#             elif mode == 'rgb_array':\n","#                 fig = plt.gcf()\n","#                 fig.canvas.draw()\n","#                 return np.array(fig.canvas.renderer._renderer)\n","\n","#     def close(self):\n","#         \"\"\"Clean up resources when closing the environment.\"\"\"\n","#         plt.close()\n","\n","#     def seed(self, seed=None):\n","#         \"\"\"Set the seed for this env's random number generator(s).\"\"\"\n","#         self.np_random, seed = seeding.np_random(seed)\n","#         return [seed]\n","\n","#     def max_possible_profit(self):\n","#         \"\"\"Calculate the maximum possible profit in the current episode.\"\"\"\n","#         current_tick = self._start_tick\n","#         last_trade_tick = current_tick - 1\n","#         profit = 1.0\n","\n","#         while current_tick <= self._end_tick:\n","#             if self.prices[current_tick] < self.prices[current_tick - 1]:\n","#                 while (current_tick <= self._end_tick and\n","#                        self.prices[current_tick] < self.prices[current_tick - 1]):\n","#                     current_tick += 1\n","#                 position = Positions.Short\n","#             else:\n","#                 while (current_tick <= self._end_tick and\n","#                        self.prices[current_tick] >= self.prices[current_tick - 1]):\n","#                     current_tick += 1\n","#                 position = Positions.Long\n","\n","#             current_price = self.prices[current_tick - 1]\n","#             last_trade_price = self.prices[last_trade_tick]\n","\n","#             if self.unit_side == 'left':\n","#                 if position == Positions.Short:\n","#                     quantity = profit * (last_trade_price - self.trade_fee)\n","#                     profit = quantity / current_price\n","#             elif self.unit_side == 'right':\n","#                 if position == Positions.Long:\n","#                     quantity = profit / last_trade_price\n","#                     profit = quantity * (current_price - self.trade_fee)\n","\n","#             last_trade_tick = current_tick - 1\n","\n","#         return profit"]},{"cell_type":"code","execution_count":19,"metadata":{"cell_id":"c19aaeb4cafb4d2bb4e2f0bed05d549f","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":0,"execution_start":1728985565883,"source_hash":"30070b96"},"outputs":[],"source":["class ForexEnv(TradingEnv):\n","\n","    def __init__(self, df, window_size, frame_bound, unit_side='left', \n","                 render_mode=None, trade_fee=0.0003, spread=0.0001, lot_size=0.01,leverage=50,\n","                 stop_loss=0.001, take_profit=0.002):\n","        assert len(frame_bound) == 2\n","        assert unit_side.lower() in ['left', 'right']\n","\n","        self.frame_bound = frame_bound\n","        self.unit_side = unit_side.lower()\n","        super().__init__(df, window_size, render_mode)\n","\n","        self.lot_size = lot_size\n","        self.leverage = leverage\n","        self.spread = spread  # Pip spread\n","        self.trade_fee = trade_fee  # Fee per lot\n","        self.unit_side = unit_side.lower()\n","        self.stop_loss = stop_loss\n","        self.take_profit = take_profit\n","        self._total_profit = 1.0\n","\n","    def _process_data(self):\n","        # Validate frame_bound and window_size\n","        if not (0 <= self.frame_bound[0] - self.window_size < len(self.df)):\n","            raise ValueError(\"frame_bound and window_size combination is out of range.\")\n","        if not (self.frame_bound[1] <= len(self.df)):\n","            raise ValueError(\"frame_bound end is out of range.\")\n","\n","        # Extract prices within the frame_bound\n","        prices = self.df.loc[:, \"Close\"].to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","\n","        # Normalize prices\n","        mean_price = np.mean(prices)\n","        std_price = np.std(prices)\n","        normalized_prices = (prices - mean_price) / std_price\n","\n","        # Calculate technical indicators using TA-Lib\n","        # Note: These indicators are calculated on the entire DataFrame\n","        # You might need to adjust the calculations to work with the window\n","        # if the indicators are designed for a specific period\n","        rsi = ta.momentum.RSIIndicator(close=self.df[\"Close\"], window=14).rsi()\n","        sma_short = ta.trend.SMAIndicator(\n","            close=self.df[\"Close\"], window=50\n","        ).sma_indicator()\n","        sma_long = ta.trend.SMAIndicator(\n","            close=self.df[\"Close\"], window=200\n","        ).sma_indicator()\n","        bollinger_high = ta.volatility.BollingerBands(\n","            close=self.df[\"Close\"], window=20\n","        ).bollinger_hband()\n","        bollinger_low = ta.volatility.BollingerBands(\n","            close=self.df[\"Close\"], window=20\n","        ).bollinger_lband()\n","        macd = ta.trend.MACD(\n","            close=self.df[\"Close\"], window_fast=12, window_slow=26, window_sign=9\n","        ).macd()\n","\n","        # Extract indicator values within the frame_bound\n","        rsi = rsi.to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","        sma_short = sma_short.to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","        sma_long = sma_long.to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","        bollinger_high = bollinger_high.to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","        bollinger_low = bollinger_low.to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","        macd = macd.to_numpy()[\n","            self.frame_bound[0] - self.window_size : self.frame_bound[1]\n","        ]\n","\n","        # Combine indicators and prices into signal features\n","        signal_features = np.column_stack(\n","            (\n","                normalized_prices,\n","                sma_short,\n","                sma_long,\n","                rsi,\n","                bollinger_high,\n","                bollinger_low,\n","                macd,\n","            )\n","        )\n","\n","        # Normalize signal features\n","        mean_features = np.nanmean(signal_features, axis=0)\n","        std_features = np.nanstd(signal_features, axis=0)\n","        signal_features = (signal_features - mean_features) / std_features\n","\n","        # Replace NaNs with zeros\n","        signal_features = np.nan_to_num(signal_features)\n","\n","        return normalized_prices.astype(np.float32), signal_features.astype(np.float32)\n","\n","    def _calculate_reward(self, action):\n","        step_reward = 0\n","        trade = False\n","\n","        if (\n","            (action == Actions.Buy.value and self._position == Positions.Short) or\n","            (action == Actions.Sell.value and self._position == Positions.Long)\n","        ):\n","            trade = True\n","\n","        if trade:\n","            current_price = self.prices[self._current_tick]\n","            last_trade_price = self.prices[self._last_trade_tick]\n","            price_diff = current_price - last_trade_price\n","\n","            # Calculate pip profit (adjust for lot size, leverage, spread, and fee)\n","            if self._position == Positions.Short:\n","                step_reward += -price_diff * self.lot_size * self.leverage * 10000\n","                step_reward -= self.spread * self.lot_size * self.leverage * 10000  # Spread\n","            elif self._position == Positions.Long:\n","                step_reward += price_diff * self.lot_size * self.leverage * 10000\n","                step_reward -= self.spread * self.lot_size * self.leverage * 10000  # Spread\n","\n","            step_reward -= self.trade_fee * self.lot_size * self.leverage * 10000  # Fee\n","\n","        return step_reward\n","\n","    def _update_profit(self, action):\n","        trade = False\n","        if (\n","            (action == Actions.Buy.value and self._position == Positions.Short) or\n","            (action == Actions.Sell.value and self._position == Positions.Long)\n","        ):\n","            trade = True\n","\n","        if trade or self._truncated:\n","            current_price = self.prices[self._current_tick]\n","            last_trade_price = self.prices[self._last_trade_tick]\n","\n","            if self.unit_side == 'left':\n","                if self._position == Positions.Short:\n","                    quantity = self._total_profit * (last_trade_price - self.trade_fee)\n","                    self._total_profit = quantity / current_price\n","\n","            elif self.unit_side == 'right':\n","                if self._position == Positions.Long:\n","                    quantity = self._total_profit / last_trade_price\n","                    self._total_profit = quantity * (current_price - self.trade_fee)\n","\n","            logging.info(f\"Updated profit: {self._total_profit}\")\n","\n","    def max_possible_profit(self):\n","        current_tick = self._start_tick\n","        last_trade_tick = current_tick - 1\n","        profit = 1.0\n","\n","        while current_tick <= self._end_tick:\n","            position = None\n","            if self.prices[current_tick] < self.prices[current_tick - 1]:\n","                while (current_tick <= self._end_tick and\n","                       self.prices[current_tick] < self.prices[current_tick - 1]):\n","                    current_tick += 1\n","                position = Positions.Short\n","            else:\n","                while (current_tick <= self._end_tick and\n","                       self.prices[current_tick] >= self.prices[current_tick - 1]):\n","                    current_tick += 1\n","                position = Positions.Long\n","\n","            current_price = self.prices[current_tick - 1]\n","            last_trade_price = self.prices[last_trade_tick]\n","\n","            if self.unit_side == 'left':\n","                if position == Positions.Short:\n","                    quantity = profit * (last_trade_price - self.trade_fee)\n","                    profit = quantity / current_price\n","\n","            elif self.unit_side == 'right':\n","                if position == Positions.Long:\n","                    quantity = profit / last_trade_price\n","                    profit = quantity * (current_price - self.trade_fee)\n","\n","            last_trade_tick = current_tick - 1\n","\n","        return profit"]},{"cell_type":"code","execution_count":20,"metadata":{"cell_id":"380f8f82d4f446b68df89510403a40f7","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":551,"execution_start":1728985565930,"source_hash":"c509e1fe"},"outputs":[],"source":["forex_df = pd.read_csv(\"./data/currency_hourly_data.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n","forex_df = forex_df.sort_values('Date')"]},{"cell_type":"code","execution_count":21,"metadata":{"cell_id":"229002d73f7c45ebb1be945fd30292a2","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":26,"execution_start":1728985566534,"source_hash":"c91a30af"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2022-07-14 00:00:00+01:00</th>\n","      <td>1.005733</td>\n","      <td>1.005834</td>\n","      <td>1.003412</td>\n","      <td>1.003613</td>\n","      <td>1.003613</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-07-14 01:00:00+01:00</th>\n","      <td>1.003613</td>\n","      <td>1.004621</td>\n","      <td>1.002406</td>\n","      <td>1.002406</td>\n","      <td>1.002406</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-07-14 02:00:00+01:00</th>\n","      <td>1.002707</td>\n","      <td>1.002908</td>\n","      <td>1.001703</td>\n","      <td>1.002104</td>\n","      <td>1.002104</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-07-14 03:00:00+01:00</th>\n","      <td>1.002305</td>\n","      <td>1.003110</td>\n","      <td>1.001703</td>\n","      <td>1.002406</td>\n","      <td>1.002406</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-07-14 04:00:00+01:00</th>\n","      <td>1.002707</td>\n","      <td>1.004319</td>\n","      <td>1.002707</td>\n","      <td>1.003613</td>\n","      <td>1.003613</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Open      High       Low     Close  Adj Close  \\\n","Date                                                                           \n","2022-07-14 00:00:00+01:00  1.005733  1.005834  1.003412  1.003613   1.003613   \n","2022-07-14 01:00:00+01:00  1.003613  1.004621  1.002406  1.002406   1.002406   \n","2022-07-14 02:00:00+01:00  1.002707  1.002908  1.001703  1.002104   1.002104   \n","2022-07-14 03:00:00+01:00  1.002305  1.003110  1.001703  1.002406   1.002406   \n","2022-07-14 04:00:00+01:00  1.002707  1.004319  1.002707  1.003613   1.003613   \n","\n","                           Volume  \n","Date                               \n","2022-07-14 00:00:00+01:00     0.0  \n","2022-07-14 01:00:00+01:00     0.0  \n","2022-07-14 02:00:00+01:00     0.0  \n","2022-07-14 03:00:00+01:00     0.0  \n","2022-07-14 04:00:00+01:00     0.0  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["forex_df.head()"]},{"cell_type":"code","execution_count":22,"metadata":{"cell_id":"81fca687d1c94171af3a7fa2dbc1d6ed","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":1,"execution_start":1728985571222,"source_hash":"eacbeaef"},"outputs":[],"source":["register(\n","    id='forex-v0',\n","    entry_point=ForexEnv,\n","    kwargs={\n","        'df': forex_df,\n","        'window_size': 20,\n","        'frame_bound': (20, len(forex_df))\n","    }\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"cell_id":"4845e2cf05dd4ba6b6beb93b8d0b9e11","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":294,"execution_start":1728985571322,"source_hash":"fdbe9abf"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"ename":"AssertionError","evalue":"High FPS! Try to reduce the 'render_fps' value.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo:\u001b[39m\u001b[38;5;124m\"\u001b[39m, info,observation )\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/gymnasium/wrappers/order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/gymnasium/wrappers/env_checker.py:67\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 169\u001b[0m, in \u001b[0;36mTradingEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    166\u001b[0m process_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    168\u001b[0m pause_time \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender_fps\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m process_time\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pause_time \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh FPS! Try to reduce the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender_fps\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m plt\u001b[38;5;241m.\u001b[39mpause(pause_time)\n","\u001b[0;31mAssertionError\u001b[0m: High FPS! Try to reduce the 'render_fps' value."]}],"source":["env = gym.make('forex-v0', df=forex_df, window_size=5, frame_bound=[100, 500])\n","\n","observation = env.reset()\n","while True:\n","    action = env.action_space.sample()\n","    observation, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","# \n","    env.render()\n","    if done:\n","        print(\"info:\", info,observation )\n","        break\n","\n","plt.cla()\n","env.unwrapped.render_all()\n","plt.show()"]},{"cell_type":"code","execution_count":24,"metadata":{"cell_id":"e7893ca8599e40d69f144904ac238c5b","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":1,"execution_start":1728985571666,"source_hash":"180dda0"},"outputs":[{"name":"stdout","output_type":"stream","text":["env information:\n","> shape: (5, 7)\n","> df.shape: (11961, 6)\n","> prices.shape: (405,)\n","> signal_features.shape: (405, 7)\n","> max_possible_profit: 0.00250234906987181\n"]}],"source":["print(\"env information:\")\n","print(\"> shape:\", env.unwrapped.shape)\n","print(\"> df.shape:\", env.unwrapped.df.shape)\n","print(\"> prices.shape:\", env.unwrapped.prices.shape)\n","print(\"> signal_features.shape:\", env.unwrapped.signal_features.shape)\n","print(\"> max_possible_profit:\", env.unwrapped.max_possible_profit())\n"]},{"cell_type":"code","execution_count":25,"metadata":{"cell_id":"3d425cc9fa8c470c953c3255a7f0544b","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":0,"execution_start":1728985571718,"source_hash":"d7a153d4"},"outputs":[{"data":{"text/plain":["Discrete(3)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["env.action_space"]},{"cell_type":"markdown","metadata":{"cell_id":"ec900c03555d4693a95a60452fb301c3","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Build Environment and Train"]},{"cell_type":"code","execution_count":26,"metadata":{"cell_id":"6a10f90964eb4a7cb472971fbff3f5f1","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":240,"execution_start":1728985571767,"source_hash":"acd05cc1"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["env_maker = lambda: gym.make('forex-v0', df=forex_df, frame_bound=(5,len(forex_df)), window_size=5)\n","env = DummyVecEnv([env_maker])\n"]},{"cell_type":"code","execution_count":27,"metadata":{"cell_id":"6b5d5a81c5ac4f8fb9cba58d0a840179","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":8633220,"execution_start":1728985572058,"source_hash":"c29e495b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n","-----------------------------\n","| time/              |      |\n","|    fps             | 1209 |\n","|    iterations      | 1    |\n","|    time_elapsed    | 1    |\n","|    total_timesteps | 2048 |\n","-----------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 816         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 5           |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.010286028 |\n","|    clip_fraction        | 0.0998      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.09       |\n","|    explained_variance   | 0.000146    |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.61e+05    |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.00653    |\n","|    value_loss           | 4.97e+05    |\n","-----------------------------------------\n","Eval num_timesteps=5000, episode_reward=5707.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 5.71e+03     |\n","| time/                   |              |\n","|    total_timesteps      | 5000         |\n","| train/                  |              |\n","|    approx_kl            | 0.0057371305 |\n","|    clip_fraction        | 0.0417       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.09        |\n","|    explained_variance   | -0.00947     |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.4e+05      |\n","|    n_updates            | 20           |\n","|    policy_gradient_loss | -0.00553     |\n","|    value_loss           | 2.69e+05     |\n","------------------------------------------\n","New best mean reward!\n","-----------------------------\n","| time/              |      |\n","|    fps             | 242  |\n","|    iterations      | 3    |\n","|    time_elapsed    | 25   |\n","|    total_timesteps | 6144 |\n","-----------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 199          |\n","|    iterations           | 4            |\n","|    time_elapsed         | 41           |\n","|    total_timesteps      | 8192         |\n","| train/                  |              |\n","|    approx_kl            | 0.0055711824 |\n","|    clip_fraction        | 0.0336       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.08        |\n","|    explained_variance   | 0.0122       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.16e+04     |\n","|    n_updates            | 30           |\n","|    policy_gradient_loss | -0.00281     |\n","|    value_loss           | 1.88e+05     |\n","------------------------------------------\n","Eval num_timesteps=10000, episode_reward=34780.57 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 3.48e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 10000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0077354736 |\n","|    clip_fraction        | 0.0517       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.07        |\n","|    explained_variance   | 0.00333      |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.89e+04     |\n","|    n_updates            | 40           |\n","|    policy_gradient_loss | -0.00594     |\n","|    value_loss           | 1.64e+05     |\n","------------------------------------------\n","New best mean reward!\n","------------------------------\n","| time/              |       |\n","|    fps             | 193   |\n","|    iterations      | 5     |\n","|    time_elapsed    | 52    |\n","|    total_timesteps | 10240 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 209          |\n","|    iterations           | 6            |\n","|    time_elapsed         | 58           |\n","|    total_timesteps      | 12288        |\n","| train/                  |              |\n","|    approx_kl            | 0.0064138225 |\n","|    clip_fraction        | 0.017        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.05        |\n","|    explained_variance   | -0.00559     |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.57e+04     |\n","|    n_updates            | 50           |\n","|    policy_gradient_loss | -0.00155     |\n","|    value_loss           | 1.18e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 227          |\n","|    iterations           | 7            |\n","|    time_elapsed         | 62           |\n","|    total_timesteps      | 14336        |\n","| train/                  |              |\n","|    approx_kl            | 0.0051521594 |\n","|    clip_fraction        | 0.0138       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.07        |\n","|    explained_variance   | -0.0237      |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.18e+04     |\n","|    n_updates            | 60           |\n","|    policy_gradient_loss | -0.0024      |\n","|    value_loss           | 1.34e+05     |\n","------------------------------------------\n","Eval num_timesteps=15000, episode_reward=25534.92 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.55e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 15000       |\n","| train/                  |             |\n","|    approx_kl            | 0.008973933 |\n","|    clip_fraction        | 0.0167      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.02       |\n","|    explained_variance   | -0.000656   |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.98e+05    |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.00286    |\n","|    value_loss           | 4.55e+05    |\n","-----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 212   |\n","|    iterations      | 8     |\n","|    time_elapsed    | 77    |\n","|    total_timesteps | 16384 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 222          |\n","|    iterations           | 9            |\n","|    time_elapsed         | 82           |\n","|    total_timesteps      | 18432        |\n","| train/                  |              |\n","|    approx_kl            | 0.0059135063 |\n","|    clip_fraction        | 0.0169       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.07        |\n","|    explained_variance   | -0.0119      |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.55e+04     |\n","|    n_updates            | 80           |\n","|    policy_gradient_loss | -0.00277     |\n","|    value_loss           | 2.63e+05     |\n","------------------------------------------\n","Eval num_timesteps=20000, episode_reward=29383.22 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.94e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 20000       |\n","| train/                  |             |\n","|    approx_kl            | 0.005008155 |\n","|    clip_fraction        | 0.0247      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.03       |\n","|    explained_variance   | -0.000427   |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 8.96e+04    |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.00261    |\n","|    value_loss           | 1.81e+05    |\n","-----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 215   |\n","|    iterations      | 10    |\n","|    time_elapsed    | 95    |\n","|    total_timesteps | 20480 |\n","------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 229         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 98          |\n","|    total_timesteps      | 22528       |\n","| train/                  |             |\n","|    approx_kl            | 0.005921588 |\n","|    clip_fraction        | 0.0115      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.04       |\n","|    explained_variance   | -0.00917    |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 7.23e+04    |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.00313    |\n","|    value_loss           | 1.97e+05    |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 244         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 100         |\n","|    total_timesteps      | 24576       |\n","| train/                  |             |\n","|    approx_kl            | 0.007949011 |\n","|    clip_fraction        | 0.0287      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.983      |\n","|    explained_variance   | 0.0264      |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 4.87e+04    |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.00327    |\n","|    value_loss           | 1.03e+05    |\n","-----------------------------------------\n","Eval num_timesteps=25000, episode_reward=24502.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.45e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 25000       |\n","| train/                  |             |\n","|    approx_kl            | 0.003680834 |\n","|    clip_fraction        | 0.00708     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.982      |\n","|    explained_variance   | -0.0198     |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.15e+05    |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00139    |\n","|    value_loss           | 2.18e+05    |\n","-----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 248   |\n","|    iterations      | 13    |\n","|    time_elapsed    | 107   |\n","|    total_timesteps | 26624 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 261          |\n","|    iterations           | 14           |\n","|    time_elapsed         | 109          |\n","|    total_timesteps      | 28672        |\n","| train/                  |              |\n","|    approx_kl            | 0.0065502543 |\n","|    clip_fraction        | 0.00586      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.978       |\n","|    explained_variance   | 0.0334       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.49e+05     |\n","|    n_updates            | 130          |\n","|    policy_gradient_loss | -0.00205     |\n","|    value_loss           | 4.58e+05     |\n","------------------------------------------\n","Eval num_timesteps=30000, episode_reward=19603.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 1.97e+03   |\n","|    mean_reward          | 1.96e+04   |\n","| time/                   |            |\n","|    total_timesteps      | 30000      |\n","| train/                  |            |\n","|    approx_kl            | 0.00269354 |\n","|    clip_fraction        | 0.00317    |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.941     |\n","|    explained_variance   | -0.0534    |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 8.39e+04   |\n","|    n_updates            | 140        |\n","|    policy_gradient_loss | -0.00158   |\n","|    value_loss           | 2.02e+05   |\n","----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 263   |\n","|    iterations      | 15    |\n","|    time_elapsed    | 116   |\n","|    total_timesteps | 30720 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 274          |\n","|    iterations           | 16           |\n","|    time_elapsed         | 119          |\n","|    total_timesteps      | 32768        |\n","| train/                  |              |\n","|    approx_kl            | 0.0037277555 |\n","|    clip_fraction        | 0.0186       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.891       |\n","|    explained_variance   | 0.0205       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.46e+04     |\n","|    n_updates            | 150          |\n","|    policy_gradient_loss | -0.00353     |\n","|    value_loss           | 1.44e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 282          |\n","|    iterations           | 17           |\n","|    time_elapsed         | 123          |\n","|    total_timesteps      | 34816        |\n","| train/                  |              |\n","|    approx_kl            | 0.0043312404 |\n","|    clip_fraction        | 0.0204       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.92        |\n","|    explained_variance   | 0.0507       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+05     |\n","|    n_updates            | 160          |\n","|    policy_gradient_loss | -0.00381     |\n","|    value_loss           | 1.12e+05     |\n","------------------------------------------\n","Eval num_timesteps=35000, episode_reward=24003.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.4e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 35000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0077973963 |\n","|    clip_fraction        | 0.0293       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.848       |\n","|    explained_variance   | 0.00827      |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.01e+04     |\n","|    n_updates            | 170          |\n","|    policy_gradient_loss | -0.00499     |\n","|    value_loss           | 1.08e+05     |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 283   |\n","|    iterations      | 18    |\n","|    time_elapsed    | 129   |\n","|    total_timesteps | 36864 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 293          |\n","|    iterations           | 19           |\n","|    time_elapsed         | 132          |\n","|    total_timesteps      | 38912        |\n","| train/                  |              |\n","|    approx_kl            | 0.0010931727 |\n","|    clip_fraction        | 0.00234      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.862       |\n","|    explained_variance   | 0.1          |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.25e+05     |\n","|    n_updates            | 180          |\n","|    policy_gradient_loss | -0.000997    |\n","|    value_loss           | 2.15e+05     |\n","------------------------------------------\n","Eval num_timesteps=40000, episode_reward=24759.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.48e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 40000       |\n","| train/                  |             |\n","|    approx_kl            | 0.005775811 |\n","|    clip_fraction        | 0.0111      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.857      |\n","|    explained_variance   | 0.0668      |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.48e+05    |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.00314    |\n","|    value_loss           | 5.37e+05    |\n","-----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 289   |\n","|    iterations      | 20    |\n","|    time_elapsed    | 141   |\n","|    total_timesteps | 40960 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 295          |\n","|    iterations           | 21           |\n","|    time_elapsed         | 145          |\n","|    total_timesteps      | 43008        |\n","| train/                  |              |\n","|    approx_kl            | 0.0010908851 |\n","|    clip_fraction        | 0.000977     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.789       |\n","|    explained_variance   | 0.0393       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.56e+04     |\n","|    n_updates            | 200          |\n","|    policy_gradient_loss | -0.00116     |\n","|    value_loss           | 2.06e+05     |\n","------------------------------------------\n","Eval num_timesteps=45000, episode_reward=24197.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.42e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 45000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0042320527 |\n","|    clip_fraction        | 0.00791      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.82        |\n","|    explained_variance   | 0.12         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.03e+04     |\n","|    n_updates            | 210          |\n","|    policy_gradient_loss | -0.00322     |\n","|    value_loss           | 1.7e+05      |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 289   |\n","|    iterations      | 22    |\n","|    time_elapsed    | 155   |\n","|    total_timesteps | 45056 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 296          |\n","|    iterations           | 23           |\n","|    time_elapsed         | 158          |\n","|    total_timesteps      | 47104        |\n","| train/                  |              |\n","|    approx_kl            | 0.0042227693 |\n","|    clip_fraction        | 0.011        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.763       |\n","|    explained_variance   | 0.126        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.88e+04     |\n","|    n_updates            | 220          |\n","|    policy_gradient_loss | -0.00351     |\n","|    value_loss           | 1.12e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 303          |\n","|    iterations           | 24           |\n","|    time_elapsed         | 161          |\n","|    total_timesteps      | 49152        |\n","| train/                  |              |\n","|    approx_kl            | 0.0014220824 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.751       |\n","|    explained_variance   | 0.0945       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.46e+04     |\n","|    n_updates            | 230          |\n","|    policy_gradient_loss | -0.00112     |\n","|    value_loss           | 8.17e+04     |\n","------------------------------------------\n","Eval num_timesteps=50000, episode_reward=25726.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.57e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 50000       |\n","| train/                  |             |\n","|    approx_kl            | 0.004055946 |\n","|    clip_fraction        | 0.029       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.695      |\n","|    explained_variance   | 0.0862      |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.71e+05    |\n","|    n_updates            | 240         |\n","|    policy_gradient_loss | -0.00437    |\n","|    value_loss           | 2.66e+05    |\n","-----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 302   |\n","|    iterations      | 25    |\n","|    time_elapsed    | 169   |\n","|    total_timesteps | 51200 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 309          |\n","|    iterations           | 26           |\n","|    time_elapsed         | 171          |\n","|    total_timesteps      | 53248        |\n","| train/                  |              |\n","|    approx_kl            | 0.0030055856 |\n","|    clip_fraction        | 0.0125       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.713       |\n","|    explained_variance   | 0.205        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.23e+05     |\n","|    n_updates            | 250          |\n","|    policy_gradient_loss | -0.00301     |\n","|    value_loss           | 2.68e+05     |\n","------------------------------------------\n","Eval num_timesteps=55000, episode_reward=23779.56 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.38e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 55000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0012392492 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.676       |\n","|    explained_variance   | 0.111        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.58e+04     |\n","|    n_updates            | 260          |\n","|    policy_gradient_loss | -0.00173     |\n","|    value_loss           | 1.7e+05      |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 309   |\n","|    iterations      | 27    |\n","|    time_elapsed    | 178   |\n","|    total_timesteps | 55296 |\n","------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 28            |\n","|    time_elapsed         | 181           |\n","|    total_timesteps      | 57344         |\n","| train/                  |               |\n","|    approx_kl            | 0.00074327725 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.688        |\n","|    explained_variance   | 0.0757        |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.18e+04      |\n","|    n_updates            | 270           |\n","|    policy_gradient_loss | -0.0011       |\n","|    value_loss           | 1.4e+05       |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 322          |\n","|    iterations           | 29           |\n","|    time_elapsed         | 184          |\n","|    total_timesteps      | 59392        |\n","| train/                  |              |\n","|    approx_kl            | 0.0020419792 |\n","|    clip_fraction        | 0.00688      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.637       |\n","|    explained_variance   | 0.256        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.05e+04     |\n","|    n_updates            | 280          |\n","|    policy_gradient_loss | -0.00277     |\n","|    value_loss           | 1.12e+05     |\n","------------------------------------------\n","Eval num_timesteps=60000, episode_reward=26332.26 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.63e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 60000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0025140455 |\n","|    clip_fraction        | 0.00303      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.638       |\n","|    explained_variance   | 0.263        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.25e+04     |\n","|    n_updates            | 290          |\n","|    policy_gradient_loss | -0.00189     |\n","|    value_loss           | 9.56e+04     |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 320   |\n","|    iterations      | 30    |\n","|    time_elapsed    | 191   |\n","|    total_timesteps | 61440 |\n","------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 327           |\n","|    iterations           | 31            |\n","|    time_elapsed         | 194           |\n","|    total_timesteps      | 63488         |\n","| train/                  |               |\n","|    approx_kl            | 0.00020443747 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.557        |\n","|    explained_variance   | -0.0793       |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.2e+05       |\n","|    n_updates            | 300           |\n","|    policy_gradient_loss | -0.000507     |\n","|    value_loss           | 3.01e+05      |\n","-------------------------------------------\n","Eval num_timesteps=65000, episode_reward=26575.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.66e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 65000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0004272195 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.64        |\n","|    explained_variance   | 0.149        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+05     |\n","|    n_updates            | 310          |\n","|    policy_gradient_loss | -0.000641    |\n","|    value_loss           | 2.9e+05      |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 325   |\n","|    iterations      | 32    |\n","|    time_elapsed    | 201   |\n","|    total_timesteps | 65536 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 330          |\n","|    iterations           | 33           |\n","|    time_elapsed         | 204          |\n","|    total_timesteps      | 67584        |\n","| train/                  |              |\n","|    approx_kl            | 0.0028443567 |\n","|    clip_fraction        | 0.00762      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.603       |\n","|    explained_variance   | 0.208        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.47e+04     |\n","|    n_updates            | 320          |\n","|    policy_gradient_loss | -0.00257     |\n","|    value_loss           | 1.87e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 333          |\n","|    iterations           | 34           |\n","|    time_elapsed         | 208          |\n","|    total_timesteps      | 69632        |\n","| train/                  |              |\n","|    approx_kl            | 0.0013801747 |\n","|    clip_fraction        | 0.00107      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.66        |\n","|    explained_variance   | -0.0231      |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.09e+05     |\n","|    n_updates            | 330          |\n","|    policy_gradient_loss | -0.0012      |\n","|    value_loss           | 2.05e+05     |\n","------------------------------------------\n","Eval num_timesteps=70000, episode_reward=25828.35 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.58e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 70000       |\n","| train/                  |             |\n","|    approx_kl            | 0.001983368 |\n","|    clip_fraction        | 0.000391    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.615      |\n","|    explained_variance   | 0.31        |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.05e+05    |\n","|    n_updates            | 340         |\n","|    policy_gradient_loss | -0.00108    |\n","|    value_loss           | 1.21e+05    |\n","-----------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 314   |\n","|    iterations      | 35    |\n","|    time_elapsed    | 227   |\n","|    total_timesteps | 71680 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 308          |\n","|    iterations           | 36           |\n","|    time_elapsed         | 238          |\n","|    total_timesteps      | 73728        |\n","| train/                  |              |\n","|    approx_kl            | 0.0015682555 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.589       |\n","|    explained_variance   | 0.329        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.19e+04     |\n","|    n_updates            | 350          |\n","|    policy_gradient_loss | -0.00147     |\n","|    value_loss           | 6.32e+04     |\n","------------------------------------------\n","Eval num_timesteps=75000, episode_reward=24956.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 75000         |\n","| train/                  |               |\n","|    approx_kl            | 0.00010394424 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.469        |\n","|    explained_variance   | -0.0881       |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+05      |\n","|    n_updates            | 360           |\n","|    policy_gradient_loss | -0.00039      |\n","|    value_loss           | 2.81e+05      |\n","-------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 298   |\n","|    iterations      | 37    |\n","|    time_elapsed    | 253   |\n","|    total_timesteps | 75776 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 303          |\n","|    iterations           | 38           |\n","|    time_elapsed         | 256          |\n","|    total_timesteps      | 77824        |\n","| train/                  |              |\n","|    approx_kl            | 0.0005780787 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.589       |\n","|    explained_variance   | 0.0736       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.98e+04     |\n","|    n_updates            | 370          |\n","|    policy_gradient_loss | -0.000749    |\n","|    value_loss           | 2.13e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 307          |\n","|    iterations           | 39           |\n","|    time_elapsed         | 259          |\n","|    total_timesteps      | 79872        |\n","| train/                  |              |\n","|    approx_kl            | 0.0021853002 |\n","|    clip_fraction        | 0.00996      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.522       |\n","|    explained_variance   | 0.305        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.29e+04     |\n","|    n_updates            | 380          |\n","|    policy_gradient_loss | -0.00152     |\n","|    value_loss           | 1.29e+05     |\n","------------------------------------------\n","Eval num_timesteps=80000, episode_reward=24074.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 80000         |\n","| train/                  |               |\n","|    approx_kl            | 0.00023342957 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.551        |\n","|    explained_variance   | 0.204         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.45e+04      |\n","|    n_updates            | 390           |\n","|    policy_gradient_loss | -0.000456     |\n","|    value_loss           | 1.19e+05      |\n","-------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 307   |\n","|    iterations      | 40    |\n","|    time_elapsed    | 266   |\n","|    total_timesteps | 81920 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 41           |\n","|    time_elapsed         | 268          |\n","|    total_timesteps      | 83968        |\n","| train/                  |              |\n","|    approx_kl            | 0.0009965447 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.5         |\n","|    explained_variance   | 0.472        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.48e+04     |\n","|    n_updates            | 400          |\n","|    policy_gradient_loss | -0.00095     |\n","|    value_loss           | 9.87e+04     |\n","------------------------------------------\n","Eval num_timesteps=85000, episode_reward=21318.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.13e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 85000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0014248637 |\n","|    clip_fraction        | 0.00137      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.505       |\n","|    explained_variance   | 0.338        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.07e+04     |\n","|    n_updates            | 410          |\n","|    policy_gradient_loss | -0.00194     |\n","|    value_loss           | 6.82e+04     |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 312   |\n","|    iterations      | 42    |\n","|    time_elapsed    | 275   |\n","|    total_timesteps | 86016 |\n","------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 317          |\n","|    iterations           | 43           |\n","|    time_elapsed         | 277          |\n","|    total_timesteps      | 88064        |\n","| train/                  |              |\n","|    approx_kl            | 0.0002558451 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.448       |\n","|    explained_variance   | 0.0452       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.1e+04      |\n","|    n_updates            | 420          |\n","|    policy_gradient_loss | -0.00017     |\n","|    value_loss           | 2.91e+05     |\n","------------------------------------------\n","Eval num_timesteps=90000, episode_reward=21093.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.11e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 90000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0010094505 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.471       |\n","|    explained_variance   | 0.4          |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.47e+04     |\n","|    n_updates            | 430          |\n","|    policy_gradient_loss | -0.00132     |\n","|    value_loss           | 1.27e+05     |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 317   |\n","|    iterations      | 44    |\n","|    time_elapsed    | 283   |\n","|    total_timesteps | 90112 |\n","------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 45            |\n","|    time_elapsed         | 286           |\n","|    total_timesteps      | 92160         |\n","| train/                  |               |\n","|    approx_kl            | 0.00068179314 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.441        |\n","|    explained_variance   | 0.256         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.78e+04      |\n","|    n_updates            | 440           |\n","|    policy_gradient_loss | -0.000234     |\n","|    value_loss           | 1.46e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 326          |\n","|    iterations           | 46           |\n","|    time_elapsed         | 288          |\n","|    total_timesteps      | 94208        |\n","| train/                  |              |\n","|    approx_kl            | 0.0006074418 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.495       |\n","|    explained_variance   | 0.35         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.02e+05     |\n","|    n_updates            | 450          |\n","|    policy_gradient_loss | -0.00128     |\n","|    value_loss           | 1.01e+05     |\n","------------------------------------------\n","Eval num_timesteps=95000, episode_reward=28626.26 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.86e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 95000        |\n","| train/                  |              |\n","|    approx_kl            | 0.0015133708 |\n","|    clip_fraction        | 0.00503      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.432       |\n","|    explained_variance   | 0.382        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.53e+04     |\n","|    n_updates            | 460          |\n","|    policy_gradient_loss | -0.00182     |\n","|    value_loss           | 8.2e+04      |\n","------------------------------------------\n","------------------------------\n","| time/              |       |\n","|    fps             | 326   |\n","|    iterations      | 47    |\n","|    time_elapsed    | 294   |\n","|    total_timesteps | 96256 |\n","------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 331           |\n","|    iterations           | 48            |\n","|    time_elapsed         | 296           |\n","|    total_timesteps      | 98304         |\n","| train/                  |               |\n","|    approx_kl            | 0.00079385226 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.475        |\n","|    explained_variance   | 0.163         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.04e+04      |\n","|    n_updates            | 470           |\n","|    policy_gradient_loss | -0.00102      |\n","|    value_loss           | 1.01e+05      |\n","-------------------------------------------\n","Eval num_timesteps=100000, episode_reward=26297.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.63e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 100000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00065692223 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.446        |\n","|    explained_variance   | 0.125         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.89e+05      |\n","|    n_updates            | 480           |\n","|    policy_gradient_loss | -0.00102      |\n","|    value_loss           | 3.61e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 331    |\n","|    iterations      | 49     |\n","|    time_elapsed    | 302    |\n","|    total_timesteps | 100352 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 50            |\n","|    time_elapsed         | 305           |\n","|    total_timesteps      | 102400        |\n","| train/                  |               |\n","|    approx_kl            | 0.00068826333 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.426        |\n","|    explained_variance   | 0.359         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.82e+04      |\n","|    n_updates            | 490           |\n","|    policy_gradient_loss | -0.00117      |\n","|    value_loss           | 1.91e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 339           |\n","|    iterations           | 51            |\n","|    time_elapsed         | 307           |\n","|    total_timesteps      | 104448        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012703805 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.455        |\n","|    explained_variance   | 0.232         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.64e+04      |\n","|    n_updates            | 500           |\n","|    policy_gradient_loss | -0.000189     |\n","|    value_loss           | 1.58e+05      |\n","-------------------------------------------\n","Eval num_timesteps=105000, episode_reward=25031.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 105000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00065014104 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.475        |\n","|    explained_variance   | 0.458         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.05e+04      |\n","|    n_updates            | 510           |\n","|    policy_gradient_loss | -0.000748     |\n","|    value_loss           | 8.77e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 339    |\n","|    iterations      | 52     |\n","|    time_elapsed    | 313    |\n","|    total_timesteps | 106496 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 343          |\n","|    iterations           | 53           |\n","|    time_elapsed         | 316          |\n","|    total_timesteps      | 108544       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001364671 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.411       |\n","|    explained_variance   | 0.459        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.88e+04     |\n","|    n_updates            | 520          |\n","|    policy_gradient_loss | -0.000158    |\n","|    value_loss           | 7.24e+04     |\n","------------------------------------------\n","Eval num_timesteps=110000, episode_reward=25967.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.6e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 110000       |\n","| train/                  |              |\n","|    approx_kl            | 9.708569e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.43        |\n","|    explained_variance   | 0.23         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.7e+04      |\n","|    n_updates            | 530          |\n","|    policy_gradient_loss | -0.000408    |\n","|    value_loss           | 1.18e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 343    |\n","|    iterations      | 54     |\n","|    time_elapsed    | 322    |\n","|    total_timesteps | 110592 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 55            |\n","|    time_elapsed         | 324           |\n","|    total_timesteps      | 112640        |\n","| train/                  |               |\n","|    approx_kl            | 0.00023216993 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.469        |\n","|    explained_variance   | 0.163         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.66e+05      |\n","|    n_updates            | 540           |\n","|    policy_gradient_loss | -0.000429     |\n","|    value_loss           | 2.7e+05       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 350           |\n","|    iterations           | 56            |\n","|    time_elapsed         | 327           |\n","|    total_timesteps      | 114688        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019388329 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.364        |\n","|    explained_variance   | 0.439         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.61e+04      |\n","|    n_updates            | 550           |\n","|    policy_gradient_loss | -0.000865     |\n","|    value_loss           | 1.59e+05      |\n","-------------------------------------------\n","Eval num_timesteps=115000, episode_reward=25559.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 115000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00046299744 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.467        |\n","|    explained_variance   | 0.284         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.22e+04      |\n","|    n_updates            | 560           |\n","|    policy_gradient_loss | -0.000538     |\n","|    value_loss           | 8.41e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 348    |\n","|    iterations      | 57     |\n","|    time_elapsed    | 334    |\n","|    total_timesteps | 116736 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 352           |\n","|    iterations           | 58            |\n","|    time_elapsed         | 337           |\n","|    total_timesteps      | 118784        |\n","| train/                  |               |\n","|    approx_kl            | 3.4152094e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.445        |\n","|    explained_variance   | 0.453         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.7e+04       |\n","|    n_updates            | 570           |\n","|    policy_gradient_loss | -0.000162     |\n","|    value_loss           | 1.19e+05      |\n","-------------------------------------------\n","Eval num_timesteps=120000, episode_reward=20632.75 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.06e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 120000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00079144316 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.431        |\n","|    explained_variance   | 0.464         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.55e+04      |\n","|    n_updates            | 580           |\n","|    policy_gradient_loss | -0.00107      |\n","|    value_loss           | 8.17e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 350    |\n","|    iterations      | 59     |\n","|    time_elapsed    | 344    |\n","|    total_timesteps | 120832 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 354           |\n","|    iterations           | 60            |\n","|    time_elapsed         | 346           |\n","|    total_timesteps      | 122880        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016071764 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.385        |\n","|    explained_variance   | 0.194         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+05      |\n","|    n_updates            | 590           |\n","|    policy_gradient_loss | -0.000663     |\n","|    value_loss           | 1.8e+05       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 357           |\n","|    iterations           | 61            |\n","|    time_elapsed         | 349           |\n","|    total_timesteps      | 124928        |\n","| train/                  |               |\n","|    approx_kl            | 0.00044915933 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.446        |\n","|    explained_variance   | 0.296         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.14e+04      |\n","|    n_updates            | 600           |\n","|    policy_gradient_loss | -0.000442     |\n","|    value_loss           | 2.21e+05      |\n","-------------------------------------------\n","Eval num_timesteps=125000, episode_reward=20954.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.1e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 125000       |\n","| train/                  |              |\n","|    approx_kl            | 7.895072e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.396       |\n","|    explained_variance   | 0.409        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.67e+04     |\n","|    n_updates            | 610          |\n","|    policy_gradient_loss | -0.000102    |\n","|    value_loss           | 1.29e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 357    |\n","|    iterations      | 62     |\n","|    time_elapsed    | 355    |\n","|    total_timesteps | 126976 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 360           |\n","|    iterations           | 63            |\n","|    time_elapsed         | 357           |\n","|    total_timesteps      | 129024        |\n","| train/                  |               |\n","|    approx_kl            | 9.2385715e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.447        |\n","|    explained_variance   | 0.395         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.77e+04      |\n","|    n_updates            | 620           |\n","|    policy_gradient_loss | -0.000186     |\n","|    value_loss           | 1.3e+05       |\n","-------------------------------------------\n","Eval num_timesteps=130000, episode_reward=20812.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.08e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 130000       |\n","| train/                  |              |\n","|    approx_kl            | 6.132334e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.404       |\n","|    explained_variance   | 0.524        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.84e+04     |\n","|    n_updates            | 630          |\n","|    policy_gradient_loss | -0.000198    |\n","|    value_loss           | 1.09e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 359    |\n","|    iterations      | 64     |\n","|    time_elapsed    | 364    |\n","|    total_timesteps | 131072 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 363          |\n","|    iterations           | 65           |\n","|    time_elapsed         | 366          |\n","|    total_timesteps      | 133120       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005393998 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.412       |\n","|    explained_variance   | 0.424        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.16e+04     |\n","|    n_updates            | 640          |\n","|    policy_gradient_loss | -0.00071     |\n","|    value_loss           | 8.68e+04     |\n","------------------------------------------\n","Eval num_timesteps=135000, episode_reward=19619.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 135000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00025400924 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.372        |\n","|    explained_variance   | 0.201         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.6e+04       |\n","|    n_updates            | 650           |\n","|    policy_gradient_loss | -0.000521     |\n","|    value_loss           | 2.59e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 362    |\n","|    iterations      | 66     |\n","|    time_elapsed    | 372    |\n","|    total_timesteps | 135168 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 365           |\n","|    iterations           | 67            |\n","|    time_elapsed         | 375           |\n","|    total_timesteps      | 137216        |\n","| train/                  |               |\n","|    approx_kl            | 3.8487895e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.456        |\n","|    explained_variance   | 0.289         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+05      |\n","|    n_updates            | 660           |\n","|    policy_gradient_loss | -0.000398     |\n","|    value_loss           | 1.87e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 368           |\n","|    iterations           | 68            |\n","|    time_elapsed         | 377           |\n","|    total_timesteps      | 139264        |\n","| train/                  |               |\n","|    approx_kl            | 0.00089710613 |\n","|    clip_fraction        | 0.00215       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.38         |\n","|    explained_variance   | 0.415         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.35e+04      |\n","|    n_updates            | 670           |\n","|    policy_gradient_loss | -0.00161      |\n","|    value_loss           | 9.1e+04       |\n","-------------------------------------------\n","Eval num_timesteps=140000, episode_reward=19993.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2e+04         |\n","| time/                   |               |\n","|    total_timesteps      | 140000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00065661245 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.427        |\n","|    explained_variance   | 0.39          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.81e+04      |\n","|    n_updates            | 680           |\n","|    policy_gradient_loss | -0.000848     |\n","|    value_loss           | 1.16e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 367    |\n","|    iterations      | 69     |\n","|    time_elapsed    | 384    |\n","|    total_timesteps | 141312 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 370          |\n","|    iterations           | 70           |\n","|    time_elapsed         | 386          |\n","|    total_timesteps      | 143360       |\n","| train/                  |              |\n","|    approx_kl            | 8.732473e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.391       |\n","|    explained_variance   | 0.56         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.56e+04     |\n","|    n_updates            | 690          |\n","|    policy_gradient_loss | -0.000197    |\n","|    value_loss           | 7.73e+04     |\n","------------------------------------------\n","Eval num_timesteps=145000, episode_reward=19829.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.98e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 145000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00018452608 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.375        |\n","|    explained_variance   | 0.558         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.95e+04      |\n","|    n_updates            | 700           |\n","|    policy_gradient_loss | -0.000278     |\n","|    value_loss           | 5.25e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 364    |\n","|    iterations      | 71     |\n","|    time_elapsed    | 399    |\n","|    total_timesteps | 145408 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 362           |\n","|    iterations           | 72            |\n","|    time_elapsed         | 406           |\n","|    total_timesteps      | 147456        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015995721 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.358        |\n","|    explained_variance   | 0.168         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.35e+04      |\n","|    n_updates            | 710           |\n","|    policy_gradient_loss | -7.69e-05     |\n","|    value_loss           | 3.17e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 361           |\n","|    iterations           | 73            |\n","|    time_elapsed         | 413           |\n","|    total_timesteps      | 149504        |\n","| train/                  |               |\n","|    approx_kl            | 0.00017843847 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.458        |\n","|    explained_variance   | 0.315         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.83e+04      |\n","|    n_updates            | 720           |\n","|    policy_gradient_loss | -0.000618     |\n","|    value_loss           | 1.72e+05      |\n","-------------------------------------------\n","Eval num_timesteps=150000, episode_reward=19619.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.96e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 150000       |\n","| train/                  |              |\n","|    approx_kl            | 5.146739e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.356       |\n","|    explained_variance   | 0.383        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.51e+04     |\n","|    n_updates            | 730          |\n","|    policy_gradient_loss | -0.00029     |\n","|    value_loss           | 1.01e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 348    |\n","|    iterations      | 74     |\n","|    time_elapsed    | 434    |\n","|    total_timesteps | 151552 |\n","-------------------------------\n","--------------------------------------\n","| time/                   |          |\n","|    fps                  | 347      |\n","|    iterations           | 75       |\n","|    time_elapsed         | 441      |\n","|    total_timesteps      | 153600   |\n","| train/                  |          |\n","|    approx_kl            | 0.000931 |\n","|    clip_fraction        | 0.000146 |\n","|    clip_range           | 0.2      |\n","|    entropy_loss         | -0.433   |\n","|    explained_variance   | 0.274    |\n","|    learning_rate        | 0.001    |\n","|    loss                 | 2.94e+04 |\n","|    n_updates            | 740      |\n","|    policy_gradient_loss | -0.00101 |\n","|    value_loss           | 8.75e+04 |\n","--------------------------------------\n","Eval num_timesteps=155000, episode_reward=18749.70 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 155000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00041019046 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.352        |\n","|    explained_variance   | 0.539         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.32e+04      |\n","|    n_updates            | 750           |\n","|    policy_gradient_loss | -0.000943     |\n","|    value_loss           | 1.02e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 338    |\n","|    iterations      | 76     |\n","|    time_elapsed    | 459    |\n","|    total_timesteps | 155648 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 338          |\n","|    iterations           | 77           |\n","|    time_elapsed         | 465          |\n","|    total_timesteps      | 157696       |\n","| train/                  |              |\n","|    approx_kl            | 7.438776e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.38        |\n","|    explained_variance   | 0.392        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.36e+04     |\n","|    n_updates            | 760          |\n","|    policy_gradient_loss | -0.000382    |\n","|    value_loss           | 8.65e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 339          |\n","|    iterations           | 78           |\n","|    time_elapsed         | 470          |\n","|    total_timesteps      | 159744       |\n","| train/                  |              |\n","|    approx_kl            | 0.0009853939 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.374       |\n","|    explained_variance   | -0.0846      |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.37e+05     |\n","|    n_updates            | 770          |\n","|    policy_gradient_loss | -0.00138     |\n","|    value_loss           | 3.24e+05     |\n","------------------------------------------\n","Eval num_timesteps=160000, episode_reward=17957.62 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 160000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00021972694 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.401        |\n","|    explained_variance   | 0.483         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.44e+04      |\n","|    n_updates            | 780           |\n","|    policy_gradient_loss | -0.000858     |\n","|    value_loss           | 1.22e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 334    |\n","|    iterations      | 79     |\n","|    time_elapsed    | 483    |\n","|    total_timesteps | 161792 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 334           |\n","|    iterations           | 80            |\n","|    time_elapsed         | 489           |\n","|    total_timesteps      | 163840        |\n","| train/                  |               |\n","|    approx_kl            | 6.6412205e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.339        |\n","|    explained_variance   | 0.58          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.45e+04      |\n","|    n_updates            | 790           |\n","|    policy_gradient_loss | -0.000133     |\n","|    value_loss           | 1.04e+05      |\n","-------------------------------------------\n","Eval num_timesteps=165000, episode_reward=17051.45 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.71e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 165000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002649359 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.428       |\n","|    explained_variance   | 0.589        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.47e+04     |\n","|    n_updates            | 800          |\n","|    policy_gradient_loss | -0.000804    |\n","|    value_loss           | 7.18e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 328    |\n","|    iterations      | 81     |\n","|    time_elapsed    | 504    |\n","|    total_timesteps | 165888 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 329           |\n","|    iterations           | 82            |\n","|    time_elapsed         | 509           |\n","|    total_timesteps      | 167936        |\n","| train/                  |               |\n","|    approx_kl            | 4.6917034e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.33         |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.17e+04      |\n","|    n_updates            | 810           |\n","|    policy_gradient_loss | -0.000274     |\n","|    value_loss           | 7.96e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 330          |\n","|    iterations           | 83           |\n","|    time_elapsed         | 513          |\n","|    total_timesteps      | 169984       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005784134 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.388       |\n","|    explained_variance   | 0.377        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.89e+04     |\n","|    n_updates            | 820          |\n","|    policy_gradient_loss | -0.000889    |\n","|    value_loss           | 8.34e+04     |\n","------------------------------------------\n","Eval num_timesteps=170000, episode_reward=18120.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.81e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 170000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005097488 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.365       |\n","|    explained_variance   | 0.0578       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.7e+05      |\n","|    n_updates            | 830          |\n","|    policy_gradient_loss | -0.00106     |\n","|    value_loss           | 2.63e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 326    |\n","|    iterations      | 84     |\n","|    time_elapsed    | 526    |\n","|    total_timesteps | 172032 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 326           |\n","|    iterations           | 85            |\n","|    time_elapsed         | 533           |\n","|    total_timesteps      | 174080        |\n","| train/                  |               |\n","|    approx_kl            | 3.3721823e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.353        |\n","|    explained_variance   | 0.471         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.2e+04       |\n","|    n_updates            | 840           |\n","|    policy_gradient_loss | -0.000296     |\n","|    value_loss           | 1.01e+05      |\n","-------------------------------------------\n","Eval num_timesteps=175000, episode_reward=18152.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.82e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 175000       |\n","| train/                  |              |\n","|    approx_kl            | 9.495765e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.347       |\n","|    explained_variance   | 0.475        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.02e+04     |\n","|    n_updates            | 850          |\n","|    policy_gradient_loss | -6.86e-05    |\n","|    value_loss           | 1.32e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 86     |\n","|    time_elapsed    | 554    |\n","|    total_timesteps | 176128 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 87            |\n","|    time_elapsed         | 560           |\n","|    total_timesteps      | 178176        |\n","| train/                  |               |\n","|    approx_kl            | 0.00036185974 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.431        |\n","|    explained_variance   | 0.508         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.36e+04      |\n","|    n_updates            | 860           |\n","|    policy_gradient_loss | -0.000637     |\n","|    value_loss           | 8.18e+04      |\n","-------------------------------------------\n","Eval num_timesteps=180000, episode_reward=21997.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 180000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00034444805 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.302        |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.33e+04      |\n","|    n_updates            | 870           |\n","|    policy_gradient_loss | -0.000757     |\n","|    value_loss           | 8.12e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 88     |\n","|    time_elapsed    | 575    |\n","|    total_timesteps | 180224 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 89           |\n","|    time_elapsed         | 582          |\n","|    total_timesteps      | 182272       |\n","| train/                  |              |\n","|    approx_kl            | 0.0003947549 |\n","|    clip_fraction        | 0.000244     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.352       |\n","|    explained_variance   | 0.329        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.38e+04     |\n","|    n_updates            | 880          |\n","|    policy_gradient_loss | -0.00115     |\n","|    value_loss           | 4.8e+04      |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 90            |\n","|    time_elapsed         | 590           |\n","|    total_timesteps      | 184320        |\n","| train/                  |               |\n","|    approx_kl            | 0.00029745608 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.423        |\n","|    explained_variance   | 0.111         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.8e+04       |\n","|    n_updates            | 890           |\n","|    policy_gradient_loss | -0.000764     |\n","|    value_loss           | 2.67e+05      |\n","-------------------------------------------\n","Eval num_timesteps=185000, episode_reward=19342.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.93e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 185000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015731683 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.287        |\n","|    explained_variance   | 0.498         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.83e+04      |\n","|    n_updates            | 900           |\n","|    policy_gradient_loss | -0.000413     |\n","|    value_loss           | 9.46e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 305    |\n","|    iterations      | 91     |\n","|    time_elapsed    | 609    |\n","|    total_timesteps | 186368 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 304          |\n","|    iterations           | 92           |\n","|    time_elapsed         | 619          |\n","|    total_timesteps      | 188416       |\n","| train/                  |              |\n","|    approx_kl            | 0.0009449066 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.354       |\n","|    explained_variance   | 0.525        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.42e+04     |\n","|    n_updates            | 910          |\n","|    policy_gradient_loss | -0.000756    |\n","|    value_loss           | 9.42e+04     |\n","------------------------------------------\n","Eval num_timesteps=190000, episode_reward=18887.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.89e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 190000       |\n","| train/                  |              |\n","|    approx_kl            | 9.640271e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.39        |\n","|    explained_variance   | 0.532        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.52e+04     |\n","|    n_updates            | 920          |\n","|    policy_gradient_loss | -0.000534    |\n","|    value_loss           | 7.09e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 295    |\n","|    iterations      | 93     |\n","|    time_elapsed    | 643    |\n","|    total_timesteps | 190464 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 296           |\n","|    iterations           | 94            |\n","|    time_elapsed         | 648           |\n","|    total_timesteps      | 192512        |\n","| train/                  |               |\n","|    approx_kl            | 0.00011707959 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.332        |\n","|    explained_variance   | 0.478         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.62e+04      |\n","|    n_updates            | 930           |\n","|    policy_gradient_loss | -0.000419     |\n","|    value_loss           | 5.8e+04       |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 297          |\n","|    iterations           | 95           |\n","|    time_elapsed         | 653          |\n","|    total_timesteps      | 194560       |\n","| train/                  |              |\n","|    approx_kl            | 0.0006258219 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.326       |\n","|    explained_variance   | 0.258        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.82e+04     |\n","|    n_updates            | 940          |\n","|    policy_gradient_loss | -0.00119     |\n","|    value_loss           | 1.75e+05     |\n","------------------------------------------\n","Eval num_timesteps=195000, episode_reward=18199.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.82e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 195000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019312903 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.402        |\n","|    explained_variance   | 0.479         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.79e+04      |\n","|    n_updates            | 950           |\n","|    policy_gradient_loss | -0.000488     |\n","|    value_loss           | 1.98e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 293    |\n","|    iterations      | 96     |\n","|    time_elapsed    | 670    |\n","|    total_timesteps | 196608 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 293          |\n","|    iterations           | 97           |\n","|    time_elapsed         | 677          |\n","|    total_timesteps      | 198656       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002743451 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.314       |\n","|    explained_variance   | 0.526        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.01e+04     |\n","|    n_updates            | 960          |\n","|    policy_gradient_loss | -0.000501    |\n","|    value_loss           | 8.46e+04     |\n","------------------------------------------\n","Eval num_timesteps=200000, episode_reward=19226.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 200000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00022795927 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.375        |\n","|    explained_variance   | 0.356         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.61e+04      |\n","|    n_updates            | 970           |\n","|    policy_gradient_loss | -0.000239     |\n","|    value_loss           | 8.9e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 287    |\n","|    iterations      | 98     |\n","|    time_elapsed    | 697    |\n","|    total_timesteps | 200704 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 288           |\n","|    iterations           | 99            |\n","|    time_elapsed         | 703           |\n","|    total_timesteps      | 202752        |\n","| train/                  |               |\n","|    approx_kl            | 0.00013961151 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.347        |\n","|    explained_variance   | 0.571         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.63e+04      |\n","|    n_updates            | 980           |\n","|    policy_gradient_loss | -0.000631     |\n","|    value_loss           | 7.05e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 288           |\n","|    iterations           | 100           |\n","|    time_elapsed         | 709           |\n","|    total_timesteps      | 204800        |\n","| train/                  |               |\n","|    approx_kl            | 3.2340904e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.338        |\n","|    explained_variance   | 0.415         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.4e+04       |\n","|    n_updates            | 990           |\n","|    policy_gradient_loss | -0.000126     |\n","|    value_loss           | 8.25e+04      |\n","-------------------------------------------\n","Eval num_timesteps=205000, episode_reward=18796.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 205000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001004005 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.322       |\n","|    explained_variance   | 0.000159     |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.3e+05      |\n","|    n_updates            | 1000         |\n","|    policy_gradient_loss | -0.00036     |\n","|    value_loss           | 2.42e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 286    |\n","|    iterations      | 101    |\n","|    time_elapsed    | 722    |\n","|    total_timesteps | 206848 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 287          |\n","|    iterations           | 102          |\n","|    time_elapsed         | 726          |\n","|    total_timesteps      | 208896       |\n","| train/                  |              |\n","|    approx_kl            | 9.062787e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.406       |\n","|    explained_variance   | 0.39         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.49e+04     |\n","|    n_updates            | 1010         |\n","|    policy_gradient_loss | -7.9e-05     |\n","|    value_loss           | 1.31e+05     |\n","------------------------------------------\n","Eval num_timesteps=210000, episode_reward=18698.71 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.87e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 210000      |\n","| train/                  |             |\n","|    approx_kl            | 0.000295195 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.332      |\n","|    explained_variance   | 0.548       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.37e+04    |\n","|    n_updates            | 1020        |\n","|    policy_gradient_loss | -0.000509   |\n","|    value_loss           | 6.22e+04    |\n","-----------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 286    |\n","|    iterations      | 103    |\n","|    time_elapsed    | 736    |\n","|    total_timesteps | 210944 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 287           |\n","|    iterations           | 104           |\n","|    time_elapsed         | 740           |\n","|    total_timesteps      | 212992        |\n","| train/                  |               |\n","|    approx_kl            | 0.00011625924 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.369        |\n","|    explained_variance   | 0.379         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.9e+04       |\n","|    n_updates            | 1030          |\n","|    policy_gradient_loss | -0.000203     |\n","|    value_loss           | 1.1e+05       |\n","-------------------------------------------\n","Eval num_timesteps=215000, episode_reward=19568.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.96e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 215000       |\n","| train/                  |              |\n","|    approx_kl            | 2.163279e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.333       |\n","|    explained_variance   | 0.583        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.51e+04     |\n","|    n_updates            | 1040         |\n","|    policy_gradient_loss | -0.000164    |\n","|    value_loss           | 9.22e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 286    |\n","|    iterations      | 105    |\n","|    time_elapsed    | 751    |\n","|    total_timesteps | 215040 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 287           |\n","|    iterations           | 106           |\n","|    time_elapsed         | 755           |\n","|    total_timesteps      | 217088        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016063027 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.324        |\n","|    explained_variance   | 0.494         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.8e+04       |\n","|    n_updates            | 1050          |\n","|    policy_gradient_loss | -0.000316     |\n","|    value_loss           | 6.4e+04       |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 288          |\n","|    iterations           | 107          |\n","|    time_elapsed         | 759          |\n","|    total_timesteps      | 219136       |\n","| train/                  |              |\n","|    approx_kl            | 5.610744e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.321       |\n","|    explained_variance   | 0.0811       |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.51e+05     |\n","|    n_updates            | 1060         |\n","|    policy_gradient_loss | -0.000313    |\n","|    value_loss           | 3.11e+05     |\n","------------------------------------------\n","Eval num_timesteps=220000, episode_reward=18796.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 220000       |\n","| train/                  |              |\n","|    approx_kl            | 7.142802e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.406       |\n","|    explained_variance   | 0.479        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.66e+04     |\n","|    n_updates            | 1070         |\n","|    policy_gradient_loss | -0.000205    |\n","|    value_loss           | 1.23e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 286    |\n","|    iterations      | 108    |\n","|    time_elapsed    | 770    |\n","|    total_timesteps | 221184 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 288           |\n","|    iterations           | 109           |\n","|    time_elapsed         | 774           |\n","|    total_timesteps      | 223232        |\n","| train/                  |               |\n","|    approx_kl            | 0.00020589549 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.31         |\n","|    explained_variance   | 0.688         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.88e+04      |\n","|    n_updates            | 1080          |\n","|    policy_gradient_loss | -0.000386     |\n","|    value_loss           | 6.64e+04      |\n","-------------------------------------------\n","Eval num_timesteps=225000, episode_reward=19616.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 225000        |\n","| train/                  |               |\n","|    approx_kl            | 7.7778386e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.395        |\n","|    explained_variance   | 0.499         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.96e+04      |\n","|    n_updates            | 1090          |\n","|    policy_gradient_loss | -0.000213     |\n","|    value_loss           | 6.46e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 287    |\n","|    iterations      | 110    |\n","|    time_elapsed    | 784    |\n","|    total_timesteps | 225280 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 288           |\n","|    iterations           | 111           |\n","|    time_elapsed         | 788           |\n","|    total_timesteps      | 227328        |\n","| train/                  |               |\n","|    approx_kl            | 0.00042458044 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.299        |\n","|    explained_variance   | 0.692         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.05e+04      |\n","|    n_updates            | 1100          |\n","|    policy_gradient_loss | -0.000746     |\n","|    value_loss           | 7.29e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 289          |\n","|    iterations           | 112          |\n","|    time_elapsed         | 791          |\n","|    total_timesteps      | 229376       |\n","| train/                  |              |\n","|    approx_kl            | 8.944186e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.337       |\n","|    explained_variance   | 0.546        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.43e+04     |\n","|    n_updates            | 1110         |\n","|    policy_gradient_loss | -0.000327    |\n","|    value_loss           | 8.05e+04     |\n","------------------------------------------\n","Eval num_timesteps=230000, episode_reward=19178.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.92e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 230000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0003198008 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.318       |\n","|    explained_variance   | 0.104        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.51e+04     |\n","|    n_updates            | 1120         |\n","|    policy_gradient_loss | -0.000654    |\n","|    value_loss           | 2.13e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 288    |\n","|    iterations      | 113    |\n","|    time_elapsed    | 803    |\n","|    total_timesteps | 231424 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 289           |\n","|    iterations           | 114           |\n","|    time_elapsed         | 807           |\n","|    total_timesteps      | 233472        |\n","| train/                  |               |\n","|    approx_kl            | 0.00067014794 |\n","|    clip_fraction        | 0.00171       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.372        |\n","|    explained_variance   | 0.558         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.82e+04      |\n","|    n_updates            | 1130          |\n","|    policy_gradient_loss | -0.00139      |\n","|    value_loss           | 8.78e+04      |\n","-------------------------------------------\n","Eval num_timesteps=235000, episode_reward=18062.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.81e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 235000        |\n","| train/                  |               |\n","|    approx_kl            | 5.7698315e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.287        |\n","|    explained_variance   | 0.632         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.95e+04      |\n","|    n_updates            | 1140          |\n","|    policy_gradient_loss | -0.000225     |\n","|    value_loss           | 8.82e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 284    |\n","|    iterations      | 115    |\n","|    time_elapsed    | 826    |\n","|    total_timesteps | 235520 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 284           |\n","|    iterations           | 116           |\n","|    time_elapsed         | 834           |\n","|    total_timesteps      | 237568        |\n","| train/                  |               |\n","|    approx_kl            | 0.00029157774 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.41         |\n","|    explained_variance   | 0.676         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.44e+04      |\n","|    n_updates            | 1150          |\n","|    policy_gradient_loss | -0.000538     |\n","|    value_loss           | 4.81e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 285          |\n","|    iterations           | 117          |\n","|    time_elapsed         | 840          |\n","|    total_timesteps      | 239616       |\n","| train/                  |              |\n","|    approx_kl            | 0.0012487416 |\n","|    clip_fraction        | 0.00298      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.282       |\n","|    explained_variance   | 0.534        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.41e+04     |\n","|    n_updates            | 1160         |\n","|    policy_gradient_loss | -0.00195     |\n","|    value_loss           | 7.2e+04      |\n","------------------------------------------\n","Eval num_timesteps=240000, episode_reward=22347.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.23e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 240000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00043009216 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.349        |\n","|    explained_variance   | 0.382         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.87e+04      |\n","|    n_updates            | 1170          |\n","|    policy_gradient_loss | -0.00109      |\n","|    value_loss           | 1.04e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 282    |\n","|    iterations      | 118    |\n","|    time_elapsed    | 854    |\n","|    total_timesteps | 241664 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 282           |\n","|    iterations           | 119           |\n","|    time_elapsed         | 861           |\n","|    total_timesteps      | 243712        |\n","| train/                  |               |\n","|    approx_kl            | 2.8707436e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.313        |\n","|    explained_variance   | 0.247         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.06e+04      |\n","|    n_updates            | 1180          |\n","|    policy_gradient_loss | -0.000112     |\n","|    value_loss           | 2.75e+05      |\n","-------------------------------------------\n","Eval num_timesteps=245000, episode_reward=21618.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 245000        |\n","| train/                  |               |\n","|    approx_kl            | 2.7144852e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.332        |\n","|    explained_variance   | 0.552         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.87e+04      |\n","|    n_updates            | 1190          |\n","|    policy_gradient_loss | -7.95e-05     |\n","|    value_loss           | 9.49e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 279    |\n","|    iterations      | 120    |\n","|    time_elapsed    | 879    |\n","|    total_timesteps | 245760 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 280           |\n","|    iterations           | 121           |\n","|    time_elapsed         | 883           |\n","|    total_timesteps      | 247808        |\n","| train/                  |               |\n","|    approx_kl            | 9.6809614e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.304        |\n","|    explained_variance   | 0.377         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.33e+04      |\n","|    n_updates            | 1200          |\n","|    policy_gradient_loss | -0.000107     |\n","|    value_loss           | 9.82e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 281          |\n","|    iterations           | 122          |\n","|    time_elapsed         | 887          |\n","|    total_timesteps      | 249856       |\n","| train/                  |              |\n","|    approx_kl            | 1.689719e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.407       |\n","|    explained_variance   | 0.636        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.54e+04     |\n","|    n_updates            | 1210         |\n","|    policy_gradient_loss | -8.6e-05     |\n","|    value_loss           | 6.03e+04     |\n","------------------------------------------\n","Eval num_timesteps=250000, episode_reward=18456.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 250000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00085663656 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.282        |\n","|    explained_variance   | 0.566         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 1220          |\n","|    policy_gradient_loss | -0.000708     |\n","|    value_loss           | 4.88e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 280    |\n","|    iterations      | 123    |\n","|    time_elapsed    | 896    |\n","|    total_timesteps | 251904 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 282          |\n","|    iterations           | 124          |\n","|    time_elapsed         | 899          |\n","|    total_timesteps      | 253952       |\n","| train/                  |              |\n","|    approx_kl            | 6.345246e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.322       |\n","|    explained_variance   | 0.403        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.84e+05     |\n","|    n_updates            | 1230         |\n","|    policy_gradient_loss | -0.000483    |\n","|    value_loss           | 1.64e+05     |\n","------------------------------------------\n","Eval num_timesteps=255000, episode_reward=20934.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.09e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 255000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00035408448 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.375        |\n","|    explained_variance   | 0.318         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.37e+05      |\n","|    n_updates            | 1240          |\n","|    policy_gradient_loss | -0.00113      |\n","|    value_loss           | 2.48e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 282    |\n","|    iterations      | 125    |\n","|    time_elapsed    | 905    |\n","|    total_timesteps | 256000 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 284           |\n","|    iterations           | 126           |\n","|    time_elapsed         | 907           |\n","|    total_timesteps      | 258048        |\n","| train/                  |               |\n","|    approx_kl            | 4.3468695e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.269        |\n","|    explained_variance   | 0.504         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.52e+04      |\n","|    n_updates            | 1250          |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 9.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=260000, episode_reward=20934.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.09e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 260000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012063183 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.332        |\n","|    explained_variance   | 0.504         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.7e+04       |\n","|    n_updates            | 1260          |\n","|    policy_gradient_loss | -0.000103     |\n","|    value_loss           | 7.15e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 284    |\n","|    iterations      | 127    |\n","|    time_elapsed    | 914    |\n","|    total_timesteps | 260096 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 285           |\n","|    iterations           | 128           |\n","|    time_elapsed         | 917           |\n","|    total_timesteps      | 262144        |\n","| train/                  |               |\n","|    approx_kl            | 4.1929772e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.369        |\n","|    explained_variance   | 0.598         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.31e+04      |\n","|    n_updates            | 1270          |\n","|    policy_gradient_loss | -0.000127     |\n","|    value_loss           | 6.95e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 287           |\n","|    iterations           | 129           |\n","|    time_elapsed         | 919           |\n","|    total_timesteps      | 264192        |\n","| train/                  |               |\n","|    approx_kl            | 0.00039092812 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.303        |\n","|    explained_variance   | 0.464         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.45e+04      |\n","|    n_updates            | 1280          |\n","|    policy_gradient_loss | -0.000958     |\n","|    value_loss           | 5.13e+04      |\n","-------------------------------------------\n","Eval num_timesteps=265000, episode_reward=19113.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 265000        |\n","| train/                  |               |\n","|    approx_kl            | 2.9246963e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.301        |\n","|    explained_variance   | 0.443         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.36e+04      |\n","|    n_updates            | 1290          |\n","|    policy_gradient_loss | -0.000289     |\n","|    value_loss           | 9.24e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 287    |\n","|    iterations      | 130    |\n","|    time_elapsed    | 926    |\n","|    total_timesteps | 266240 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 288           |\n","|    iterations           | 131           |\n","|    time_elapsed         | 929           |\n","|    total_timesteps      | 268288        |\n","| train/                  |               |\n","|    approx_kl            | 5.0561473e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.365        |\n","|    explained_variance   | 0.439         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.2e+04       |\n","|    n_updates            | 1300          |\n","|    policy_gradient_loss | -0.00022      |\n","|    value_loss           | 1.81e+05      |\n","-------------------------------------------\n","Eval num_timesteps=270000, episode_reward=21918.20 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 270000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00083005626 |\n","|    clip_fraction        | 0.00166       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.277        |\n","|    explained_variance   | 0.644         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.17e+04      |\n","|    n_updates            | 1310          |\n","|    policy_gradient_loss | -0.000932     |\n","|    value_loss           | 6.77e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 288    |\n","|    iterations      | 132    |\n","|    time_elapsed    | 937    |\n","|    total_timesteps | 270336 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 289           |\n","|    iterations           | 133           |\n","|    time_elapsed         | 939           |\n","|    total_timesteps      | 272384        |\n","| train/                  |               |\n","|    approx_kl            | 0.00027444286 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.34         |\n","|    explained_variance   | 0.45          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.36e+04      |\n","|    n_updates            | 1320          |\n","|    policy_gradient_loss | -0.000133     |\n","|    value_loss           | 9.6e+04       |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 290          |\n","|    iterations           | 134          |\n","|    time_elapsed         | 943          |\n","|    total_timesteps      | 274432       |\n","| train/                  |              |\n","|    approx_kl            | 5.301769e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.329       |\n","|    explained_variance   | 0.732        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.15e+04     |\n","|    n_updates            | 1330         |\n","|    policy_gradient_loss | -0.000413    |\n","|    value_loss           | 5.61e+04     |\n","------------------------------------------\n","Eval num_timesteps=275000, episode_reward=19214.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 275000        |\n","| train/                  |               |\n","|    approx_kl            | 2.0993932e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.294        |\n","|    explained_variance   | 0.516         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.31e+04      |\n","|    n_updates            | 1340          |\n","|    policy_gradient_loss | -0.000177     |\n","|    value_loss           | 6.16e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 288    |\n","|    iterations      | 135    |\n","|    time_elapsed    | 957    |\n","|    total_timesteps | 276480 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 289          |\n","|    iterations           | 136          |\n","|    time_elapsed         | 962          |\n","|    total_timesteps      | 278528       |\n","| train/                  |              |\n","|    approx_kl            | 9.631796e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.291       |\n","|    explained_variance   | 0.443        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.23e+05     |\n","|    n_updates            | 1350         |\n","|    policy_gradient_loss | -3.22e-05    |\n","|    value_loss           | 1.82e+05     |\n","------------------------------------------\n","Eval num_timesteps=280000, episode_reward=19199.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.92e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 280000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0006296163 |\n","|    clip_fraction        | 0.000635     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.371       |\n","|    explained_variance   | 0.46         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.55e+04     |\n","|    n_updates            | 1360         |\n","|    policy_gradient_loss | -0.001       |\n","|    value_loss           | 1.38e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 287    |\n","|    iterations      | 137    |\n","|    time_elapsed    | 974    |\n","|    total_timesteps | 280576 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 289           |\n","|    iterations           | 138           |\n","|    time_elapsed         | 977           |\n","|    total_timesteps      | 282624        |\n","| train/                  |               |\n","|    approx_kl            | 0.00022962119 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.296        |\n","|    explained_variance   | 0.641         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.89e+04      |\n","|    n_updates            | 1370          |\n","|    policy_gradient_loss | -0.000554     |\n","|    value_loss           | 5.51e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 290           |\n","|    iterations           | 139           |\n","|    time_elapsed         | 980           |\n","|    total_timesteps      | 284672        |\n","| train/                  |               |\n","|    approx_kl            | 4.2080064e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.327        |\n","|    explained_variance   | 0.517         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.88e+04      |\n","|    n_updates            | 1380          |\n","|    policy_gradient_loss | -0.000185     |\n","|    value_loss           | 8.34e+04      |\n","-------------------------------------------\n","Eval num_timesteps=285000, episode_reward=20099.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 285000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00025972168 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.305        |\n","|    explained_variance   | 0.664         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.91e+04      |\n","|    n_updates            | 1390          |\n","|    policy_gradient_loss | -0.000564     |\n","|    value_loss           | 6.82e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 290    |\n","|    iterations      | 140    |\n","|    time_elapsed    | 986    |\n","|    total_timesteps | 286720 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 291           |\n","|    iterations           | 141           |\n","|    time_elapsed         | 989           |\n","|    total_timesteps      | 288768        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015586015 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.275        |\n","|    explained_variance   | 0.452         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.62e+04      |\n","|    n_updates            | 1400          |\n","|    policy_gradient_loss | -0.000306     |\n","|    value_loss           | 7.12e+04      |\n","-------------------------------------------\n","Eval num_timesteps=290000, episode_reward=20458.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 290000        |\n","| train/                  |               |\n","|    approx_kl            | 2.9938528e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.278        |\n","|    explained_variance   | 0.272         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.71e+04      |\n","|    n_updates            | 1410          |\n","|    policy_gradient_loss | -3.66e-05     |\n","|    value_loss           | 2.15e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 291    |\n","|    iterations      | 142    |\n","|    time_elapsed    | 996    |\n","|    total_timesteps | 290816 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 292           |\n","|    iterations           | 143           |\n","|    time_elapsed         | 999           |\n","|    total_timesteps      | 292864        |\n","| train/                  |               |\n","|    approx_kl            | 0.00020205582 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.381        |\n","|    explained_variance   | 0.561         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.91e+04      |\n","|    n_updates            | 1420          |\n","|    policy_gradient_loss | -0.000476     |\n","|    value_loss           | 1.14e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 294          |\n","|    iterations           | 144          |\n","|    time_elapsed         | 1002         |\n","|    total_timesteps      | 294912       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005630808 |\n","|    clip_fraction        | 0.000781     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.262       |\n","|    explained_variance   | 0.688        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.91e+04     |\n","|    n_updates            | 1430         |\n","|    policy_gradient_loss | -0.000546    |\n","|    value_loss           | 7.72e+04     |\n","------------------------------------------\n","Eval num_timesteps=295000, episode_reward=17018.86 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 295000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00077927473 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.36         |\n","|    explained_variance   | 0.525         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.43e+04      |\n","|    n_updates            | 1440          |\n","|    policy_gradient_loss | -0.000618     |\n","|    value_loss           | 6.67e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 294    |\n","|    iterations      | 145    |\n","|    time_elapsed    | 1009   |\n","|    total_timesteps | 296960 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 295           |\n","|    iterations           | 146           |\n","|    time_elapsed         | 1012          |\n","|    total_timesteps      | 299008        |\n","| train/                  |               |\n","|    approx_kl            | 0.00074419356 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.272        |\n","|    explained_variance   | 0.714         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.33e+04      |\n","|    n_updates            | 1450          |\n","|    policy_gradient_loss | -0.00136      |\n","|    value_loss           | 6.17e+04      |\n","-------------------------------------------\n","Eval num_timesteps=300000, episode_reward=20510.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 300000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00027373544 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.301        |\n","|    explained_variance   | 0.537         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.86e+04      |\n","|    n_updates            | 1460          |\n","|    policy_gradient_loss | -0.000695     |\n","|    value_loss           | 6.94e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 294    |\n","|    iterations      | 147    |\n","|    time_elapsed    | 1021   |\n","|    total_timesteps | 301056 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 295           |\n","|    iterations           | 148           |\n","|    time_elapsed         | 1024          |\n","|    total_timesteps      | 303104        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016071895 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.274        |\n","|    explained_variance   | 0.345         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+05         |\n","|    n_updates            | 1470          |\n","|    policy_gradient_loss | -0.000449     |\n","|    value_loss           | 1.87e+05      |\n","-------------------------------------------\n","Eval num_timesteps=305000, episode_reward=21754.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 305000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00053762435 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.349        |\n","|    explained_variance   | 0.622         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.17e+04      |\n","|    n_updates            | 1480          |\n","|    policy_gradient_loss | -0.00131      |\n","|    value_loss           | 7.58e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 295    |\n","|    iterations      | 149    |\n","|    time_elapsed    | 1033   |\n","|    total_timesteps | 305152 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 296          |\n","|    iterations           | 150          |\n","|    time_elapsed         | 1036         |\n","|    total_timesteps      | 307200       |\n","| train/                  |              |\n","|    approx_kl            | 0.0007112724 |\n","|    clip_fraction        | 0.000781     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.247       |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.06e+04     |\n","|    n_updates            | 1490         |\n","|    policy_gradient_loss | -0.000753    |\n","|    value_loss           | 6.31e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 297           |\n","|    iterations           | 151           |\n","|    time_elapsed         | 1038          |\n","|    total_timesteps      | 309248        |\n","| train/                  |               |\n","|    approx_kl            | 0.00028901992 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.38         |\n","|    explained_variance   | 0.566         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.55e+04      |\n","|    n_updates            | 1500          |\n","|    policy_gradient_loss | -0.000442     |\n","|    value_loss           | 6.4e+04       |\n","-------------------------------------------\n","Eval num_timesteps=310000, episode_reward=20949.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.09e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 310000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0009869209 |\n","|    clip_fraction        | 0.00371      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.24        |\n","|    explained_variance   | 0.657        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.65e+04     |\n","|    n_updates            | 1510         |\n","|    policy_gradient_loss | -0.00184     |\n","|    value_loss           | 5.93e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 297    |\n","|    iterations      | 152    |\n","|    time_elapsed    | 1045   |\n","|    total_timesteps | 311296 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 299           |\n","|    iterations           | 153           |\n","|    time_elapsed         | 1047          |\n","|    total_timesteps      | 313344        |\n","| train/                  |               |\n","|    approx_kl            | 0.00082723785 |\n","|    clip_fraction        | 0.00259       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.322        |\n","|    explained_variance   | 0.606         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 1520          |\n","|    policy_gradient_loss | -0.00179      |\n","|    value_loss           | 4.77e+04      |\n","-------------------------------------------\n","Eval num_timesteps=315000, episode_reward=18809.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 315000       |\n","| train/                  |              |\n","|    approx_kl            | 9.685551e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.302       |\n","|    explained_variance   | 0.25         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.02e+05     |\n","|    n_updates            | 1530         |\n","|    policy_gradient_loss | -4.49e-05    |\n","|    value_loss           | 1.93e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 299    |\n","|    iterations      | 154    |\n","|    time_elapsed    | 1053   |\n","|    total_timesteps | 315392 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 300           |\n","|    iterations           | 155           |\n","|    time_elapsed         | 1055          |\n","|    total_timesteps      | 317440        |\n","| train/                  |               |\n","|    approx_kl            | 3.3024087e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.313        |\n","|    explained_variance   | 0.601         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.32e+04      |\n","|    n_updates            | 1540          |\n","|    policy_gradient_loss | -0.000168     |\n","|    value_loss           | 7.42e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 301          |\n","|    iterations           | 156          |\n","|    time_elapsed         | 1058         |\n","|    total_timesteps      | 319488       |\n","| train/                  |              |\n","|    approx_kl            | 2.794026e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.275       |\n","|    explained_variance   | 0.64         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.67e+04     |\n","|    n_updates            | 1550         |\n","|    policy_gradient_loss | -1.84e-05    |\n","|    value_loss           | 6.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=320000, episode_reward=18441.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 320000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00041387804 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.374        |\n","|    explained_variance   | 0.651         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.6e+04       |\n","|    n_updates            | 1560          |\n","|    policy_gradient_loss | -0.000571     |\n","|    value_loss           | 6.19e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 302    |\n","|    iterations      | 157    |\n","|    time_elapsed    | 1064   |\n","|    total_timesteps | 321536 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 303          |\n","|    iterations           | 158          |\n","|    time_elapsed         | 1066         |\n","|    total_timesteps      | 323584       |\n","| train/                  |              |\n","|    approx_kl            | 0.0007668847 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.253       |\n","|    explained_variance   | 0.636        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.77e+04     |\n","|    n_updates            | 1570         |\n","|    policy_gradient_loss | -0.000895    |\n","|    value_loss           | 4.13e+04     |\n","------------------------------------------\n","Eval num_timesteps=325000, episode_reward=17670.27 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.77e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 325000        |\n","| train/                  |               |\n","|    approx_kl            | 7.0452224e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.296        |\n","|    explained_variance   | 0.449         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.19e+04      |\n","|    n_updates            | 1580          |\n","|    policy_gradient_loss | -7.62e-05     |\n","|    value_loss           | 1.22e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 303    |\n","|    iterations      | 159    |\n","|    time_elapsed    | 1073   |\n","|    total_timesteps | 325632 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 304           |\n","|    iterations           | 160           |\n","|    time_elapsed         | 1075          |\n","|    total_timesteps      | 327680        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014634585 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.364        |\n","|    explained_variance   | 0.504         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.34e+04      |\n","|    n_updates            | 1590          |\n","|    policy_gradient_loss | -0.000548     |\n","|    value_loss           | 1.82e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 305           |\n","|    iterations           | 161           |\n","|    time_elapsed         | 1077          |\n","|    total_timesteps      | 329728        |\n","| train/                  |               |\n","|    approx_kl            | 6.8149326e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.244        |\n","|    explained_variance   | 0.469         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.58e+04      |\n","|    n_updates            | 1600          |\n","|    policy_gradient_loss | -0.000237     |\n","|    value_loss           | 1.06e+05      |\n","-------------------------------------------\n","Eval num_timesteps=330000, episode_reward=18567.56 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 330000        |\n","| train/                  |               |\n","|    approx_kl            | 2.7390692e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.298        |\n","|    explained_variance   | 0.667         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.08e+04      |\n","|    n_updates            | 1610          |\n","|    policy_gradient_loss | 4.15e-05      |\n","|    value_loss           | 9.2e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 306    |\n","|    iterations      | 162    |\n","|    time_elapsed    | 1084   |\n","|    total_timesteps | 331776 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 307           |\n","|    iterations           | 163           |\n","|    time_elapsed         | 1086          |\n","|    total_timesteps      | 333824        |\n","| train/                  |               |\n","|    approx_kl            | 1.4266552e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.345        |\n","|    explained_variance   | 0.689         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.66e+04      |\n","|    n_updates            | 1620          |\n","|    policy_gradient_loss | -0.000221     |\n","|    value_loss           | 5.9e+04       |\n","-------------------------------------------\n","Eval num_timesteps=335000, episode_reward=19934.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.99e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 335000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0009998771 |\n","|    clip_fraction        | 0.00527      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.265       |\n","|    explained_variance   | 0.486        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.99e+04     |\n","|    n_updates            | 1630         |\n","|    policy_gradient_loss | -0.00179     |\n","|    value_loss           | 5.05e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 307    |\n","|    iterations      | 164    |\n","|    time_elapsed    | 1092   |\n","|    total_timesteps | 335872 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 308           |\n","|    iterations           | 165           |\n","|    time_elapsed         | 1094          |\n","|    total_timesteps      | 337920        |\n","| train/                  |               |\n","|    approx_kl            | 0.00033060554 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.3          |\n","|    explained_variance   | 0.447         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.26e+04      |\n","|    n_updates            | 1640          |\n","|    policy_gradient_loss | -0.000744     |\n","|    value_loss           | 1.37e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 309          |\n","|    iterations           | 166          |\n","|    time_elapsed         | 1097         |\n","|    total_timesteps      | 339968       |\n","| train/                  |              |\n","|    approx_kl            | 9.195035e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.361       |\n","|    explained_variance   | 0.473        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.57e+04     |\n","|    n_updates            | 1650         |\n","|    policy_gradient_loss | -5.74e-05    |\n","|    value_loss           | 2.17e+05     |\n","------------------------------------------\n","Eval num_timesteps=340000, episode_reward=18580.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 340000        |\n","| train/                  |               |\n","|    approx_kl            | 1.8701947e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.26         |\n","|    explained_variance   | 0.661         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 1660          |\n","|    policy_gradient_loss | -0.000171     |\n","|    value_loss           | 6.53e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 167    |\n","|    time_elapsed    | 1105   |\n","|    total_timesteps | 342016 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 168          |\n","|    time_elapsed         | 1109         |\n","|    total_timesteps      | 344064       |\n","| train/                  |              |\n","|    approx_kl            | 0.0009009216 |\n","|    clip_fraction        | 0.00269      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.314       |\n","|    explained_variance   | 0.625        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.48e+04     |\n","|    n_updates            | 1670         |\n","|    policy_gradient_loss | -0.00153     |\n","|    value_loss           | 7.17e+04     |\n","------------------------------------------\n","Eval num_timesteps=345000, episode_reward=18833.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 345000       |\n","| train/                  |              |\n","|    approx_kl            | 7.431107e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.308       |\n","|    explained_variance   | 0.718        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.53e+04     |\n","|    n_updates            | 1680         |\n","|    policy_gradient_loss | -0.000214    |\n","|    value_loss           | 6.07e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 306    |\n","|    iterations      | 169    |\n","|    time_elapsed    | 1129   |\n","|    total_timesteps | 346112 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 170           |\n","|    time_elapsed         | 1134          |\n","|    total_timesteps      | 348160        |\n","| train/                  |               |\n","|    approx_kl            | 1.9811414e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.284        |\n","|    explained_variance   | 0.538         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.84e+04      |\n","|    n_updates            | 1690          |\n","|    policy_gradient_loss | -9.27e-05     |\n","|    value_loss           | 6.09e+04      |\n","-------------------------------------------\n","Eval num_timesteps=350000, episode_reward=17894.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.79e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 350000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00011910434 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.298        |\n","|    explained_variance   | 0.342         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.2e+05       |\n","|    n_updates            | 1700          |\n","|    policy_gradient_loss | -0.000643     |\n","|    value_loss           | 2.91e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 305    |\n","|    iterations      | 171    |\n","|    time_elapsed    | 1145   |\n","|    total_timesteps | 350208 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 172           |\n","|    time_elapsed         | 1148          |\n","|    total_timesteps      | 352256        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012621921 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.358        |\n","|    explained_variance   | 0.546         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.76e+04      |\n","|    n_updates            | 1710          |\n","|    policy_gradient_loss | -0.000431     |\n","|    value_loss           | 1.32e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 307           |\n","|    iterations           | 173           |\n","|    time_elapsed         | 1150          |\n","|    total_timesteps      | 354304        |\n","| train/                  |               |\n","|    approx_kl            | 4.0281215e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.281        |\n","|    explained_variance   | 0.6           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.87e+04      |\n","|    n_updates            | 1720          |\n","|    policy_gradient_loss | -4e-05        |\n","|    value_loss           | 5.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=355000, episode_reward=18218.26 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.82e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 355000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014858271 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.308        |\n","|    explained_variance   | 0.442         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.62e+04      |\n","|    n_updates            | 1730          |\n","|    policy_gradient_loss | -0.00021      |\n","|    value_loss           | 6.98e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 307    |\n","|    iterations      | 174    |\n","|    time_elapsed    | 1157   |\n","|    total_timesteps | 356352 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 308           |\n","|    iterations           | 175           |\n","|    time_elapsed         | 1160          |\n","|    total_timesteps      | 358400        |\n","| train/                  |               |\n","|    approx_kl            | 0.00048016125 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.296        |\n","|    explained_variance   | 0.581         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.23e+04      |\n","|    n_updates            | 1740          |\n","|    policy_gradient_loss | -0.00103      |\n","|    value_loss           | 8.21e+04      |\n","-------------------------------------------\n","Eval num_timesteps=360000, episode_reward=18858.42 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.89e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 360000        |\n","| train/                  |               |\n","|    approx_kl            | 1.9397907e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.266        |\n","|    explained_variance   | 0.625         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.65e+04      |\n","|    n_updates            | 1750          |\n","|    policy_gradient_loss | -0.000266     |\n","|    value_loss           | 4.88e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 308    |\n","|    iterations      | 176    |\n","|    time_elapsed    | 1166   |\n","|    total_timesteps | 360448 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 177           |\n","|    time_elapsed         | 1169          |\n","|    total_timesteps      | 362496        |\n","| train/                  |               |\n","|    approx_kl            | 1.9970263e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.296        |\n","|    explained_variance   | 0.342         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.14e+04      |\n","|    n_updates            | 1760          |\n","|    policy_gradient_loss | -7.26e-05     |\n","|    value_loss           | 1.8e+05       |\n","-------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 310         |\n","|    iterations           | 178         |\n","|    time_elapsed         | 1172        |\n","|    total_timesteps      | 364544      |\n","| train/                  |             |\n","|    approx_kl            | 7.02336e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.364      |\n","|    explained_variance   | 0.504       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 4.43e+04    |\n","|    n_updates            | 1770        |\n","|    policy_gradient_loss | -0.00034    |\n","|    value_loss           | 9.31e+04    |\n","-----------------------------------------\n","Eval num_timesteps=365000, episode_reward=18587.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.86e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 365000       |\n","| train/                  |              |\n","|    approx_kl            | 3.852634e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.548        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.67e+04     |\n","|    n_updates            | 1780         |\n","|    policy_gradient_loss | -0.000412    |\n","|    value_loss           | 6.11e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 179    |\n","|    time_elapsed    | 1180   |\n","|    total_timesteps | 366592 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 180          |\n","|    time_elapsed         | 1183         |\n","|    total_timesteps      | 368640       |\n","| train/                  |              |\n","|    approx_kl            | 9.340781e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.341       |\n","|    explained_variance   | 0.617        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.99e+04     |\n","|    n_updates            | 1790         |\n","|    policy_gradient_loss | -0.000253    |\n","|    value_loss           | 6.38e+04     |\n","------------------------------------------\n","Eval num_timesteps=370000, episode_reward=17191.57 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.72e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 370000        |\n","| train/                  |               |\n","|    approx_kl            | 1.6983395e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.255        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 1800          |\n","|    policy_gradient_loss | -6.85e-05     |\n","|    value_loss           | 5.37e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 181    |\n","|    time_elapsed    | 1189   |\n","|    total_timesteps | 370688 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 182           |\n","|    time_elapsed         | 1192          |\n","|    total_timesteps      | 372736        |\n","| train/                  |               |\n","|    approx_kl            | 0.00053126283 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.279        |\n","|    explained_variance   | 0.691         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.96e+04      |\n","|    n_updates            | 1810          |\n","|    policy_gradient_loss | -0.00119      |\n","|    value_loss           | 6.78e+04      |\n","-------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 313        |\n","|    iterations           | 183        |\n","|    time_elapsed         | 1194       |\n","|    total_timesteps      | 374784     |\n","| train/                  |            |\n","|    approx_kl            | 6.0038e-06 |\n","|    clip_fraction        | 0          |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.297     |\n","|    explained_variance   | 0.294      |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 1.87e+05   |\n","|    n_updates            | 1820       |\n","|    policy_gradient_loss | -8.88e-05  |\n","|    value_loss           | 2.8e+05    |\n","----------------------------------------\n","Eval num_timesteps=375000, episode_reward=16912.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.69e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 375000        |\n","| train/                  |               |\n","|    approx_kl            | 1.6123202e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.339        |\n","|    explained_variance   | 0.526         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.86e+04      |\n","|    n_updates            | 1830          |\n","|    policy_gradient_loss | -0.000187     |\n","|    value_loss           | 1.15e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 184    |\n","|    time_elapsed    | 1202   |\n","|    total_timesteps | 376832 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 185           |\n","|    time_elapsed         | 1205          |\n","|    total_timesteps      | 378880        |\n","| train/                  |               |\n","|    approx_kl            | 0.00021144105 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.237        |\n","|    explained_variance   | 0.732         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.61e+04      |\n","|    n_updates            | 1840          |\n","|    policy_gradient_loss | -0.00056      |\n","|    value_loss           | 5.03e+04      |\n","-------------------------------------------\n","Eval num_timesteps=380000, episode_reward=18624.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.86e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 380000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0003892654 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.363       |\n","|    explained_variance   | 0.591        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.44e+04     |\n","|    n_updates            | 1850         |\n","|    policy_gradient_loss | -0.00045     |\n","|    value_loss           | 5.53e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 186    |\n","|    time_elapsed    | 1220   |\n","|    total_timesteps | 380928 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 187          |\n","|    time_elapsed         | 1225         |\n","|    total_timesteps      | 382976       |\n","| train/                  |              |\n","|    approx_kl            | 9.638397e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.223       |\n","|    explained_variance   | 0.652        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.01e+04     |\n","|    n_updates            | 1860         |\n","|    policy_gradient_loss | -0.000277    |\n","|    value_loss           | 6.73e+04     |\n","------------------------------------------\n","Eval num_timesteps=385000, episode_reward=17626.52 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.76e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 385000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00048715709 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.315        |\n","|    explained_variance   | 0.459         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.31e+04      |\n","|    n_updates            | 1870          |\n","|    policy_gradient_loss | -0.000932     |\n","|    value_loss           | 5.95e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 188    |\n","|    time_elapsed    | 1243   |\n","|    total_timesteps | 385024 |\n","-------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 310         |\n","|    iterations           | 189         |\n","|    time_elapsed         | 1248        |\n","|    total_timesteps      | 387072      |\n","| train/                  |             |\n","|    approx_kl            | 0.000229131 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.297      |\n","|    explained_variance   | 0.374       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.13e+05    |\n","|    n_updates            | 1880        |\n","|    policy_gradient_loss | -0.000597   |\n","|    value_loss           | 2.69e+05    |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 190          |\n","|    time_elapsed         | 1251         |\n","|    total_timesteps      | 389120       |\n","| train/                  |              |\n","|    approx_kl            | 1.028119e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.304       |\n","|    explained_variance   | 0.639        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.91e+04     |\n","|    n_updates            | 1890         |\n","|    policy_gradient_loss | -0.000133    |\n","|    value_loss           | 8.35e+04     |\n","------------------------------------------\n","Eval num_timesteps=390000, episode_reward=18765.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 390000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00031016083 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.275        |\n","|    explained_variance   | 0.533         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.8e+04       |\n","|    n_updates            | 1900          |\n","|    policy_gradient_loss | -0.000332     |\n","|    value_loss           | 1.12e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 191    |\n","|    time_elapsed    | 1261   |\n","|    total_timesteps | 391168 |\n","-------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 310            |\n","|    iterations           | 192            |\n","|    time_elapsed         | 1264           |\n","|    total_timesteps      | 393216         |\n","| train/                  |                |\n","|    approx_kl            | 1.20959885e-05 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.334         |\n","|    explained_variance   | 0.53           |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.89e+04       |\n","|    n_updates            | 1910           |\n","|    policy_gradient_loss | -0.00014       |\n","|    value_loss           | 6.17e+04       |\n","--------------------------------------------\n","Eval num_timesteps=395000, episode_reward=18765.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 395000       |\n","| train/                  |              |\n","|    approx_kl            | 3.157393e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.263       |\n","|    explained_variance   | 0.616        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.18e+04     |\n","|    n_updates            | 1920         |\n","|    policy_gradient_loss | -7.97e-05    |\n","|    value_loss           | 5.6e+04      |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 193    |\n","|    time_elapsed    | 1274   |\n","|    total_timesteps | 395264 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 194           |\n","|    time_elapsed         | 1279          |\n","|    total_timesteps      | 397312        |\n","| train/                  |               |\n","|    approx_kl            | 3.7042977e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.289        |\n","|    explained_variance   | 0.388         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.76e+04      |\n","|    n_updates            | 1930          |\n","|    policy_gradient_loss | -9.11e-05     |\n","|    value_loss           | 7.03e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 195           |\n","|    time_elapsed         | 1284          |\n","|    total_timesteps      | 399360        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014935847 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.346        |\n","|    explained_variance   | 0.47          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.59e+04      |\n","|    n_updates            | 1940          |\n","|    policy_gradient_loss | -0.00026      |\n","|    value_loss           | 2.97e+05      |\n","-------------------------------------------\n","Eval num_timesteps=400000, episode_reward=18874.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.89e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 400000        |\n","| train/                  |               |\n","|    approx_kl            | 2.5569461e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.246        |\n","|    explained_variance   | 0.622         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.93e+04      |\n","|    n_updates            | 1950          |\n","|    policy_gradient_loss | -2.88e-05     |\n","|    value_loss           | 7.2e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 308    |\n","|    iterations      | 196    |\n","|    time_elapsed    | 1299   |\n","|    total_timesteps | 401408 |\n","-------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 309         |\n","|    iterations           | 197         |\n","|    time_elapsed         | 1304        |\n","|    total_timesteps      | 403456      |\n","| train/                  |             |\n","|    approx_kl            | 8.14331e-06 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.294      |\n","|    explained_variance   | 0.66        |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.27e+04    |\n","|    n_updates            | 1960        |\n","|    policy_gradient_loss | -3.38e-05   |\n","|    value_loss           | 7.86e+04    |\n","-----------------------------------------\n","Eval num_timesteps=405000, episode_reward=18996.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.9e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 405000       |\n","| train/                  |              |\n","|    approx_kl            | 3.530775e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.338       |\n","|    explained_variance   | 0.689        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.76e+04     |\n","|    n_updates            | 1970         |\n","|    policy_gradient_loss | -0.000286    |\n","|    value_loss           | 6.82e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 308    |\n","|    iterations      | 198    |\n","|    time_elapsed    | 1315   |\n","|    total_timesteps | 405504 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 199           |\n","|    time_elapsed         | 1318          |\n","|    total_timesteps      | 407552        |\n","| train/                  |               |\n","|    approx_kl            | 0.00035395494 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.257        |\n","|    explained_variance   | 0.648         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.88e+04      |\n","|    n_updates            | 1980          |\n","|    policy_gradient_loss | -0.000444     |\n","|    value_loss           | 4.97e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 200           |\n","|    time_elapsed         | 1321          |\n","|    total_timesteps      | 409600        |\n","| train/                  |               |\n","|    approx_kl            | 3.7662074e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.293        |\n","|    explained_variance   | 0.536         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.34e+04      |\n","|    n_updates            | 1990          |\n","|    policy_gradient_loss | -0.00011      |\n","|    value_loss           | 1.32e+05      |\n","-------------------------------------------\n","Eval num_timesteps=410000, episode_reward=17428.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.74e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 410000      |\n","| train/                  |             |\n","|    approx_kl            | 6.11766e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.343      |\n","|    explained_variance   | 0.457       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 6.54e+04    |\n","|    n_updates            | 2000        |\n","|    policy_gradient_loss | -0.000262   |\n","|    value_loss           | 2.53e+05    |\n","-----------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 201    |\n","|    time_elapsed    | 1331   |\n","|    total_timesteps | 411648 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 202           |\n","|    time_elapsed         | 1334          |\n","|    total_timesteps      | 413696        |\n","| train/                  |               |\n","|    approx_kl            | 0.00026955537 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.243        |\n","|    explained_variance   | 0.617         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.7e+04       |\n","|    n_updates            | 2010          |\n","|    policy_gradient_loss | -0.000523     |\n","|    value_loss           | 7.57e+04      |\n","-------------------------------------------\n","Eval num_timesteps=415000, episode_reward=20094.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 415000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00022956016 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.303        |\n","|    explained_variance   | 0.513         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.44e+04      |\n","|    n_updates            | 2020          |\n","|    policy_gradient_loss | -0.000449     |\n","|    value_loss           | 7.71e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 307    |\n","|    iterations      | 203    |\n","|    time_elapsed    | 1350   |\n","|    total_timesteps | 415744 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 308           |\n","|    iterations           | 204           |\n","|    time_elapsed         | 1354          |\n","|    total_timesteps      | 417792        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014924753 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.301        |\n","|    explained_variance   | 0.655         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 2030          |\n","|    policy_gradient_loss | -0.000357     |\n","|    value_loss           | 5.3e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 205           |\n","|    time_elapsed         | 1358          |\n","|    total_timesteps      | 419840        |\n","| train/                  |               |\n","|    approx_kl            | 7.9844816e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.279        |\n","|    explained_variance   | 0.464         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.91e+04      |\n","|    n_updates            | 2040          |\n","|    policy_gradient_loss | -0.00023      |\n","|    value_loss           | 7.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=420000, episode_reward=19980.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2e+04        |\n","| time/                   |              |\n","|    total_timesteps      | 420000       |\n","| train/                  |              |\n","|    approx_kl            | 8.641538e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.276       |\n","|    explained_variance   | 0.37         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.56e+04     |\n","|    n_updates            | 2050         |\n","|    policy_gradient_loss | -4.22e-05    |\n","|    value_loss           | 2.08e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 307    |\n","|    iterations      | 206    |\n","|    time_elapsed    | 1371   |\n","|    total_timesteps | 421888 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 308           |\n","|    iterations           | 207           |\n","|    time_elapsed         | 1375          |\n","|    total_timesteps      | 423936        |\n","| train/                  |               |\n","|    approx_kl            | 0.00034483295 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.337        |\n","|    explained_variance   | 0.573         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.42e+04      |\n","|    n_updates            | 2060          |\n","|    policy_gradient_loss | -0.000767     |\n","|    value_loss           | 1.06e+05      |\n","-------------------------------------------\n","Eval num_timesteps=425000, episode_reward=20834.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.08e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 425000       |\n","| train/                  |              |\n","|    approx_kl            | 4.770342e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.271       |\n","|    explained_variance   | 0.626        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.68e+04     |\n","|    n_updates            | 2070         |\n","|    policy_gradient_loss | -0.000151    |\n","|    value_loss           | 6.25e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 306    |\n","|    iterations      | 208    |\n","|    time_elapsed    | 1387   |\n","|    total_timesteps | 425984 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 209           |\n","|    time_elapsed         | 1394          |\n","|    total_timesteps      | 428032        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012244936 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.299        |\n","|    explained_variance   | 0.557         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.82e+04      |\n","|    n_updates            | 2080          |\n","|    policy_gradient_loss | -0.000407     |\n","|    value_loss           | 1.16e+05      |\n","-------------------------------------------\n","Eval num_timesteps=430000, episode_reward=20837.41 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 430000        |\n","| train/                  |               |\n","|    approx_kl            | 8.9585985e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.287        |\n","|    explained_variance   | 0.732         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.36e+04      |\n","|    n_updates            | 2090          |\n","|    policy_gradient_loss | -0.00028      |\n","|    value_loss           | 6.22e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 305    |\n","|    iterations      | 210    |\n","|    time_elapsed    | 1405   |\n","|    total_timesteps | 430080 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 306          |\n","|    iterations           | 211          |\n","|    time_elapsed         | 1409         |\n","|    total_timesteps      | 432128       |\n","| train/                  |              |\n","|    approx_kl            | 7.980241e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.261       |\n","|    explained_variance   | 0.558        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+04     |\n","|    n_updates            | 2100         |\n","|    policy_gradient_loss | -0.00029     |\n","|    value_loss           | 6.61e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 307           |\n","|    iterations           | 212           |\n","|    time_elapsed         | 1413          |\n","|    total_timesteps      | 434176        |\n","| train/                  |               |\n","|    approx_kl            | 1.0665564e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.251        |\n","|    explained_variance   | 0.395         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.94e+04      |\n","|    n_updates            | 2110          |\n","|    policy_gradient_loss | -0.000146     |\n","|    value_loss           | 2.49e+05      |\n","-------------------------------------------\n","Eval num_timesteps=435000, episode_reward=20192.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 435000        |\n","| train/                  |               |\n","|    approx_kl            | 9.9155295e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.364        |\n","|    explained_variance   | 0.542         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.97e+04      |\n","|    n_updates            | 2120          |\n","|    policy_gradient_loss | -0.000123     |\n","|    value_loss           | 1.11e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 306    |\n","|    iterations      | 213    |\n","|    time_elapsed    | 1423   |\n","|    total_timesteps | 436224 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 214           |\n","|    time_elapsed         | 1427          |\n","|    total_timesteps      | 438272        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019031385 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.237        |\n","|    explained_variance   | 0.659         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 2130          |\n","|    policy_gradient_loss | -0.000453     |\n","|    value_loss           | 4.55e+04      |\n","-------------------------------------------\n","Eval num_timesteps=440000, episode_reward=19619.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 440000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00024556305 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.333        |\n","|    explained_variance   | 0.485         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.01e+04      |\n","|    n_updates            | 2140          |\n","|    policy_gradient_loss | -0.000207     |\n","|    value_loss           | 7.48e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 305    |\n","|    iterations      | 215    |\n","|    time_elapsed    | 1440   |\n","|    total_timesteps | 440320 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 305           |\n","|    iterations           | 216           |\n","|    time_elapsed         | 1445          |\n","|    total_timesteps      | 442368        |\n","| train/                  |               |\n","|    approx_kl            | 0.00042995263 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.253        |\n","|    explained_variance   | 0.597         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 2150          |\n","|    policy_gradient_loss | -0.000415     |\n","|    value_loss           | 5.02e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 217           |\n","|    time_elapsed         | 1451          |\n","|    total_timesteps      | 444416        |\n","| train/                  |               |\n","|    approx_kl            | 0.00058639667 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.253        |\n","|    explained_variance   | 0.643         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.14e+04      |\n","|    n_updates            | 2160          |\n","|    policy_gradient_loss | -0.00111      |\n","|    value_loss           | 4.73e+04      |\n","-------------------------------------------\n","Eval num_timesteps=445000, episode_reward=19676.20 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.97e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 445000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001041955 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.274       |\n","|    explained_variance   | 0.445        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.06e+05     |\n","|    n_updates            | 2170         |\n","|    policy_gradient_loss | -0.000194    |\n","|    value_loss           | 2.92e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 304    |\n","|    iterations      | 218    |\n","|    time_elapsed    | 1464   |\n","|    total_timesteps | 446464 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 305           |\n","|    iterations           | 219           |\n","|    time_elapsed         | 1468          |\n","|    total_timesteps      | 448512        |\n","| train/                  |               |\n","|    approx_kl            | 1.4841848e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.34         |\n","|    explained_variance   | 0.601         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.77e+04      |\n","|    n_updates            | 2180          |\n","|    policy_gradient_loss | -0.000105     |\n","|    value_loss           | 7.44e+04      |\n","-------------------------------------------\n","Eval num_timesteps=450000, episode_reward=19565.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 450000        |\n","| train/                  |               |\n","|    approx_kl            | 6.5858476e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.237        |\n","|    explained_variance   | 0.717         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.15e+04      |\n","|    n_updates            | 2190          |\n","|    policy_gradient_loss | -0.000313     |\n","|    value_loss           | 6.05e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 304    |\n","|    iterations      | 220    |\n","|    time_elapsed    | 1477   |\n","|    total_timesteps | 450560 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 305           |\n","|    iterations           | 221           |\n","|    time_elapsed         | 1480          |\n","|    total_timesteps      | 452608        |\n","| train/                  |               |\n","|    approx_kl            | 3.9293547e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.348        |\n","|    explained_variance   | 0.609         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.5e+04       |\n","|    n_updates            | 2200          |\n","|    policy_gradient_loss | -0.000111     |\n","|    value_loss           | 9.88e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 222           |\n","|    time_elapsed         | 1483          |\n","|    total_timesteps      | 454656        |\n","| train/                  |               |\n","|    approx_kl            | 5.1504816e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.227        |\n","|    explained_variance   | 0.711         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 2210          |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 5.27e+04      |\n","-------------------------------------------\n","Eval num_timesteps=455000, episode_reward=20270.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.03e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 455000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001076755 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.289       |\n","|    explained_variance   | 0.634        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.94e+04     |\n","|    n_updates            | 2220         |\n","|    policy_gradient_loss | -0.000292    |\n","|    value_loss           | 4.34e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 306    |\n","|    iterations      | 223    |\n","|    time_elapsed    | 1492   |\n","|    total_timesteps | 456704 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 306           |\n","|    iterations           | 224           |\n","|    time_elapsed         | 1496          |\n","|    total_timesteps      | 458752        |\n","| train/                  |               |\n","|    approx_kl            | 2.9680348e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.271        |\n","|    explained_variance   | 0.298         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.73e+04      |\n","|    n_updates            | 2230          |\n","|    policy_gradient_loss | -0.000237     |\n","|    value_loss           | 2.14e+05      |\n","-------------------------------------------\n","Eval num_timesteps=460000, episode_reward=19676.20 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.97e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 460000       |\n","| train/                  |              |\n","|    approx_kl            | 1.678834e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.303       |\n","|    explained_variance   | 0.688        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.33e+04     |\n","|    n_updates            | 2240         |\n","|    policy_gradient_loss | -0.000174    |\n","|    value_loss           | 8.71e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 306    |\n","|    iterations      | 225    |\n","|    time_elapsed    | 1505   |\n","|    total_timesteps | 460800 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 306          |\n","|    iterations           | 226          |\n","|    time_elapsed         | 1508         |\n","|    total_timesteps      | 462848       |\n","| train/                  |              |\n","|    approx_kl            | 9.768954e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.246       |\n","|    explained_variance   | 0.712        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.81e+04     |\n","|    n_updates            | 2250         |\n","|    policy_gradient_loss | -0.000152    |\n","|    value_loss           | 8.4e+04      |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 307           |\n","|    iterations           | 227           |\n","|    time_elapsed         | 1512          |\n","|    total_timesteps      | 464896        |\n","| train/                  |               |\n","|    approx_kl            | 0.00025107004 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.331        |\n","|    explained_variance   | 0.626         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 2260          |\n","|    policy_gradient_loss | -0.000514     |\n","|    value_loss           | 7.5e+04       |\n","-------------------------------------------\n","Eval num_timesteps=465000, episode_reward=19036.82 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.9e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 465000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005715532 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.699        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.15e+04     |\n","|    n_updates            | 2270         |\n","|    policy_gradient_loss | -0.000576    |\n","|    value_loss           | 4.52e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 307    |\n","|    iterations      | 228    |\n","|    time_elapsed    | 1520   |\n","|    total_timesteps | 466944 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 307          |\n","|    iterations           | 229          |\n","|    time_elapsed         | 1523         |\n","|    total_timesteps      | 468992       |\n","| train/                  |              |\n","|    approx_kl            | 8.297086e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.265       |\n","|    explained_variance   | 0.586        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.95e+04     |\n","|    n_updates            | 2280         |\n","|    policy_gradient_loss | -0.000266    |\n","|    value_loss           | 5.56e+04     |\n","------------------------------------------\n","Eval num_timesteps=470000, episode_reward=19247.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 470000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010191492 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.309        |\n","|    explained_variance   | 0.377         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.71e+04      |\n","|    n_updates            | 2290          |\n","|    policy_gradient_loss | -0.000418     |\n","|    value_loss           | 1.81e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 307    |\n","|    iterations      | 230    |\n","|    time_elapsed    | 1530   |\n","|    total_timesteps | 471040 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 308           |\n","|    iterations           | 231           |\n","|    time_elapsed         | 1532          |\n","|    total_timesteps      | 473088        |\n","| train/                  |               |\n","|    approx_kl            | 0.00017732778 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.25         |\n","|    explained_variance   | 0.483         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.68e+04      |\n","|    n_updates            | 2300          |\n","|    policy_gradient_loss | -0.000343     |\n","|    value_loss           | 7.7e+04       |\n","-------------------------------------------\n","Eval num_timesteps=475000, episode_reward=19247.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 475000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00031288757 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.252        |\n","|    explained_variance   | 0.541         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.06e+04      |\n","|    n_updates            | 2310          |\n","|    policy_gradient_loss | -0.000194     |\n","|    value_loss           | 8.8e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 308    |\n","|    iterations      | 232    |\n","|    time_elapsed    | 1540   |\n","|    total_timesteps | 475136 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 233           |\n","|    time_elapsed         | 1543          |\n","|    total_timesteps      | 477184        |\n","| train/                  |               |\n","|    approx_kl            | 3.5142555e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.346        |\n","|    explained_variance   | 0.636         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.36e+04      |\n","|    n_updates            | 2320          |\n","|    policy_gradient_loss | -0.000349     |\n","|    value_loss           | 6.02e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 234          |\n","|    time_elapsed         | 1545         |\n","|    total_timesteps      | 479232       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005187829 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.212       |\n","|    explained_variance   | 0.687        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.4e+04      |\n","|    n_updates            | 2330         |\n","|    policy_gradient_loss | -0.000665    |\n","|    value_loss           | 4.49e+04     |\n","------------------------------------------\n","Eval num_timesteps=480000, episode_reward=18816.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 480000        |\n","| train/                  |               |\n","|    approx_kl            | 6.5171975e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.274        |\n","|    explained_variance   | 0.686         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.45e+04      |\n","|    n_updates            | 2340          |\n","|    policy_gradient_loss | -0.000192     |\n","|    value_loss           | 9.44e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 235    |\n","|    time_elapsed    | 1552   |\n","|    total_timesteps | 481280 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 236           |\n","|    time_elapsed         | 1554          |\n","|    total_timesteps      | 483328        |\n","| train/                  |               |\n","|    approx_kl            | 2.0325242e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.332        |\n","|    explained_variance   | 0.6           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.1e+04       |\n","|    n_updates            | 2350          |\n","|    policy_gradient_loss | -3.44e-05     |\n","|    value_loss           | 1.83e+05      |\n","-------------------------------------------\n","Eval num_timesteps=485000, episode_reward=18816.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 485000        |\n","| train/                  |               |\n","|    approx_kl            | 2.7247763e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.213        |\n","|    explained_variance   | 0.695         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.34e+04      |\n","|    n_updates            | 2360          |\n","|    policy_gradient_loss | -0.000228     |\n","|    value_loss           | 7.59e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 237    |\n","|    time_elapsed    | 1562   |\n","|    total_timesteps | 485376 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 238          |\n","|    time_elapsed         | 1565         |\n","|    total_timesteps      | 487424       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002458674 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.283       |\n","|    explained_variance   | 0.661        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.23e+04     |\n","|    n_updates            | 2370         |\n","|    policy_gradient_loss | -0.000501    |\n","|    value_loss           | 7.59e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 239           |\n","|    time_elapsed         | 1568          |\n","|    total_timesteps      | 489472        |\n","| train/                  |               |\n","|    approx_kl            | 1.5093305e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.298        |\n","|    explained_variance   | 0.739         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.87e+04      |\n","|    n_updates            | 2380          |\n","|    policy_gradient_loss | -9.52e-05     |\n","|    value_loss           | 4.84e+04      |\n","-------------------------------------------\n","Eval num_timesteps=490000, episode_reward=20441.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 490000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00018282488 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.247        |\n","|    explained_variance   | 0.568         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.34e+04      |\n","|    n_updates            | 2390          |\n","|    policy_gradient_loss | -0.000281     |\n","|    value_loss           | 5.07e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 240    |\n","|    time_elapsed    | 1577   |\n","|    total_timesteps | 491520 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 241           |\n","|    time_elapsed         | 1580          |\n","|    total_timesteps      | 493568        |\n","| train/                  |               |\n","|    approx_kl            | 3.9743492e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.235        |\n","|    explained_variance   | 0.544         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.36e+04      |\n","|    n_updates            | 2400          |\n","|    policy_gradient_loss | -0.000186     |\n","|    value_loss           | 1.04e+05      |\n","-------------------------------------------\n","Eval num_timesteps=495000, episode_reward=20096.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.01e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 495000       |\n","| train/                  |              |\n","|    approx_kl            | 5.612246e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.326       |\n","|    explained_variance   | 0.648        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.6e+04      |\n","|    n_updates            | 2410         |\n","|    policy_gradient_loss | -0.000214    |\n","|    value_loss           | 1.06e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 242    |\n","|    time_elapsed    | 1588   |\n","|    total_timesteps | 495616 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 243           |\n","|    time_elapsed         | 1591          |\n","|    total_timesteps      | 497664        |\n","| train/                  |               |\n","|    approx_kl            | 4.8142625e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.243        |\n","|    explained_variance   | 0.596         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.81e+04      |\n","|    n_updates            | 2420          |\n","|    policy_gradient_loss | -0.000151     |\n","|    value_loss           | 4.65e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 313          |\n","|    iterations           | 244          |\n","|    time_elapsed         | 1595         |\n","|    total_timesteps      | 499712       |\n","| train/                  |              |\n","|    approx_kl            | 0.0003643609 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.273       |\n","|    explained_variance   | 0.606        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.51e+04     |\n","|    n_updates            | 2430         |\n","|    policy_gradient_loss | -0.000251    |\n","|    value_loss           | 8.39e+04     |\n","------------------------------------------\n","Eval num_timesteps=500000, episode_reward=20440.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 500000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00013028059 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.275        |\n","|    explained_variance   | 0.782         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.87e+04      |\n","|    n_updates            | 2440          |\n","|    policy_gradient_loss | -0.000255     |\n","|    value_loss           | 5.29e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 245    |\n","|    time_elapsed    | 1605   |\n","|    total_timesteps | 501760 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 246           |\n","|    time_elapsed         | 1610          |\n","|    total_timesteps      | 503808        |\n","| train/                  |               |\n","|    approx_kl            | 8.9414796e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.237        |\n","|    explained_variance   | 0.608         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 2450          |\n","|    policy_gradient_loss | -0.000242     |\n","|    value_loss           | 5.11e+04      |\n","-------------------------------------------\n","Eval num_timesteps=505000, episode_reward=23115.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.31e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 505000        |\n","| train/                  |               |\n","|    approx_kl            | 2.2425578e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.454         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.38e+04      |\n","|    n_updates            | 2460          |\n","|    policy_gradient_loss | -7.43e-05     |\n","|    value_loss           | 1.78e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 247    |\n","|    time_elapsed    | 1629   |\n","|    total_timesteps | 505856 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 248           |\n","|    time_elapsed         | 1632          |\n","|    total_timesteps      | 507904        |\n","| train/                  |               |\n","|    approx_kl            | 0.00043973644 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.34         |\n","|    explained_variance   | 0.574         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.07e+04      |\n","|    n_updates            | 2470          |\n","|    policy_gradient_loss | -0.000931     |\n","|    value_loss           | 1.06e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 249          |\n","|    time_elapsed         | 1635         |\n","|    total_timesteps      | 509952       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005426656 |\n","|    clip_fraction        | 0.00381      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.23        |\n","|    explained_variance   | 0.546        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.89e+04     |\n","|    n_updates            | 2480         |\n","|    policy_gradient_loss | -0.00168     |\n","|    value_loss           | 3.55e+04     |\n","------------------------------------------\n","Eval num_timesteps=510000, episode_reward=19565.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.96e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 510000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0004537453 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.311       |\n","|    explained_variance   | 0.495        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.75e+04     |\n","|    n_updates            | 2490         |\n","|    policy_gradient_loss | -0.000506    |\n","|    value_loss           | 7.33e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 250    |\n","|    time_elapsed    | 1643   |\n","|    total_timesteps | 512000 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 251           |\n","|    time_elapsed         | 1647          |\n","|    total_timesteps      | 514048        |\n","| train/                  |               |\n","|    approx_kl            | 1.6246515e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.245        |\n","|    explained_variance   | 0.582         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.96e+04      |\n","|    n_updates            | 2500          |\n","|    policy_gradient_loss | 2.59e-05      |\n","|    value_loss           | 5e+04         |\n","-------------------------------------------\n","Eval num_timesteps=515000, episode_reward=18857.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.89e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 515000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016869095 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.234        |\n","|    explained_variance   | 0.505         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.6e+04       |\n","|    n_updates            | 2510          |\n","|    policy_gradient_loss | -0.00027      |\n","|    value_loss           | 4.97e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 252    |\n","|    time_elapsed    | 1655   |\n","|    total_timesteps | 516096 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 253           |\n","|    time_elapsed         | 1657          |\n","|    total_timesteps      | 518144        |\n","| train/                  |               |\n","|    approx_kl            | 2.3836328e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.243        |\n","|    explained_variance   | 0.383         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.6e+05       |\n","|    n_updates            | 2520          |\n","|    policy_gradient_loss | -1.51e-05     |\n","|    value_loss           | 1.82e+05      |\n","-------------------------------------------\n","Eval num_timesteps=520000, episode_reward=19749.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 520000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00033763493 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.331        |\n","|    explained_variance   | 0.667         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.63e+04      |\n","|    n_updates            | 2530          |\n","|    policy_gradient_loss | -0.000818     |\n","|    value_loss           | 9.85e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 254    |\n","|    time_elapsed    | 1666   |\n","|    total_timesteps | 520192 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 255           |\n","|    time_elapsed         | 1670          |\n","|    total_timesteps      | 522240        |\n","| train/                  |               |\n","|    approx_kl            | 5.5431767e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.226        |\n","|    explained_variance   | 0.436         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.84e+04      |\n","|    n_updates            | 2540          |\n","|    policy_gradient_loss | -9.44e-05     |\n","|    value_loss           | 6.22e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 256           |\n","|    time_elapsed         | 1674          |\n","|    total_timesteps      | 524288        |\n","| train/                  |               |\n","|    approx_kl            | 8.1131584e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.322        |\n","|    explained_variance   | 0.594         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.94e+04      |\n","|    n_updates            | 2550          |\n","|    policy_gradient_loss | -0.000293     |\n","|    value_loss           | 7.91e+04      |\n","-------------------------------------------\n","Eval num_timesteps=525000, episode_reward=19098.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 525000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00013387421 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.225        |\n","|    explained_variance   | 0.497         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.97e+04      |\n","|    n_updates            | 2560          |\n","|    policy_gradient_loss | -0.00024      |\n","|    value_loss           | 4.43e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 257    |\n","|    time_elapsed    | 1687   |\n","|    total_timesteps | 526336 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 258           |\n","|    time_elapsed         | 1690          |\n","|    total_timesteps      | 528384        |\n","| train/                  |               |\n","|    approx_kl            | 5.0832954e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.273        |\n","|    explained_variance   | 0.706         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.69e+04      |\n","|    n_updates            | 2570          |\n","|    policy_gradient_loss | -0.000188     |\n","|    value_loss           | 5.52e+04      |\n","-------------------------------------------\n","Eval num_timesteps=530000, episode_reward=19676.20 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 530000        |\n","| train/                  |               |\n","|    approx_kl            | 2.0059728e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.243        |\n","|    explained_variance   | 0.578         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.94e+04      |\n","|    n_updates            | 2580          |\n","|    policy_gradient_loss | -3.66e-05     |\n","|    value_loss           | 2.04e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 259    |\n","|    time_elapsed    | 1698   |\n","|    total_timesteps | 530432 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 260           |\n","|    time_elapsed         | 1700          |\n","|    total_timesteps      | 532480        |\n","| train/                  |               |\n","|    approx_kl            | 3.2936572e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.292        |\n","|    explained_variance   | 0.567         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.99e+04      |\n","|    n_updates            | 2590          |\n","|    policy_gradient_loss | -0.000254     |\n","|    value_loss           | 8.43e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 261           |\n","|    time_elapsed         | 1704          |\n","|    total_timesteps      | 534528        |\n","| train/                  |               |\n","|    approx_kl            | 0.00023327683 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.236        |\n","|    explained_variance   | 0.196         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.53e+04      |\n","|    n_updates            | 2600          |\n","|    policy_gradient_loss | -0.000417     |\n","|    value_loss           | 8.97e+04      |\n","-------------------------------------------\n","Eval num_timesteps=535000, episode_reward=18857.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.89e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 535000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0006085589 |\n","|    clip_fraction        | 0.000879     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.326       |\n","|    explained_variance   | 0.509        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.06e+04     |\n","|    n_updates            | 2610         |\n","|    policy_gradient_loss | -0.00106     |\n","|    value_loss           | 5.53e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 262    |\n","|    time_elapsed    | 1713   |\n","|    total_timesteps | 536576 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 263           |\n","|    time_elapsed         | 1717          |\n","|    total_timesteps      | 538624        |\n","| train/                  |               |\n","|    approx_kl            | 2.7426082e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.23         |\n","|    explained_variance   | 0.464         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 2620          |\n","|    policy_gradient_loss | -7.54e-05     |\n","|    value_loss           | 5.34e+04      |\n","-------------------------------------------\n","Eval num_timesteps=540000, episode_reward=21451.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.15e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 540000      |\n","| train/                  |             |\n","|    approx_kl            | 0.001136594 |\n","|    clip_fraction        | 0.00352     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.26       |\n","|    explained_variance   | 0.643       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.04e+04    |\n","|    n_updates            | 2630        |\n","|    policy_gradient_loss | -0.00255    |\n","|    value_loss           | 5.11e+04    |\n","-----------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 264    |\n","|    time_elapsed    | 1727   |\n","|    total_timesteps | 540672 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 265           |\n","|    time_elapsed         | 1730          |\n","|    total_timesteps      | 542720        |\n","| train/                  |               |\n","|    approx_kl            | 1.6988866e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.261        |\n","|    explained_variance   | 0.404         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.39e+04      |\n","|    n_updates            | 2640          |\n","|    policy_gradient_loss | -0.000152     |\n","|    value_loss           | 2.94e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 266          |\n","|    time_elapsed         | 1734         |\n","|    total_timesteps      | 544768       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001405506 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.259       |\n","|    explained_variance   | 0.531        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.3e+04      |\n","|    n_updates            | 2650         |\n","|    policy_gradient_loss | -0.000539    |\n","|    value_loss           | 5.64e+04     |\n","------------------------------------------\n","Eval num_timesteps=545000, episode_reward=20131.73 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.01e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 545000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005475812 |\n","|    clip_fraction        | 0.000439     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.583        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.75e+04     |\n","|    n_updates            | 2660         |\n","|    policy_gradient_loss | -0.000725    |\n","|    value_loss           | 7.65e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 267    |\n","|    time_elapsed    | 1741   |\n","|    total_timesteps | 546816 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 268          |\n","|    time_elapsed         | 1743         |\n","|    total_timesteps      | 548864       |\n","| train/                  |              |\n","|    approx_kl            | 0.0004977039 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.337       |\n","|    explained_variance   | 0.682        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.29e+04     |\n","|    n_updates            | 2670         |\n","|    policy_gradient_loss | -0.000985    |\n","|    value_loss           | 5.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=550000, episode_reward=19826.70 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.98e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 550000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0008127806 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.209       |\n","|    explained_variance   | 0.571        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.14e+04     |\n","|    n_updates            | 2680         |\n","|    policy_gradient_loss | -0.000908    |\n","|    value_loss           | 3.9e+04      |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 269    |\n","|    time_elapsed    | 1751   |\n","|    total_timesteps | 550912 |\n","-------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 315         |\n","|    iterations           | 270         |\n","|    time_elapsed         | 1754        |\n","|    total_timesteps      | 552960      |\n","| train/                  |             |\n","|    approx_kl            | 1.17202e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.246      |\n","|    explained_variance   | 0.588       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.3e+04     |\n","|    n_updates            | 2690        |\n","|    policy_gradient_loss | -0.000114   |\n","|    value_loss           | 6.15e+04    |\n","-----------------------------------------\n","Eval num_timesteps=555000, episode_reward=19826.70 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.98e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 555000        |\n","| train/                  |               |\n","|    approx_kl            | 4.0402694e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.311        |\n","|    explained_variance   | 0.491         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.37e+04      |\n","|    n_updates            | 2700          |\n","|    policy_gradient_loss | -0.000138     |\n","|    value_loss           | 1.87e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 271    |\n","|    time_elapsed    | 1762   |\n","|    total_timesteps | 555008 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 272           |\n","|    time_elapsed         | 1764          |\n","|    total_timesteps      | 557056        |\n","| train/                  |               |\n","|    approx_kl            | 8.3824794e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.204        |\n","|    explained_variance   | 0.728         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.09e+04      |\n","|    n_updates            | 2710          |\n","|    policy_gradient_loss | -0.000254     |\n","|    value_loss           | 5.22e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 273           |\n","|    time_elapsed         | 1768          |\n","|    total_timesteps      | 559104        |\n","| train/                  |               |\n","|    approx_kl            | 1.7388142e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.279        |\n","|    explained_variance   | 0.669         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.81e+04      |\n","|    n_updates            | 2720          |\n","|    policy_gradient_loss | -6.37e-05     |\n","|    value_loss           | 8.69e+04      |\n","-------------------------------------------\n","Eval num_timesteps=560000, episode_reward=20491.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 560000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019390712 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.309        |\n","|    explained_variance   | 0.724         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.96e+04      |\n","|    n_updates            | 2730          |\n","|    policy_gradient_loss | -0.000476     |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 274    |\n","|    time_elapsed    | 1776   |\n","|    total_timesteps | 561152 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 275           |\n","|    time_elapsed         | 1779          |\n","|    total_timesteps      | 563200        |\n","| train/                  |               |\n","|    approx_kl            | 0.00034252473 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.232        |\n","|    explained_variance   | 0.603         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.67e+04      |\n","|    n_updates            | 2740          |\n","|    policy_gradient_loss | -0.000738     |\n","|    value_loss           | 6.79e+04      |\n","-------------------------------------------\n","Eval num_timesteps=565000, episode_reward=19456.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 565000        |\n","| train/                  |               |\n","|    approx_kl            | 4.5567285e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.21         |\n","|    explained_variance   | 0.677         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.63e+04      |\n","|    n_updates            | 2750          |\n","|    policy_gradient_loss | -6.71e-05     |\n","|    value_loss           | 7.12e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 276    |\n","|    time_elapsed    | 1786   |\n","|    total_timesteps | 565248 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 277           |\n","|    time_elapsed         | 1789          |\n","|    total_timesteps      | 567296        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019283473 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.301        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.24e+04      |\n","|    n_updates            | 2760          |\n","|    policy_gradient_loss | -0.000461     |\n","|    value_loss           | 1.16e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 278           |\n","|    time_elapsed         | 1792          |\n","|    total_timesteps      | 569344        |\n","| train/                  |               |\n","|    approx_kl            | 1.2097502e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.241        |\n","|    explained_variance   | 0.67          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.94e+04      |\n","|    n_updates            | 2770          |\n","|    policy_gradient_loss | -8.46e-05     |\n","|    value_loss           | 4.39e+04      |\n","-------------------------------------------\n","Eval num_timesteps=570000, episode_reward=17966.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 570000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00084515894 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.601         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.33e+04      |\n","|    n_updates            | 2780          |\n","|    policy_gradient_loss | -0.000808     |\n","|    value_loss           | 7.72e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 279    |\n","|    time_elapsed    | 1800   |\n","|    total_timesteps | 571392 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 280           |\n","|    time_elapsed         | 1803          |\n","|    total_timesteps      | 573440        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010020562 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.263        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 2790          |\n","|    policy_gradient_loss | -0.000228     |\n","|    value_loss           | 4.46e+04      |\n","-------------------------------------------\n","Eval num_timesteps=575000, episode_reward=18816.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 575000       |\n","| train/                  |              |\n","|    approx_kl            | 8.624545e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.587        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.03e+04     |\n","|    n_updates            | 2800         |\n","|    policy_gradient_loss | -0.000292    |\n","|    value_loss           | 4.88e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 281    |\n","|    time_elapsed    | 1810   |\n","|    total_timesteps | 575488 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 318          |\n","|    iterations           | 282          |\n","|    time_elapsed         | 1812         |\n","|    total_timesteps      | 577536       |\n","| train/                  |              |\n","|    approx_kl            | 5.078886e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.208       |\n","|    explained_variance   | 0.529        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.8e+04      |\n","|    n_updates            | 2810         |\n","|    policy_gradient_loss | -0.000265    |\n","|    value_loss           | 1.58e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 319          |\n","|    iterations           | 283          |\n","|    time_elapsed         | 1816         |\n","|    total_timesteps      | 579584       |\n","| train/                  |              |\n","|    approx_kl            | 4.225236e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.331       |\n","|    explained_variance   | 0.625        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.46e+04     |\n","|    n_updates            | 2820         |\n","|    policy_gradient_loss | -0.000124    |\n","|    value_loss           | 1.01e+05     |\n","------------------------------------------\n","Eval num_timesteps=580000, episode_reward=19523.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 580000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00036363688 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.235        |\n","|    explained_variance   | 0.592         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 2830          |\n","|    policy_gradient_loss | -0.000522     |\n","|    value_loss           | 3.67e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 318    |\n","|    iterations      | 284    |\n","|    time_elapsed    | 1828   |\n","|    total_timesteps | 581632 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 285           |\n","|    time_elapsed         | 1833          |\n","|    total_timesteps      | 583680        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012867941 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.294        |\n","|    explained_variance   | 0.458         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.18e+04      |\n","|    n_updates            | 2840          |\n","|    policy_gradient_loss | -0.000225     |\n","|    value_loss           | 7.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=585000, episode_reward=21681.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.17e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 585000        |\n","| train/                  |               |\n","|    approx_kl            | 1.5875354e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.259        |\n","|    explained_variance   | 0.566         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.08e+04      |\n","|    n_updates            | 2850          |\n","|    policy_gradient_loss | -0.000144     |\n","|    value_loss           | 6.03e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 286    |\n","|    time_elapsed    | 1846   |\n","|    total_timesteps | 585728 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 317          |\n","|    iterations           | 287          |\n","|    time_elapsed         | 1850         |\n","|    total_timesteps      | 587776       |\n","| train/                  |              |\n","|    approx_kl            | 6.196121e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.228       |\n","|    explained_variance   | 0.641        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.35e+04     |\n","|    n_updates            | 2860         |\n","|    policy_gradient_loss | -0.000542    |\n","|    value_loss           | 3.2e+04      |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 288           |\n","|    time_elapsed         | 1853          |\n","|    total_timesteps      | 589824        |\n","| train/                  |               |\n","|    approx_kl            | 0.00073467917 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.225        |\n","|    explained_variance   | 0.555         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.6e+04       |\n","|    n_updates            | 2870          |\n","|    policy_gradient_loss | -0.0014       |\n","|    value_loss           | 9.38e+04      |\n","-------------------------------------------\n","Eval num_timesteps=590000, episode_reward=19579.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.96e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 590000      |\n","| train/                  |             |\n","|    approx_kl            | 2.00879e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.333      |\n","|    explained_variance   | 0.665       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.39e+04    |\n","|    n_updates            | 2880        |\n","|    policy_gradient_loss | -8.9e-05    |\n","|    value_loss           | 7.25e+04    |\n","-----------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 289    |\n","|    time_elapsed    | 1863   |\n","|    total_timesteps | 591872 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 290           |\n","|    time_elapsed         | 1867          |\n","|    total_timesteps      | 593920        |\n","| train/                  |               |\n","|    approx_kl            | 2.7660863e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.232        |\n","|    explained_variance   | 0.605         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.18e+04      |\n","|    n_updates            | 2890          |\n","|    policy_gradient_loss | -2.12e-06     |\n","|    value_loss           | 4.78e+04      |\n","-------------------------------------------\n","Eval num_timesteps=595000, episode_reward=19955.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2e+04         |\n","| time/                   |               |\n","|    total_timesteps      | 595000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00067421753 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.316        |\n","|    explained_variance   | 0.564         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.27e+04      |\n","|    n_updates            | 2900          |\n","|    policy_gradient_loss | -0.000846     |\n","|    value_loss           | 7.46e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 291    |\n","|    time_elapsed    | 1883   |\n","|    total_timesteps | 595968 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 292           |\n","|    time_elapsed         | 1889          |\n","|    total_timesteps      | 598016        |\n","| train/                  |               |\n","|    approx_kl            | 2.0525884e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.228        |\n","|    explained_variance   | 0.441         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.11e+04      |\n","|    n_updates            | 2910          |\n","|    policy_gradient_loss | -0.000204     |\n","|    value_loss           | 4.37e+04      |\n","-------------------------------------------\n","Eval num_timesteps=600000, episode_reward=19579.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.96e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 600000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0004335881 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.261       |\n","|    explained_variance   | 0.685        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+04     |\n","|    n_updates            | 2920         |\n","|    policy_gradient_loss | -0.000693    |\n","|    value_loss           | 5.74e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 293    |\n","|    time_elapsed    | 1897   |\n","|    total_timesteps | 600064 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 294           |\n","|    time_elapsed         | 1900          |\n","|    total_timesteps      | 602112        |\n","| train/                  |               |\n","|    approx_kl            | 1.5170837e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.245        |\n","|    explained_variance   | 0.501         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.55e+05      |\n","|    n_updates            | 2930          |\n","|    policy_gradient_loss | -0.000118     |\n","|    value_loss           | 1.72e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 295           |\n","|    time_elapsed         | 1902          |\n","|    total_timesteps      | 604160        |\n","| train/                  |               |\n","|    approx_kl            | 2.1407759e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.299        |\n","|    explained_variance   | 0.61          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2e+04         |\n","|    n_updates            | 2940          |\n","|    policy_gradient_loss | -0.000262     |\n","|    value_loss           | 6.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=605000, episode_reward=19417.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.94e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 605000       |\n","| train/                  |              |\n","|    approx_kl            | 9.528594e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.227       |\n","|    explained_variance   | 0.525        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.74e+04     |\n","|    n_updates            | 2950         |\n","|    policy_gradient_loss | -7.31e-05    |\n","|    value_loss           | 8.01e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 296    |\n","|    time_elapsed    | 1909   |\n","|    total_timesteps | 606208 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 318          |\n","|    iterations           | 297          |\n","|    time_elapsed         | 1912         |\n","|    total_timesteps      | 608256       |\n","| train/                  |              |\n","|    approx_kl            | 8.443455e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.332       |\n","|    explained_variance   | 0.705        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.3e+04      |\n","|    n_updates            | 2960         |\n","|    policy_gradient_loss | -0.000275    |\n","|    value_loss           | 5.62e+04     |\n","------------------------------------------\n","Eval num_timesteps=610000, episode_reward=22783.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.28e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 610000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00047673372 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.219        |\n","|    explained_variance   | 0.579         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.14e+04      |\n","|    n_updates            | 2970          |\n","|    policy_gradient_loss | -0.000686     |\n","|    value_loss           | 3.88e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 298    |\n","|    time_elapsed    | 1919   |\n","|    total_timesteps | 610304 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 318          |\n","|    iterations           | 299          |\n","|    time_elapsed         | 1922         |\n","|    total_timesteps      | 612352       |\n","| train/                  |              |\n","|    approx_kl            | 5.423528e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.267       |\n","|    explained_variance   | 0.651        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.74e+04     |\n","|    n_updates            | 2980         |\n","|    policy_gradient_loss | -9.66e-05    |\n","|    value_loss           | 4.99e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 300           |\n","|    time_elapsed         | 1926          |\n","|    total_timesteps      | 614400        |\n","| train/                  |               |\n","|    approx_kl            | 4.4163055e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.258        |\n","|    explained_variance   | 0.562         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.76e+04      |\n","|    n_updates            | 2990          |\n","|    policy_gradient_loss | -0.000218     |\n","|    value_loss           | 1.92e+05      |\n","-------------------------------------------\n","Eval num_timesteps=615000, episode_reward=20441.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 615000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010715911 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.265        |\n","|    explained_variance   | 0.554         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.75e+04      |\n","|    n_updates            | 3000          |\n","|    policy_gradient_loss | -0.000426     |\n","|    value_loss           | 6.92e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 318    |\n","|    iterations      | 301    |\n","|    time_elapsed    | 1933   |\n","|    total_timesteps | 616448 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 319          |\n","|    iterations           | 302          |\n","|    time_elapsed         | 1937         |\n","|    total_timesteps      | 618496       |\n","| train/                  |              |\n","|    approx_kl            | 0.0004952792 |\n","|    clip_fraction        | 0.000488     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.242       |\n","|    explained_variance   | 0.458        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.16e+04     |\n","|    n_updates            | 3010         |\n","|    policy_gradient_loss | -0.00043     |\n","|    value_loss           | 6.93e+04     |\n","------------------------------------------\n","Eval num_timesteps=620000, episode_reward=17792.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.78e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 620000        |\n","| train/                  |               |\n","|    approx_kl            | 2.5151938e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.339        |\n","|    explained_variance   | 0.642         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.69e+04      |\n","|    n_updates            | 3020          |\n","|    policy_gradient_loss | -0.000254     |\n","|    value_loss           | 6.15e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 319    |\n","|    iterations      | 303    |\n","|    time_elapsed    | 1944   |\n","|    total_timesteps | 620544 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 304           |\n","|    time_elapsed         | 1947          |\n","|    total_timesteps      | 622592        |\n","| train/                  |               |\n","|    approx_kl            | 0.00062442315 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.528         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.56e+04      |\n","|    n_updates            | 3030          |\n","|    policy_gradient_loss | -0.000777     |\n","|    value_loss           | 4.28e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 320           |\n","|    iterations           | 305           |\n","|    time_elapsed         | 1951          |\n","|    total_timesteps      | 624640        |\n","| train/                  |               |\n","|    approx_kl            | 4.7175883e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.252        |\n","|    explained_variance   | 0.705         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.93e+04      |\n","|    n_updates            | 3040          |\n","|    policy_gradient_loss | -0.000238     |\n","|    value_loss           | 5.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=625000, episode_reward=18441.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 625000        |\n","| train/                  |               |\n","|    approx_kl            | 1.6955484e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.327        |\n","|    explained_variance   | 0.53          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.75e+04      |\n","|    n_updates            | 3050          |\n","|    policy_gradient_loss | -9.23e-05     |\n","|    value_loss           | 1.82e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 319    |\n","|    iterations      | 306    |\n","|    time_elapsed    | 1960   |\n","|    total_timesteps | 626688 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 320           |\n","|    iterations           | 307           |\n","|    time_elapsed         | 1964          |\n","|    total_timesteps      | 628736        |\n","| train/                  |               |\n","|    approx_kl            | 0.00029847768 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.2          |\n","|    explained_variance   | 0.568         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.73e+04      |\n","|    n_updates            | 3060          |\n","|    policy_gradient_loss | -0.00067      |\n","|    value_loss           | 7.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=630000, episode_reward=18732.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 630000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014585917 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.409         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.65e+04      |\n","|    n_updates            | 3070          |\n","|    policy_gradient_loss | -0.000191     |\n","|    value_loss           | 6.3e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 308    |\n","|    time_elapsed    | 1985   |\n","|    total_timesteps | 630784 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 309           |\n","|    time_elapsed         | 1992          |\n","|    total_timesteps      | 632832        |\n","| train/                  |               |\n","|    approx_kl            | 2.3498462e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.31         |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 3080          |\n","|    policy_gradient_loss | -0.000313     |\n","|    value_loss           | 4.83e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 310           |\n","|    time_elapsed         | 1996          |\n","|    total_timesteps      | 634880        |\n","| train/                  |               |\n","|    approx_kl            | 0.00011910545 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.241        |\n","|    explained_variance   | 0.593         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 3090          |\n","|    policy_gradient_loss | -0.000233     |\n","|    value_loss           | 3.58e+04      |\n","-------------------------------------------\n","Eval num_timesteps=635000, episode_reward=19547.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 635000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00060821685 |\n","|    clip_fraction        | 0.00161       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.229        |\n","|    explained_variance   | 0.732         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.95e+04      |\n","|    n_updates            | 3100          |\n","|    policy_gradient_loss | -0.00188      |\n","|    value_loss           | 6.49e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 311    |\n","|    time_elapsed    | 2007   |\n","|    total_timesteps | 636928 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 312           |\n","|    time_elapsed         | 2012          |\n","|    total_timesteps      | 638976        |\n","| train/                  |               |\n","|    approx_kl            | 8.6246786e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.315        |\n","|    explained_variance   | 0.616         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.2e+04       |\n","|    n_updates            | 3110          |\n","|    policy_gradient_loss | -0.000273     |\n","|    value_loss           | 1.91e+05      |\n","-------------------------------------------\n","Eval num_timesteps=640000, episode_reward=18499.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.85e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 640000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0006013506 |\n","|    clip_fraction        | 0.00161      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.235       |\n","|    explained_variance   | 0.684        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.26e+04     |\n","|    n_updates            | 3120         |\n","|    policy_gradient_loss | -0.00118     |\n","|    value_loss           | 3.66e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 313    |\n","|    time_elapsed    | 2026   |\n","|    total_timesteps | 641024 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 316          |\n","|    iterations           | 314          |\n","|    time_elapsed         | 2031         |\n","|    total_timesteps      | 643072       |\n","| train/                  |              |\n","|    approx_kl            | 0.0010380695 |\n","|    clip_fraction        | 0.00322      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.285       |\n","|    explained_variance   | 0.567        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.4e+04      |\n","|    n_updates            | 3130         |\n","|    policy_gradient_loss | -0.00144     |\n","|    value_loss           | 8.59e+04     |\n","------------------------------------------\n","Eval num_timesteps=645000, episode_reward=17733.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.77e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 645000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012321488 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.266        |\n","|    explained_variance   | 0.854         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.38e+04      |\n","|    n_updates            | 3140          |\n","|    policy_gradient_loss | -4.42e-05     |\n","|    value_loss           | 3.6e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 315    |\n","|    time_elapsed    | 2041   |\n","|    total_timesteps | 645120 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 316           |\n","|    time_elapsed         | 2045          |\n","|    total_timesteps      | 647168        |\n","| train/                  |               |\n","|    approx_kl            | 0.00042965615 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.237        |\n","|    explained_variance   | 0.489         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3e+04         |\n","|    n_updates            | 3150          |\n","|    policy_gradient_loss | -0.000595     |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 317           |\n","|    time_elapsed         | 2049          |\n","|    total_timesteps      | 649216        |\n","| train/                  |               |\n","|    approx_kl            | 3.2261567e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.221        |\n","|    explained_variance   | 0.526         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.05e+04      |\n","|    n_updates            | 3160          |\n","|    policy_gradient_loss | -0.000158     |\n","|    value_loss           | 1.93e+05      |\n","-------------------------------------------\n","Eval num_timesteps=650000, episode_reward=19135.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 650000        |\n","| train/                  |               |\n","|    approx_kl            | 1.4031975e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.326        |\n","|    explained_variance   | 0.666         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.19e+04      |\n","|    n_updates            | 3170          |\n","|    policy_gradient_loss | -9.68e-05     |\n","|    value_loss           | 9.83e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 318    |\n","|    time_elapsed    | 2059   |\n","|    total_timesteps | 651264 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 319           |\n","|    time_elapsed         | 2064          |\n","|    total_timesteps      | 653312        |\n","| train/                  |               |\n","|    approx_kl            | 0.00028333167 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.24         |\n","|    explained_variance   | 0.553         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.32e+03      |\n","|    n_updates            | 3180          |\n","|    policy_gradient_loss | -0.000452     |\n","|    value_loss           | 3.33e+04      |\n","-------------------------------------------\n","Eval num_timesteps=655000, episode_reward=17792.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.78e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 655000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00023638198 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.288        |\n","|    explained_variance   | 0.667         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.6e+04       |\n","|    n_updates            | 3190          |\n","|    policy_gradient_loss | -0.000295     |\n","|    value_loss           | 5.87e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 320    |\n","|    time_elapsed    | 2077   |\n","|    total_timesteps | 655360 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 321           |\n","|    time_elapsed         | 2081          |\n","|    total_timesteps      | 657408        |\n","| train/                  |               |\n","|    approx_kl            | 1.0092859e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.249        |\n","|    explained_variance   | 0.631         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.39e+04      |\n","|    n_updates            | 3200          |\n","|    policy_gradient_loss | -5.98e-06     |\n","|    value_loss           | 4.47e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 322           |\n","|    time_elapsed         | 2084          |\n","|    total_timesteps      | 659456        |\n","| train/                  |               |\n","|    approx_kl            | 5.0532515e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.229        |\n","|    explained_variance   | 0.635         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.2e+04       |\n","|    n_updates            | 3210          |\n","|    policy_gradient_loss | -0.000151     |\n","|    value_loss           | 4.61e+04      |\n","-------------------------------------------\n","Eval num_timesteps=660000, episode_reward=18441.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 660000        |\n","| train/                  |               |\n","|    approx_kl            | 1.0884833e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.223        |\n","|    explained_variance   | 0.599         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4e+04         |\n","|    n_updates            | 3220          |\n","|    policy_gradient_loss | -7.56e-05     |\n","|    value_loss           | 1.47e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 323    |\n","|    time_elapsed    | 2092   |\n","|    total_timesteps | 661504 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 324           |\n","|    time_elapsed         | 2095          |\n","|    total_timesteps      | 663552        |\n","| train/                  |               |\n","|    approx_kl            | 5.1491865e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.341        |\n","|    explained_variance   | 0.54          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.19e+04      |\n","|    n_updates            | 3230          |\n","|    policy_gradient_loss | -0.000272     |\n","|    value_loss           | 8.34e+04      |\n","-------------------------------------------\n","Eval num_timesteps=665000, episode_reward=17792.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.78e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 665000       |\n","| train/                  |              |\n","|    approx_kl            | 7.653635e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.219       |\n","|    explained_variance   | 0.62         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.35e+04     |\n","|    n_updates            | 3240         |\n","|    policy_gradient_loss | -0.000292    |\n","|    value_loss           | 5.27e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 325    |\n","|    time_elapsed    | 2104   |\n","|    total_timesteps | 665600 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 326           |\n","|    time_elapsed         | 2107          |\n","|    total_timesteps      | 667648        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012397318 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.32         |\n","|    explained_variance   | 0.634         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.41e+04      |\n","|    n_updates            | 3250          |\n","|    policy_gradient_loss | -0.000106     |\n","|    value_loss           | 5.71e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 327           |\n","|    time_elapsed         | 2109          |\n","|    total_timesteps      | 669696        |\n","| train/                  |               |\n","|    approx_kl            | 2.7581642e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.229        |\n","|    explained_variance   | 0.728         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.6e+03       |\n","|    n_updates            | 3260          |\n","|    policy_gradient_loss | -0.000298     |\n","|    value_loss           | 4.69e+04      |\n","-------------------------------------------\n","Eval num_timesteps=670000, episode_reward=18441.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 670000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014061597 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.251        |\n","|    explained_variance   | 0.721         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.07e+05      |\n","|    n_updates            | 3270          |\n","|    policy_gradient_loss | -0.000509     |\n","|    value_loss           | 8.62e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 328    |\n","|    time_elapsed    | 2121   |\n","|    total_timesteps | 671744 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 329           |\n","|    time_elapsed         | 2125          |\n","|    total_timesteps      | 673792        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010165671 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.235        |\n","|    explained_variance   | 0.531         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.76e+04      |\n","|    n_updates            | 3280          |\n","|    policy_gradient_loss | -0.000328     |\n","|    value_loss           | 1.89e+05      |\n","-------------------------------------------\n","Eval num_timesteps=675000, episode_reward=19199.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 675000        |\n","| train/                  |               |\n","|    approx_kl            | 7.2722876e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.298        |\n","|    explained_variance   | 0.711         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 3290          |\n","|    policy_gradient_loss | -0.00025      |\n","|    value_loss           | 5.85e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 330    |\n","|    time_elapsed    | 2139   |\n","|    total_timesteps | 675840 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 331           |\n","|    time_elapsed         | 2143          |\n","|    total_timesteps      | 677888        |\n","| train/                  |               |\n","|    approx_kl            | 0.00034369345 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.222        |\n","|    explained_variance   | 0.6           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.8e+04       |\n","|    n_updates            | 3300          |\n","|    policy_gradient_loss | -0.000168     |\n","|    value_loss           | 7.09e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 332           |\n","|    time_elapsed         | 2147          |\n","|    total_timesteps      | 679936        |\n","| train/                  |               |\n","|    approx_kl            | 0.00065722805 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.325        |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 3310          |\n","|    policy_gradient_loss | -0.000683     |\n","|    value_loss           | 4.04e+04      |\n","-------------------------------------------\n","Eval num_timesteps=680000, episode_reward=19355.39 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 680000        |\n","| train/                  |               |\n","|    approx_kl            | 1.1748751e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.228        |\n","|    explained_variance   | 0.485         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 3320          |\n","|    policy_gradient_loss | -5.14e-05     |\n","|    value_loss           | 6.75e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 333    |\n","|    time_elapsed    | 2157   |\n","|    total_timesteps | 681984 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 316          |\n","|    iterations           | 334          |\n","|    time_elapsed         | 2159         |\n","|    total_timesteps      | 684032       |\n","| train/                  |              |\n","|    approx_kl            | 6.778783e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.275       |\n","|    explained_variance   | 0.717        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.21e+04     |\n","|    n_updates            | 3330         |\n","|    policy_gradient_loss | -0.000364    |\n","|    value_loss           | 6.06e+04     |\n","------------------------------------------\n","Eval num_timesteps=685000, episode_reward=22239.16 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.22e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 685000       |\n","| train/                  |              |\n","|    approx_kl            | 5.170208e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.245       |\n","|    explained_variance   | 0.429        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1e+05        |\n","|    n_updates            | 3340         |\n","|    policy_gradient_loss | -6.75e-05    |\n","|    value_loss           | 2.5e+05      |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 335    |\n","|    time_elapsed    | 2166   |\n","|    total_timesteps | 686080 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 336           |\n","|    time_elapsed         | 2169          |\n","|    total_timesteps      | 688128        |\n","| train/                  |               |\n","|    approx_kl            | 1.8566265e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.264        |\n","|    explained_variance   | 0.656         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.37e+04      |\n","|    n_updates            | 3350          |\n","|    policy_gradient_loss | -0.000117     |\n","|    value_loss           | 5.59e+04      |\n","-------------------------------------------\n","Eval num_timesteps=690000, episode_reward=20022.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2e+04        |\n","| time/                   |              |\n","|    total_timesteps      | 690000       |\n","| train/                  |              |\n","|    approx_kl            | 5.495618e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.249       |\n","|    explained_variance   | 0.727        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.33e+04     |\n","|    n_updates            | 3360         |\n","|    policy_gradient_loss | -8.19e-05    |\n","|    value_loss           | 7.16e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 337    |\n","|    time_elapsed    | 2177   |\n","|    total_timesteps | 690176 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 338           |\n","|    time_elapsed         | 2179          |\n","|    total_timesteps      | 692224        |\n","| train/                  |               |\n","|    approx_kl            | 1.7481449e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.341        |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.21e+04      |\n","|    n_updates            | 3370          |\n","|    policy_gradient_loss | -0.000128     |\n","|    value_loss           | 5.4e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 339           |\n","|    time_elapsed         | 2182          |\n","|    total_timesteps      | 694272        |\n","| train/                  |               |\n","|    approx_kl            | 0.00056910445 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.21         |\n","|    explained_variance   | 0.626         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.51e+04      |\n","|    n_updates            | 3380          |\n","|    policy_gradient_loss | -0.000522     |\n","|    value_loss           | 3.62e+04      |\n","-------------------------------------------\n","Eval num_timesteps=695000, episode_reward=20045.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2e+04         |\n","| time/                   |               |\n","|    total_timesteps      | 695000        |\n","| train/                  |               |\n","|    approx_kl            | 2.2916502e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.247        |\n","|    explained_variance   | 0.644         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.83e+04      |\n","|    n_updates            | 3390          |\n","|    policy_gradient_loss | -0.000273     |\n","|    value_loss           | 5.11e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 318    |\n","|    iterations      | 340    |\n","|    time_elapsed    | 2189   |\n","|    total_timesteps | 696320 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 318          |\n","|    iterations           | 341          |\n","|    time_elapsed         | 2193         |\n","|    total_timesteps      | 698368       |\n","| train/                  |              |\n","|    approx_kl            | 8.047314e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.311       |\n","|    explained_variance   | 0.47         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.11e+04     |\n","|    n_updates            | 3400         |\n","|    policy_gradient_loss | -0.000278    |\n","|    value_loss           | 2.57e+05     |\n","------------------------------------------\n","Eval num_timesteps=700000, episode_reward=20786.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 700000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00011113504 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.622         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.6e+04       |\n","|    n_updates            | 3410          |\n","|    policy_gradient_loss | -0.000125     |\n","|    value_loss           | 5.04e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 317    |\n","|    iterations      | 342    |\n","|    time_elapsed    | 2207   |\n","|    total_timesteps | 700416 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 343           |\n","|    time_elapsed         | 2215          |\n","|    total_timesteps      | 702464        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016911127 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.264        |\n","|    explained_variance   | 0.407         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.65e+04      |\n","|    n_updates            | 3420          |\n","|    policy_gradient_loss | -0.000342     |\n","|    value_loss           | 6.84e+04      |\n","-------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 317        |\n","|    iterations           | 344        |\n","|    time_elapsed         | 2221       |\n","|    total_timesteps      | 704512     |\n","| train/                  |            |\n","|    approx_kl            | 2.2155e-05 |\n","|    clip_fraction        | 0          |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.309     |\n","|    explained_variance   | 0.588      |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 1.08e+04   |\n","|    n_updates            | 3430       |\n","|    policy_gradient_loss | -6.66e-05  |\n","|    value_loss           | 3.85e+04   |\n","----------------------------------------\n","Eval num_timesteps=705000, episode_reward=21591.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 705000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00031103333 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.241        |\n","|    explained_variance   | 0.479         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.58e+04      |\n","|    n_updates            | 3440          |\n","|    policy_gradient_loss | -0.000557     |\n","|    value_loss           | 5.23e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 345    |\n","|    time_elapsed    | 2234   |\n","|    total_timesteps | 706560 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 346           |\n","|    time_elapsed         | 2238          |\n","|    total_timesteps      | 708608        |\n","| train/                  |               |\n","|    approx_kl            | 3.4811674e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.22         |\n","|    explained_variance   | 0.453         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.78e+04      |\n","|    n_updates            | 3450          |\n","|    policy_gradient_loss | -5.1e-05      |\n","|    value_loss           | 1.13e+05      |\n","-------------------------------------------\n","Eval num_timesteps=710000, episode_reward=21591.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 710000        |\n","| train/                  |               |\n","|    approx_kl            | 1.1046039e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.304        |\n","|    explained_variance   | 0.616         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.3e+04       |\n","|    n_updates            | 3460          |\n","|    policy_gradient_loss | -9.51e-06     |\n","|    value_loss           | 1.34e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 347    |\n","|    time_elapsed    | 2247   |\n","|    total_timesteps | 710656 |\n","-------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 316            |\n","|    iterations           | 348            |\n","|    time_elapsed         | 2251           |\n","|    total_timesteps      | 712704         |\n","| train/                  |                |\n","|    approx_kl            | 0.000106563675 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.22          |\n","|    explained_variance   | 0.552          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.04e+04       |\n","|    n_updates            | 3470           |\n","|    policy_gradient_loss | -0.00024       |\n","|    value_loss           | 4.88e+04       |\n","--------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 349           |\n","|    time_elapsed         | 2255          |\n","|    total_timesteps      | 714752        |\n","| train/                  |               |\n","|    approx_kl            | 4.8930466e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.285        |\n","|    explained_variance   | 0.603         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.17e+04      |\n","|    n_updates            | 3480          |\n","|    policy_gradient_loss | -4.09e-05     |\n","|    value_loss           | 6.3e+04       |\n","-------------------------------------------\n","Eval num_timesteps=715000, episode_reward=21156.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.12e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 715000       |\n","| train/                  |              |\n","|    approx_kl            | 5.552167e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.268       |\n","|    explained_variance   | 0.713        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.12e+04     |\n","|    n_updates            | 3490         |\n","|    policy_gradient_loss | -0.00029     |\n","|    value_loss           | 5.28e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 316    |\n","|    iterations      | 350    |\n","|    time_elapsed    | 2267   |\n","|    total_timesteps | 716800 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 316          |\n","|    iterations           | 351          |\n","|    time_elapsed         | 2271         |\n","|    total_timesteps      | 718848       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005464504 |\n","|    clip_fraction        | 0.000684     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.23        |\n","|    explained_variance   | 0.642        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.09e+04     |\n","|    n_updates            | 3500         |\n","|    policy_gradient_loss | -0.000981    |\n","|    value_loss           | 4.58e+04     |\n","------------------------------------------\n","Eval num_timesteps=720000, episode_reward=22038.27 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 720000        |\n","| train/                  |               |\n","|    approx_kl            | 2.7226342e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.558         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.88e+05      |\n","|    n_updates            | 3510          |\n","|    policy_gradient_loss | -6.93e-05     |\n","|    value_loss           | 1.45e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 352    |\n","|    time_elapsed    | 2286   |\n","|    total_timesteps | 720896 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 353           |\n","|    time_elapsed         | 2291          |\n","|    total_timesteps      | 722944        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015188378 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.315        |\n","|    explained_variance   | 0.669         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.53e+04      |\n","|    n_updates            | 3520          |\n","|    policy_gradient_loss | -0.000362     |\n","|    value_loss           | 1e+05         |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 354           |\n","|    time_elapsed         | 2297          |\n","|    total_timesteps      | 724992        |\n","| train/                  |               |\n","|    approx_kl            | 0.00062068354 |\n","|    clip_fraction        | 0.00215       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.243        |\n","|    explained_variance   | 0.584         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+04      |\n","|    n_updates            | 3530          |\n","|    policy_gradient_loss | -0.00128      |\n","|    value_loss           | 4.04e+04      |\n","-------------------------------------------\n","Eval num_timesteps=725000, episode_reward=20228.12 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 725000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010082073 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.647         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.3e+04       |\n","|    n_updates            | 3540          |\n","|    policy_gradient_loss | -0.000153     |\n","|    value_loss           | 7.4e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 355    |\n","|    time_elapsed    | 2308   |\n","|    total_timesteps | 727040 |\n","-------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 315         |\n","|    iterations           | 356         |\n","|    time_elapsed         | 2311        |\n","|    total_timesteps      | 729088      |\n","| train/                  |             |\n","|    approx_kl            | 0.000245665 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.25       |\n","|    explained_variance   | 0.675       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.44e+04    |\n","|    n_updates            | 3550        |\n","|    policy_gradient_loss | -0.000401   |\n","|    value_loss           | 4.94e+04    |\n","-----------------------------------------\n","Eval num_timesteps=730000, episode_reward=26350.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 730000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00030314096 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.632         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 3560          |\n","|    policy_gradient_loss | -0.000635     |\n","|    value_loss           | 3.59e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 357    |\n","|    time_elapsed    | 2319   |\n","|    total_timesteps | 731136 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 315          |\n","|    iterations           | 358          |\n","|    time_elapsed         | 2322         |\n","|    total_timesteps      | 733184       |\n","| train/                  |              |\n","|    approx_kl            | 8.334033e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.196       |\n","|    explained_variance   | 0.498        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.43e+04     |\n","|    n_updates            | 3570         |\n","|    policy_gradient_loss | -0.000226    |\n","|    value_loss           | 9.31e+04     |\n","------------------------------------------\n","Eval num_timesteps=735000, episode_reward=26015.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.6e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 735000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00018433254 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.33         |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.22e+04      |\n","|    n_updates            | 3580          |\n","|    policy_gradient_loss | -0.000509     |\n","|    value_loss           | 7.74e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 359    |\n","|    time_elapsed    | 2330   |\n","|    total_timesteps | 735232 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 360           |\n","|    time_elapsed         | 2333          |\n","|    total_timesteps      | 737280        |\n","| train/                  |               |\n","|    approx_kl            | 5.2338495e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.226        |\n","|    explained_variance   | 0.643         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.02e+04      |\n","|    n_updates            | 3590          |\n","|    policy_gradient_loss | -0.000266     |\n","|    value_loss           | 4.6e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 361           |\n","|    time_elapsed         | 2338          |\n","|    total_timesteps      | 739328        |\n","| train/                  |               |\n","|    approx_kl            | 0.00027343136 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.313        |\n","|    explained_variance   | 0.588         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.04e+04      |\n","|    n_updates            | 3600          |\n","|    policy_gradient_loss | -0.000317     |\n","|    value_loss           | 7.58e+04      |\n","-------------------------------------------\n","Eval num_timesteps=740000, episode_reward=26015.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.6e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 740000       |\n","| train/                  |              |\n","|    approx_kl            | 7.890491e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.221       |\n","|    explained_variance   | 0.7          |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.42e+03     |\n","|    n_updates            | 3610         |\n","|    policy_gradient_loss | -0.000196    |\n","|    value_loss           | 3.65e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 362    |\n","|    time_elapsed    | 2350   |\n","|    total_timesteps | 741376 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 315          |\n","|    iterations           | 363          |\n","|    time_elapsed         | 2355         |\n","|    total_timesteps      | 743424       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001823724 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.88e+04     |\n","|    n_updates            | 3620         |\n","|    policy_gradient_loss | -0.000385    |\n","|    value_loss           | 5.53e+04     |\n","------------------------------------------\n","Eval num_timesteps=745000, episode_reward=27681.10 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.77e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 745000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019371751 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.41          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.56e+04      |\n","|    n_updates            | 3630          |\n","|    policy_gradient_loss | -0.00054      |\n","|    value_loss           | 1.66e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 364    |\n","|    time_elapsed    | 2366   |\n","|    total_timesteps | 745472 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 365           |\n","|    time_elapsed         | 2369          |\n","|    total_timesteps      | 747520        |\n","| train/                  |               |\n","|    approx_kl            | 0.00017510873 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.305        |\n","|    explained_variance   | 0.687         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.24e+04      |\n","|    n_updates            | 3640          |\n","|    policy_gradient_loss | -0.000411     |\n","|    value_loss           | 5.54e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 315          |\n","|    iterations           | 366          |\n","|    time_elapsed         | 2373         |\n","|    total_timesteps      | 749568       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002824509 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.207       |\n","|    explained_variance   | 0.486        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.97e+04     |\n","|    n_updates            | 3650         |\n","|    policy_gradient_loss | -0.000328    |\n","|    value_loss           | 6.13e+04     |\n","------------------------------------------\n","Eval num_timesteps=750000, episode_reward=23795.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.38e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 750000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002211706 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.333       |\n","|    explained_variance   | 0.626        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.29e+04     |\n","|    n_updates            | 3660         |\n","|    policy_gradient_loss | -5.49e-05    |\n","|    value_loss           | 5.56e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 315    |\n","|    iterations      | 367    |\n","|    time_elapsed    | 2385   |\n","|    total_timesteps | 751616 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 368           |\n","|    time_elapsed         | 2391          |\n","|    total_timesteps      | 753664        |\n","| train/                  |               |\n","|    approx_kl            | 0.00092002604 |\n","|    clip_fraction        | 0.00234       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.643         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.85e+04      |\n","|    n_updates            | 3670          |\n","|    policy_gradient_loss | -0.001        |\n","|    value_loss           | 4.53e+04      |\n","-------------------------------------------\n","Eval num_timesteps=755000, episode_reward=22173.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.22e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 755000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014658505 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.264        |\n","|    explained_variance   | 0.656         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 3680          |\n","|    policy_gradient_loss | -0.000568     |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 369    |\n","|    time_elapsed    | 2407   |\n","|    total_timesteps | 755712 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 370          |\n","|    time_elapsed         | 2411         |\n","|    total_timesteps      | 757760       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002839371 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.211       |\n","|    explained_variance   | 0.631        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.53e+05     |\n","|    n_updates            | 3690         |\n","|    policy_gradient_loss | -0.000707    |\n","|    value_loss           | 1.45e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 371           |\n","|    time_elapsed         | 2416          |\n","|    total_timesteps      | 759808        |\n","| train/                  |               |\n","|    approx_kl            | 2.0939478e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.273        |\n","|    explained_variance   | 0.682         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 3700          |\n","|    policy_gradient_loss | -0.000242     |\n","|    value_loss           | 5.29e+04      |\n","-------------------------------------------\n","Eval num_timesteps=760000, episode_reward=22066.82 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.21e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 760000       |\n","| train/                  |              |\n","|    approx_kl            | 3.421199e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.224       |\n","|    explained_variance   | 0.565        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.44e+04     |\n","|    n_updates            | 3710         |\n","|    policy_gradient_loss | 3.1e-05      |\n","|    value_loss           | 6.96e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 372    |\n","|    time_elapsed    | 2425   |\n","|    total_timesteps | 761856 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 373           |\n","|    time_elapsed         | 2428          |\n","|    total_timesteps      | 763904        |\n","| train/                  |               |\n","|    approx_kl            | 1.5751983e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.339        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.93e+04      |\n","|    n_updates            | 3720          |\n","|    policy_gradient_loss | -0.000121     |\n","|    value_loss           | 4.8e+04       |\n","-------------------------------------------\n","Eval num_timesteps=765000, episode_reward=20668.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.07e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 765000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00020148876 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.204        |\n","|    explained_variance   | 0.602         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.92e+03      |\n","|    n_updates            | 3730          |\n","|    policy_gradient_loss | -0.000238     |\n","|    value_loss           | 3.11e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 374    |\n","|    time_elapsed    | 2437   |\n","|    total_timesteps | 765952 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 375          |\n","|    time_elapsed         | 2441         |\n","|    total_timesteps      | 768000       |\n","| train/                  |              |\n","|    approx_kl            | 5.564507e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.232       |\n","|    explained_variance   | 0.611        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.21e+04     |\n","|    n_updates            | 3740         |\n","|    policy_gradient_loss | -4.09e-05    |\n","|    value_loss           | 1.17e+05     |\n","------------------------------------------\n","Eval num_timesteps=770000, episode_reward=21044.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.1e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 770000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00018962933 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.289        |\n","|    explained_variance   | 0.697         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.13e+04      |\n","|    n_updates            | 3750          |\n","|    policy_gradient_loss | -0.000723     |\n","|    value_loss           | 1.01e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 376    |\n","|    time_elapsed    | 2453   |\n","|    total_timesteps | 770048 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 377           |\n","|    time_elapsed         | 2458          |\n","|    total_timesteps      | 772096        |\n","| train/                  |               |\n","|    approx_kl            | 3.8734026e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.526         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.34e+04      |\n","|    n_updates            | 3760          |\n","|    policy_gradient_loss | -0.000113     |\n","|    value_loss           | 4.99e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 378          |\n","|    time_elapsed         | 2462         |\n","|    total_timesteps      | 774144       |\n","| train/                  |              |\n","|    approx_kl            | 0.0004481029 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.249       |\n","|    explained_variance   | 0.636        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+04     |\n","|    n_updates            | 3770         |\n","|    policy_gradient_loss | -0.000505    |\n","|    value_loss           | 6.18e+04     |\n","------------------------------------------\n","Eval num_timesteps=775000, episode_reward=17712.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.77e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 775000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00071932573 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.308        |\n","|    explained_variance   | 0.808         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.06e+03      |\n","|    n_updates            | 3780          |\n","|    policy_gradient_loss | -0.000628     |\n","|    value_loss           | 3.31e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 379    |\n","|    time_elapsed    | 2473   |\n","|    total_timesteps | 776192 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 380          |\n","|    time_elapsed         | 2476         |\n","|    total_timesteps      | 778240       |\n","| train/                  |              |\n","|    approx_kl            | 3.901191e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.221       |\n","|    explained_variance   | 0.501        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.11e+04     |\n","|    n_updates            | 3790         |\n","|    policy_gradient_loss | -0.000125    |\n","|    value_loss           | 4.76e+04     |\n","------------------------------------------\n","Eval num_timesteps=780000, episode_reward=18629.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 780000        |\n","| train/                  |               |\n","|    approx_kl            | 8.9815585e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.22         |\n","|    explained_variance   | 0.589         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.54e+04      |\n","|    n_updates            | 3800          |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 1.08e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 381    |\n","|    time_elapsed    | 2486   |\n","|    total_timesteps | 780288 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 382          |\n","|    time_elapsed         | 2489         |\n","|    total_timesteps      | 782336       |\n","| train/                  |              |\n","|    approx_kl            | 1.306471e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.295       |\n","|    explained_variance   | 0.57         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.84e+04     |\n","|    n_updates            | 3810         |\n","|    policy_gradient_loss | -3.49e-05    |\n","|    value_loss           | 1.28e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 383           |\n","|    time_elapsed         | 2493          |\n","|    total_timesteps      | 784384        |\n","| train/                  |               |\n","|    approx_kl            | 0.00035183172 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.625         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 3820          |\n","|    policy_gradient_loss | -0.000688     |\n","|    value_loss           | 4.79e+04      |\n","-------------------------------------------\n","Eval num_timesteps=785000, episode_reward=17480.22 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.75e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 785000        |\n","| train/                  |               |\n","|    approx_kl            | 8.7198365e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.269        |\n","|    explained_variance   | 0.385         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.32e+04      |\n","|    n_updates            | 3830          |\n","|    policy_gradient_loss | -0.000345     |\n","|    value_loss           | 8.48e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 384    |\n","|    time_elapsed    | 2505   |\n","|    total_timesteps | 786432 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 385           |\n","|    time_elapsed         | 2509          |\n","|    total_timesteps      | 788480        |\n","| train/                  |               |\n","|    approx_kl            | 0.00042274376 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.267        |\n","|    explained_variance   | 0.746         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 3840          |\n","|    policy_gradient_loss | -0.000881     |\n","|    value_loss           | 3.4e+04       |\n","-------------------------------------------\n","Eval num_timesteps=790000, episode_reward=20783.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 790000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00036646903 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.215        |\n","|    explained_variance   | 0.649         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.54e+03      |\n","|    n_updates            | 3850          |\n","|    policy_gradient_loss | -0.00072      |\n","|    value_loss           | 2.89e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 386    |\n","|    time_elapsed    | 2520   |\n","|    total_timesteps | 790528 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 387          |\n","|    time_elapsed         | 2523         |\n","|    total_timesteps      | 792576       |\n","| train/                  |              |\n","|    approx_kl            | 3.084165e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.203       |\n","|    explained_variance   | 0.586        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.19e+04     |\n","|    n_updates            | 3860         |\n","|    policy_gradient_loss | -9.83e-05    |\n","|    value_loss           | 1.35e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 388           |\n","|    time_elapsed         | 2526          |\n","|    total_timesteps      | 794624        |\n","| train/                  |               |\n","|    approx_kl            | 0.00079973217 |\n","|    clip_fraction        | 0.00215       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.296        |\n","|    explained_variance   | 0.657         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.62e+04      |\n","|    n_updates            | 3870          |\n","|    policy_gradient_loss | -0.00166      |\n","|    value_loss           | 7.65e+04      |\n","-------------------------------------------\n","Eval num_timesteps=795000, episode_reward=18435.59 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 795000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00022294495 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.232        |\n","|    explained_variance   | 0.59          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 3880          |\n","|    policy_gradient_loss | -0.000247     |\n","|    value_loss           | 3.33e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 389    |\n","|    time_elapsed    | 2535   |\n","|    total_timesteps | 796672 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 390           |\n","|    time_elapsed         | 2538          |\n","|    total_timesteps      | 798720        |\n","| train/                  |               |\n","|    approx_kl            | 0.00056776544 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.258        |\n","|    explained_variance   | 0.435         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.33e+04      |\n","|    n_updates            | 3890          |\n","|    policy_gradient_loss | -0.000839     |\n","|    value_loss           | 5.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=800000, episode_reward=18033.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 800000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015044908 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.242        |\n","|    explained_variance   | 0.757         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.54e+03      |\n","|    n_updates            | 3900          |\n","|    policy_gradient_loss | -0.000353     |\n","|    value_loss           | 3.9e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 391    |\n","|    time_elapsed    | 2553   |\n","|    total_timesteps | 800768 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 392           |\n","|    time_elapsed         | 2557          |\n","|    total_timesteps      | 802816        |\n","| train/                  |               |\n","|    approx_kl            | 0.00033174062 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.593         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+04      |\n","|    n_updates            | 3910          |\n","|    policy_gradient_loss | -0.00066      |\n","|    value_loss           | 4.35e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 393           |\n","|    time_elapsed         | 2562          |\n","|    total_timesteps      | 804864        |\n","| train/                  |               |\n","|    approx_kl            | 2.9659714e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.2          |\n","|    explained_variance   | 0.591         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.38e+04      |\n","|    n_updates            | 3920          |\n","|    policy_gradient_loss | -5.27e-05     |\n","|    value_loss           | 1.28e+05      |\n","-------------------------------------------\n","Eval num_timesteps=805000, episode_reward=20783.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 805000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00013063123 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.308        |\n","|    explained_variance   | 0.776         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.86e+04      |\n","|    n_updates            | 3930          |\n","|    policy_gradient_loss | -0.000267     |\n","|    value_loss           | 7.51e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 394    |\n","|    time_elapsed    | 2580   |\n","|    total_timesteps | 806912 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 395          |\n","|    time_elapsed         | 2584         |\n","|    total_timesteps      | 808960       |\n","| train/                  |              |\n","|    approx_kl            | 6.857279e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.199       |\n","|    explained_variance   | 0.54         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.55e+03     |\n","|    n_updates            | 3940         |\n","|    policy_gradient_loss | -0.000202    |\n","|    value_loss           | 3.97e+04     |\n","------------------------------------------\n","Eval num_timesteps=810000, episode_reward=20451.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 810000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00070405286 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.291        |\n","|    explained_variance   | 0.579         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.28e+04      |\n","|    n_updates            | 3950          |\n","|    policy_gradient_loss | -0.000773     |\n","|    value_loss           | 5.4e+04       |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 396    |\n","|    time_elapsed    | 2596   |\n","|    total_timesteps | 811008 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 397           |\n","|    time_elapsed         | 2600          |\n","|    total_timesteps      | 813056        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012772591 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.71          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 3960          |\n","|    policy_gradient_loss | -0.000809     |\n","|    value_loss           | 4.36e+04      |\n","-------------------------------------------\n","Eval num_timesteps=815000, episode_reward=20455.16 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 815000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00035517474 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.234        |\n","|    explained_variance   | 0.788         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.02e+04      |\n","|    n_updates            | 3970          |\n","|    policy_gradient_loss | -0.000403     |\n","|    value_loss           | 5.02e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 398    |\n","|    time_elapsed    | 2608   |\n","|    total_timesteps | 815104 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 399          |\n","|    time_elapsed         | 2613         |\n","|    total_timesteps      | 817152       |\n","| train/                  |              |\n","|    approx_kl            | 8.242743e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.195       |\n","|    explained_variance   | 0.463        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.41e+04     |\n","|    n_updates            | 3980         |\n","|    policy_gradient_loss | -0.000222    |\n","|    value_loss           | 1.13e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 400           |\n","|    time_elapsed         | 2618          |\n","|    total_timesteps      | 819200        |\n","| train/                  |               |\n","|    approx_kl            | 0.00023501119 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.287        |\n","|    explained_variance   | 0.685         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.27e+04      |\n","|    n_updates            | 3990          |\n","|    policy_gradient_loss | -0.000555     |\n","|    value_loss           | 5.13e+04      |\n","-------------------------------------------\n","Eval num_timesteps=820000, episode_reward=20551.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.06e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 820000       |\n","| train/                  |              |\n","|    approx_kl            | 4.252966e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.197       |\n","|    explained_variance   | 0.511        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.35e+04     |\n","|    n_updates            | 4000         |\n","|    policy_gradient_loss | -0.00029     |\n","|    value_loss           | 4.59e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 401    |\n","|    time_elapsed    | 2633   |\n","|    total_timesteps | 821248 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 402          |\n","|    time_elapsed         | 2637         |\n","|    total_timesteps      | 823296       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005348361 |\n","|    clip_fraction        | 0.000244     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.314       |\n","|    explained_variance   | 0.648        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.39e+04     |\n","|    n_updates            | 4010         |\n","|    policy_gradient_loss | -0.00104     |\n","|    value_loss           | 6.3e+04      |\n","------------------------------------------\n","Eval num_timesteps=825000, episode_reward=18033.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 825000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00040737272 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.617         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.71e+04      |\n","|    n_updates            | 4020          |\n","|    policy_gradient_loss | -0.000221     |\n","|    value_loss           | 4.87e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 403    |\n","|    time_elapsed    | 2649   |\n","|    total_timesteps | 825344 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 404           |\n","|    time_elapsed         | 2652          |\n","|    total_timesteps      | 827392        |\n","| train/                  |               |\n","|    approx_kl            | 0.00027360406 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.248        |\n","|    explained_variance   | 0.723         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.55e+04      |\n","|    n_updates            | 4030          |\n","|    policy_gradient_loss | -0.000484     |\n","|    value_loss           | 5.13e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 405           |\n","|    time_elapsed         | 2655          |\n","|    total_timesteps      | 829440        |\n","| train/                  |               |\n","|    approx_kl            | 0.00020131547 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.215        |\n","|    explained_variance   | 0.549         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.63e+04      |\n","|    n_updates            | 4040          |\n","|    policy_gradient_loss | -0.000594     |\n","|    value_loss           | 1.91e+05      |\n","-------------------------------------------\n","Eval num_timesteps=830000, episode_reward=19471.26 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 830000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00018085368 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.257        |\n","|    explained_variance   | 0.67          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.38e+04      |\n","|    n_updates            | 4050          |\n","|    policy_gradient_loss | -0.000497     |\n","|    value_loss           | 6.07e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 406    |\n","|    time_elapsed    | 2664   |\n","|    total_timesteps | 831488 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 407          |\n","|    time_elapsed         | 2667         |\n","|    total_timesteps      | 833536       |\n","| train/                  |              |\n","|    approx_kl            | 0.0007801042 |\n","|    clip_fraction        | 0.00117      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.222       |\n","|    explained_variance   | 0.469        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.88e+04     |\n","|    n_updates            | 4060         |\n","|    policy_gradient_loss | -0.000992    |\n","|    value_loss           | 6.34e+04     |\n","------------------------------------------\n","Eval num_timesteps=835000, episode_reward=19692.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.97e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 835000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005769802 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.304       |\n","|    explained_variance   | 0.715        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.23e+04     |\n","|    n_updates            | 4070         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 4.9e+04      |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 408    |\n","|    time_elapsed    | 2677   |\n","|    total_timesteps | 835584 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 409           |\n","|    time_elapsed         | 2681          |\n","|    total_timesteps      | 837632        |\n","| train/                  |               |\n","|    approx_kl            | 0.00061157986 |\n","|    clip_fraction        | 0.002         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.606         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.17e+04      |\n","|    n_updates            | 4080          |\n","|    policy_gradient_loss | -0.000931     |\n","|    value_loss           | 3.66e+04      |\n","-------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 312        |\n","|    iterations           | 410        |\n","|    time_elapsed         | 2685       |\n","|    total_timesteps      | 839680     |\n","| train/                  |            |\n","|    approx_kl            | 4.7176e-05 |\n","|    clip_fraction        | 0          |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.223     |\n","|    explained_variance   | 0.76       |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 1.98e+04   |\n","|    n_updates            | 4090       |\n","|    policy_gradient_loss | -0.000168  |\n","|    value_loss           | 6.72e+04   |\n","----------------------------------------\n","Eval num_timesteps=840000, episode_reward=19430.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.94e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 840000       |\n","| train/                  |              |\n","|    approx_kl            | 4.048992e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.274       |\n","|    explained_variance   | 0.56         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.05e+05     |\n","|    n_updates            | 4100         |\n","|    policy_gradient_loss | -0.000233    |\n","|    value_loss           | 1.66e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 411    |\n","|    time_elapsed    | 2704   |\n","|    total_timesteps | 841728 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 412           |\n","|    time_elapsed         | 2711          |\n","|    total_timesteps      | 843776        |\n","| train/                  |               |\n","|    approx_kl            | 1.5096157e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.491         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.96e+04      |\n","|    n_updates            | 4110          |\n","|    policy_gradient_loss | -2.09e-05     |\n","|    value_loss           | 6.45e+04      |\n","-------------------------------------------\n","Eval num_timesteps=845000, episode_reward=19139.12 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 845000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010907816 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.238        |\n","|    explained_variance   | 0.464         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.34e+04      |\n","|    n_updates            | 4120          |\n","|    policy_gradient_loss | -0.000212     |\n","|    value_loss           | 6.49e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 413    |\n","|    time_elapsed    | 2724   |\n","|    total_timesteps | 845824 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 414           |\n","|    time_elapsed         | 2727          |\n","|    total_timesteps      | 847872        |\n","| train/                  |               |\n","|    approx_kl            | 3.7076505e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.292        |\n","|    explained_variance   | 0.778         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.2e+04       |\n","|    n_updates            | 4130          |\n","|    policy_gradient_loss | -0.000107     |\n","|    value_loss           | 4.09e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 415           |\n","|    time_elapsed         | 2731          |\n","|    total_timesteps      | 849920        |\n","| train/                  |               |\n","|    approx_kl            | 6.3752435e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.207        |\n","|    explained_variance   | 0.34          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.06e+03      |\n","|    n_updates            | 4140          |\n","|    policy_gradient_loss | -0.00022      |\n","|    value_loss           | 3.06e+04      |\n","-------------------------------------------\n","Eval num_timesteps=850000, episode_reward=19430.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.94e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 850000       |\n","| train/                  |              |\n","|    approx_kl            | 3.640732e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.211       |\n","|    explained_variance   | 0.689        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.46e+04     |\n","|    n_updates            | 4150         |\n","|    policy_gradient_loss | -0.000205    |\n","|    value_loss           | 7.1e+04      |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 416    |\n","|    time_elapsed    | 2745   |\n","|    total_timesteps | 851968 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 417          |\n","|    time_elapsed         | 2751         |\n","|    total_timesteps      | 854016       |\n","| train/                  |              |\n","|    approx_kl            | 7.131367e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.273       |\n","|    explained_variance   | 0.68         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.54e+04     |\n","|    n_updates            | 4160         |\n","|    policy_gradient_loss | -0.000306    |\n","|    value_loss           | 1.29e+05     |\n","------------------------------------------\n","Eval num_timesteps=855000, episode_reward=19896.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.99e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 855000       |\n","| train/                  |              |\n","|    approx_kl            | 9.975716e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.199       |\n","|    explained_variance   | 0.542        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.11e+04     |\n","|    n_updates            | 4170         |\n","|    policy_gradient_loss | -0.000177    |\n","|    value_loss           | 4.65e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 418    |\n","|    time_elapsed    | 2763   |\n","|    total_timesteps | 856064 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 419           |\n","|    time_elapsed         | 2767          |\n","|    total_timesteps      | 858112        |\n","| train/                  |               |\n","|    approx_kl            | 0.00017258027 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.254        |\n","|    explained_variance   | 0.661         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.45e+04      |\n","|    n_updates            | 4180          |\n","|    policy_gradient_loss | -0.000158     |\n","|    value_loss           | 5.41e+04      |\n","-------------------------------------------\n","Eval num_timesteps=860000, episode_reward=20382.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.04e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 860000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0002622264 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.25        |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.01e+03     |\n","|    n_updates            | 4190         |\n","|    policy_gradient_loss | -0.000444    |\n","|    value_loss           | 3.82e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 420    |\n","|    time_elapsed    | 2777   |\n","|    total_timesteps | 860160 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 421           |\n","|    time_elapsed         | 2781          |\n","|    total_timesteps      | 862208        |\n","| train/                  |               |\n","|    approx_kl            | 3.7298625e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.226        |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.24e+04      |\n","|    n_updates            | 4200          |\n","|    policy_gradient_loss | -0.00016      |\n","|    value_loss           | 4.69e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 422           |\n","|    time_elapsed         | 2784          |\n","|    total_timesteps      | 864256        |\n","| train/                  |               |\n","|    approx_kl            | 5.9088372e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.196        |\n","|    explained_variance   | 0.674         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.17e+04      |\n","|    n_updates            | 4210          |\n","|    policy_gradient_loss | -0.000166     |\n","|    value_loss           | 1.34e+05      |\n","-------------------------------------------\n","Eval num_timesteps=865000, episode_reward=20310.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.03e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 865000       |\n","| train/                  |              |\n","|    approx_kl            | 8.694682e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.278       |\n","|    explained_variance   | 0.688        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.75e+04     |\n","|    n_updates            | 4220         |\n","|    policy_gradient_loss | -0.000201    |\n","|    value_loss           | 8.87e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 423    |\n","|    time_elapsed    | 2795   |\n","|    total_timesteps | 866304 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 424           |\n","|    time_elapsed         | 2799          |\n","|    total_timesteps      | 868352        |\n","| train/                  |               |\n","|    approx_kl            | 0.00088113785 |\n","|    clip_fraction        | 0.00425       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.22         |\n","|    explained_variance   | 0.607         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 4230          |\n","|    policy_gradient_loss | -0.00164      |\n","|    value_loss           | 3.64e+04      |\n","-------------------------------------------\n","Eval num_timesteps=870000, episode_reward=20269.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.03e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 870000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00068097643 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.25         |\n","|    explained_variance   | 0.439         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.08e+04      |\n","|    n_updates            | 4240          |\n","|    policy_gradient_loss | -0.00067      |\n","|    value_loss           | 6.43e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 425    |\n","|    time_elapsed    | 2812   |\n","|    total_timesteps | 870400 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 309           |\n","|    iterations           | 426           |\n","|    time_elapsed         | 2816          |\n","|    total_timesteps      | 872448        |\n","| train/                  |               |\n","|    approx_kl            | 3.0858908e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.245        |\n","|    explained_variance   | 0.779         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.7e+04       |\n","|    n_updates            | 4250          |\n","|    policy_gradient_loss | -8.46e-05     |\n","|    value_loss           | 5.29e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 427          |\n","|    time_elapsed         | 2820         |\n","|    total_timesteps      | 874496       |\n","| train/                  |              |\n","|    approx_kl            | 7.071672e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.208       |\n","|    explained_variance   | 0.646        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 4260         |\n","|    policy_gradient_loss | -0.000118    |\n","|    value_loss           | 3.94e+04     |\n","------------------------------------------\n","Eval num_timesteps=875000, episode_reward=19471.26 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 875000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012987648 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.03e+04      |\n","|    n_updates            | 4270          |\n","|    policy_gradient_loss | -0.000578     |\n","|    value_loss           | 1.25e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 428    |\n","|    time_elapsed    | 2830   |\n","|    total_timesteps | 876544 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 309          |\n","|    iterations           | 429          |\n","|    time_elapsed         | 2834         |\n","|    total_timesteps      | 878592       |\n","| train/                  |              |\n","|    approx_kl            | 9.956327e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.295       |\n","|    explained_variance   | 0.639        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.64e+04     |\n","|    n_updates            | 4280         |\n","|    policy_gradient_loss | -0.000418    |\n","|    value_loss           | 7.84e+04     |\n","------------------------------------------\n","Eval num_timesteps=880000, episode_reward=20392.57 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.04e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 880000       |\n","| train/                  |              |\n","|    approx_kl            | 7.239613e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.2         |\n","|    explained_variance   | 0.595        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.49e+04     |\n","|    n_updates            | 4290         |\n","|    policy_gradient_loss | -0.000447    |\n","|    value_loss           | 4.21e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 309    |\n","|    iterations      | 430    |\n","|    time_elapsed    | 2841   |\n","|    total_timesteps | 880640 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 431          |\n","|    time_elapsed         | 2845         |\n","|    total_timesteps      | 882688       |\n","| train/                  |              |\n","|    approx_kl            | 0.0010391378 |\n","|    clip_fraction        | 0.00605      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.289       |\n","|    explained_variance   | 0.674        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.78e+03     |\n","|    n_updates            | 4300         |\n","|    policy_gradient_loss | -0.00247     |\n","|    value_loss           | 6.28e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 310          |\n","|    iterations           | 432          |\n","|    time_elapsed         | 2847         |\n","|    total_timesteps      | 884736       |\n","| train/                  |              |\n","|    approx_kl            | 1.764443e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.212       |\n","|    explained_variance   | 0.73         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.52e+04     |\n","|    n_updates            | 4310         |\n","|    policy_gradient_loss | -0.000163    |\n","|    value_loss           | 3.7e+04      |\n","------------------------------------------\n","Eval num_timesteps=885000, episode_reward=19007.66 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.9e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 885000        |\n","| train/                  |               |\n","|    approx_kl            | 2.2291788e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.224        |\n","|    explained_variance   | 0.819         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 4320          |\n","|    policy_gradient_loss | -3.72e-05     |\n","|    value_loss           | 3.97e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 433    |\n","|    time_elapsed    | 2856   |\n","|    total_timesteps | 886784 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 434           |\n","|    time_elapsed         | 2860          |\n","|    total_timesteps      | 888832        |\n","| train/                  |               |\n","|    approx_kl            | 1.3870886e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.202        |\n","|    explained_variance   | 0.464         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.97e+04      |\n","|    n_updates            | 4330          |\n","|    policy_gradient_loss | -0.000212     |\n","|    value_loss           | 1.24e+05      |\n","-------------------------------------------\n","Eval num_timesteps=890000, episode_reward=20191.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 890000        |\n","| train/                  |               |\n","|    approx_kl            | 2.4524343e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.279        |\n","|    explained_variance   | 0.746         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 4340          |\n","|    policy_gradient_loss | -0.000169     |\n","|    value_loss           | 5.07e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 435    |\n","|    time_elapsed    | 2870   |\n","|    total_timesteps | 890880 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 310           |\n","|    iterations           | 436           |\n","|    time_elapsed         | 2874          |\n","|    total_timesteps      | 892928        |\n","| train/                  |               |\n","|    approx_kl            | 0.00010230724 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.198        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.35e+04      |\n","|    n_updates            | 4350          |\n","|    policy_gradient_loss | -0.000139     |\n","|    value_loss           | 4.89e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 437          |\n","|    time_elapsed         | 2877         |\n","|    total_timesteps      | 894976       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005247911 |\n","|    clip_fraction        | 0.000635     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.303       |\n","|    explained_variance   | 0.699        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.75e+04     |\n","|    n_updates            | 4360         |\n","|    policy_gradient_loss | -0.000429    |\n","|    value_loss           | 5.43e+04     |\n","------------------------------------------\n","Eval num_timesteps=895000, episode_reward=19659.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 895000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00021638512 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.66          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.19e+03      |\n","|    n_updates            | 4370          |\n","|    policy_gradient_loss | -0.000245     |\n","|    value_loss           | 3.68e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 438    |\n","|    time_elapsed    | 2886   |\n","|    total_timesteps | 897024 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 439          |\n","|    time_elapsed         | 2889         |\n","|    total_timesteps      | 899072       |\n","| train/                  |              |\n","|    approx_kl            | 7.486006e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.713        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.35e+04     |\n","|    n_updates            | 4380         |\n","|    policy_gradient_loss | -0.000185    |\n","|    value_loss           | 4.58e+04     |\n","------------------------------------------\n","Eval num_timesteps=900000, episode_reward=19449.26 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 900000        |\n","| train/                  |               |\n","|    approx_kl            | 5.6846475e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.471         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.13e+04      |\n","|    n_updates            | 4390          |\n","|    policy_gradient_loss | -5.09e-05     |\n","|    value_loss           | 1.65e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 310    |\n","|    iterations      | 440    |\n","|    time_elapsed    | 2897   |\n","|    total_timesteps | 901120 |\n","-------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 311         |\n","|    iterations           | 441         |\n","|    time_elapsed         | 2901        |\n","|    total_timesteps      | 903168      |\n","| train/                  |             |\n","|    approx_kl            | 5.50315e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.25       |\n","|    explained_variance   | 0.752       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.91e+04    |\n","|    n_updates            | 4400        |\n","|    policy_gradient_loss | -0.000279   |\n","|    value_loss           | 6.1e+04     |\n","-----------------------------------------\n","Eval num_timesteps=905000, episode_reward=20439.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.04e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 905000       |\n","| train/                  |              |\n","|    approx_kl            | 9.272105e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.229       |\n","|    explained_variance   | 0.591        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.44e+04     |\n","|    n_updates            | 4410         |\n","|    policy_gradient_loss | -0.000132    |\n","|    value_loss           | 8.18e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 442    |\n","|    time_elapsed    | 2910   |\n","|    total_timesteps | 905216 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 443          |\n","|    time_elapsed         | 2914         |\n","|    total_timesteps      | 907264       |\n","| train/                  |              |\n","|    approx_kl            | 4.549016e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.282       |\n","|    explained_variance   | 0.719        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.17e+04     |\n","|    n_updates            | 4420         |\n","|    policy_gradient_loss | -0.000212    |\n","|    value_loss           | 4.26e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 444          |\n","|    time_elapsed         | 2918         |\n","|    total_timesteps      | 909312       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005487355 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.22        |\n","|    explained_variance   | 0.631        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.8e+04      |\n","|    n_updates            | 4430         |\n","|    policy_gradient_loss | -0.000871    |\n","|    value_loss           | 3.57e+04     |\n","------------------------------------------\n","Eval num_timesteps=910000, episode_reward=21519.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.15e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 910000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014257312 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.221        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.66e+04      |\n","|    n_updates            | 4440          |\n","|    policy_gradient_loss | -0.000193     |\n","|    value_loss           | 6.03e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 445    |\n","|    time_elapsed    | 2927   |\n","|    total_timesteps | 911360 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 446          |\n","|    time_elapsed         | 2930         |\n","|    total_timesteps      | 913408       |\n","| train/                  |              |\n","|    approx_kl            | 5.569923e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.261       |\n","|    explained_variance   | 0.386        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.6e+04      |\n","|    n_updates            | 4450         |\n","|    policy_gradient_loss | -0.000164    |\n","|    value_loss           | 1.88e+05     |\n","------------------------------------------\n","Eval num_timesteps=915000, episode_reward=21898.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 915000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015470115 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.2          |\n","|    explained_variance   | 0.648         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 4460          |\n","|    policy_gradient_loss | -0.000392     |\n","|    value_loss           | 4.56e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 447    |\n","|    time_elapsed    | 2942   |\n","|    total_timesteps | 915456 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 448          |\n","|    time_elapsed         | 2945         |\n","|    total_timesteps      | 917504       |\n","| train/                  |              |\n","|    approx_kl            | 6.070896e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.242       |\n","|    explained_variance   | 0.693        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.85e+04     |\n","|    n_updates            | 4470         |\n","|    policy_gradient_loss | -5.36e-05    |\n","|    value_loss           | 6.4e+04      |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 311          |\n","|    iterations           | 449          |\n","|    time_elapsed         | 2950         |\n","|    total_timesteps      | 919552       |\n","| train/                  |              |\n","|    approx_kl            | 0.0001589944 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.286       |\n","|    explained_variance   | 0.785        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.72e+04     |\n","|    n_updates            | 4480         |\n","|    policy_gradient_loss | -0.000527    |\n","|    value_loss           | 4.02e+04     |\n","------------------------------------------\n","Eval num_timesteps=920000, episode_reward=19659.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.97e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 920000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0003211763 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.195       |\n","|    explained_variance   | 0.519        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.5e+04      |\n","|    n_updates            | 4490         |\n","|    policy_gradient_loss | -0.000495    |\n","|    value_loss           | 4.75e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 450    |\n","|    time_elapsed    | 2961   |\n","|    total_timesteps | 921600 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 451           |\n","|    time_elapsed         | 2965          |\n","|    total_timesteps      | 923648        |\n","| train/                  |               |\n","|    approx_kl            | 6.3702464e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.639         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.15e+04      |\n","|    n_updates            | 4500          |\n","|    policy_gradient_loss | -8.21e-05     |\n","|    value_loss           | 1.08e+05      |\n","-------------------------------------------\n","Eval num_timesteps=925000, episode_reward=19659.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 925000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016211215 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.268        |\n","|    explained_variance   | 0.548         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.67e+04      |\n","|    n_updates            | 4510          |\n","|    policy_gradient_loss | -0.000411     |\n","|    value_loss           | 1.27e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 452    |\n","|    time_elapsed    | 2974   |\n","|    total_timesteps | 925696 |\n","-------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 311         |\n","|    iterations           | 453         |\n","|    time_elapsed         | 2977        |\n","|    total_timesteps      | 927744      |\n","| train/                  |             |\n","|    approx_kl            | 0.000499423 |\n","|    clip_fraction        | 0.000586    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.192      |\n","|    explained_variance   | 0.626       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.88e+04    |\n","|    n_updates            | 4520        |\n","|    policy_gradient_loss | -0.000867   |\n","|    value_loss           | 5.52e+04    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 454           |\n","|    time_elapsed         | 2980          |\n","|    total_timesteps      | 929792        |\n","| train/                  |               |\n","|    approx_kl            | 0.00033621283 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.255        |\n","|    explained_variance   | 0.5           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.71e+04      |\n","|    n_updates            | 4530          |\n","|    policy_gradient_loss | -0.000483     |\n","|    value_loss           | 6.9e+04       |\n","-------------------------------------------\n","Eval num_timesteps=930000, episode_reward=19659.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 930000        |\n","| train/                  |               |\n","|    approx_kl            | 7.5415825e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.255        |\n","|    explained_variance   | 0.713         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 4540          |\n","|    policy_gradient_loss | -0.000154     |\n","|    value_loss           | 5.29e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 455    |\n","|    time_elapsed    | 2989   |\n","|    total_timesteps | 931840 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 456           |\n","|    time_elapsed         | 2993          |\n","|    total_timesteps      | 933888        |\n","| train/                  |               |\n","|    approx_kl            | 0.00021912696 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.221        |\n","|    explained_variance   | 0.506         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.99e+04      |\n","|    n_updates            | 4550          |\n","|    policy_gradient_loss | -0.00052      |\n","|    value_loss           | 5.3e+04       |\n","-------------------------------------------\n","Eval num_timesteps=935000, episode_reward=20310.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.03e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 935000        |\n","| train/                  |               |\n","|    approx_kl            | 2.1315354e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.191        |\n","|    explained_variance   | 0.665         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.17e+04      |\n","|    n_updates            | 4560          |\n","|    policy_gradient_loss | -0.000107     |\n","|    value_loss           | 1.52e+05      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 457    |\n","|    time_elapsed    | 3005   |\n","|    total_timesteps | 935936 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 458           |\n","|    time_elapsed         | 3009          |\n","|    total_timesteps      | 937984        |\n","| train/                  |               |\n","|    approx_kl            | 0.00018421933 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.274        |\n","|    explained_variance   | 0.713         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.57e+04      |\n","|    n_updates            | 4570          |\n","|    policy_gradient_loss | -0.000246     |\n","|    value_loss           | 8.57e+04      |\n","-------------------------------------------\n","Eval num_timesteps=940000, episode_reward=20310.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.03e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 940000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014079758 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.216        |\n","|    explained_variance   | 0.499         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 4580          |\n","|    policy_gradient_loss | -0.000269     |\n","|    value_loss           | 4.58e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 311    |\n","|    iterations      | 459    |\n","|    time_elapsed    | 3018   |\n","|    total_timesteps | 940032 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 311           |\n","|    iterations           | 460           |\n","|    time_elapsed         | 3021          |\n","|    total_timesteps      | 942080        |\n","| train/                  |               |\n","|    approx_kl            | 0.00039583258 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.25         |\n","|    explained_variance   | 0.65          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.05e+04      |\n","|    n_updates            | 4590          |\n","|    policy_gradient_loss | -0.000543     |\n","|    value_loss           | 6.07e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 461           |\n","|    time_elapsed         | 3024          |\n","|    total_timesteps      | 944128        |\n","| train/                  |               |\n","|    approx_kl            | 1.5403813e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.232        |\n","|    explained_variance   | 0.804         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 4600          |\n","|    policy_gradient_loss | -0.000142     |\n","|    value_loss           | 4.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=945000, episode_reward=20176.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 945000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00015613178 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.215        |\n","|    explained_variance   | 0.63          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+04       |\n","|    n_updates            | 4610          |\n","|    policy_gradient_loss | -0.000123     |\n","|    value_loss           | 4.23e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 462    |\n","|    time_elapsed    | 3032   |\n","|    total_timesteps | 946176 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 463           |\n","|    time_elapsed         | 3035          |\n","|    total_timesteps      | 948224        |\n","| train/                  |               |\n","|    approx_kl            | 0.00012123957 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.605         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.44e+04      |\n","|    n_updates            | 4620          |\n","|    policy_gradient_loss | -0.000169     |\n","|    value_loss           | 2.25e+05      |\n","-------------------------------------------\n","Eval num_timesteps=950000, episode_reward=21844.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 950000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00019238464 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.298        |\n","|    explained_variance   | 0.685         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.2e+04       |\n","|    n_updates            | 4630          |\n","|    policy_gradient_loss | -0.000363     |\n","|    value_loss           | 9.29e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 464    |\n","|    time_elapsed    | 3044   |\n","|    total_timesteps | 950272 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 465           |\n","|    time_elapsed         | 3048          |\n","|    total_timesteps      | 952320        |\n","| train/                  |               |\n","|    approx_kl            | 0.00025347082 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.192        |\n","|    explained_variance   | 0.601         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.46e+03      |\n","|    n_updates            | 4640          |\n","|    policy_gradient_loss | -0.000345     |\n","|    value_loss           | 3.99e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 466           |\n","|    time_elapsed         | 3052          |\n","|    total_timesteps      | 954368        |\n","| train/                  |               |\n","|    approx_kl            | 1.5099795e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.275        |\n","|    explained_variance   | 0.68          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.64e+04      |\n","|    n_updates            | 4650          |\n","|    policy_gradient_loss | -4.97e-05     |\n","|    value_loss           | 5.02e+04      |\n","-------------------------------------------\n","Eval num_timesteps=955000, episode_reward=22302.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.23e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 955000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00049742626 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.209        |\n","|    explained_variance   | 0.739         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 4660          |\n","|    policy_gradient_loss | -0.000476     |\n","|    value_loss           | 4.14e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 467    |\n","|    time_elapsed    | 3061   |\n","|    total_timesteps | 956416 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 312           |\n","|    iterations           | 468           |\n","|    time_elapsed         | 3064          |\n","|    total_timesteps      | 958464        |\n","| train/                  |               |\n","|    approx_kl            | 0.00065145665 |\n","|    clip_fraction        | 0.00161       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.699         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.42e+03      |\n","|    n_updates            | 4670          |\n","|    policy_gradient_loss | -0.000719     |\n","|    value_loss           | 3.02e+04      |\n","-------------------------------------------\n","Eval num_timesteps=960000, episode_reward=20193.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.02e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 960000       |\n","| train/                  |              |\n","|    approx_kl            | 1.546336e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.211       |\n","|    explained_variance   | 0.559        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.57e+05     |\n","|    n_updates            | 4680         |\n","|    policy_gradient_loss | -9.52e-05    |\n","|    value_loss           | 2.15e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 312    |\n","|    iterations      | 469    |\n","|    time_elapsed    | 3072   |\n","|    total_timesteps | 960512 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 312          |\n","|    iterations           | 470          |\n","|    time_elapsed         | 3075         |\n","|    total_timesteps      | 962560       |\n","| train/                  |              |\n","|    approx_kl            | 6.160687e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.279       |\n","|    explained_variance   | 0.717        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.41e+04     |\n","|    n_updates            | 4690         |\n","|    policy_gradient_loss | -0.000437    |\n","|    value_loss           | 6.41e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 471           |\n","|    time_elapsed         | 3078          |\n","|    total_timesteps      | 964608        |\n","| train/                  |               |\n","|    approx_kl            | 3.6285463e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.196        |\n","|    explained_variance   | 0.541         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 4700          |\n","|    policy_gradient_loss | -7.45e-05     |\n","|    value_loss           | 4.56e+04      |\n","-------------------------------------------\n","Eval num_timesteps=965000, episode_reward=20193.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 965000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00016324426 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.279        |\n","|    explained_variance   | 0.59          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+04      |\n","|    n_updates            | 4710          |\n","|    policy_gradient_loss | -0.000194     |\n","|    value_loss           | 6.46e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 472    |\n","|    time_elapsed    | 3087   |\n","|    total_timesteps | 966656 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 313          |\n","|    iterations           | 473          |\n","|    time_elapsed         | 3090         |\n","|    total_timesteps      | 968704       |\n","| train/                  |              |\n","|    approx_kl            | 6.796373e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.19        |\n","|    explained_variance   | 0.635        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.35e+04     |\n","|    n_updates            | 4720         |\n","|    policy_gradient_loss | -7e-05       |\n","|    value_loss           | 5.93e+04     |\n","------------------------------------------\n","Eval num_timesteps=970000, episode_reward=20374.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 970000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00021018108 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.24         |\n","|    explained_variance   | 0.763         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.53e+04      |\n","|    n_updates            | 4730          |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 5.99e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 474    |\n","|    time_elapsed    | 3100   |\n","|    total_timesteps | 970752 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 475           |\n","|    time_elapsed         | 3103          |\n","|    total_timesteps      | 972800        |\n","| train/                  |               |\n","|    approx_kl            | 1.4012039e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.563         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.16e+04      |\n","|    n_updates            | 4740          |\n","|    policy_gradient_loss | -0.000137     |\n","|    value_loss           | 1.93e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 313           |\n","|    iterations           | 476           |\n","|    time_elapsed         | 3106          |\n","|    total_timesteps      | 974848        |\n","| train/                  |               |\n","|    approx_kl            | 3.8859842e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.242        |\n","|    explained_variance   | 0.763         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.2e+04       |\n","|    n_updates            | 4750          |\n","|    policy_gradient_loss | -0.000427     |\n","|    value_loss           | 5.52e+04      |\n","-------------------------------------------\n","Eval num_timesteps=975000, episode_reward=20026.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2e+04       |\n","| time/                   |             |\n","|    total_timesteps      | 975000      |\n","| train/                  |             |\n","|    approx_kl            | 3.16019e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.209      |\n","|    explained_variance   | 0.708       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.72e+04    |\n","|    n_updates            | 4760        |\n","|    policy_gradient_loss | 3.54e-05    |\n","|    value_loss           | 7.66e+04    |\n","-----------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 477    |\n","|    time_elapsed    | 3113   |\n","|    total_timesteps | 976896 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 478           |\n","|    time_elapsed         | 3116          |\n","|    total_timesteps      | 978944        |\n","| train/                  |               |\n","|    approx_kl            | 4.8968417e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.273        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.6e+04       |\n","|    n_updates            | 4770          |\n","|    policy_gradient_loss | -0.000145     |\n","|    value_loss           | 5.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=980000, episode_reward=21769.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 980000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0008379235 |\n","|    clip_fraction        | 0.00376      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.212       |\n","|    explained_variance   | 0.617        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.63e+04     |\n","|    n_updates            | 4780         |\n","|    policy_gradient_loss | -0.00111     |\n","|    value_loss           | 4.07e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 479    |\n","|    time_elapsed    | 3125   |\n","|    total_timesteps | 980992 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 480          |\n","|    time_elapsed         | 3128         |\n","|    total_timesteps      | 983040       |\n","| train/                  |              |\n","|    approx_kl            | 9.342015e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.215       |\n","|    explained_variance   | 0.75         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.51e+03     |\n","|    n_updates            | 4790         |\n","|    policy_gradient_loss | -9.94e-05    |\n","|    value_loss           | 5.11e+04     |\n","------------------------------------------\n","Eval num_timesteps=985000, episode_reward=22466.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.25e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 985000       |\n","| train/                  |              |\n","|    approx_kl            | 3.755861e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.234       |\n","|    explained_variance   | 0.679        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.66e+04     |\n","|    n_updates            | 4800         |\n","|    policy_gradient_loss | -3.9e-05     |\n","|    value_loss           | 1.98e+05     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 313    |\n","|    iterations      | 481    |\n","|    time_elapsed    | 3137   |\n","|    total_timesteps | 985088 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 482           |\n","|    time_elapsed         | 3141          |\n","|    total_timesteps      | 987136        |\n","| train/                  |               |\n","|    approx_kl            | 1.3580604e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.529         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.26e+04      |\n","|    n_updates            | 4810          |\n","|    policy_gradient_loss | -7.61e-05     |\n","|    value_loss           | 5.53e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 483           |\n","|    time_elapsed         | 3144          |\n","|    total_timesteps      | 989184        |\n","| train/                  |               |\n","|    approx_kl            | 5.6526274e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.231        |\n","|    explained_variance   | 0.75          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 4820          |\n","|    policy_gradient_loss | -0.00025      |\n","|    value_loss           | 5.32e+04      |\n","-------------------------------------------\n","Eval num_timesteps=990000, episode_reward=19794.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.98e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 990000       |\n","| train/                  |              |\n","|    approx_kl            | 0.0010962116 |\n","|    clip_fraction        | 0.00366      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.277       |\n","|    explained_variance   | 0.827        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.82e+04     |\n","|    n_updates            | 4830         |\n","|    policy_gradient_loss | -0.00195     |\n","|    value_loss           | 3.81e+04     |\n","------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 484    |\n","|    time_elapsed    | 3152   |\n","|    total_timesteps | 991232 |\n","-------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 314           |\n","|    iterations           | 485           |\n","|    time_elapsed         | 3155          |\n","|    total_timesteps      | 993280        |\n","| train/                  |               |\n","|    approx_kl            | 0.00014803192 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.586         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.49e+04      |\n","|    n_updates            | 4840          |\n","|    policy_gradient_loss | -0.000153     |\n","|    value_loss           | 4.63e+04      |\n","-------------------------------------------\n","Eval num_timesteps=995000, episode_reward=20097.71 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 995000        |\n","| train/                  |               |\n","|    approx_kl            | 0.00035218705 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.212        |\n","|    explained_variance   | 0.764         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.41e+04      |\n","|    n_updates            | 4850          |\n","|    policy_gradient_loss | -0.00102      |\n","|    value_loss           | 6.92e+04      |\n","-------------------------------------------\n","-------------------------------\n","| time/              |        |\n","|    fps             | 314    |\n","|    iterations      | 486    |\n","|    time_elapsed    | 3164   |\n","|    total_timesteps | 995328 |\n","-------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 314          |\n","|    iterations           | 487          |\n","|    time_elapsed         | 3167         |\n","|    total_timesteps      | 997376       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005845255 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.257       |\n","|    explained_variance   | 0.667        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.46e+04     |\n","|    n_updates            | 4860         |\n","|    policy_gradient_loss | -0.00126     |\n","|    value_loss           | 1.06e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 315          |\n","|    iterations           | 488          |\n","|    time_elapsed         | 3170         |\n","|    total_timesteps      | 999424       |\n","| train/                  |              |\n","|    approx_kl            | 0.0005394558 |\n","|    clip_fraction        | 0.00156      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.17        |\n","|    explained_variance   | 0.693        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.14e+03     |\n","|    n_updates            | 4870         |\n","|    policy_gradient_loss | -0.000756    |\n","|    value_loss           | 4.09e+04     |\n","------------------------------------------\n","Eval num_timesteps=1000000, episode_reward=20474.52 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1000000       |\n","| train/                  |               |\n","|    approx_kl            | 5.0677918e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.24         |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.69e+04      |\n","|    n_updates            | 4880          |\n","|    policy_gradient_loss | -8.77e-05     |\n","|    value_loss           | 5.46e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 314     |\n","|    iterations      | 489     |\n","|    time_elapsed    | 3179    |\n","|    total_timesteps | 1001472 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 315         |\n","|    iterations           | 490         |\n","|    time_elapsed         | 3183        |\n","|    total_timesteps      | 1003520     |\n","| train/                  |             |\n","|    approx_kl            | 0.000393775 |\n","|    clip_fraction        | 0.000293    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.247      |\n","|    explained_variance   | 0.774       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.38e+04    |\n","|    n_updates            | 4890        |\n","|    policy_gradient_loss | -0.000568   |\n","|    value_loss           | 4.05e+04    |\n","-----------------------------------------\n","Eval num_timesteps=1005000, episode_reward=21027.79 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.1e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1005000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00073918223 |\n","|    clip_fraction        | 0.00171       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.198        |\n","|    explained_variance   | 0.614         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.19e+04      |\n","|    n_updates            | 4900          |\n","|    policy_gradient_loss | -0.00095      |\n","|    value_loss           | 3.93e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 315     |\n","|    iterations      | 491     |\n","|    time_elapsed    | 3191    |\n","|    total_timesteps | 1005568 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 315          |\n","|    iterations           | 492          |\n","|    time_elapsed         | 3194         |\n","|    total_timesteps      | 1007616      |\n","| train/                  |              |\n","|    approx_kl            | 2.472516e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.181       |\n","|    explained_variance   | 0.669        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.64e+04     |\n","|    n_updates            | 4910         |\n","|    policy_gradient_loss | -9.71e-06    |\n","|    value_loss           | 1.3e+05      |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 315           |\n","|    iterations           | 493           |\n","|    time_elapsed         | 3197          |\n","|    total_timesteps      | 1009664       |\n","| train/                  |               |\n","|    approx_kl            | 9.1663795e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.259        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.83e+04      |\n","|    n_updates            | 4920          |\n","|    policy_gradient_loss | -0.000242     |\n","|    value_loss           | 9.2e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1010000, episode_reward=21027.79 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.1e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1010000      |\n","| train/                  |              |\n","|    approx_kl            | 1.210437e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.201       |\n","|    explained_variance   | 0.621        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.42e+04     |\n","|    n_updates            | 4930         |\n","|    policy_gradient_loss | -8.2e-05     |\n","|    value_loss           | 4.2e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 315     |\n","|    iterations      | 494     |\n","|    time_elapsed    | 3204    |\n","|    total_timesteps | 1011712 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 316          |\n","|    iterations           | 495          |\n","|    time_elapsed         | 3208         |\n","|    total_timesteps      | 1013760      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005303097 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.235       |\n","|    explained_variance   | 0.654        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.33e+03     |\n","|    n_updates            | 4940         |\n","|    policy_gradient_loss | -0.000361    |\n","|    value_loss           | 4.58e+04     |\n","------------------------------------------\n","Eval num_timesteps=1015000, episode_reward=20024.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2e+04         |\n","| time/                   |               |\n","|    total_timesteps      | 1015000       |\n","| train/                  |               |\n","|    approx_kl            | 6.7872024e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.222        |\n","|    explained_variance   | 0.74          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.81e+03      |\n","|    n_updates            | 4950          |\n","|    policy_gradient_loss | -0.000251     |\n","|    value_loss           | 4.99e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 315     |\n","|    iterations      | 496     |\n","|    time_elapsed    | 3217    |\n","|    total_timesteps | 1015808 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 497           |\n","|    time_elapsed         | 3220          |\n","|    total_timesteps      | 1017856       |\n","| train/                  |               |\n","|    approx_kl            | 6.4691354e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.196        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.26e+04      |\n","|    n_updates            | 4960          |\n","|    policy_gradient_loss | -0.000162     |\n","|    value_loss           | 3.1e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 498           |\n","|    time_elapsed         | 3223          |\n","|    total_timesteps      | 1019904       |\n","| train/                  |               |\n","|    approx_kl            | 2.5925692e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.561         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.03e+04      |\n","|    n_updates            | 4970          |\n","|    policy_gradient_loss | -0.000241     |\n","|    value_loss           | 9.92e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1020000, episode_reward=19557.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1020000       |\n","| train/                  |               |\n","|    approx_kl            | 2.5892281e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.281        |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.47e+04      |\n","|    n_updates            | 4980          |\n","|    policy_gradient_loss | -0.000152     |\n","|    value_loss           | 6.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 316     |\n","|    iterations      | 499     |\n","|    time_elapsed    | 3231    |\n","|    total_timesteps | 1021952 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 316          |\n","|    iterations           | 500          |\n","|    time_elapsed         | 3234         |\n","|    total_timesteps      | 1024000      |\n","| train/                  |              |\n","|    approx_kl            | 3.191532e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.185       |\n","|    explained_variance   | 0.564        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.56e+04     |\n","|    n_updates            | 4990         |\n","|    policy_gradient_loss | -0.000258    |\n","|    value_loss           | 5.03e+04     |\n","------------------------------------------\n","Eval num_timesteps=1025000, episode_reward=20690.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.07e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1025000       |\n","| train/                  |               |\n","|    approx_kl            | 1.6365317e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.258        |\n","|    explained_variance   | 0.645         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.05e+04      |\n","|    n_updates            | 5000          |\n","|    policy_gradient_loss | -0.000137     |\n","|    value_loss           | 5.09e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 316     |\n","|    iterations      | 501     |\n","|    time_elapsed    | 3242    |\n","|    total_timesteps | 1026048 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 316          |\n","|    iterations           | 502          |\n","|    time_elapsed         | 3245         |\n","|    total_timesteps      | 1028096      |\n","| train/                  |              |\n","|    approx_kl            | 7.337978e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.202       |\n","|    explained_variance   | 0.685        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.53e+04     |\n","|    n_updates            | 5010         |\n","|    policy_gradient_loss | -3.25e-05    |\n","|    value_loss           | 4.57e+04     |\n","------------------------------------------\n","Eval num_timesteps=1030000, episode_reward=18163.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.82e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1030000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039346272 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.187        |\n","|    explained_variance   | 0.659         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.21e+03      |\n","|    n_updates            | 5020          |\n","|    policy_gradient_loss | -0.000566     |\n","|    value_loss           | 2.83e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 316     |\n","|    iterations      | 503     |\n","|    time_elapsed    | 3254    |\n","|    total_timesteps | 1030144 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 316           |\n","|    iterations           | 504           |\n","|    time_elapsed         | 3257          |\n","|    total_timesteps      | 1032192       |\n","| train/                  |               |\n","|    approx_kl            | 7.4595184e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.551         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.49e+05      |\n","|    n_updates            | 5030          |\n","|    policy_gradient_loss | -0.000147     |\n","|    value_loss           | 1.41e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 505           |\n","|    time_elapsed         | 3260          |\n","|    total_timesteps      | 1034240       |\n","| train/                  |               |\n","|    approx_kl            | 4.5406865e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.272        |\n","|    explained_variance   | 0.635         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 5040          |\n","|    policy_gradient_loss | -0.000367     |\n","|    value_loss           | 6.59e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1035000, episode_reward=20082.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1035000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014469851 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.183        |\n","|    explained_variance   | 0.536         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.79e+04      |\n","|    n_updates            | 5050          |\n","|    policy_gradient_loss | -0.000114     |\n","|    value_loss           | 5.77e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 317     |\n","|    iterations      | 506     |\n","|    time_elapsed    | 3269    |\n","|    total_timesteps | 1036288 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 507           |\n","|    time_elapsed         | 3272          |\n","|    total_timesteps      | 1038336       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017327903 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.266        |\n","|    explained_variance   | 0.699         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+04      |\n","|    n_updates            | 5060          |\n","|    policy_gradient_loss | -0.000117     |\n","|    value_loss           | 4.74e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1040000, episode_reward=18415.42 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.84e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1040000      |\n","| train/                  |              |\n","|    approx_kl            | 9.425043e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.18        |\n","|    explained_variance   | 0.711        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.63e+04     |\n","|    n_updates            | 5070         |\n","|    policy_gradient_loss | -0.000258    |\n","|    value_loss           | 5.17e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 317     |\n","|    iterations      | 508     |\n","|    time_elapsed    | 3279    |\n","|    total_timesteps | 1040384 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 509           |\n","|    time_elapsed         | 3282          |\n","|    total_timesteps      | 1042432       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019597125 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.21         |\n","|    explained_variance   | 0.822         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.26e+04      |\n","|    n_updates            | 5080          |\n","|    policy_gradient_loss | -0.000389     |\n","|    value_loss           | 3.98e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 317           |\n","|    iterations           | 510           |\n","|    time_elapsed         | 3285          |\n","|    total_timesteps      | 1044480       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011803361 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.448         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.42e+04      |\n","|    n_updates            | 5090          |\n","|    policy_gradient_loss | -0.000264     |\n","|    value_loss           | 1.65e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1045000, episode_reward=20228.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1045000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011155254 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.244        |\n","|    explained_variance   | 0.773         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.73e+03      |\n","|    n_updates            | 5100          |\n","|    policy_gradient_loss | -0.000462     |\n","|    value_loss           | 4.4e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 317     |\n","|    iterations      | 511     |\n","|    time_elapsed    | 3293    |\n","|    total_timesteps | 1046528 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 512           |\n","|    time_elapsed         | 3296          |\n","|    total_timesteps      | 1048576       |\n","| train/                  |               |\n","|    approx_kl            | 3.8894184e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.183        |\n","|    explained_variance   | 0.572         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+04      |\n","|    n_updates            | 5110          |\n","|    policy_gradient_loss | -4.5e-05      |\n","|    value_loss           | 5.65e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1050000, episode_reward=18780.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1050000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024318931 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.729         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.59e+03      |\n","|    n_updates            | 5120          |\n","|    policy_gradient_loss | -0.000552     |\n","|    value_loss           | 4.48e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 317     |\n","|    iterations      | 513     |\n","|    time_elapsed    | 3306    |\n","|    total_timesteps | 1050624 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 514           |\n","|    time_elapsed         | 3309          |\n","|    total_timesteps      | 1052672       |\n","| train/                  |               |\n","|    approx_kl            | 3.8940925e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.717         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.17e+03      |\n","|    n_updates            | 5130          |\n","|    policy_gradient_loss | -8e-05        |\n","|    value_loss           | 2.61e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 515           |\n","|    time_elapsed         | 3313          |\n","|    total_timesteps      | 1054720       |\n","| train/                  |               |\n","|    approx_kl            | 1.3987126e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.21         |\n","|    explained_variance   | 0.775         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 5140          |\n","|    policy_gradient_loss | -0.000224     |\n","|    value_loss           | 5.03e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1055000, episode_reward=19671.56 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.97e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 1055000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000103695376 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.209         |\n","|    explained_variance   | 0.705          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 3.03e+04       |\n","|    n_updates            | 5150           |\n","|    policy_gradient_loss | -0.000192      |\n","|    value_loss           | 1.09e+05       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 318     |\n","|    iterations      | 516     |\n","|    time_elapsed    | 3322    |\n","|    total_timesteps | 1056768 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 318          |\n","|    iterations           | 517          |\n","|    time_elapsed         | 3325         |\n","|    total_timesteps      | 1058816      |\n","| train/                  |              |\n","|    approx_kl            | 6.665956e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.214       |\n","|    explained_variance   | 0.652        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.9e+03      |\n","|    n_updates            | 5160         |\n","|    policy_gradient_loss | -0.000159    |\n","|    value_loss           | 3.78e+04     |\n","------------------------------------------\n","Eval num_timesteps=1060000, episode_reward=18508.35 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1060000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00072870374 |\n","|    clip_fraction        | 0.00244       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.423         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.2e+04       |\n","|    n_updates            | 5170          |\n","|    policy_gradient_loss | -0.000906     |\n","|    value_loss           | 6.15e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 318     |\n","|    iterations      | 518     |\n","|    time_elapsed    | 3332    |\n","|    total_timesteps | 1060864 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 318          |\n","|    iterations           | 519          |\n","|    time_elapsed         | 3335         |\n","|    total_timesteps      | 1062912      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006594093 |\n","|    clip_fraction        | 0.00151      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.28        |\n","|    explained_variance   | 0.75         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.05e+04     |\n","|    n_updates            | 5180         |\n","|    policy_gradient_loss | -0.000947    |\n","|    value_loss           | 3.96e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 318           |\n","|    iterations           | 520           |\n","|    time_elapsed         | 3338          |\n","|    total_timesteps      | 1064960       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014510081 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.572         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.64e+04      |\n","|    n_updates            | 5190          |\n","|    policy_gradient_loss | -9.36e-05     |\n","|    value_loss           | 3.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1065000, episode_reward=18504.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.85e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 1065000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000110163295 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.195         |\n","|    explained_variance   | 0.835          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.31e+04       |\n","|    n_updates            | 5200           |\n","|    policy_gradient_loss | -0.000154      |\n","|    value_loss           | 3.9e+04        |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 318     |\n","|    iterations      | 521     |\n","|    time_elapsed    | 3346    |\n","|    total_timesteps | 1067008 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 319          |\n","|    iterations           | 522          |\n","|    time_elapsed         | 3349         |\n","|    total_timesteps      | 1069056      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001607342 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.27        |\n","|    explained_variance   | 0.491        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.93e+04     |\n","|    n_updates            | 5210         |\n","|    policy_gradient_loss | -0.0004      |\n","|    value_loss           | 1.7e+05      |\n","------------------------------------------\n","Eval num_timesteps=1070000, episode_reward=20291.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.03e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1070000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028081474 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.72          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.67e+04      |\n","|    n_updates            | 5220          |\n","|    policy_gradient_loss | -0.00045      |\n","|    value_loss           | 4.15e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 318     |\n","|    iterations      | 523     |\n","|    time_elapsed    | 3358    |\n","|    total_timesteps | 1071104 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 524           |\n","|    time_elapsed         | 3363          |\n","|    total_timesteps      | 1073152       |\n","| train/                  |               |\n","|    approx_kl            | 1.4977093e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.224        |\n","|    explained_variance   | 0.718         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.54e+04      |\n","|    n_updates            | 5230          |\n","|    policy_gradient_loss | -7.13e-05     |\n","|    value_loss           | 5.2e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1075000, episode_reward=19705.62 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1075000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015626408 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.258        |\n","|    explained_variance   | 0.828         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.31e+04      |\n","|    n_updates            | 5240          |\n","|    policy_gradient_loss | -0.000416     |\n","|    value_loss           | 3.98e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 318     |\n","|    iterations      | 525     |\n","|    time_elapsed    | 3372    |\n","|    total_timesteps | 1075200 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 526           |\n","|    time_elapsed         | 3374          |\n","|    total_timesteps      | 1077248       |\n","| train/                  |               |\n","|    approx_kl            | 3.2623793e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.188        |\n","|    explained_variance   | 0.473         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.13e+03      |\n","|    n_updates            | 5250          |\n","|    policy_gradient_loss | -0.000197     |\n","|    value_loss           | 3.79e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 319          |\n","|    iterations           | 527          |\n","|    time_elapsed         | 3377         |\n","|    total_timesteps      | 1079296      |\n","| train/                  |              |\n","|    approx_kl            | 3.565839e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.171       |\n","|    explained_variance   | 0.724        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.94e+04     |\n","|    n_updates            | 5260         |\n","|    policy_gradient_loss | -0.000118    |\n","|    value_loss           | 7.39e+04     |\n","------------------------------------------\n","Eval num_timesteps=1080000, episode_reward=19705.62 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.97e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1080000      |\n","| train/                  |              |\n","|    approx_kl            | 6.163979e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.262       |\n","|    explained_variance   | 0.622        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.09e+05     |\n","|    n_updates            | 5270         |\n","|    policy_gradient_loss | -5.88e-05    |\n","|    value_loss           | 1.23e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 319     |\n","|    iterations      | 528     |\n","|    time_elapsed    | 3385    |\n","|    total_timesteps | 1081344 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 529           |\n","|    time_elapsed         | 3388          |\n","|    total_timesteps      | 1083392       |\n","| train/                  |               |\n","|    approx_kl            | 1.0240299e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.191        |\n","|    explained_variance   | 0.611         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.47e+04      |\n","|    n_updates            | 5280          |\n","|    policy_gradient_loss | -2.93e-05     |\n","|    value_loss           | 3.81e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1085000, episode_reward=19831.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.98e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1085000       |\n","| train/                  |               |\n","|    approx_kl            | 1.1810014e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.236        |\n","|    explained_variance   | 0.616         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.48e+04      |\n","|    n_updates            | 5290          |\n","|    policy_gradient_loss | -4.74e-05     |\n","|    value_loss           | 6.85e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 319     |\n","|    iterations      | 530     |\n","|    time_elapsed    | 3397    |\n","|    total_timesteps | 1085440 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 531           |\n","|    time_elapsed         | 3401          |\n","|    total_timesteps      | 1087488       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018549929 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.215        |\n","|    explained_variance   | 0.79          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.55e+03      |\n","|    n_updates            | 5300          |\n","|    policy_gradient_loss | -0.000194     |\n","|    value_loss           | 4.31e+04      |\n","-------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 320         |\n","|    iterations           | 532         |\n","|    time_elapsed         | 3404        |\n","|    total_timesteps      | 1089536     |\n","| train/                  |             |\n","|    approx_kl            | 0.000265006 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.2        |\n","|    explained_variance   | 0.633       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.3e+04     |\n","|    n_updates            | 5310        |\n","|    policy_gradient_loss | -0.000424   |\n","|    value_loss           | 3.45e+04    |\n","-----------------------------------------\n","Eval num_timesteps=1090000, episode_reward=20128.42 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1090000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024312569 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.694         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.25e+04      |\n","|    n_updates            | 5320          |\n","|    policy_gradient_loss | -0.000498     |\n","|    value_loss           | 7.54e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 319     |\n","|    iterations      | 533     |\n","|    time_elapsed    | 3414    |\n","|    total_timesteps | 1091584 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 534           |\n","|    time_elapsed         | 3418          |\n","|    total_timesteps      | 1093632       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020900113 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.685         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.52e+04      |\n","|    n_updates            | 5330          |\n","|    policy_gradient_loss | -0.000272     |\n","|    value_loss           | 4.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1095000, episode_reward=21741.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.17e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1095000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046866824 |\n","|    clip_fraction        | 0.00146       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.188        |\n","|    explained_variance   | 0.732         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 5340          |\n","|    policy_gradient_loss | -0.000683     |\n","|    value_loss           | 2.59e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 319     |\n","|    iterations      | 535     |\n","|    time_elapsed    | 3427    |\n","|    total_timesteps | 1095680 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 319           |\n","|    iterations           | 536           |\n","|    time_elapsed         | 3431          |\n","|    total_timesteps      | 1097728       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030095357 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.238        |\n","|    explained_variance   | 0.668         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.08e+04      |\n","|    n_updates            | 5350          |\n","|    policy_gradient_loss | -0.00046      |\n","|    value_loss           | 5.66e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 320           |\n","|    iterations           | 537           |\n","|    time_elapsed         | 3434          |\n","|    total_timesteps      | 1099776       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033134685 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.207        |\n","|    explained_variance   | 0.694         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.33e+03      |\n","|    n_updates            | 5360          |\n","|    policy_gradient_loss | -0.000404     |\n","|    value_loss           | 3.44e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1100000, episode_reward=23175.42 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.32e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1100000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026171168 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.174        |\n","|    explained_variance   | 0.716         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.27e+04      |\n","|    n_updates            | 5370          |\n","|    policy_gradient_loss | -0.000353     |\n","|    value_loss           | 2.48e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 320     |\n","|    iterations      | 538     |\n","|    time_elapsed    | 3443    |\n","|    total_timesteps | 1101824 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 320           |\n","|    iterations           | 539           |\n","|    time_elapsed         | 3446          |\n","|    total_timesteps      | 1103872       |\n","| train/                  |               |\n","|    approx_kl            | 5.3257187e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.662         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.1e+04       |\n","|    n_updates            | 5380          |\n","|    policy_gradient_loss | -6.03e-05     |\n","|    value_loss           | 8.35e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1105000, episode_reward=23181.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.32e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1105000       |\n","| train/                  |               |\n","|    approx_kl            | 6.1903294e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.714         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.44e+04      |\n","|    n_updates            | 5390          |\n","|    policy_gradient_loss | -0.000287     |\n","|    value_loss           | 6.94e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 320     |\n","|    iterations      | 540     |\n","|    time_elapsed    | 3454    |\n","|    total_timesteps | 1105920 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 320           |\n","|    iterations           | 541           |\n","|    time_elapsed         | 3457          |\n","|    total_timesteps      | 1107968       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028585774 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.661         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.35e+04      |\n","|    n_updates            | 5400          |\n","|    policy_gradient_loss | -0.000269     |\n","|    value_loss           | 4.62e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1110000, episode_reward=22711.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.27e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 1110000     |\n","| train/                  |             |\n","|    approx_kl            | 9.36375e-06 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.257      |\n","|    explained_variance   | 0.693       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.92e+04    |\n","|    n_updates            | 5410        |\n","|    policy_gradient_loss | -7.74e-05   |\n","|    value_loss           | 6.15e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 320     |\n","|    iterations      | 542     |\n","|    time_elapsed    | 3464    |\n","|    total_timesteps | 1110016 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 320          |\n","|    iterations           | 543          |\n","|    time_elapsed         | 3467         |\n","|    total_timesteps      | 1112064      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002551915 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.171       |\n","|    explained_variance   | 0.691        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.55e+04     |\n","|    n_updates            | 5420         |\n","|    policy_gradient_loss | -0.000516    |\n","|    value_loss           | 3.81e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 320          |\n","|    iterations           | 544          |\n","|    time_elapsed         | 3470         |\n","|    total_timesteps      | 1114112      |\n","| train/                  |              |\n","|    approx_kl            | 9.544281e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.193       |\n","|    explained_variance   | 0.82         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.6e+03      |\n","|    n_updates            | 5430         |\n","|    policy_gradient_loss | -9.65e-05    |\n","|    value_loss           | 3.6e+04      |\n","------------------------------------------\n","Eval num_timesteps=1115000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1115000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021569015 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.614         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.07e+04      |\n","|    n_updates            | 5440          |\n","|    policy_gradient_loss | -0.000346     |\n","|    value_loss           | 1.15e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 320     |\n","|    iterations      | 545     |\n","|    time_elapsed    | 3479    |\n","|    total_timesteps | 1116160 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 321           |\n","|    iterations           | 546           |\n","|    time_elapsed         | 3482          |\n","|    total_timesteps      | 1118208       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018202982 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.242        |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 5450          |\n","|    policy_gradient_loss | -0.000594     |\n","|    value_loss           | 4.96e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1120000, episode_reward=21515.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.15e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1120000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020169141 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.17         |\n","|    explained_variance   | 0.593         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.64e+04      |\n","|    n_updates            | 5460          |\n","|    policy_gradient_loss | -0.000163     |\n","|    value_loss           | 4.95e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 320     |\n","|    iterations      | 547     |\n","|    time_elapsed    | 3490    |\n","|    total_timesteps | 1120256 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 321           |\n","|    iterations           | 548           |\n","|    time_elapsed         | 3493          |\n","|    total_timesteps      | 1122304       |\n","| train/                  |               |\n","|    approx_kl            | 0.00065797253 |\n","|    clip_fraction        | 0.00181       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.27         |\n","|    explained_variance   | 0.73          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.21e+04      |\n","|    n_updates            | 5470          |\n","|    policy_gradient_loss | -0.000885     |\n","|    value_loss           | 3.46e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 321           |\n","|    iterations           | 549           |\n","|    time_elapsed         | 3496          |\n","|    total_timesteps      | 1124352       |\n","| train/                  |               |\n","|    approx_kl            | 4.1029998e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.606         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 5480          |\n","|    policy_gradient_loss | -0.00017      |\n","|    value_loss           | 3.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1125000, episode_reward=20291.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.03e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1125000      |\n","| train/                  |              |\n","|    approx_kl            | 1.554619e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.208       |\n","|    explained_variance   | 0.713        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.76e+04     |\n","|    n_updates            | 5490         |\n","|    policy_gradient_loss | -0.000289    |\n","|    value_loss           | 5.62e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 321     |\n","|    iterations      | 550     |\n","|    time_elapsed    | 3504    |\n","|    total_timesteps | 1126400 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 321           |\n","|    iterations           | 551           |\n","|    time_elapsed         | 3507          |\n","|    total_timesteps      | 1128448       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010993128 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.665         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.63e+04      |\n","|    n_updates            | 5500          |\n","|    policy_gradient_loss | -0.000131     |\n","|    value_loss           | 1.77e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1130000, episode_reward=19627.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1130000       |\n","| train/                  |               |\n","|    approx_kl            | 6.8009715e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.212        |\n","|    explained_variance   | 0.575         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.5e+04       |\n","|    n_updates            | 5510          |\n","|    policy_gradient_loss | -0.000466     |\n","|    value_loss           | 4.69e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 321     |\n","|    iterations      | 552     |\n","|    time_elapsed    | 3516    |\n","|    total_timesteps | 1130496 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 321          |\n","|    iterations           | 553          |\n","|    time_elapsed         | 3519         |\n","|    total_timesteps      | 1132544      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001709149 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.196       |\n","|    explained_variance   | 0.543        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.61e+04     |\n","|    n_updates            | 5520         |\n","|    policy_gradient_loss | -0.000303    |\n","|    value_loss           | 5.3e+04      |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 554           |\n","|    time_elapsed         | 3522          |\n","|    total_timesteps      | 1134592       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041669823 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.28         |\n","|    explained_variance   | 0.659         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 5530          |\n","|    policy_gradient_loss | -0.00091      |\n","|    value_loss           | 4.09e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1135000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.2e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1135000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006292456 |\n","|    clip_fraction        | 0.00459      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.148       |\n","|    explained_variance   | 0.477        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.31e+03     |\n","|    n_updates            | 5540         |\n","|    policy_gradient_loss | -0.00105     |\n","|    value_loss           | 3.15e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 321     |\n","|    iterations      | 555     |\n","|    time_elapsed    | 3530    |\n","|    total_timesteps | 1136640 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 556           |\n","|    time_elapsed         | 3533          |\n","|    total_timesteps      | 1138688       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019149444 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.182        |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.08e+03      |\n","|    n_updates            | 5550          |\n","|    policy_gradient_loss | -0.000634     |\n","|    value_loss           | 3.74e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1140000, episode_reward=21186.87 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.12e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1140000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013676172 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.254        |\n","|    explained_variance   | 0.598         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.91e+05      |\n","|    n_updates            | 5560          |\n","|    policy_gradient_loss | -0.000162     |\n","|    value_loss           | 1.65e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 557     |\n","|    time_elapsed    | 3541    |\n","|    total_timesteps | 1140736 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 558           |\n","|    time_elapsed         | 3544          |\n","|    total_timesteps      | 1142784       |\n","| train/                  |               |\n","|    approx_kl            | 3.1255535e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.471         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.67e+04      |\n","|    n_updates            | 5570          |\n","|    policy_gradient_loss | -0.000188     |\n","|    value_loss           | 4.37e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 559           |\n","|    time_elapsed         | 3547          |\n","|    total_timesteps      | 1144832       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011890341 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.205        |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.76e+04      |\n","|    n_updates            | 5580          |\n","|    policy_gradient_loss | -0.000127     |\n","|    value_loss           | 6.57e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1145000, episode_reward=21515.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.15e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1145000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1342945e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.253        |\n","|    explained_variance   | 0.799         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.56e+03      |\n","|    n_updates            | 5590          |\n","|    policy_gradient_loss | -3.55e-05     |\n","|    value_loss           | 4.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 560     |\n","|    time_elapsed    | 3557    |\n","|    total_timesteps | 1146880 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 561           |\n","|    time_elapsed         | 3560          |\n","|    total_timesteps      | 1148928       |\n","| train/                  |               |\n","|    approx_kl            | 1.7081009e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.182        |\n","|    explained_variance   | 0.57          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.49e+04      |\n","|    n_updates            | 5600          |\n","|    policy_gradient_loss | -0.000178     |\n","|    value_loss           | 3.94e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1150000, episode_reward=21515.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.15e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1150000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001134889 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.16        |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.46e+04     |\n","|    n_updates            | 5610         |\n","|    policy_gradient_loss | -0.000397    |\n","|    value_loss           | 5.85e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 562     |\n","|    time_elapsed    | 3570    |\n","|    total_timesteps | 1150976 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 563           |\n","|    time_elapsed         | 3573          |\n","|    total_timesteps      | 1153024       |\n","| train/                  |               |\n","|    approx_kl            | 4.9536204e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.256        |\n","|    explained_variance   | 0.589         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.44e+04      |\n","|    n_updates            | 5620          |\n","|    policy_gradient_loss | -0.000371     |\n","|    value_loss           | 1.3e+05       |\n","-------------------------------------------\n","Eval num_timesteps=1155000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.2e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1155000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007479183 |\n","|    clip_fraction        | 0.00464      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.173       |\n","|    explained_variance   | 0.59         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.12e+04     |\n","|    n_updates            | 5630         |\n","|    policy_gradient_loss | -0.00182     |\n","|    value_loss           | 3.62e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 564     |\n","|    time_elapsed    | 3581    |\n","|    total_timesteps | 1155072 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 322           |\n","|    iterations           | 565           |\n","|    time_elapsed         | 3585          |\n","|    total_timesteps      | 1157120       |\n","| train/                  |               |\n","|    approx_kl            | 1.1955417e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.218        |\n","|    explained_variance   | 0.717         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.59e+04      |\n","|    n_updates            | 5640          |\n","|    policy_gradient_loss | -0.00013      |\n","|    value_loss           | 5.06e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 323           |\n","|    iterations           | 566           |\n","|    time_elapsed         | 3588          |\n","|    total_timesteps      | 1159168       |\n","| train/                  |               |\n","|    approx_kl            | 8.5290754e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.783         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.49e+04      |\n","|    n_updates            | 5650          |\n","|    policy_gradient_loss | -0.000423     |\n","|    value_loss           | 4.07e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1160000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.2e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1160000      |\n","| train/                  |              |\n","|    approx_kl            | 7.650268e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.176       |\n","|    explained_variance   | 0.591        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.42e+04     |\n","|    n_updates            | 5660         |\n","|    policy_gradient_loss | -0.000201    |\n","|    value_loss           | 3.62e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 567     |\n","|    time_elapsed    | 3598    |\n","|    total_timesteps | 1161216 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 322          |\n","|    iterations           | 568          |\n","|    time_elapsed         | 3601         |\n","|    total_timesteps      | 1163264      |\n","| train/                  |              |\n","|    approx_kl            | 8.742674e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.158       |\n","|    explained_variance   | 0.638        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.87e+04     |\n","|    n_updates            | 5670         |\n","|    policy_gradient_loss | -6.15e-05    |\n","|    value_loss           | 1.37e+05     |\n","------------------------------------------\n","Eval num_timesteps=1165000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1165000       |\n","| train/                  |               |\n","|    approx_kl            | 5.4142612e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.268        |\n","|    explained_variance   | 0.657         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.47e+04      |\n","|    n_updates            | 5680          |\n","|    policy_gradient_loss | -0.000226     |\n","|    value_loss           | 7.75e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 569     |\n","|    time_elapsed    | 3611    |\n","|    total_timesteps | 1165312 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 322          |\n","|    iterations           | 570          |\n","|    time_elapsed         | 3615         |\n","|    total_timesteps      | 1167360      |\n","| train/                  |              |\n","|    approx_kl            | 7.603638e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.183       |\n","|    explained_variance   | 0.551        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.5e+04      |\n","|    n_updates            | 5690         |\n","|    policy_gradient_loss | -0.000182    |\n","|    value_loss           | 3.25e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 323           |\n","|    iterations           | 571           |\n","|    time_elapsed         | 3618          |\n","|    total_timesteps      | 1169408       |\n","| train/                  |               |\n","|    approx_kl            | 2.1926011e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.227        |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.12e+04      |\n","|    n_updates            | 5700          |\n","|    policy_gradient_loss | -0.000166     |\n","|    value_loss           | 6.37e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1170000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1170000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042841688 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.194        |\n","|    explained_variance   | 0.709         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.45e+03      |\n","|    n_updates            | 5710          |\n","|    policy_gradient_loss | -0.00061      |\n","|    value_loss           | 4.89e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 322     |\n","|    iterations      | 572     |\n","|    time_elapsed    | 3626    |\n","|    total_timesteps | 1171456 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 323          |\n","|    iterations           | 573          |\n","|    time_elapsed         | 3630         |\n","|    total_timesteps      | 1173504      |\n","| train/                  |              |\n","|    approx_kl            | 4.003619e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.171       |\n","|    explained_variance   | 0.643        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 5720         |\n","|    policy_gradient_loss | -0.000312    |\n","|    value_loss           | 3.03e+04     |\n","------------------------------------------\n","Eval num_timesteps=1175000, episode_reward=22836.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.28e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1175000       |\n","| train/                  |               |\n","|    approx_kl            | 1.3180979e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 5730          |\n","|    policy_gradient_loss | -7.41e-05     |\n","|    value_loss           | 9.71e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 323     |\n","|    iterations      | 574     |\n","|    time_elapsed    | 3638    |\n","|    total_timesteps | 1175552 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 323           |\n","|    iterations           | 575           |\n","|    time_elapsed         | 3642          |\n","|    total_timesteps      | 1177600       |\n","| train/                  |               |\n","|    approx_kl            | 5.2856863e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.28         |\n","|    explained_variance   | 0.723         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.63e+04      |\n","|    n_updates            | 5740          |\n","|    policy_gradient_loss | -0.000252     |\n","|    value_loss           | 7.24e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 323           |\n","|    iterations           | 576           |\n","|    time_elapsed         | 3644          |\n","|    total_timesteps      | 1179648       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017937331 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.166        |\n","|    explained_variance   | 0.656         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.47e+04      |\n","|    n_updates            | 5750          |\n","|    policy_gradient_loss | -0.000339     |\n","|    value_loss           | 4.56e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1180000, episode_reward=21961.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1180000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013272307 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.256        |\n","|    explained_variance   | 0.743         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.32e+04      |\n","|    n_updates            | 5760          |\n","|    policy_gradient_loss | -0.000142     |\n","|    value_loss           | 5.53e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 323     |\n","|    iterations      | 577     |\n","|    time_elapsed    | 3652    |\n","|    total_timesteps | 1181696 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 323          |\n","|    iterations           | 578          |\n","|    time_elapsed         | 3655         |\n","|    total_timesteps      | 1183744      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004049733 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.17        |\n","|    explained_variance   | 0.795        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.4e+03      |\n","|    n_updates            | 5770         |\n","|    policy_gradient_loss | -0.000501    |\n","|    value_loss           | 3.58e+04     |\n","------------------------------------------\n","Eval num_timesteps=1185000, episode_reward=24121.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1185000       |\n","| train/                  |               |\n","|    approx_kl            | 9.9943514e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.189        |\n","|    explained_variance   | 0.765         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.9e+03       |\n","|    n_updates            | 5780          |\n","|    policy_gradient_loss | -0.000186     |\n","|    value_loss           | 3.18e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 323     |\n","|    iterations      | 579     |\n","|    time_elapsed    | 3664    |\n","|    total_timesteps | 1185792 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 323           |\n","|    iterations           | 580           |\n","|    time_elapsed         | 3667          |\n","|    total_timesteps      | 1187840       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034157568 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.621         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.31e+05      |\n","|    n_updates            | 5790          |\n","|    policy_gradient_loss | -0.000647     |\n","|    value_loss           | 1.27e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 324           |\n","|    iterations           | 581           |\n","|    time_elapsed         | 3671          |\n","|    total_timesteps      | 1189888       |\n","| train/                  |               |\n","|    approx_kl            | 5.7818193e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.245        |\n","|    explained_variance   | 0.772         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.3e+03       |\n","|    n_updates            | 5800          |\n","|    policy_gradient_loss | -0.000461     |\n","|    value_loss           | 3.95e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1190000, episode_reward=24838.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.48e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1190000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00061808655 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.366         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.16e+04      |\n","|    n_updates            | 5810          |\n","|    policy_gradient_loss | -0.000479     |\n","|    value_loss           | 8.8e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 323     |\n","|    iterations      | 582     |\n","|    time_elapsed    | 3679    |\n","|    total_timesteps | 1191936 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 324          |\n","|    iterations           | 583          |\n","|    time_elapsed         | 3682         |\n","|    total_timesteps      | 1193984      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006583936 |\n","|    clip_fraction        | 0.00239      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.262       |\n","|    explained_variance   | 0.549        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.59e+04     |\n","|    n_updates            | 5820         |\n","|    policy_gradient_loss | -0.00109     |\n","|    value_loss           | 4.66e+04     |\n","------------------------------------------\n","Eval num_timesteps=1195000, episode_reward=24665.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.47e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1195000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039773743 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.645         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.34e+04      |\n","|    n_updates            | 5830          |\n","|    policy_gradient_loss | -0.000626     |\n","|    value_loss           | 3.39e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 324     |\n","|    iterations      | 584     |\n","|    time_elapsed    | 3690    |\n","|    total_timesteps | 1196032 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 324           |\n","|    iterations           | 585           |\n","|    time_elapsed         | 3693          |\n","|    total_timesteps      | 1198080       |\n","| train/                  |               |\n","|    approx_kl            | 1.9809115e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 5840          |\n","|    policy_gradient_loss | -0.000138     |\n","|    value_loss           | 3.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1200000, episode_reward=25056.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.51e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1200000       |\n","| train/                  |               |\n","|    approx_kl            | 2.2092427e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.177        |\n","|    explained_variance   | 0.611         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.65e+04      |\n","|    n_updates            | 5850          |\n","|    policy_gradient_loss | -0.000151     |\n","|    value_loss           | 1.26e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 324     |\n","|    iterations      | 586     |\n","|    time_elapsed    | 3701    |\n","|    total_timesteps | 1200128 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 324           |\n","|    iterations           | 587           |\n","|    time_elapsed         | 3704          |\n","|    total_timesteps      | 1202176       |\n","| train/                  |               |\n","|    approx_kl            | 2.8066017e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.21         |\n","|    explained_variance   | 0.563         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.79e+04      |\n","|    n_updates            | 5860          |\n","|    policy_gradient_loss | -0.000232     |\n","|    value_loss           | 4.74e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 324          |\n","|    iterations           | 588          |\n","|    time_elapsed         | 3706         |\n","|    total_timesteps      | 1204224      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005425421 |\n","|    clip_fraction        | 0.00161      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.583        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.07e+04     |\n","|    n_updates            | 5870         |\n","|    policy_gradient_loss | -0.000684    |\n","|    value_loss           | 5.67e+04     |\n","------------------------------------------\n","Eval num_timesteps=1205000, episode_reward=24501.20 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1205000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00035222244 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.276        |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.31e+03      |\n","|    n_updates            | 5880          |\n","|    policy_gradient_loss | -0.000563     |\n","|    value_loss           | 3.95e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 324     |\n","|    iterations      | 589     |\n","|    time_elapsed    | 3714    |\n","|    total_timesteps | 1206272 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 325           |\n","|    iterations           | 590           |\n","|    time_elapsed         | 3717          |\n","|    total_timesteps      | 1208320       |\n","| train/                  |               |\n","|    approx_kl            | 0.00095588143 |\n","|    clip_fraction        | 0.00522       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.66e+04      |\n","|    n_updates            | 5890          |\n","|    policy_gradient_loss | -0.00153      |\n","|    value_loss           | 3.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1210000, episode_reward=24695.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.47e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1210000       |\n","| train/                  |               |\n","|    approx_kl            | 3.0187919e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.174        |\n","|    explained_variance   | 0.707         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.27e+04      |\n","|    n_updates            | 5900          |\n","|    policy_gradient_loss | -0.00019      |\n","|    value_loss           | 5.28e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 324     |\n","|    iterations      | 591     |\n","|    time_elapsed    | 3725    |\n","|    total_timesteps | 1210368 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 325          |\n","|    iterations           | 592          |\n","|    time_elapsed         | 3728         |\n","|    total_timesteps      | 1212416      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003865522 |\n","|    clip_fraction        | 0.000684     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.244       |\n","|    explained_variance   | 0.673        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.92e+04     |\n","|    n_updates            | 5910         |\n","|    policy_gradient_loss | -0.000927    |\n","|    value_loss           | 1.18e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 325           |\n","|    iterations           | 593           |\n","|    time_elapsed         | 3731          |\n","|    total_timesteps      | 1214464       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010737963 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.15         |\n","|    explained_variance   | 0.561         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.38e+04      |\n","|    n_updates            | 5920          |\n","|    policy_gradient_loss | -0.000132     |\n","|    value_loss           | 4.69e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1215000, episode_reward=24298.66 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.43e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1215000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006256567 |\n","|    clip_fraction        | 0.00117      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.174       |\n","|    explained_variance   | 0.608        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.28e+04     |\n","|    n_updates            | 5930         |\n","|    policy_gradient_loss | -0.000981    |\n","|    value_loss           | 6.64e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 325     |\n","|    iterations      | 594     |\n","|    time_elapsed    | 3738    |\n","|    total_timesteps | 1216512 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 325           |\n","|    iterations           | 595           |\n","|    time_elapsed         | 3741          |\n","|    total_timesteps      | 1218560       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026481447 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.256        |\n","|    explained_variance   | 0.811         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 5940          |\n","|    policy_gradient_loss | -0.000438     |\n","|    value_loss           | 3.64e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1220000, episode_reward=26430.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.64e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1220000      |\n","| train/                  |              |\n","|    approx_kl            | 7.501745e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.507        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.93e+04     |\n","|    n_updates            | 5950         |\n","|    policy_gradient_loss | -6.72e-05    |\n","|    value_loss           | 4.97e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 325     |\n","|    iterations      | 596     |\n","|    time_elapsed    | 3749    |\n","|    total_timesteps | 1220608 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 325          |\n","|    iterations           | 597          |\n","|    time_elapsed         | 3752         |\n","|    total_timesteps      | 1222656      |\n","| train/                  |              |\n","|    approx_kl            | 6.003739e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.151       |\n","|    explained_variance   | 0.731        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.97e+04     |\n","|    n_updates            | 5960         |\n","|    policy_gradient_loss | -0.000305    |\n","|    value_loss           | 5.75e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 326          |\n","|    iterations           | 598          |\n","|    time_elapsed         | 3755         |\n","|    total_timesteps      | 1224704      |\n","| train/                  |              |\n","|    approx_kl            | 6.757822e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.246       |\n","|    explained_variance   | 0.761        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.77e+04     |\n","|    n_updates            | 5970         |\n","|    policy_gradient_loss | -4.6e-05     |\n","|    value_loss           | 1.05e+05     |\n","------------------------------------------\n","Eval num_timesteps=1225000, episode_reward=26247.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.62e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1225000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039793825 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.585         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 5980          |\n","|    policy_gradient_loss | -0.000402     |\n","|    value_loss           | 4.07e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 326     |\n","|    iterations      | 599     |\n","|    time_elapsed    | 3763    |\n","|    total_timesteps | 1226752 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 326           |\n","|    iterations           | 600           |\n","|    time_elapsed         | 3765          |\n","|    total_timesteps      | 1228800       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017041629 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.685         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.72e+04      |\n","|    n_updates            | 5990          |\n","|    policy_gradient_loss | -0.000119     |\n","|    value_loss           | 6.07e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1230000, episode_reward=25473.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.55e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1230000      |\n","| train/                  |              |\n","|    approx_kl            | 8.357482e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.224       |\n","|    explained_variance   | 0.793        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.05e+03     |\n","|    n_updates            | 6000         |\n","|    policy_gradient_loss | -7.85e-05    |\n","|    value_loss           | 3.26e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 326     |\n","|    iterations      | 601     |\n","|    time_elapsed    | 3773    |\n","|    total_timesteps | 1230848 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 326           |\n","|    iterations           | 602           |\n","|    time_elapsed         | 3776          |\n","|    total_timesteps      | 1232896       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010304595 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.548         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.56e+03      |\n","|    n_updates            | 6010          |\n","|    policy_gradient_loss | -7.67e-05     |\n","|    value_loss           | 3.49e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 326          |\n","|    iterations           | 603          |\n","|    time_elapsed         | 3779         |\n","|    total_timesteps      | 1234944      |\n","| train/                  |              |\n","|    approx_kl            | 9.000875e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.151       |\n","|    explained_variance   | 0.666        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+05     |\n","|    n_updates            | 6020         |\n","|    policy_gradient_loss | -0.000326    |\n","|    value_loss           | 1.54e+05     |\n","------------------------------------------\n","Eval num_timesteps=1235000, episode_reward=25952.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.6e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1235000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002747124 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.255       |\n","|    explained_variance   | 0.743        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.57e+04     |\n","|    n_updates            | 6030         |\n","|    policy_gradient_loss | -0.000703    |\n","|    value_loss           | 7.46e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 326     |\n","|    iterations      | 604     |\n","|    time_elapsed    | 3787    |\n","|    total_timesteps | 1236992 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 326           |\n","|    iterations           | 605           |\n","|    time_elapsed         | 3790          |\n","|    total_timesteps      | 1239040       |\n","| train/                  |               |\n","|    approx_kl            | 1.2567762e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.582         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.47e+04      |\n","|    n_updates            | 6040          |\n","|    policy_gradient_loss | -9.07e-05     |\n","|    value_loss           | 4.01e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1240000, episode_reward=25591.34 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1240000       |\n","| train/                  |               |\n","|    approx_kl            | 6.6800305e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.662         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.32e+04      |\n","|    n_updates            | 6050          |\n","|    policy_gradient_loss | -0.000194     |\n","|    value_loss           | 5.89e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 326     |\n","|    iterations      | 606     |\n","|    time_elapsed    | 3797    |\n","|    total_timesteps | 1241088 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 327          |\n","|    iterations           | 607          |\n","|    time_elapsed         | 3800         |\n","|    total_timesteps      | 1243136      |\n","| train/                  |              |\n","|    approx_kl            | 4.679762e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.196       |\n","|    explained_variance   | 0.806        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.9e+03      |\n","|    n_updates            | 6060         |\n","|    policy_gradient_loss | -0.000103    |\n","|    value_loss           | 3.24e+04     |\n","------------------------------------------\n","Eval num_timesteps=1245000, episode_reward=25477.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.55e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1245000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004376728 |\n","|    clip_fraction        | 0.000488     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.156       |\n","|    explained_variance   | 0.606        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.06e+04     |\n","|    n_updates            | 6070         |\n","|    policy_gradient_loss | -0.00065     |\n","|    value_loss           | 3.07e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 326     |\n","|    iterations      | 608     |\n","|    time_elapsed    | 3808    |\n","|    total_timesteps | 1245184 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 327           |\n","|    iterations           | 609           |\n","|    time_elapsed         | 3811          |\n","|    total_timesteps      | 1247232       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014518673 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.143        |\n","|    explained_variance   | 0.571         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.29e+04      |\n","|    n_updates            | 6080          |\n","|    policy_gradient_loss | -0.000771     |\n","|    value_loss           | 1.52e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 327           |\n","|    iterations           | 610           |\n","|    time_elapsed         | 3814          |\n","|    total_timesteps      | 1249280       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018496008 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.269        |\n","|    explained_variance   | 0.694         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.98e+04      |\n","|    n_updates            | 6090          |\n","|    policy_gradient_loss | -0.000535     |\n","|    value_loss           | 8.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1250000, episode_reward=25647.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1250000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018011025 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.576         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.52e+04      |\n","|    n_updates            | 6100          |\n","|    policy_gradient_loss | -0.000357     |\n","|    value_loss           | 4.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 327     |\n","|    iterations      | 611     |\n","|    time_elapsed    | 3822    |\n","|    total_timesteps | 1251328 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 327           |\n","|    iterations           | 612           |\n","|    time_elapsed         | 3825          |\n","|    total_timesteps      | 1253376       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042625837 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.243        |\n","|    explained_variance   | 0.678         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.63e+04      |\n","|    n_updates            | 6110          |\n","|    policy_gradient_loss | -0.000635     |\n","|    value_loss           | 5.77e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1255000, episode_reward=26013.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.6e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1255000       |\n","| train/                  |               |\n","|    approx_kl            | 9.0502435e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.682         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.96e+04      |\n","|    n_updates            | 6120          |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 3.18e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 327     |\n","|    iterations      | 613     |\n","|    time_elapsed    | 3832    |\n","|    total_timesteps | 1255424 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 327           |\n","|    iterations           | 614           |\n","|    time_elapsed         | 3835          |\n","|    total_timesteps      | 1257472       |\n","| train/                  |               |\n","|    approx_kl            | 0.00079031877 |\n","|    clip_fraction        | 0.00151       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.668         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.98e+04      |\n","|    n_updates            | 6130          |\n","|    policy_gradient_loss | -0.00134      |\n","|    value_loss           | 5.31e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 328           |\n","|    iterations           | 615           |\n","|    time_elapsed         | 3838          |\n","|    total_timesteps      | 1259520       |\n","| train/                  |               |\n","|    approx_kl            | 6.9314847e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.542         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.16e+04      |\n","|    n_updates            | 6140          |\n","|    policy_gradient_loss | -6.28e-05     |\n","|    value_loss           | 1.72e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1260000, episode_reward=23767.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.38e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1260000      |\n","| train/                  |              |\n","|    approx_kl            | 8.214949e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.246       |\n","|    explained_variance   | 0.751        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.8e+03      |\n","|    n_updates            | 6150         |\n","|    policy_gradient_loss | -0.000157    |\n","|    value_loss           | 3.96e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 328     |\n","|    iterations      | 616     |\n","|    time_elapsed    | 3846    |\n","|    total_timesteps | 1261568 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 328           |\n","|    iterations           | 617           |\n","|    time_elapsed         | 3848          |\n","|    total_timesteps      | 1263616       |\n","| train/                  |               |\n","|    approx_kl            | 5.8392965e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.629         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.79e+04      |\n","|    n_updates            | 6160          |\n","|    policy_gradient_loss | -0.00021      |\n","|    value_loss           | 5.38e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1265000, episode_reward=23658.34 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1265000       |\n","| train/                  |               |\n","|    approx_kl            | 3.7653372e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.261        |\n","|    explained_variance   | 0.723         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+04      |\n","|    n_updates            | 6170          |\n","|    policy_gradient_loss | -6.41e-05     |\n","|    value_loss           | 4.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 328     |\n","|    iterations      | 618     |\n","|    time_elapsed    | 3856    |\n","|    total_timesteps | 1265664 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 328          |\n","|    iterations           | 619          |\n","|    time_elapsed         | 3859         |\n","|    total_timesteps      | 1267712      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006220124 |\n","|    clip_fraction        | 0.00195      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.143       |\n","|    explained_variance   | 0.737        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.52e+04     |\n","|    n_updates            | 6180         |\n","|    policy_gradient_loss | -0.00111     |\n","|    value_loss           | 3.67e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 328           |\n","|    iterations           | 620           |\n","|    time_elapsed         | 3862          |\n","|    total_timesteps      | 1269760       |\n","| train/                  |               |\n","|    approx_kl            | 8.7591645e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.45e+04      |\n","|    n_updates            | 6190          |\n","|    policy_gradient_loss | -0.000214     |\n","|    value_loss           | 3.96e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1270000, episode_reward=23731.41 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1270000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029138467 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.18         |\n","|    explained_variance   | 0.727         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.33e+04      |\n","|    n_updates            | 6200          |\n","|    policy_gradient_loss | -0.000921     |\n","|    value_loss           | 1.17e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 328     |\n","|    iterations      | 621     |\n","|    time_elapsed    | 3869    |\n","|    total_timesteps | 1271808 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 328           |\n","|    iterations           | 622           |\n","|    time_elapsed         | 3873          |\n","|    total_timesteps      | 1273856       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014696133 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.212        |\n","|    explained_variance   | 0.75          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.18e+04      |\n","|    n_updates            | 6210          |\n","|    policy_gradient_loss | -0.000544     |\n","|    value_loss           | 3.93e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1275000, episode_reward=22004.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1275000       |\n","| train/                  |               |\n","|    approx_kl            | 3.7479243e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.614         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.41e+04      |\n","|    n_updates            | 6220          |\n","|    policy_gradient_loss | -5.96e-06     |\n","|    value_loss           | 7.64e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 328     |\n","|    iterations      | 623     |\n","|    time_elapsed    | 3880    |\n","|    total_timesteps | 1275904 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 329           |\n","|    iterations           | 624           |\n","|    time_elapsed         | 3883          |\n","|    total_timesteps      | 1277952       |\n","| train/                  |               |\n","|    approx_kl            | 9.2142436e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.263        |\n","|    explained_variance   | 0.753         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 6230          |\n","|    policy_gradient_loss | -0.000223     |\n","|    value_loss           | 5.2e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1280000, episode_reward=21889.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.19e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1280000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009465808 |\n","|    clip_fraction        | 0.00464      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.145       |\n","|    explained_variance   | 0.635        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.83e+03     |\n","|    n_updates            | 6240         |\n","|    policy_gradient_loss | -0.00112     |\n","|    value_loss           | 3.3e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 328     |\n","|    iterations      | 625     |\n","|    time_elapsed    | 3890    |\n","|    total_timesteps | 1280000 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 329           |\n","|    iterations           | 626           |\n","|    time_elapsed         | 3893          |\n","|    total_timesteps      | 1282048       |\n","| train/                  |               |\n","|    approx_kl            | 1.9450992e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.716         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.87e+04      |\n","|    n_updates            | 6250          |\n","|    policy_gradient_loss | -0.000114     |\n","|    value_loss           | 4.51e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 329          |\n","|    iterations           | 627          |\n","|    time_elapsed         | 3896         |\n","|    total_timesteps      | 1284096      |\n","| train/                  |              |\n","|    approx_kl            | 5.085292e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.249       |\n","|    explained_variance   | 0.744        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.59e+04     |\n","|    n_updates            | 6260         |\n","|    policy_gradient_loss | -0.000254    |\n","|    value_loss           | 1.53e+05     |\n","------------------------------------------\n","Eval num_timesteps=1285000, episode_reward=20983.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.1e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1285000      |\n","| train/                  |              |\n","|    approx_kl            | 6.936316e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.151       |\n","|    explained_variance   | 0.552        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.98e+04     |\n","|    n_updates            | 6270         |\n","|    policy_gradient_loss | -1.47e-05    |\n","|    value_loss           | 5.66e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 329     |\n","|    iterations      | 628     |\n","|    time_elapsed    | 3904    |\n","|    total_timesteps | 1286144 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 329           |\n","|    iterations           | 629           |\n","|    time_elapsed         | 3907          |\n","|    total_timesteps      | 1288192       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036620654 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.181        |\n","|    explained_variance   | 0.502         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.56e+04      |\n","|    n_updates            | 6280          |\n","|    policy_gradient_loss | -0.000335     |\n","|    value_loss           | 6.5e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1290000, episode_reward=21311.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.13e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1290000      |\n","| train/                  |              |\n","|    approx_kl            | 3.888001e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.246       |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.65e+03     |\n","|    n_updates            | 6290         |\n","|    policy_gradient_loss | -9.14e-05    |\n","|    value_loss           | 3.63e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 329     |\n","|    iterations      | 630     |\n","|    time_elapsed    | 3915    |\n","|    total_timesteps | 1290240 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 329           |\n","|    iterations           | 631           |\n","|    time_elapsed         | 3918          |\n","|    total_timesteps      | 1292288       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025003878 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.543         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.31e+03      |\n","|    n_updates            | 6300          |\n","|    policy_gradient_loss | -0.000233     |\n","|    value_loss           | 3.3e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 330           |\n","|    iterations           | 632           |\n","|    time_elapsed         | 3921          |\n","|    total_timesteps      | 1294336       |\n","| train/                  |               |\n","|    approx_kl            | 6.1283965e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.746         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.91e+04      |\n","|    n_updates            | 6310          |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 5.32e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1295000, episode_reward=22004.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1295000       |\n","| train/                  |               |\n","|    approx_kl            | 1.8335792e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.245        |\n","|    explained_variance   | 0.543         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.43e+04      |\n","|    n_updates            | 6320          |\n","|    policy_gradient_loss | -0.000106     |\n","|    value_loss           | 1.88e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 329     |\n","|    iterations      | 633     |\n","|    time_elapsed    | 3929    |\n","|    total_timesteps | 1296384 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 330           |\n","|    iterations           | 634           |\n","|    time_elapsed         | 3932          |\n","|    total_timesteps      | 1298432       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019212996 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.624         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.5e+03       |\n","|    n_updates            | 6330          |\n","|    policy_gradient_loss | -0.00031      |\n","|    value_loss           | 4.02e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1300000, episode_reward=22004.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1300000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038026331 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.189        |\n","|    explained_variance   | 0.716         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.16e+04      |\n","|    n_updates            | 6340          |\n","|    policy_gradient_loss | -0.00023      |\n","|    value_loss           | 6.38e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 330     |\n","|    iterations      | 635     |\n","|    time_elapsed    | 3939    |\n","|    total_timesteps | 1300480 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 330          |\n","|    iterations           | 636          |\n","|    time_elapsed         | 3942         |\n","|    total_timesteps      | 1302528      |\n","| train/                  |              |\n","|    approx_kl            | 8.766452e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.218       |\n","|    explained_variance   | 0.787        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.86e+03     |\n","|    n_updates            | 6350         |\n","|    policy_gradient_loss | -4.82e-05    |\n","|    value_loss           | 3.77e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 330           |\n","|    iterations           | 637           |\n","|    time_elapsed         | 3945          |\n","|    total_timesteps      | 1304576       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022778689 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.583         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.45e+03      |\n","|    n_updates            | 6360          |\n","|    policy_gradient_loss | -0.000329     |\n","|    value_loss           | 2.92e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1305000, episode_reward=23731.41 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1305000       |\n","| train/                  |               |\n","|    approx_kl            | 5.2620715e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.713         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 6370          |\n","|    policy_gradient_loss | -0.000217     |\n","|    value_loss           | 7.33e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 330     |\n","|    iterations      | 638     |\n","|    time_elapsed    | 3953    |\n","|    total_timesteps | 1306624 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 330          |\n","|    iterations           | 639          |\n","|    time_elapsed         | 3956         |\n","|    total_timesteps      | 1308672      |\n","| train/                  |              |\n","|    approx_kl            | 8.493022e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.241       |\n","|    explained_variance   | 0.702        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.41e+04     |\n","|    n_updates            | 6380         |\n","|    policy_gradient_loss | -6.88e-05    |\n","|    value_loss           | 6.41e+04     |\n","------------------------------------------\n","Eval num_timesteps=1310000, episode_reward=24678.35 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.47e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1310000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00086013495 |\n","|    clip_fraction        | 0.00483       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.177        |\n","|    explained_variance   | 0.486         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.72e+03      |\n","|    n_updates            | 6390          |\n","|    policy_gradient_loss | -0.00119      |\n","|    value_loss           | 3.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 330     |\n","|    iterations      | 640     |\n","|    time_elapsed    | 3964    |\n","|    total_timesteps | 1310720 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 330           |\n","|    iterations           | 641           |\n","|    time_elapsed         | 3967          |\n","|    total_timesteps      | 1312768       |\n","| train/                  |               |\n","|    approx_kl            | 6.0163176e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.194        |\n","|    explained_variance   | 0.655         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.96e+04      |\n","|    n_updates            | 6400          |\n","|    policy_gradient_loss | -2.81e-05     |\n","|    value_loss           | 7.22e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 331          |\n","|    iterations           | 642          |\n","|    time_elapsed         | 3969         |\n","|    total_timesteps      | 1314816      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008139657 |\n","|    clip_fraction        | 0.00356      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.194       |\n","|    explained_variance   | 0.807        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.01e+04     |\n","|    n_updates            | 6410         |\n","|    policy_gradient_loss | -0.00175     |\n","|    value_loss           | 4.03e+04     |\n","------------------------------------------\n","Eval num_timesteps=1315000, episode_reward=25651.98 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1315000       |\n","| train/                  |               |\n","|    approx_kl            | 5.8981153e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.729         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 6420          |\n","|    policy_gradient_loss | -0.000135     |\n","|    value_loss           | 2.74e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 331     |\n","|    iterations      | 643     |\n","|    time_elapsed    | 3977    |\n","|    total_timesteps | 1316864 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 331          |\n","|    iterations           | 644          |\n","|    time_elapsed         | 3981         |\n","|    total_timesteps      | 1318912      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004825909 |\n","|    clip_fraction        | 0.00151      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.138       |\n","|    explained_variance   | 0.764        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.71e+04     |\n","|    n_updates            | 6430         |\n","|    policy_gradient_loss | -0.00144     |\n","|    value_loss           | 8.47e+04     |\n","------------------------------------------\n","Eval num_timesteps=1320000, episode_reward=26596.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.66e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1320000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010016924 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.253        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.62e+04      |\n","|    n_updates            | 6440          |\n","|    policy_gradient_loss | -0.000369     |\n","|    value_loss           | 8.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 331     |\n","|    iterations      | 645     |\n","|    time_elapsed    | 3988    |\n","|    total_timesteps | 1320960 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 331           |\n","|    iterations           | 646           |\n","|    time_elapsed         | 3991          |\n","|    total_timesteps      | 1323008       |\n","| train/                  |               |\n","|    approx_kl            | 0.00054772955 |\n","|    clip_fraction        | 0.00342       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.87e+03      |\n","|    n_updates            | 6450          |\n","|    policy_gradient_loss | -0.00111      |\n","|    value_loss           | 3.87e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1325000, episode_reward=23494.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 2.35e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 1325000        |\n","| train/                  |                |\n","|    approx_kl            | 1.28264655e-05 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.224         |\n","|    explained_variance   | 0.733          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 4.82e+04       |\n","|    n_updates            | 6460           |\n","|    policy_gradient_loss | -0.000143      |\n","|    value_loss           | 5.84e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 331     |\n","|    iterations      | 647     |\n","|    time_elapsed    | 3999    |\n","|    total_timesteps | 1325056 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 331          |\n","|    iterations           | 648          |\n","|    time_elapsed         | 4002         |\n","|    total_timesteps      | 1327104      |\n","| train/                  |              |\n","|    approx_kl            | 8.176765e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.155       |\n","|    explained_variance   | 0.755        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.19e+04     |\n","|    n_updates            | 6470         |\n","|    policy_gradient_loss | -7.66e-05    |\n","|    value_loss           | 4.18e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 331          |\n","|    iterations           | 649          |\n","|    time_elapsed         | 4005         |\n","|    total_timesteps      | 1329152      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003611813 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.17        |\n","|    explained_variance   | 0.778        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.27e+04     |\n","|    n_updates            | 6480         |\n","|    policy_gradient_loss | -0.00059     |\n","|    value_loss           | 5.01e+04     |\n","------------------------------------------\n","Eval num_timesteps=1330000, episode_reward=26144.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.61e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1330000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014836533 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.373         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.7e+04       |\n","|    n_updates            | 6490          |\n","|    policy_gradient_loss | -0.000422     |\n","|    value_loss           | 1.3e+05       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 331     |\n","|    iterations      | 650     |\n","|    time_elapsed    | 4013    |\n","|    total_timesteps | 1331200 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 331           |\n","|    iterations           | 651           |\n","|    time_elapsed         | 4016          |\n","|    total_timesteps      | 1333248       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023578497 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.24         |\n","|    explained_variance   | 0.743         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.7e+04       |\n","|    n_updates            | 6500          |\n","|    policy_gradient_loss | -0.000489     |\n","|    value_loss           | 4.29e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1335000, episode_reward=25544.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.55e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1335000       |\n","| train/                  |               |\n","|    approx_kl            | 1.9247265e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.676         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.55e+04      |\n","|    n_updates            | 6510          |\n","|    policy_gradient_loss | -0.000119     |\n","|    value_loss           | 3.78e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 331     |\n","|    iterations      | 652     |\n","|    time_elapsed    | 4024    |\n","|    total_timesteps | 1335296 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 332           |\n","|    iterations           | 653           |\n","|    time_elapsed         | 4026          |\n","|    total_timesteps      | 1337344       |\n","| train/                  |               |\n","|    approx_kl            | 7.1006856e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.248        |\n","|    explained_variance   | 0.536         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.59e+04      |\n","|    n_updates            | 6520          |\n","|    policy_gradient_loss | -0.000154     |\n","|    value_loss           | 5.5e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 332           |\n","|    iterations           | 654           |\n","|    time_elapsed         | 4029          |\n","|    total_timesteps      | 1339392       |\n","| train/                  |               |\n","|    approx_kl            | 0.00054333964 |\n","|    clip_fraction        | 0.00132       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.754         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.34e+04      |\n","|    n_updates            | 6530          |\n","|    policy_gradient_loss | -0.000638     |\n","|    value_loss           | 3.49e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1340000, episode_reward=26291.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.63e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1340000      |\n","| train/                  |              |\n","|    approx_kl            | 6.577876e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.183       |\n","|    explained_variance   | 0.692        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.32e+04     |\n","|    n_updates            | 6540         |\n","|    policy_gradient_loss | -9.84e-05    |\n","|    value_loss           | 4.74e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 332     |\n","|    iterations      | 655     |\n","|    time_elapsed    | 4037    |\n","|    total_timesteps | 1341440 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 332           |\n","|    iterations           | 656           |\n","|    time_elapsed         | 4040          |\n","|    total_timesteps      | 1343488       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020262491 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.621         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.88e+04      |\n","|    n_updates            | 6550          |\n","|    policy_gradient_loss | -0.000467     |\n","|    value_loss           | 1.15e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1345000, episode_reward=25272.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.53e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1345000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003987494 |\n","|    clip_fraction        | 0.000684     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.217       |\n","|    explained_variance   | 0.645        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.17e+04     |\n","|    n_updates            | 6560         |\n","|    policy_gradient_loss | -0.00101     |\n","|    value_loss           | 4.09e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 332     |\n","|    iterations      | 657     |\n","|    time_elapsed    | 4047    |\n","|    total_timesteps | 1345536 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 332          |\n","|    iterations           | 658          |\n","|    time_elapsed         | 4050         |\n","|    total_timesteps      | 1347584      |\n","| train/                  |              |\n","|    approx_kl            | 4.896836e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.151       |\n","|    explained_variance   | 0.564        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.92e+04     |\n","|    n_updates            | 6570         |\n","|    policy_gradient_loss | -3.26e-05    |\n","|    value_loss           | 5.72e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 332           |\n","|    iterations           | 659           |\n","|    time_elapsed         | 4054          |\n","|    total_timesteps      | 1349632       |\n","| train/                  |               |\n","|    approx_kl            | 4.8427173e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.244        |\n","|    explained_variance   | 0.659         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.07e+04      |\n","|    n_updates            | 6580          |\n","|    policy_gradient_loss | -0.000215     |\n","|    value_loss           | 3.66e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1350000, episode_reward=26291.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.63e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1350000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041965637 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.704         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 6590          |\n","|    policy_gradient_loss | -0.000371     |\n","|    value_loss           | 3.07e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 332     |\n","|    iterations      | 660     |\n","|    time_elapsed    | 4061    |\n","|    total_timesteps | 1351680 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 333          |\n","|    iterations           | 661          |\n","|    time_elapsed         | 4064         |\n","|    total_timesteps      | 1353728      |\n","| train/                  |              |\n","|    approx_kl            | 4.715062e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.727        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.48e+04     |\n","|    n_updates            | 6600         |\n","|    policy_gradient_loss | -0.000297    |\n","|    value_loss           | 5.35e+04     |\n","------------------------------------------\n","Eval num_timesteps=1355000, episode_reward=26291.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.63e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1355000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021859867 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.214        |\n","|    explained_variance   | 0.566         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.12e+04      |\n","|    n_updates            | 6610          |\n","|    policy_gradient_loss | -0.000679     |\n","|    value_loss           | 1.14e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 332     |\n","|    iterations      | 662     |\n","|    time_elapsed    | 4072    |\n","|    total_timesteps | 1355776 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 333           |\n","|    iterations           | 663           |\n","|    time_elapsed         | 4075          |\n","|    total_timesteps      | 1357824       |\n","| train/                  |               |\n","|    approx_kl            | 4.6107103e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.614         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.28e+03      |\n","|    n_updates            | 6620          |\n","|    policy_gradient_loss | -0.000249     |\n","|    value_loss           | 3.04e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 333           |\n","|    iterations           | 664           |\n","|    time_elapsed         | 4078          |\n","|    total_timesteps      | 1359872       |\n","| train/                  |               |\n","|    approx_kl            | 0.00065381546 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.57          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.84e+04      |\n","|    n_updates            | 6630          |\n","|    policy_gradient_loss | -0.000452     |\n","|    value_loss           | 5.24e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1360000, episode_reward=24803.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.48e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1360000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002617733 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.252       |\n","|    explained_variance   | 0.803        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.33e+04     |\n","|    n_updates            | 6640         |\n","|    policy_gradient_loss | -0.000315    |\n","|    value_loss           | 2.89e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 333     |\n","|    iterations      | 665     |\n","|    time_elapsed    | 4086    |\n","|    total_timesteps | 1361920 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 333           |\n","|    iterations           | 666           |\n","|    time_elapsed         | 4089          |\n","|    total_timesteps      | 1363968       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020207488 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.622         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.09e+04      |\n","|    n_updates            | 6650          |\n","|    policy_gradient_loss | -0.000311     |\n","|    value_loss           | 2.97e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1365000, episode_reward=25911.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.59e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1365000       |\n","| train/                  |               |\n","|    approx_kl            | 6.8280846e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.588         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.55e+04      |\n","|    n_updates            | 6660          |\n","|    policy_gradient_loss | -0.000236     |\n","|    value_loss           | 9.06e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 333     |\n","|    iterations      | 667     |\n","|    time_elapsed    | 4097    |\n","|    total_timesteps | 1366016 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 333          |\n","|    iterations           | 668          |\n","|    time_elapsed         | 4100         |\n","|    total_timesteps      | 1368064      |\n","| train/                  |              |\n","|    approx_kl            | 3.957245e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.231       |\n","|    explained_variance   | 0.689        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.51e+04     |\n","|    n_updates            | 6670         |\n","|    policy_gradient_loss | -0.000162    |\n","|    value_loss           | 8.27e+04     |\n","------------------------------------------\n","Eval num_timesteps=1370000, episode_reward=24939.39 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1370000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048255356 |\n","|    clip_fraction        | 0.00234       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.602         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.82e+04      |\n","|    n_updates            | 6680          |\n","|    policy_gradient_loss | -0.000379     |\n","|    value_loss           | 3.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 333     |\n","|    iterations      | 669     |\n","|    time_elapsed    | 4107    |\n","|    total_timesteps | 1370112 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 333           |\n","|    iterations           | 670           |\n","|    time_elapsed         | 4110          |\n","|    total_timesteps      | 1372160       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034883735 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.19         |\n","|    explained_variance   | 0.637         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.36e+04      |\n","|    n_updates            | 6690          |\n","|    policy_gradient_loss | -0.000255     |\n","|    value_loss           | 5.41e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 334           |\n","|    iterations           | 671           |\n","|    time_elapsed         | 4113          |\n","|    total_timesteps      | 1374208       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018785821 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.219        |\n","|    explained_variance   | 0.782         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.9e+03       |\n","|    n_updates            | 6700          |\n","|    policy_gradient_loss | -0.000348     |\n","|    value_loss           | 2.66e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1375000, episode_reward=23936.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.39e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1375000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002495634 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.603        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.43e+03     |\n","|    n_updates            | 6710         |\n","|    policy_gradient_loss | -0.000351    |\n","|    value_loss           | 2.76e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 333     |\n","|    iterations      | 672     |\n","|    time_elapsed    | 4121    |\n","|    total_timesteps | 1376256 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 334          |\n","|    iterations           | 673          |\n","|    time_elapsed         | 4124         |\n","|    total_timesteps      | 1378304      |\n","| train/                  |              |\n","|    approx_kl            | 4.440348e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.146       |\n","|    explained_variance   | 0.763        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.38e+04     |\n","|    n_updates            | 6720         |\n","|    policy_gradient_loss | -7.34e-05    |\n","|    value_loss           | 6.33e+04     |\n","------------------------------------------\n","Eval num_timesteps=1380000, episode_reward=24046.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1380000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028296237 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.239        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.05e+04      |\n","|    n_updates            | 6730          |\n","|    policy_gradient_loss | -0.000378     |\n","|    value_loss           | 6.79e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 334     |\n","|    iterations      | 674     |\n","|    time_elapsed    | 4131    |\n","|    total_timesteps | 1380352 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 334          |\n","|    iterations           | 675          |\n","|    time_elapsed         | 4134         |\n","|    total_timesteps      | 1382400      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003113218 |\n","|    clip_fraction        | 0.000586     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.17        |\n","|    explained_variance   | 0.588        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.5e+04      |\n","|    n_updates            | 6740         |\n","|    policy_gradient_loss | -0.000558    |\n","|    value_loss           | 3.58e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 334          |\n","|    iterations           | 676          |\n","|    time_elapsed         | 4137         |\n","|    total_timesteps      | 1384448      |\n","| train/                  |              |\n","|    approx_kl            | 4.520311e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.195       |\n","|    explained_variance   | 0.579        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.69e+04     |\n","|    n_updates            | 6750         |\n","|    policy_gradient_loss | -0.000243    |\n","|    value_loss           | 5.67e+04     |\n","------------------------------------------\n","Eval num_timesteps=1385000, episode_reward=21557.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.16e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1385000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003266926 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.203       |\n","|    explained_variance   | 0.763        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.04e+04     |\n","|    n_updates            | 6760         |\n","|    policy_gradient_loss | -0.00014     |\n","|    value_loss           | 3.43e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 334     |\n","|    iterations      | 677     |\n","|    time_elapsed    | 4145    |\n","|    total_timesteps | 1386496 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 334          |\n","|    iterations           | 678          |\n","|    time_elapsed         | 4148         |\n","|    total_timesteps      | 1388544      |\n","| train/                  |              |\n","|    approx_kl            | 3.707921e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.159       |\n","|    explained_variance   | 0.641        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.46e+04     |\n","|    n_updates            | 6770         |\n","|    policy_gradient_loss | -8.36e-05    |\n","|    value_loss           | 3.87e+04     |\n","------------------------------------------\n","Eval num_timesteps=1390000, episode_reward=21672.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.17e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1390000       |\n","| train/                  |               |\n","|    approx_kl            | 1.7838611e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.726         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.74e+04      |\n","|    n_updates            | 6780          |\n","|    policy_gradient_loss | -2.78e-05     |\n","|    value_loss           | 8.15e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 334     |\n","|    iterations      | 679     |\n","|    time_elapsed    | 4155    |\n","|    total_timesteps | 1390592 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 334          |\n","|    iterations           | 680          |\n","|    time_elapsed         | 4158         |\n","|    total_timesteps      | 1392640      |\n","| train/                  |              |\n","|    approx_kl            | 9.756535e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.264       |\n","|    explained_variance   | 0.59         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.37e+04     |\n","|    n_updates            | 6790         |\n","|    policy_gradient_loss | -0.00012     |\n","|    value_loss           | 6.83e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 681           |\n","|    time_elapsed         | 4161          |\n","|    total_timesteps      | 1394688       |\n","| train/                  |               |\n","|    approx_kl            | 1.7397077e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.588         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 6800          |\n","|    policy_gradient_loss | -0.000173     |\n","|    value_loss           | 4.05e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1395000, episode_reward=21614.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1395000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048473987 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.238        |\n","|    explained_variance   | 0.647         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 6810          |\n","|    policy_gradient_loss | -0.000394     |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 335     |\n","|    iterations      | 682     |\n","|    time_elapsed    | 4169    |\n","|    total_timesteps | 1396736 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 683           |\n","|    time_elapsed         | 4172          |\n","|    total_timesteps      | 1398784       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047157402 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.712         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.37e+03      |\n","|    n_updates            | 6820          |\n","|    policy_gradient_loss | -0.000464     |\n","|    value_loss           | 4.19e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1400000, episode_reward=24108.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1400000       |\n","| train/                  |               |\n","|    approx_kl            | 8.9851645e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.651         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.16e+04      |\n","|    n_updates            | 6830          |\n","|    policy_gradient_loss | -0.000303     |\n","|    value_loss           | 4.21e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 335     |\n","|    iterations      | 684     |\n","|    time_elapsed    | 4180    |\n","|    total_timesteps | 1400832 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 685           |\n","|    time_elapsed         | 4182          |\n","|    total_timesteps      | 1402880       |\n","| train/                  |               |\n","|    approx_kl            | 7.1553484e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.611         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.03e+04      |\n","|    n_updates            | 6840          |\n","|    policy_gradient_loss | -0.000232     |\n","|    value_loss           | 1.12e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 686           |\n","|    time_elapsed         | 4185          |\n","|    total_timesteps      | 1404928       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022729914 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.241        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 6850          |\n","|    policy_gradient_loss | -0.000369     |\n","|    value_loss           | 4.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1405000, episode_reward=21889.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1405000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034399368 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.664         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.05e+03      |\n","|    n_updates            | 6860          |\n","|    policy_gradient_loss | -0.000339     |\n","|    value_loss           | 3.87e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 335     |\n","|    iterations      | 687     |\n","|    time_elapsed    | 4193    |\n","|    total_timesteps | 1406976 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 688           |\n","|    time_elapsed         | 4196          |\n","|    total_timesteps      | 1409024       |\n","| train/                  |               |\n","|    approx_kl            | 7.7630975e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.248        |\n","|    explained_variance   | 0.626         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.53e+04      |\n","|    n_updates            | 6870          |\n","|    policy_gradient_loss | 2.4e-06       |\n","|    value_loss           | 4.93e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1410000, episode_reward=20708.94 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.07e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1410000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00035547873 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.14         |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 6880          |\n","|    policy_gradient_loss | -0.000373     |\n","|    value_loss           | 3.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 335     |\n","|    iterations      | 689     |\n","|    time_elapsed    | 4204    |\n","|    total_timesteps | 1411072 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 335           |\n","|    iterations           | 690           |\n","|    time_elapsed         | 4206          |\n","|    total_timesteps      | 1413120       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020114309 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.191        |\n","|    explained_variance   | 0.714         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.38e+04      |\n","|    n_updates            | 6890          |\n","|    policy_gradient_loss | -0.000325     |\n","|    value_loss           | 4.63e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1415000, episode_reward=21614.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1415000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013752308 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.53          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.2e+04       |\n","|    n_updates            | 6900          |\n","|    policy_gradient_loss | -0.000234     |\n","|    value_loss           | 1.24e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 335     |\n","|    iterations      | 691     |\n","|    time_elapsed    | 4214    |\n","|    total_timesteps | 1415168 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 336          |\n","|    iterations           | 692          |\n","|    time_elapsed         | 4217         |\n","|    total_timesteps      | 1417216      |\n","| train/                  |              |\n","|    approx_kl            | 3.347639e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.215       |\n","|    explained_variance   | 0.786        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.13e+04     |\n","|    n_updates            | 6910         |\n","|    policy_gradient_loss | -0.000149    |\n","|    value_loss           | 3.18e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 336          |\n","|    iterations           | 693          |\n","|    time_elapsed         | 4220         |\n","|    total_timesteps      | 1419264      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004931859 |\n","|    clip_fraction        | 0.00127      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.152       |\n","|    explained_variance   | 0.568        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.79e+04     |\n","|    n_updates            | 6920         |\n","|    policy_gradient_loss | -0.000788    |\n","|    value_loss           | 6.13e+04     |\n","------------------------------------------\n","Eval num_timesteps=1420000, episode_reward=24091.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1420000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012493107 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.244        |\n","|    explained_variance   | 0.735         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+04      |\n","|    n_updates            | 6930          |\n","|    policy_gradient_loss | -0.000224     |\n","|    value_loss           | 4.18e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 336     |\n","|    iterations      | 694     |\n","|    time_elapsed    | 4227    |\n","|    total_timesteps | 1421312 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 336           |\n","|    iterations           | 695           |\n","|    time_elapsed         | 4230          |\n","|    total_timesteps      | 1423360       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014747045 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.736         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.3e+03       |\n","|    n_updates            | 6940          |\n","|    policy_gradient_loss | -0.000165     |\n","|    value_loss           | 2.84e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1425000, episode_reward=24271.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.43e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1425000       |\n","| train/                  |               |\n","|    approx_kl            | 5.8505277e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.782         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.28e+04      |\n","|    n_updates            | 6950          |\n","|    policy_gradient_loss | -0.000302     |\n","|    value_loss           | 4.5e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 336     |\n","|    iterations      | 696     |\n","|    time_elapsed    | 4238    |\n","|    total_timesteps | 1425408 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 336           |\n","|    iterations           | 697           |\n","|    time_elapsed         | 4241          |\n","|    total_timesteps      | 1427456       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037855556 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.705         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.13e+04      |\n","|    n_updates            | 6960          |\n","|    policy_gradient_loss | -0.000483     |\n","|    value_loss           | 7.52e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 336          |\n","|    iterations           | 698          |\n","|    time_elapsed         | 4244         |\n","|    total_timesteps      | 1429504      |\n","| train/                  |              |\n","|    approx_kl            | 2.325268e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.169       |\n","|    explained_variance   | 0.629        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.68e+03     |\n","|    n_updates            | 6970         |\n","|    policy_gradient_loss | -0.000142    |\n","|    value_loss           | 2.89e+04     |\n","------------------------------------------\n","Eval num_timesteps=1430000, episode_reward=25157.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.52e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1430000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005930563 |\n","|    clip_fraction        | 0.000781     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.161       |\n","|    explained_variance   | 0.678        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.83e+04     |\n","|    n_updates            | 6980         |\n","|    policy_gradient_loss | -0.000228    |\n","|    value_loss           | 5.47e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 336     |\n","|    iterations      | 699     |\n","|    time_elapsed    | 4251    |\n","|    total_timesteps | 1431552 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 336          |\n","|    iterations           | 700          |\n","|    time_elapsed         | 4254         |\n","|    total_timesteps      | 1433600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004208895 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.254       |\n","|    explained_variance   | 0.797        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.07e+04     |\n","|    n_updates            | 6990         |\n","|    policy_gradient_loss | -0.000761    |\n","|    value_loss           | 3.71e+04     |\n","------------------------------------------\n","Eval num_timesteps=1435000, episode_reward=25373.44 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.54e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1435000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026422457 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.21e+04      |\n","|    n_updates            | 7000          |\n","|    policy_gradient_loss | -0.000316     |\n","|    value_loss           | 3.83e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 336     |\n","|    iterations      | 701     |\n","|    time_elapsed    | 4262    |\n","|    total_timesteps | 1435648 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 337          |\n","|    iterations           | 702          |\n","|    time_elapsed         | 4265         |\n","|    total_timesteps      | 1437696      |\n","| train/                  |              |\n","|    approx_kl            | 6.849441e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.158       |\n","|    explained_variance   | 0.806        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.69e+03     |\n","|    n_updates            | 7010         |\n","|    policy_gradient_loss | -0.000321    |\n","|    value_loss           | 3.26e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 337          |\n","|    iterations           | 703          |\n","|    time_elapsed         | 4268         |\n","|    total_timesteps      | 1439744      |\n","| train/                  |              |\n","|    approx_kl            | 5.280046e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.227       |\n","|    explained_variance   | 0.579        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.08e+04     |\n","|    n_updates            | 7020         |\n","|    policy_gradient_loss | -0.000154    |\n","|    value_loss           | 1.59e+05     |\n","------------------------------------------\n","Eval num_timesteps=1440000, episode_reward=25373.44 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.54e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1440000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041779937 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.14         |\n","|    explained_variance   | 0.695         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.4e+04       |\n","|    n_updates            | 7030          |\n","|    policy_gradient_loss | -0.00069      |\n","|    value_loss           | 3.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 337     |\n","|    iterations      | 704     |\n","|    time_elapsed    | 4276    |\n","|    total_timesteps | 1441792 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 337           |\n","|    iterations           | 705           |\n","|    time_elapsed         | 4278          |\n","|    total_timesteps      | 1443840       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015641667 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.18         |\n","|    explained_variance   | 0.66          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.82e+03      |\n","|    n_updates            | 7040          |\n","|    policy_gradient_loss | 1.53e-06      |\n","|    value_loss           | 4.73e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1445000, episode_reward=24221.92 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.42e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1445000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041609895 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.221        |\n","|    explained_variance   | 0.814         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 7050          |\n","|    policy_gradient_loss | -0.00147      |\n","|    value_loss           | 3.38e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 337     |\n","|    iterations      | 706     |\n","|    time_elapsed    | 4286    |\n","|    total_timesteps | 1445888 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 337          |\n","|    iterations           | 707          |\n","|    time_elapsed         | 4289         |\n","|    total_timesteps      | 1447936      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003452114 |\n","|    clip_fraction        | 0.000244     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.155       |\n","|    explained_variance   | 0.583        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.41e+04     |\n","|    n_updates            | 7060         |\n","|    policy_gradient_loss | -0.000516    |\n","|    value_loss           | 3.86e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 337           |\n","|    iterations           | 708           |\n","|    time_elapsed         | 4292          |\n","|    total_timesteps      | 1449984       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016223668 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.73          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.59e+03      |\n","|    n_updates            | 7070          |\n","|    policy_gradient_loss | -0.000456     |\n","|    value_loss           | 6.81e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1450000, episode_reward=23606.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.36e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1450000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042009933 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.23         |\n","|    explained_variance   | 0.672         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.31e+04      |\n","|    n_updates            | 7080          |\n","|    policy_gradient_loss | -0.00123      |\n","|    value_loss           | 6.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 337     |\n","|    iterations      | 709     |\n","|    time_elapsed    | 4300    |\n","|    total_timesteps | 1452032 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 337          |\n","|    iterations           | 710          |\n","|    time_elapsed         | 4303         |\n","|    total_timesteps      | 1454080      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001985901 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.567        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.5e+04      |\n","|    n_updates            | 7090         |\n","|    policy_gradient_loss | -0.000234    |\n","|    value_loss           | 3.44e+04     |\n","------------------------------------------\n","Eval num_timesteps=1455000, episode_reward=18784.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1455000       |\n","| train/                  |               |\n","|    approx_kl            | 1.3485231e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.65          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.97e+03      |\n","|    n_updates            | 7100          |\n","|    policy_gradient_loss | -4.47e-05     |\n","|    value_loss           | 5.34e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 337     |\n","|    iterations      | 711     |\n","|    time_elapsed    | 4311    |\n","|    total_timesteps | 1456128 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 337           |\n","|    iterations           | 712           |\n","|    time_elapsed         | 4314          |\n","|    total_timesteps      | 1458176       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034454267 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.199        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.47e+03      |\n","|    n_updates            | 7110          |\n","|    policy_gradient_loss | -0.000319     |\n","|    value_loss           | 3.19e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1460000, episode_reward=22523.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1460000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047102038 |\n","|    clip_fraction        | 0.00132       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.671         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.41e+03      |\n","|    n_updates            | 7120          |\n","|    policy_gradient_loss | -0.000725     |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 337     |\n","|    iterations      | 713     |\n","|    time_elapsed    | 4321    |\n","|    total_timesteps | 1460224 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 338           |\n","|    iterations           | 714           |\n","|    time_elapsed         | 4324          |\n","|    total_timesteps      | 1462272       |\n","| train/                  |               |\n","|    approx_kl            | 2.5436515e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.581         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.4e+04       |\n","|    n_updates            | 7130          |\n","|    policy_gradient_loss | -0.000173     |\n","|    value_loss           | 9.8e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 338           |\n","|    iterations           | 715           |\n","|    time_elapsed         | 4327          |\n","|    total_timesteps      | 1464320       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020232223 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.245        |\n","|    explained_variance   | 0.719         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.14e+04      |\n","|    n_updates            | 7140          |\n","|    policy_gradient_loss | -0.000932     |\n","|    value_loss           | 6.92e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1465000, episode_reward=22177.22 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.22e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1465000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021470262 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.715         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.95e+03      |\n","|    n_updates            | 7150          |\n","|    policy_gradient_loss | -0.000355     |\n","|    value_loss           | 2.09e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 338     |\n","|    iterations      | 716     |\n","|    time_elapsed    | 4335    |\n","|    total_timesteps | 1466368 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 338           |\n","|    iterations           | 717           |\n","|    time_elapsed         | 4338          |\n","|    total_timesteps      | 1468416       |\n","| train/                  |               |\n","|    approx_kl            | 5.6267774e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.207        |\n","|    explained_variance   | 0.611         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.98e+04      |\n","|    n_updates            | 7160          |\n","|    policy_gradient_loss | -8.24e-05     |\n","|    value_loss           | 6.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1470000, episode_reward=14206.88 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.42e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1470000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048560364 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.818         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.21e+04      |\n","|    n_updates            | 7170          |\n","|    policy_gradient_loss | -0.000479     |\n","|    value_loss           | 3.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 338     |\n","|    iterations      | 718     |\n","|    time_elapsed    | 4345    |\n","|    total_timesteps | 1470464 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 338          |\n","|    iterations           | 719          |\n","|    time_elapsed         | 4348         |\n","|    total_timesteps      | 1472512      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004518742 |\n","|    clip_fraction        | 0.000879     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.145       |\n","|    explained_variance   | 0.714        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.14e+03     |\n","|    n_updates            | 7180         |\n","|    policy_gradient_loss | -0.000554    |\n","|    value_loss           | 2.64e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 338           |\n","|    iterations           | 720           |\n","|    time_elapsed         | 4351          |\n","|    total_timesteps      | 1474560       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017677498 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.608         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.03e+04      |\n","|    n_updates            | 7190          |\n","|    policy_gradient_loss | -0.000182     |\n","|    value_loss           | 1.68e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1475000, episode_reward=22523.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.25e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1475000      |\n","| train/                  |              |\n","|    approx_kl            | 7.763208e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.239       |\n","|    explained_variance   | 0.767        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.65e+04     |\n","|    n_updates            | 7200         |\n","|    policy_gradient_loss | -0.000377    |\n","|    value_loss           | 5.34e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 338     |\n","|    iterations      | 721     |\n","|    time_elapsed    | 4359    |\n","|    total_timesteps | 1476608 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 338           |\n","|    iterations           | 722           |\n","|    time_elapsed         | 4362          |\n","|    total_timesteps      | 1478656       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038960733 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.682         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.26e+04      |\n","|    n_updates            | 7210          |\n","|    policy_gradient_loss | -0.000399     |\n","|    value_loss           | 3.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1480000, episode_reward=22523.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1480000       |\n","| train/                  |               |\n","|    approx_kl            | 1.4621095e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.222        |\n","|    explained_variance   | 0.709         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.25e+03      |\n","|    n_updates            | 7220          |\n","|    policy_gradient_loss | 2.58e-06      |\n","|    value_loss           | 3.93e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 338     |\n","|    iterations      | 723     |\n","|    time_elapsed    | 4369    |\n","|    total_timesteps | 1480704 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 339           |\n","|    iterations           | 724           |\n","|    time_elapsed         | 4372          |\n","|    total_timesteps      | 1482752       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010511832 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.131        |\n","|    explained_variance   | 0.755         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.96e+04      |\n","|    n_updates            | 7230          |\n","|    policy_gradient_loss | -7.22e-05     |\n","|    value_loss           | 4.26e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 339           |\n","|    iterations           | 725           |\n","|    time_elapsed         | 4375          |\n","|    total_timesteps      | 1484800       |\n","| train/                  |               |\n","|    approx_kl            | 0.00076851435 |\n","|    clip_fraction        | 0.00269       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.806         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.42e+03      |\n","|    n_updates            | 7240          |\n","|    policy_gradient_loss | -0.00123      |\n","|    value_loss           | 3.4e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1485000, episode_reward=18000.66 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.8e+04        |\n","| time/                   |                |\n","|    total_timesteps      | 1485000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000109825254 |\n","|    clip_fraction        | 4.88e-05       |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.121         |\n","|    explained_variance   | 0.587          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 2.21e+05       |\n","|    n_updates            | 7250           |\n","|    policy_gradient_loss | -0.000274      |\n","|    value_loss           | 1.41e+05       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 339     |\n","|    iterations      | 726     |\n","|    time_elapsed    | 4383    |\n","|    total_timesteps | 1486848 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 339           |\n","|    iterations           | 727           |\n","|    time_elapsed         | 4386          |\n","|    total_timesteps      | 1488896       |\n","| train/                  |               |\n","|    approx_kl            | 2.3528206e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.213        |\n","|    explained_variance   | 0.843         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.52e+03      |\n","|    n_updates            | 7260          |\n","|    policy_gradient_loss | -6.4e-05      |\n","|    value_loss           | 2.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1490000, episode_reward=17451.12 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.75e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1490000       |\n","| train/                  |               |\n","|    approx_kl            | 1.5776284e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.423         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.18e+04      |\n","|    n_updates            | 7270          |\n","|    policy_gradient_loss | -6.1e-05      |\n","|    value_loss           | 4.85e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 339     |\n","|    iterations      | 728     |\n","|    time_elapsed    | 4394    |\n","|    total_timesteps | 1490944 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 339           |\n","|    iterations           | 729           |\n","|    time_elapsed         | 4396          |\n","|    total_timesteps      | 1492992       |\n","| train/                  |               |\n","|    approx_kl            | 5.4460455e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.228        |\n","|    explained_variance   | 0.759         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.66e+04      |\n","|    n_updates            | 7280          |\n","|    policy_gradient_loss | -0.000381     |\n","|    value_loss           | 3.98e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1495000, episode_reward=14195.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.42e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1495000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007156442 |\n","|    clip_fraction        | 0.00542      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.731        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.55e+04     |\n","|    n_updates            | 7290         |\n","|    policy_gradient_loss | -0.00127     |\n","|    value_loss           | 3.29e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 339     |\n","|    iterations      | 730     |\n","|    time_elapsed    | 4404    |\n","|    total_timesteps | 1495040 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 339          |\n","|    iterations           | 731          |\n","|    time_elapsed         | 4407         |\n","|    total_timesteps      | 1497088      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004060058 |\n","|    clip_fraction        | 0.00083      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.153       |\n","|    explained_variance   | 0.728        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.63e+04     |\n","|    n_updates            | 7300         |\n","|    policy_gradient_loss | -0.0015      |\n","|    value_loss           | 5.31e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 339          |\n","|    iterations           | 732          |\n","|    time_elapsed         | 4410         |\n","|    total_timesteps      | 1499136      |\n","| train/                  |              |\n","|    approx_kl            | 3.060908e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.16        |\n","|    explained_variance   | 0.702        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.59e+04     |\n","|    n_updates            | 7310         |\n","|    policy_gradient_loss | -0.000108    |\n","|    value_loss           | 1.71e+05     |\n","------------------------------------------\n","Eval num_timesteps=1500000, episode_reward=12629.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.26e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1500000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015758802 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.171        |\n","|    explained_variance   | 0.688         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 7320          |\n","|    policy_gradient_loss | -0.000688     |\n","|    value_loss           | 2.99e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 339     |\n","|    iterations      | 733     |\n","|    time_elapsed    | 4417    |\n","|    total_timesteps | 1501184 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 340           |\n","|    iterations           | 734           |\n","|    time_elapsed         | 4420          |\n","|    total_timesteps      | 1503232       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033045132 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.41          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.74e+03      |\n","|    n_updates            | 7330          |\n","|    policy_gradient_loss | -0.000173     |\n","|    value_loss           | 4.95e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1505000, episode_reward=18142.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.81e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1505000      |\n","| train/                  |              |\n","|    approx_kl            | 6.495073e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.248       |\n","|    explained_variance   | 0.816        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.93e+03     |\n","|    n_updates            | 7340         |\n","|    policy_gradient_loss | -0.000121    |\n","|    value_loss           | 3.18e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 339     |\n","|    iterations      | 735     |\n","|    time_elapsed    | 4428    |\n","|    total_timesteps | 1505280 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 340           |\n","|    iterations           | 736           |\n","|    time_elapsed         | 4431          |\n","|    total_timesteps      | 1507328       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027629035 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.729         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+04       |\n","|    n_updates            | 7350          |\n","|    policy_gradient_loss | -0.000324     |\n","|    value_loss           | 3.03e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 340          |\n","|    iterations           | 737          |\n","|    time_elapsed         | 4434         |\n","|    total_timesteps      | 1509376      |\n","| train/                  |              |\n","|    approx_kl            | 2.146294e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.14        |\n","|    explained_variance   | 0.823        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.58e+04     |\n","|    n_updates            | 7360         |\n","|    policy_gradient_loss | -0.000194    |\n","|    value_loss           | 4.15e+04     |\n","------------------------------------------\n","Eval num_timesteps=1510000, episode_reward=18420.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.84e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1510000      |\n","| train/                  |              |\n","|    approx_kl            | 3.620636e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.207       |\n","|    explained_variance   | 0.61         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.42e+04     |\n","|    n_updates            | 7370         |\n","|    policy_gradient_loss | -0.000104    |\n","|    value_loss           | 1.45e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 340     |\n","|    iterations      | 738     |\n","|    time_elapsed    | 4441    |\n","|    total_timesteps | 1511424 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 340           |\n","|    iterations           | 739           |\n","|    time_elapsed         | 4444          |\n","|    total_timesteps      | 1513472       |\n","| train/                  |               |\n","|    approx_kl            | 2.1029526e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.611         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.34e+04      |\n","|    n_updates            | 7380          |\n","|    policy_gradient_loss | 2.48e-05      |\n","|    value_loss           | 6.17e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1515000, episode_reward=22523.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.25e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1515000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005787192 |\n","|    clip_fraction        | 0.0022       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.578        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.88e+04     |\n","|    n_updates            | 7390         |\n","|    policy_gradient_loss | -0.00101     |\n","|    value_loss           | 6.06e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 340     |\n","|    iterations      | 740     |\n","|    time_elapsed    | 4451    |\n","|    total_timesteps | 1515520 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 340         |\n","|    iterations           | 741         |\n","|    time_elapsed         | 4455        |\n","|    total_timesteps      | 1517568     |\n","| train/                  |             |\n","|    approx_kl            | 8.87074e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.221      |\n","|    explained_variance   | 0.801       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 8.57e+03    |\n","|    n_updates            | 7400        |\n","|    policy_gradient_loss | -0.000396   |\n","|    value_loss           | 3.46e+04    |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 340          |\n","|    iterations           | 742          |\n","|    time_elapsed         | 4458         |\n","|    total_timesteps      | 1519616      |\n","| train/                  |              |\n","|    approx_kl            | 5.927842e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.551        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.36e+04     |\n","|    n_updates            | 7410         |\n","|    policy_gradient_loss | -8.93e-05    |\n","|    value_loss           | 3.68e+04     |\n","------------------------------------------\n","Eval num_timesteps=1520000, episode_reward=24047.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.4e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1520000      |\n","| train/                  |              |\n","|    approx_kl            | 3.409272e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.118       |\n","|    explained_variance   | 0.621        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.12e+04     |\n","|    n_updates            | 7420         |\n","|    policy_gradient_loss | -3.73e-05    |\n","|    value_loss           | 5.64e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 340     |\n","|    iterations      | 743     |\n","|    time_elapsed    | 4465    |\n","|    total_timesteps | 1521664 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 340         |\n","|    iterations           | 744         |\n","|    time_elapsed         | 4468        |\n","|    total_timesteps      | 1523712     |\n","| train/                  |             |\n","|    approx_kl            | 6.16312e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.211      |\n","|    explained_variance   | 0.789       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 3.18e+04    |\n","|    n_updates            | 7430        |\n","|    policy_gradient_loss | -8.57e-05   |\n","|    value_loss           | 7.9e+04     |\n","-----------------------------------------\n","Eval num_timesteps=1525000, episode_reward=24058.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1525000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1812913e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.562         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.51e+03      |\n","|    n_updates            | 7440          |\n","|    policy_gradient_loss | -0.000156     |\n","|    value_loss           | 2.62e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 340     |\n","|    iterations      | 745     |\n","|    time_elapsed    | 4476    |\n","|    total_timesteps | 1525760 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 746           |\n","|    time_elapsed         | 4479          |\n","|    total_timesteps      | 1527808       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033775374 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.171        |\n","|    explained_variance   | 0.535         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.89e+04      |\n","|    n_updates            | 7450          |\n","|    policy_gradient_loss | -0.000748     |\n","|    value_loss           | 4.78e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 341          |\n","|    iterations           | 747          |\n","|    time_elapsed         | 4482         |\n","|    total_timesteps      | 1529856      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004725151 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.19        |\n","|    explained_variance   | 0.795        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.72e+03     |\n","|    n_updates            | 7460         |\n","|    policy_gradient_loss | -0.000482    |\n","|    value_loss           | 2.83e+04     |\n","------------------------------------------\n","Eval num_timesteps=1530000, episode_reward=25633.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1530000       |\n","| train/                  |               |\n","|    approx_kl            | 1.1622935e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.719         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.47e+03      |\n","|    n_updates            | 7470          |\n","|    policy_gradient_loss | -7.5e-05      |\n","|    value_loss           | 2.8e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 748     |\n","|    time_elapsed    | 4490    |\n","|    total_timesteps | 1531904 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 749           |\n","|    time_elapsed         | 4493          |\n","|    total_timesteps      | 1533952       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032074976 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.687         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 7480          |\n","|    policy_gradient_loss | -0.000686     |\n","|    value_loss           | 4.15e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1535000, episode_reward=23764.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.38e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1535000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004018953 |\n","|    clip_fraction        | 0.00107      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.238       |\n","|    explained_variance   | 0.74         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.22e+04     |\n","|    n_updates            | 7490         |\n","|    policy_gradient_loss | -0.000772    |\n","|    value_loss           | 7.17e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 750     |\n","|    time_elapsed    | 4500    |\n","|    total_timesteps | 1536000 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 751           |\n","|    time_elapsed         | 4503          |\n","|    total_timesteps      | 1538048       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012838058 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.649         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.31e+03      |\n","|    n_updates            | 7500          |\n","|    policy_gradient_loss | -0.000111     |\n","|    value_loss           | 3.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1540000, episode_reward=24522.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.45e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1540000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001850946 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.202       |\n","|    explained_variance   | 0.671        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.69e+04     |\n","|    n_updates            | 7510         |\n","|    policy_gradient_loss | -0.000406    |\n","|    value_loss           | 6.11e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 752     |\n","|    time_elapsed    | 4511    |\n","|    total_timesteps | 1540096 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 341          |\n","|    iterations           | 753          |\n","|    time_elapsed         | 4514         |\n","|    total_timesteps      | 1542144      |\n","| train/                  |              |\n","|    approx_kl            | 2.020548e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.168       |\n","|    explained_variance   | 0.699        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.54e+03     |\n","|    n_updates            | 7520         |\n","|    policy_gradient_loss | -0.000124    |\n","|    value_loss           | 2.93e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 754           |\n","|    time_elapsed         | 4517          |\n","|    total_timesteps      | 1544192       |\n","| train/                  |               |\n","|    approx_kl            | 2.9610848e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.143        |\n","|    explained_variance   | 0.539         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 7530          |\n","|    policy_gradient_loss | -0.000318     |\n","|    value_loss           | 3.93e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1545000, episode_reward=24554.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.46e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1545000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015071325 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.123        |\n","|    explained_variance   | 0.519         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.81e+04      |\n","|    n_updates            | 7540          |\n","|    policy_gradient_loss | -0.000553     |\n","|    value_loss           | 9.27e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 755     |\n","|    time_elapsed    | 4525    |\n","|    total_timesteps | 1546240 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 756           |\n","|    time_elapsed         | 4528          |\n","|    total_timesteps      | 1548288       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019306169 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.231        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 7550          |\n","|    policy_gradient_loss | -0.000813     |\n","|    value_loss           | 5.75e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1550000, episode_reward=24854.41 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1550000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031868767 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.146        |\n","|    explained_variance   | 0.444         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.85e+04      |\n","|    n_updates            | 7560          |\n","|    policy_gradient_loss | -0.000315     |\n","|    value_loss           | 5.13e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 757     |\n","|    time_elapsed    | 4536    |\n","|    total_timesteps | 1550336 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 758           |\n","|    time_elapsed         | 4539          |\n","|    total_timesteps      | 1552384       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019970373 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.215        |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 7570          |\n","|    policy_gradient_loss | -0.000377     |\n","|    value_loss           | 5.14e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 759           |\n","|    time_elapsed         | 4545          |\n","|    total_timesteps      | 1554432       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015110822 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.718         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 7580          |\n","|    policy_gradient_loss | -0.000108     |\n","|    value_loss           | 3.28e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1555000, episode_reward=24633.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.46e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1555000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031379997 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.468         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.76e+04      |\n","|    n_updates            | 7590          |\n","|    policy_gradient_loss | -0.00073      |\n","|    value_loss           | 4.31e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 760     |\n","|    time_elapsed    | 4553    |\n","|    total_timesteps | 1556480 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 341           |\n","|    iterations           | 761           |\n","|    time_elapsed         | 4557          |\n","|    total_timesteps      | 1558528       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016765192 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.131        |\n","|    explained_variance   | 0.618         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.6e+04       |\n","|    n_updates            | 7600          |\n","|    policy_gradient_loss | -0.000303     |\n","|    value_loss           | 1.13e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1560000, episode_reward=24415.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1560000       |\n","| train/                  |               |\n","|    approx_kl            | 1.5714875e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.208        |\n","|    explained_variance   | 0.73          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.04e+04      |\n","|    n_updates            | 7610          |\n","|    policy_gradient_loss | -0.00011      |\n","|    value_loss           | 3.89e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 341     |\n","|    iterations      | 762     |\n","|    time_elapsed    | 4565    |\n","|    total_timesteps | 1560576 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 342           |\n","|    iterations           | 763           |\n","|    time_elapsed         | 4568          |\n","|    total_timesteps      | 1562624       |\n","| train/                  |               |\n","|    approx_kl            | 3.8520055e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.602         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4e+04         |\n","|    n_updates            | 7620          |\n","|    policy_gradient_loss | -6.43e-05     |\n","|    value_loss           | 6.66e+04      |\n","-------------------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 342            |\n","|    iterations           | 764            |\n","|    time_elapsed         | 4571           |\n","|    total_timesteps      | 1564672        |\n","| train/                  |                |\n","|    approx_kl            | 1.15706935e-05 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.232         |\n","|    explained_variance   | 0.698          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 8.11e+03       |\n","|    n_updates            | 7630           |\n","|    policy_gradient_loss | -6.6e-05       |\n","|    value_loss           | 3.86e+04       |\n","--------------------------------------------\n","Eval num_timesteps=1565000, episode_reward=26074.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.61e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1565000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002535092 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.14        |\n","|    explained_variance   | 0.714        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.33e+04     |\n","|    n_updates            | 7640         |\n","|    policy_gradient_loss | -0.000162    |\n","|    value_loss           | 3.02e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 342     |\n","|    iterations      | 765     |\n","|    time_elapsed    | 4579    |\n","|    total_timesteps | 1566720 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 342          |\n","|    iterations           | 766          |\n","|    time_elapsed         | 4582         |\n","|    total_timesteps      | 1568768      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003122236 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.159       |\n","|    explained_variance   | 0.667        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.44e+04     |\n","|    n_updates            | 7650         |\n","|    policy_gradient_loss | -0.000418    |\n","|    value_loss           | 3.59e+04     |\n","------------------------------------------\n","Eval num_timesteps=1570000, episode_reward=25261.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.53e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1570000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040194052 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.651         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.49e+04      |\n","|    n_updates            | 7660          |\n","|    policy_gradient_loss | -0.000628     |\n","|    value_loss           | 6.94e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 342     |\n","|    iterations      | 767     |\n","|    time_elapsed    | 4590    |\n","|    total_timesteps | 1570816 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 342           |\n","|    iterations           | 768           |\n","|    time_elapsed         | 4593          |\n","|    total_timesteps      | 1572864       |\n","| train/                  |               |\n","|    approx_kl            | 0.00050538476 |\n","|    clip_fraction        | 0.00391       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.183        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.94e+04      |\n","|    n_updates            | 7670          |\n","|    policy_gradient_loss | -0.00207      |\n","|    value_loss           | 3.5e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 342           |\n","|    iterations           | 769           |\n","|    time_elapsed         | 4596          |\n","|    total_timesteps      | 1574912       |\n","| train/                  |               |\n","|    approx_kl            | 1.1138531e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.04e+04      |\n","|    n_updates            | 7680          |\n","|    policy_gradient_loss | -8.67e-05     |\n","|    value_loss           | 4.35e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1575000, episode_reward=24415.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.44e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1575000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008267438 |\n","|    clip_fraction        | 0.00278      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.241       |\n","|    explained_variance   | 0.752        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.14e+03     |\n","|    n_updates            | 7690         |\n","|    policy_gradient_loss | -0.00118     |\n","|    value_loss           | 2.87e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 342     |\n","|    iterations      | 770     |\n","|    time_elapsed    | 4604    |\n","|    total_timesteps | 1576960 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 342           |\n","|    iterations           | 771           |\n","|    time_elapsed         | 4607          |\n","|    total_timesteps      | 1579008       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019738977 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.678         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 7700          |\n","|    policy_gradient_loss | -0.000157     |\n","|    value_loss           | 3.62e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1580000, episode_reward=24993.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1580000       |\n","| train/                  |               |\n","|    approx_kl            | 1.4499237e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.691         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.02e+03      |\n","|    n_updates            | 7710          |\n","|    policy_gradient_loss | -0.000241     |\n","|    value_loss           | 5.23e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 342     |\n","|    iterations      | 772     |\n","|    time_elapsed    | 4615    |\n","|    total_timesteps | 1581056 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 342           |\n","|    iterations           | 773           |\n","|    time_elapsed         | 4618          |\n","|    total_timesteps      | 1583104       |\n","| train/                  |               |\n","|    approx_kl            | 2.2119522e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.207        |\n","|    explained_variance   | 0.723         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.21e+04      |\n","|    n_updates            | 7720          |\n","|    policy_gradient_loss | -0.000118     |\n","|    value_loss           | 8.84e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1585000, episode_reward=25274.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.53e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1585000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003072023 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.12        |\n","|    explained_variance   | 0.588        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.18e+04     |\n","|    n_updates            | 7730         |\n","|    policy_gradient_loss | -0.000372    |\n","|    value_loss           | 3.57e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 342     |\n","|    iterations      | 774     |\n","|    time_elapsed    | 4626    |\n","|    total_timesteps | 1585152 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 342           |\n","|    iterations           | 775           |\n","|    time_elapsed         | 4629          |\n","|    total_timesteps      | 1587200       |\n","| train/                  |               |\n","|    approx_kl            | 4.2143016e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.171        |\n","|    explained_variance   | 0.699         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.79e+04      |\n","|    n_updates            | 7740          |\n","|    policy_gradient_loss | -7.45e-05     |\n","|    value_loss           | 5.83e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 343           |\n","|    iterations           | 776           |\n","|    time_elapsed         | 4631          |\n","|    total_timesteps      | 1589248       |\n","| train/                  |               |\n","|    approx_kl            | 1.4896825e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.222        |\n","|    explained_variance   | 0.856         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.23e+03      |\n","|    n_updates            | 7750          |\n","|    policy_gradient_loss | -0.000202     |\n","|    value_loss           | 3.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1590000, episode_reward=24942.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1590000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010898936 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.146        |\n","|    explained_variance   | 0.431         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 7760          |\n","|    policy_gradient_loss | -0.000164     |\n","|    value_loss           | 3.55e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 342     |\n","|    iterations      | 777     |\n","|    time_elapsed    | 4639    |\n","|    total_timesteps | 1591296 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 343           |\n","|    iterations           | 778           |\n","|    time_elapsed         | 4642          |\n","|    total_timesteps      | 1593344       |\n","| train/                  |               |\n","|    approx_kl            | 2.1323794e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.111        |\n","|    explained_variance   | 0.636         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.88e+04      |\n","|    n_updates            | 7770          |\n","|    policy_gradient_loss | 4.4e-06       |\n","|    value_loss           | 7.13e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1595000, episode_reward=24562.44 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.46e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1595000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022652716 |\n","|    clip_fraction        | 0.00122       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.202        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.31e+04      |\n","|    n_updates            | 7780          |\n","|    policy_gradient_loss | -0.000997     |\n","|    value_loss           | 6.58e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 343     |\n","|    iterations      | 779     |\n","|    time_elapsed    | 4650    |\n","|    total_timesteps | 1595392 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 343          |\n","|    iterations           | 780          |\n","|    time_elapsed         | 4653         |\n","|    total_timesteps      | 1597440      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007994722 |\n","|    clip_fraction        | 0.00645      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.147       |\n","|    explained_variance   | 0.586        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.04e+03     |\n","|    n_updates            | 7790         |\n","|    policy_gradient_loss | -0.00161     |\n","|    value_loss           | 3.42e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 343           |\n","|    iterations           | 781           |\n","|    time_elapsed         | 4656          |\n","|    total_timesteps      | 1599488       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010474675 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.677         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.5e+04       |\n","|    n_updates            | 7800          |\n","|    policy_gradient_loss | -0.000209     |\n","|    value_loss           | 5.44e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1600000, episode_reward=21194.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.12e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1600000      |\n","| train/                  |              |\n","|    approx_kl            | 2.000737e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.183       |\n","|    explained_variance   | 0.838        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.77e+03     |\n","|    n_updates            | 7810         |\n","|    policy_gradient_loss | -0.00016     |\n","|    value_loss           | 3.14e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 343     |\n","|    iterations      | 782     |\n","|    time_elapsed    | 4664    |\n","|    total_timesteps | 1601536 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 343           |\n","|    iterations           | 783           |\n","|    time_elapsed         | 4667          |\n","|    total_timesteps      | 1603584       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011440698 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.643         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 7820          |\n","|    policy_gradient_loss | -0.000187     |\n","|    value_loss           | 2.77e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1605000, episode_reward=25332.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.53e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 1605000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000264307 |\n","|    clip_fraction        | 0.000684    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.0996     |\n","|    explained_variance   | 0.627       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.77e+04    |\n","|    n_updates            | 7830        |\n","|    policy_gradient_loss | -0.000589   |\n","|    value_loss           | 6.57e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 343     |\n","|    iterations      | 784     |\n","|    time_elapsed    | 4674    |\n","|    total_timesteps | 1605632 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 343           |\n","|    iterations           | 785           |\n","|    time_elapsed         | 4678          |\n","|    total_timesteps      | 1607680       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024353416 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.219        |\n","|    explained_variance   | 0.794         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 7840          |\n","|    policy_gradient_loss | -0.000682     |\n","|    value_loss           | 6.66e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 343           |\n","|    iterations           | 786           |\n","|    time_elapsed         | 4681          |\n","|    total_timesteps      | 1609728       |\n","| train/                  |               |\n","|    approx_kl            | 0.00059811666 |\n","|    clip_fraction        | 0.00347       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.631         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.12e+04      |\n","|    n_updates            | 7850          |\n","|    policy_gradient_loss | -0.000907     |\n","|    value_loss           | 2.5e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1610000, episode_reward=25665.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1610000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042163098 |\n","|    clip_fraction        | 0.00259       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.192        |\n","|    explained_variance   | 0.636         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 7860          |\n","|    policy_gradient_loss | -0.0015       |\n","|    value_loss           | 5.41e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 343     |\n","|    iterations      | 787     |\n","|    time_elapsed    | 4688    |\n","|    total_timesteps | 1611776 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 343          |\n","|    iterations           | 788          |\n","|    time_elapsed         | 4691         |\n","|    total_timesteps      | 1613824      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005580651 |\n","|    clip_fraction        | 0.00283      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.172       |\n","|    explained_variance   | 0.784        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.32e+03     |\n","|    n_updates            | 7870         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 3.09e+04     |\n","------------------------------------------\n","Eval num_timesteps=1615000, episode_reward=21473.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.15e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1615000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002493096 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.141       |\n","|    explained_variance   | 0.628        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.57e+03     |\n","|    n_updates            | 7880         |\n","|    policy_gradient_loss | -0.00033     |\n","|    value_loss           | 3.44e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 343     |\n","|    iterations      | 789     |\n","|    time_elapsed    | 4699    |\n","|    total_timesteps | 1615872 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 790           |\n","|    time_elapsed         | 4702          |\n","|    total_timesteps      | 1617920       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012436564 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0906       |\n","|    explained_variance   | 0.597         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.2e+04       |\n","|    n_updates            | 7890          |\n","|    policy_gradient_loss | -0.000467     |\n","|    value_loss           | 9.14e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 791           |\n","|    time_elapsed         | 4705          |\n","|    total_timesteps      | 1619968       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044973794 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.233        |\n","|    explained_variance   | 0.657         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.7e+04       |\n","|    n_updates            | 7900          |\n","|    policy_gradient_loss | -0.000712     |\n","|    value_loss           | 4.93e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1620000, episode_reward=23312.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.33e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1620000      |\n","| train/                  |              |\n","|    approx_kl            | 2.821174e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.143       |\n","|    explained_variance   | 0.627        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.06e+03     |\n","|    n_updates            | 7910         |\n","|    policy_gradient_loss | -0.000163    |\n","|    value_loss           | 2.55e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 792     |\n","|    time_elapsed    | 4713    |\n","|    total_timesteps | 1622016 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 793           |\n","|    time_elapsed         | 4716          |\n","|    total_timesteps      | 1624064       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027945824 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.214        |\n","|    explained_variance   | 0.624         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 7920          |\n","|    policy_gradient_loss | -0.000203     |\n","|    value_loss           | 4.94e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1625000, episode_reward=23312.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.33e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1625000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025521326 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.742         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.34e+04      |\n","|    n_updates            | 7930          |\n","|    policy_gradient_loss | -0.000197     |\n","|    value_loss           | 2.51e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 794     |\n","|    time_elapsed    | 4723    |\n","|    total_timesteps | 1626112 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 795           |\n","|    time_elapsed         | 4726          |\n","|    total_timesteps      | 1628160       |\n","| train/                  |               |\n","|    approx_kl            | 0.00051049865 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.607         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 7940          |\n","|    policy_gradient_loss | -0.000534     |\n","|    value_loss           | 3.68e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1630000, episode_reward=21776.56 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1630000       |\n","| train/                  |               |\n","|    approx_kl            | 2.0489388e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.51          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.98e+04      |\n","|    n_updates            | 7950          |\n","|    policy_gradient_loss | -4.93e-05     |\n","|    value_loss           | 1.25e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 796     |\n","|    time_elapsed    | 4734    |\n","|    total_timesteps | 1630208 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 797           |\n","|    time_elapsed         | 4737          |\n","|    total_timesteps      | 1632256       |\n","| train/                  |               |\n","|    approx_kl            | 5.2962278e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.205        |\n","|    explained_variance   | 0.804         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.74e+04      |\n","|    n_updates            | 7960          |\n","|    policy_gradient_loss | -5.02e-05     |\n","|    value_loss           | 3.55e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 798          |\n","|    time_elapsed         | 4740         |\n","|    total_timesteps      | 1634304      |\n","| train/                  |              |\n","|    approx_kl            | 4.250396e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.137       |\n","|    explained_variance   | 0.482        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.28e+04     |\n","|    n_updates            | 7970         |\n","|    policy_gradient_loss | -0.000134    |\n","|    value_loss           | 5.3e+04      |\n","------------------------------------------\n","Eval num_timesteps=1635000, episode_reward=22559.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.26e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1635000      |\n","| train/                  |              |\n","|    approx_kl            | 7.315411e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.222       |\n","|    explained_variance   | 0.74         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.24e+04     |\n","|    n_updates            | 7980         |\n","|    policy_gradient_loss | -0.000295    |\n","|    value_loss           | 2.92e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 799     |\n","|    time_elapsed    | 4747    |\n","|    total_timesteps | 1636352 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 800           |\n","|    time_elapsed         | 4750          |\n","|    total_timesteps      | 1638400       |\n","| train/                  |               |\n","|    approx_kl            | 0.00049303996 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.635         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.7e+03       |\n","|    n_updates            | 7990          |\n","|    policy_gradient_loss | -0.000335     |\n","|    value_loss           | 2.71e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1640000, episode_reward=23312.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.33e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1640000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015709642 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.157        |\n","|    explained_variance   | 0.653         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.21e+04      |\n","|    n_updates            | 8000          |\n","|    policy_gradient_loss | -0.000343     |\n","|    value_loss           | 4.26e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 801     |\n","|    time_elapsed    | 4758    |\n","|    total_timesteps | 1640448 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 802           |\n","|    time_elapsed         | 4761          |\n","|    total_timesteps      | 1642496       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024315185 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.623         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.87e+04      |\n","|    n_updates            | 8010          |\n","|    policy_gradient_loss | -0.00084      |\n","|    value_loss           | 1.19e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 803           |\n","|    time_elapsed         | 4764          |\n","|    total_timesteps      | 1644544       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037564116 |\n","|    clip_fraction        | 0.00176       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.18         |\n","|    explained_variance   | 0.712         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 8020          |\n","|    policy_gradient_loss | -0.0012       |\n","|    value_loss           | 2.92e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1645000, episode_reward=23591.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.36e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1645000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004916881 |\n","|    clip_fraction        | 0.0022       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.145       |\n","|    explained_variance   | 0.489        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.45e+04     |\n","|    n_updates            | 8030         |\n","|    policy_gradient_loss | -0.000493    |\n","|    value_loss           | 5.26e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 804     |\n","|    time_elapsed    | 4772    |\n","|    total_timesteps | 1646592 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 805          |\n","|    time_elapsed         | 4775         |\n","|    total_timesteps      | 1648640      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006901042 |\n","|    clip_fraction        | 0.0022       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.243       |\n","|    explained_variance   | 0.802        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+04     |\n","|    n_updates            | 8040         |\n","|    policy_gradient_loss | -0.000764    |\n","|    value_loss           | 2.93e+04     |\n","------------------------------------------\n","Eval num_timesteps=1650000, episode_reward=25603.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1650000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012313272 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.67          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.82e+04      |\n","|    n_updates            | 8050          |\n","|    policy_gradient_loss | -9.43e-05     |\n","|    value_loss           | 4.21e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 806     |\n","|    time_elapsed    | 4783    |\n","|    total_timesteps | 1650688 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 807           |\n","|    time_elapsed         | 4785          |\n","|    total_timesteps      | 1652736       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011658727 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.683         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.04e+04      |\n","|    n_updates            | 8060          |\n","|    policy_gradient_loss | -0.000363     |\n","|    value_loss           | 4.13e+04      |\n","-------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 345         |\n","|    iterations           | 808         |\n","|    time_elapsed         | 4788        |\n","|    total_timesteps      | 1654784     |\n","| train/                  |             |\n","|    approx_kl            | 8.25536e-06 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.2        |\n","|    explained_variance   | 0.725       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 4.07e+04    |\n","|    n_updates            | 8070        |\n","|    policy_gradient_loss | -0.000104   |\n","|    value_loss           | 8.85e+04    |\n","-----------------------------------------\n","Eval num_timesteps=1655000, episode_reward=22850.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.29e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1655000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033601496 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.67e+04      |\n","|    n_updates            | 8080          |\n","|    policy_gradient_loss | -0.000713     |\n","|    value_loss           | 3.38e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 809     |\n","|    time_elapsed    | 4796    |\n","|    total_timesteps | 1656832 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 810           |\n","|    time_elapsed         | 4799          |\n","|    total_timesteps      | 1658880       |\n","| train/                  |               |\n","|    approx_kl            | 1.3276178e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.457         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.38e+04      |\n","|    n_updates            | 8090          |\n","|    policy_gradient_loss | -2.18e-05     |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1660000, episode_reward=23150.44 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.32e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1660000      |\n","| train/                  |              |\n","|    approx_kl            | 7.199036e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.219       |\n","|    explained_variance   | 0.88         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.55e+04     |\n","|    n_updates            | 8100         |\n","|    policy_gradient_loss | -0.00017     |\n","|    value_loss           | 2.05e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 811     |\n","|    time_elapsed    | 4809    |\n","|    total_timesteps | 1660928 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 812           |\n","|    time_elapsed         | 4813          |\n","|    total_timesteps      | 1662976       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046711086 |\n","|    clip_fraction        | 0.00259       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.63          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 8110          |\n","|    policy_gradient_loss | -0.00108      |\n","|    value_loss           | 3.15e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1665000, episode_reward=24526.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1665000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040041082 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.754         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.18e+04      |\n","|    n_updates            | 8120          |\n","|    policy_gradient_loss | -0.000763     |\n","|    value_loss           | 4.07e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 813     |\n","|    time_elapsed    | 4822    |\n","|    total_timesteps | 1665024 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 814           |\n","|    time_elapsed         | 4826          |\n","|    total_timesteps      | 1667072       |\n","| train/                  |               |\n","|    approx_kl            | 0.00053952547 |\n","|    clip_fraction        | 0.00176       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.722         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 8130          |\n","|    policy_gradient_loss | -0.00097      |\n","|    value_loss           | 8.27e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 815          |\n","|    time_elapsed         | 4829         |\n","|    total_timesteps      | 1669120      |\n","| train/                  |              |\n","|    approx_kl            | 5.784066e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.589        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.89e+03     |\n","|    n_updates            | 8140         |\n","|    policy_gradient_loss | -6.52e-05    |\n","|    value_loss           | 2.75e+04     |\n","------------------------------------------\n","Eval num_timesteps=1670000, episode_reward=24179.10 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.42e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1670000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015385935 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.189        |\n","|    explained_variance   | 0.692         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.14e+04      |\n","|    n_updates            | 8150          |\n","|    policy_gradient_loss | -0.000149     |\n","|    value_loss           | 4.72e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 816     |\n","|    time_elapsed    | 4840    |\n","|    total_timesteps | 1671168 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 817          |\n","|    time_elapsed         | 4844         |\n","|    total_timesteps      | 1673216      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001495429 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.187       |\n","|    explained_variance   | 0.815        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.22e+03     |\n","|    n_updates            | 8160         |\n","|    policy_gradient_loss | -9.96e-05    |\n","|    value_loss           | 2.56e+04     |\n","------------------------------------------\n","Eval num_timesteps=1675000, episode_reward=23651.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1675000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025526312 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.57          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 8170          |\n","|    policy_gradient_loss | -0.000424     |\n","|    value_loss           | 4.26e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 818     |\n","|    time_elapsed    | 4853    |\n","|    total_timesteps | 1675264 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 819           |\n","|    time_elapsed         | 4856          |\n","|    total_timesteps      | 1677312       |\n","| train/                  |               |\n","|    approx_kl            | 1.6293227e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.105        |\n","|    explained_variance   | 0.462         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 8180          |\n","|    policy_gradient_loss | -4.77e-05     |\n","|    value_loss           | 6.55e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 820           |\n","|    time_elapsed         | 4860          |\n","|    total_timesteps      | 1679360       |\n","| train/                  |               |\n","|    approx_kl            | 2.8649229e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.213        |\n","|    explained_variance   | 0.788         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.79e+04      |\n","|    n_updates            | 8190          |\n","|    policy_gradient_loss | -9.99e-05     |\n","|    value_loss           | 6.51e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1680000, episode_reward=22572.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.26e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1680000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016548627 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.615         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.15e+03      |\n","|    n_updates            | 8200          |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 2.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 821     |\n","|    time_elapsed    | 4869    |\n","|    total_timesteps | 1681408 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 822          |\n","|    time_elapsed         | 4872         |\n","|    total_timesteps      | 1683456      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006250751 |\n","|    clip_fraction        | 0.00352      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.188       |\n","|    explained_variance   | 0.755        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.34e+04     |\n","|    n_updates            | 8210         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 4.57e+04     |\n","------------------------------------------\n","Eval num_timesteps=1685000, episode_reward=21933.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.19e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1685000      |\n","| train/                  |              |\n","|    approx_kl            | 9.196985e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.17        |\n","|    explained_variance   | 0.69         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.53e+04     |\n","|    n_updates            | 8220         |\n","|    policy_gradient_loss | -0.000134    |\n","|    value_loss           | 5.01e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 823     |\n","|    time_elapsed    | 4881    |\n","|    total_timesteps | 1685504 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 824           |\n","|    time_elapsed         | 4885          |\n","|    total_timesteps      | 1687552       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012287963 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.557         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.62e+03      |\n","|    n_updates            | 8230          |\n","|    policy_gradient_loss | -0.000237     |\n","|    value_loss           | 2.81e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 825           |\n","|    time_elapsed         | 4888          |\n","|    total_timesteps      | 1689600       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028630646 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.097        |\n","|    explained_variance   | 0.523         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.02e+03      |\n","|    n_updates            | 8240          |\n","|    policy_gradient_loss | -0.000625     |\n","|    value_loss           | 6.66e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1690000, episode_reward=21888.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1690000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011043082 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.229        |\n","|    explained_variance   | 0.722         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.82e+04      |\n","|    n_updates            | 8250          |\n","|    policy_gradient_loss | -0.000378     |\n","|    value_loss           | 5.18e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 826     |\n","|    time_elapsed    | 4898    |\n","|    total_timesteps | 1691648 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 827           |\n","|    time_elapsed         | 4902          |\n","|    total_timesteps      | 1693696       |\n","| train/                  |               |\n","|    approx_kl            | 0.00092129235 |\n","|    clip_fraction        | 0.00601       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.578         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.98e+03      |\n","|    n_updates            | 8260          |\n","|    policy_gradient_loss | -0.00222      |\n","|    value_loss           | 5.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1695000, episode_reward=22086.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1695000       |\n","| train/                  |               |\n","|    approx_kl            | 1.1487107e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.757         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+04       |\n","|    n_updates            | 8270          |\n","|    policy_gradient_loss | -0.000123     |\n","|    value_loss           | 5.03e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 828     |\n","|    time_elapsed    | 4911    |\n","|    total_timesteps | 1695744 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 829           |\n","|    time_elapsed         | 4914          |\n","|    total_timesteps      | 1697792       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034813167 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.78e+03      |\n","|    n_updates            | 8280          |\n","|    policy_gradient_loss | -0.000501     |\n","|    value_loss           | 2.93e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 830          |\n","|    time_elapsed         | 4918         |\n","|    total_timesteps      | 1699840      |\n","| train/                  |              |\n","|    approx_kl            | 6.915469e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.157       |\n","|    explained_variance   | 0.629        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.75e+03     |\n","|    n_updates            | 8290         |\n","|    policy_gradient_loss | -0.000412    |\n","|    value_loss           | 3.39e+04     |\n","------------------------------------------\n","Eval num_timesteps=1700000, episode_reward=23372.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.34e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1700000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004048167 |\n","|    clip_fraction        | 0.00107      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.104       |\n","|    explained_variance   | 0.624        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.16e+04     |\n","|    n_updates            | 8300         |\n","|    policy_gradient_loss | -0.00107     |\n","|    value_loss           | 1.02e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 831     |\n","|    time_elapsed    | 4927    |\n","|    total_timesteps | 1701888 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 832          |\n","|    time_elapsed         | 4930         |\n","|    total_timesteps      | 1703936      |\n","| train/                  |              |\n","|    approx_kl            | 8.113595e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.208       |\n","|    explained_variance   | 0.813        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.3e+04      |\n","|    n_updates            | 8310         |\n","|    policy_gradient_loss | -0.000452    |\n","|    value_loss           | 3.92e+04     |\n","------------------------------------------\n","Eval num_timesteps=1705000, episode_reward=23682.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1705000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00064908754 |\n","|    clip_fraction        | 0.00225       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.531         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.08e+04      |\n","|    n_updates            | 8320          |\n","|    policy_gradient_loss | -0.000434     |\n","|    value_loss           | 5.58e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 833     |\n","|    time_elapsed    | 4939    |\n","|    total_timesteps | 1705984 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 834           |\n","|    time_elapsed         | 4942          |\n","|    total_timesteps      | 1708032       |\n","| train/                  |               |\n","|    approx_kl            | 0.00065246667 |\n","|    clip_fraction        | 0.0019        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.228        |\n","|    explained_variance   | 0.806         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.64e+04      |\n","|    n_updates            | 8330          |\n","|    policy_gradient_loss | -0.000684     |\n","|    value_loss           | 3.25e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1710000, episode_reward=23355.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.34e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1710000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011631366 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.14         |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.28e+04      |\n","|    n_updates            | 8340          |\n","|    policy_gradient_loss | -0.000113     |\n","|    value_loss           | 3.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 835     |\n","|    time_elapsed    | 4951    |\n","|    total_timesteps | 1710080 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 836           |\n","|    time_elapsed         | 4955          |\n","|    total_timesteps      | 1712128       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036734962 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 8350          |\n","|    policy_gradient_loss | -0.000797     |\n","|    value_loss           | 3.52e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 837           |\n","|    time_elapsed         | 4959          |\n","|    total_timesteps      | 1714176       |\n","| train/                  |               |\n","|    approx_kl            | 2.7474598e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.128        |\n","|    explained_variance   | 0.628         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.44e+04      |\n","|    n_updates            | 8360          |\n","|    policy_gradient_loss | -9.15e-05     |\n","|    value_loss           | 1.65e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1715000, episode_reward=22922.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.29e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1715000      |\n","| train/                  |              |\n","|    approx_kl            | 8.218904e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.182       |\n","|    explained_variance   | 0.705        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.37e+03     |\n","|    n_updates            | 8370         |\n","|    policy_gradient_loss | -0.000361    |\n","|    value_loss           | 3.97e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 838     |\n","|    time_elapsed    | 4968    |\n","|    total_timesteps | 1716224 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 839          |\n","|    time_elapsed         | 4971         |\n","|    total_timesteps      | 1718272      |\n","| train/                  |              |\n","|    approx_kl            | 2.268568e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.156       |\n","|    explained_variance   | 0.477        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.95e+04     |\n","|    n_updates            | 8380         |\n","|    policy_gradient_loss | -0.000143    |\n","|    value_loss           | 5.5e+04      |\n","------------------------------------------\n","Eval num_timesteps=1720000, episode_reward=21888.52 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1720000       |\n","| train/                  |               |\n","|    approx_kl            | 1.8966937e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.239        |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 8390          |\n","|    policy_gradient_loss | -0.000118     |\n","|    value_loss           | 3.54e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 840     |\n","|    time_elapsed    | 4980    |\n","|    total_timesteps | 1720320 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 841           |\n","|    time_elapsed         | 4983          |\n","|    total_timesteps      | 1722368       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017959633 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.657         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.26e+04      |\n","|    n_updates            | 8400          |\n","|    policy_gradient_loss | -0.000212     |\n","|    value_loss           | 2.68e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 842          |\n","|    time_elapsed         | 4987         |\n","|    total_timesteps      | 1724416      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002656304 |\n","|    clip_fraction        | 0.000488     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.142       |\n","|    explained_variance   | 0.563        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.21e+04     |\n","|    n_updates            | 8410         |\n","|    policy_gradient_loss | -0.000715    |\n","|    value_loss           | 5.45e+04     |\n","------------------------------------------\n","Eval num_timesteps=1725000, episode_reward=25467.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.55e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1725000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00074829225 |\n","|    clip_fraction        | 0.00308       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.189        |\n","|    explained_variance   | 0.798         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.18e+04      |\n","|    n_updates            | 8420          |\n","|    policy_gradient_loss | -0.00147      |\n","|    value_loss           | 1.03e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 843     |\n","|    time_elapsed    | 4996    |\n","|    total_timesteps | 1726464 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 844           |\n","|    time_elapsed         | 4999          |\n","|    total_timesteps      | 1728512       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014494272 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.634         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.68e+04      |\n","|    n_updates            | 8430          |\n","|    policy_gradient_loss | -0.000597     |\n","|    value_loss           | 3.81e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1730000, episode_reward=21544.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.15e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1730000       |\n","| train/                  |               |\n","|    approx_kl            | 2.3958157e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.604         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.91e+03      |\n","|    n_updates            | 8440          |\n","|    policy_gradient_loss | 6.76e-06      |\n","|    value_loss           | 5.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 845     |\n","|    time_elapsed    | 5008    |\n","|    total_timesteps | 1730560 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 846           |\n","|    time_elapsed         | 5012          |\n","|    total_timesteps      | 1732608       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042047663 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.224        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.44e+04      |\n","|    n_updates            | 8450          |\n","|    policy_gradient_loss | -0.000484     |\n","|    value_loss           | 2.9e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 847           |\n","|    time_elapsed         | 5016          |\n","|    total_timesteps      | 1734656       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014526176 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.656         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.7e+03       |\n","|    n_updates            | 8460          |\n","|    policy_gradient_loss | -0.000254     |\n","|    value_loss           | 2.65e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1735000, episode_reward=22278.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.23e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1735000      |\n","| train/                  |              |\n","|    approx_kl            | 3.614553e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.125       |\n","|    explained_variance   | 0.69         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.54e+04     |\n","|    n_updates            | 8470         |\n","|    policy_gradient_loss | -0.00021     |\n","|    value_loss           | 6.31e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 848     |\n","|    time_elapsed    | 5025    |\n","|    total_timesteps | 1736704 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 849           |\n","|    time_elapsed         | 5028          |\n","|    total_timesteps      | 1738752       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015416666 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.699         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.44e+04      |\n","|    n_updates            | 8480          |\n","|    policy_gradient_loss | -0.00057      |\n","|    value_loss           | 1.29e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1740000, episode_reward=23355.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.34e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1740000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044036942 |\n","|    clip_fraction        | 0.00161       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.619         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.14e+03      |\n","|    n_updates            | 8490          |\n","|    policy_gradient_loss | -0.000647     |\n","|    value_loss           | 2.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 850     |\n","|    time_elapsed    | 5038    |\n","|    total_timesteps | 1740800 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 851           |\n","|    time_elapsed         | 5041          |\n","|    total_timesteps      | 1742848       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013118441 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.597         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.4e+04       |\n","|    n_updates            | 8500          |\n","|    policy_gradient_loss | -0.000224     |\n","|    value_loss           | 4.61e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 852           |\n","|    time_elapsed         | 5045          |\n","|    total_timesteps      | 1744896       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013548552 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.198        |\n","|    explained_variance   | 0.822         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.97e+03      |\n","|    n_updates            | 8510          |\n","|    policy_gradient_loss | -0.000171     |\n","|    value_loss           | 2.49e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1745000, episode_reward=21355.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.14e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1745000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005587955 |\n","|    clip_fraction        | 0.002        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.15        |\n","|    explained_variance   | 0.629        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.64e+03     |\n","|    n_updates            | 8520         |\n","|    policy_gradient_loss | -0.000901    |\n","|    value_loss           | 2.59e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 853     |\n","|    time_elapsed    | 5053    |\n","|    total_timesteps | 1746944 |\n","--------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 345            |\n","|    iterations           | 854            |\n","|    time_elapsed         | 5057           |\n","|    total_timesteps      | 1748992        |\n","| train/                  |                |\n","|    approx_kl            | 0.000104921375 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.105         |\n","|    explained_variance   | 0.465          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 9.19e+03       |\n","|    n_updates            | 8530           |\n","|    policy_gradient_loss | -0.000257      |\n","|    value_loss           | 1.42e+05       |\n","--------------------------------------------\n","Eval num_timesteps=1750000, episode_reward=21355.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.14e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1750000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014557558 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.202        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.05e+04      |\n","|    n_updates            | 8540          |\n","|    policy_gradient_loss | -0.000331     |\n","|    value_loss           | 6.85e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 855     |\n","|    time_elapsed    | 5066    |\n","|    total_timesteps | 1751040 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 856           |\n","|    time_elapsed         | 5069          |\n","|    total_timesteps      | 1753088       |\n","| train/                  |               |\n","|    approx_kl            | 6.7475776e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.557         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.8e+04       |\n","|    n_updates            | 8550          |\n","|    policy_gradient_loss | -5.39e-05     |\n","|    value_loss           | 3.13e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1755000, episode_reward=21556.59 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.16e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1755000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0010780066 |\n","|    clip_fraction        | 0.00757      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.192       |\n","|    explained_variance   | 0.694        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.36e+04     |\n","|    n_updates            | 8560         |\n","|    policy_gradient_loss | -0.00167     |\n","|    value_loss           | 5.29e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 857     |\n","|    time_elapsed    | 5079    |\n","|    total_timesteps | 1755136 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 858           |\n","|    time_elapsed         | 5082          |\n","|    total_timesteps      | 1757184       |\n","| train/                  |               |\n","|    approx_kl            | 0.00049053296 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.178        |\n","|    explained_variance   | 0.761         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.48e+03      |\n","|    n_updates            | 8570          |\n","|    policy_gradient_loss | -0.000344     |\n","|    value_loss           | 3.03e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 859          |\n","|    time_elapsed         | 5085         |\n","|    total_timesteps      | 1759232      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003242997 |\n","|    clip_fraction        | 0.000781     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.144       |\n","|    explained_variance   | 0.624        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.45e+04     |\n","|    n_updates            | 8580         |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 3.23e+04     |\n","------------------------------------------\n","Eval num_timesteps=1760000, episode_reward=20705.34 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.07e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1760000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017234887 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0977       |\n","|    explained_variance   | 0.476         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.56e+04      |\n","|    n_updates            | 8590          |\n","|    policy_gradient_loss | -0.000529     |\n","|    value_loss           | 8.08e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 860     |\n","|    time_elapsed    | 5094    |\n","|    total_timesteps | 1761280 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 861          |\n","|    time_elapsed         | 5097         |\n","|    total_timesteps      | 1763328      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007439092 |\n","|    clip_fraction        | 0.00459      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.223       |\n","|    explained_variance   | 0.762        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.52e+04     |\n","|    n_updates            | 8600         |\n","|    policy_gradient_loss | -0.00187     |\n","|    value_loss           | 5.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=1765000, episode_reward=22597.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.26e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1765000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033785007 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.652         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.69e+04      |\n","|    n_updates            | 8610          |\n","|    policy_gradient_loss | -8.66e-05     |\n","|    value_loss           | 2.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 862     |\n","|    time_elapsed    | 5107    |\n","|    total_timesteps | 1765376 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 863           |\n","|    time_elapsed         | 5110          |\n","|    total_timesteps      | 1767424       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039553968 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.216        |\n","|    explained_variance   | 0.708         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.55e+04      |\n","|    n_updates            | 8620          |\n","|    policy_gradient_loss | -0.000517     |\n","|    value_loss           | 3.93e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 864           |\n","|    time_elapsed         | 5113          |\n","|    total_timesteps      | 1769472       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036948355 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.751         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.48e+03      |\n","|    n_updates            | 8630          |\n","|    policy_gradient_loss | -0.000534     |\n","|    value_loss           | 2.49e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1770000, episode_reward=22366.73 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.24e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1770000       |\n","| train/                  |               |\n","|    approx_kl            | 4.8993854e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.602         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 8640          |\n","|    policy_gradient_loss | -0.000368     |\n","|    value_loss           | 3.52e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 865     |\n","|    time_elapsed    | 5122    |\n","|    total_timesteps | 1771520 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 866           |\n","|    time_elapsed         | 5125          |\n","|    total_timesteps      | 1773568       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013858432 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.52          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.58e+04      |\n","|    n_updates            | 8650          |\n","|    policy_gradient_loss | -0.000214     |\n","|    value_loss           | 8.85e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1775000, episode_reward=23399.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.34e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1775000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021273302 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.202        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.68e+03      |\n","|    n_updates            | 8660          |\n","|    policy_gradient_loss | -0.000587     |\n","|    value_loss           | 3.45e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 867     |\n","|    time_elapsed    | 5135    |\n","|    total_timesteps | 1775616 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 868           |\n","|    time_elapsed         | 5138          |\n","|    total_timesteps      | 1777664       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019109217 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 8670          |\n","|    policy_gradient_loss | -0.000632     |\n","|    value_loss           | 3.45e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 869          |\n","|    time_elapsed         | 5141         |\n","|    total_timesteps      | 1779712      |\n","| train/                  |              |\n","|    approx_kl            | 2.478616e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.231       |\n","|    explained_variance   | 0.739        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.11e+04     |\n","|    n_updates            | 8680         |\n","|    policy_gradient_loss | -0.000173    |\n","|    value_loss           | 3.82e+04     |\n","------------------------------------------\n","Eval num_timesteps=1780000, episode_reward=22421.66 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.24e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1780000      |\n","| train/                  |              |\n","|    approx_kl            | 3.988098e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.131       |\n","|    explained_variance   | 0.73         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.81e+03     |\n","|    n_updates            | 8690         |\n","|    policy_gradient_loss | 2.39e-05     |\n","|    value_loss           | 4.52e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 870     |\n","|    time_elapsed    | 5150    |\n","|    total_timesteps | 1781760 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 871           |\n","|    time_elapsed         | 5154          |\n","|    total_timesteps      | 1783808       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048839714 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.599         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.5e+03       |\n","|    n_updates            | 8700          |\n","|    policy_gradient_loss | -0.00115      |\n","|    value_loss           | 2.6e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1785000, episode_reward=22018.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1785000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043008509 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.13         |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.63e+04      |\n","|    n_updates            | 8710          |\n","|    policy_gradient_loss | -0.00101      |\n","|    value_loss           | 8.69e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 872     |\n","|    time_elapsed    | 5163    |\n","|    total_timesteps | 1785856 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 873           |\n","|    time_elapsed         | 5166          |\n","|    total_timesteps      | 1787904       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014008165 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.79          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.45e+03      |\n","|    n_updates            | 8720          |\n","|    policy_gradient_loss | -0.000303     |\n","|    value_loss           | 2.82e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 874          |\n","|    time_elapsed         | 5170         |\n","|    total_timesteps      | 1789952      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006760077 |\n","|    clip_fraction        | 0.00415      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.168       |\n","|    explained_variance   | 0.664        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.56e+04     |\n","|    n_updates            | 8730         |\n","|    policy_gradient_loss | -0.00134     |\n","|    value_loss           | 5.06e+04     |\n","------------------------------------------\n","Eval num_timesteps=1790000, episode_reward=20683.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.07e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1790000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002818783 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.228       |\n","|    explained_variance   | 0.807        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.12e+04     |\n","|    n_updates            | 8740         |\n","|    policy_gradient_loss | -0.000698    |\n","|    value_loss           | 3.59e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 875     |\n","|    time_elapsed    | 5179    |\n","|    total_timesteps | 1792000 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 876           |\n","|    time_elapsed         | 5183          |\n","|    total_timesteps      | 1794048       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021114788 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.746         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.54e+04      |\n","|    n_updates            | 8750          |\n","|    policy_gradient_loss | -0.000243     |\n","|    value_loss           | 2.59e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1795000, episode_reward=21817.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1795000       |\n","| train/                  |               |\n","|    approx_kl            | 1.2107455e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.662         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.99e+04      |\n","|    n_updates            | 8760          |\n","|    policy_gradient_loss | -0.000151     |\n","|    value_loss           | 4.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 877     |\n","|    time_elapsed    | 5192    |\n","|    total_timesteps | 1796096 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 878          |\n","|    time_elapsed         | 5196         |\n","|    total_timesteps      | 1798144      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005638034 |\n","|    clip_fraction        | 0.00273      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.183       |\n","|    explained_variance   | 0.777        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.36e+04     |\n","|    n_updates            | 8770         |\n","|    policy_gradient_loss | -0.00109     |\n","|    value_loss           | 1.09e+05     |\n","------------------------------------------\n","Eval num_timesteps=1800000, episode_reward=22215.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.22e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1800000       |\n","| train/                  |               |\n","|    approx_kl            | 2.3230736e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.628         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.71e+03      |\n","|    n_updates            | 8780          |\n","|    policy_gradient_loss | -0.000122     |\n","|    value_loss           | 4.36e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 879     |\n","|    time_elapsed    | 5205    |\n","|    total_timesteps | 1800192 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 880           |\n","|    time_elapsed         | 5208          |\n","|    total_timesteps      | 1802240       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016574835 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.19         |\n","|    explained_variance   | 0.652         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 8790          |\n","|    policy_gradient_loss | -0.000255     |\n","|    value_loss           | 4.27e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 881           |\n","|    time_elapsed         | 5212          |\n","|    total_timesteps      | 1804288       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031350777 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.215        |\n","|    explained_variance   | 0.848         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.24e+03      |\n","|    n_updates            | 8800          |\n","|    policy_gradient_loss | -0.000544     |\n","|    value_loss           | 3.1e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1805000, episode_reward=24010.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.4e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1805000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002488525 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.153       |\n","|    explained_variance   | 0.609        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.44e+04     |\n","|    n_updates            | 8810         |\n","|    policy_gradient_loss | -0.00041     |\n","|    value_loss           | 3.77e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 882     |\n","|    time_elapsed    | 5221    |\n","|    total_timesteps | 1806336 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 883           |\n","|    time_elapsed         | 5224          |\n","|    total_timesteps      | 1808384       |\n","| train/                  |               |\n","|    approx_kl            | 1.5405007e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.133        |\n","|    explained_variance   | 0.652         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.74e+04      |\n","|    n_updates            | 8820          |\n","|    policy_gradient_loss | -0.000212     |\n","|    value_loss           | 5.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1810000, episode_reward=22200.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.22e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1810000      |\n","| train/                  |              |\n","|    approx_kl            | 9.486894e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.187       |\n","|    explained_variance   | 0.638        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.66e+04     |\n","|    n_updates            | 8830         |\n","|    policy_gradient_loss | -0.000283    |\n","|    value_loss           | 1.51e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 884     |\n","|    time_elapsed    | 5233    |\n","|    total_timesteps | 1810432 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 885           |\n","|    time_elapsed         | 5236          |\n","|    total_timesteps      | 1812480       |\n","| train/                  |               |\n","|    approx_kl            | 2.3314497e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.656         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 8840          |\n","|    policy_gradient_loss | -0.000164     |\n","|    value_loss           | 3.46e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 886           |\n","|    time_elapsed         | 5240          |\n","|    total_timesteps      | 1814528       |\n","| train/                  |               |\n","|    approx_kl            | 2.9855728e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.68          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 8850          |\n","|    policy_gradient_loss | -0.00013      |\n","|    value_loss           | 4.95e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1815000, episode_reward=21380.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.14e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1815000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041789527 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.192        |\n","|    explained_variance   | 0.824         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.14e+04      |\n","|    n_updates            | 8860          |\n","|    policy_gradient_loss | -0.000605     |\n","|    value_loss           | 3.46e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 887     |\n","|    time_elapsed    | 5249    |\n","|    total_timesteps | 1816576 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 888           |\n","|    time_elapsed         | 5253          |\n","|    total_timesteps      | 1818624       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026136162 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.671         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.31e+04      |\n","|    n_updates            | 8870          |\n","|    policy_gradient_loss | -0.000268     |\n","|    value_loss           | 2.96e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1820000, episode_reward=20683.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.07e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1820000      |\n","| train/                  |              |\n","|    approx_kl            | 4.988251e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.12        |\n","|    explained_variance   | 0.66         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.71e+04     |\n","|    n_updates            | 8880         |\n","|    policy_gradient_loss | -5.88e-05    |\n","|    value_loss           | 1.25e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 889     |\n","|    time_elapsed    | 5262    |\n","|    total_timesteps | 1820672 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 890           |\n","|    time_elapsed         | 5265          |\n","|    total_timesteps      | 1822720       |\n","| train/                  |               |\n","|    approx_kl            | 1.0784512e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.2          |\n","|    explained_variance   | 0.746         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.49e+04      |\n","|    n_updates            | 8890          |\n","|    policy_gradient_loss | -8.58e-05     |\n","|    value_loss           | 6.68e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 891           |\n","|    time_elapsed         | 5269          |\n","|    total_timesteps      | 1824768       |\n","| train/                  |               |\n","|    approx_kl            | 4.8545626e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 8900          |\n","|    policy_gradient_loss | -0.000108     |\n","|    value_loss           | 2.24e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1825000, episode_reward=23732.34 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 1.97e+03   |\n","|    mean_reward          | 2.37e+04   |\n","| time/                   |            |\n","|    total_timesteps      | 1825000    |\n","| train/                  |            |\n","|    approx_kl            | 0.00025851 |\n","|    clip_fraction        | 0          |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.205     |\n","|    explained_variance   | 0.78       |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 8.48e+03   |\n","|    n_updates            | 8910       |\n","|    policy_gradient_loss | -0.000142  |\n","|    value_loss           | 4.17e+04   |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 892     |\n","|    time_elapsed    | 5277    |\n","|    total_timesteps | 1826816 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 893           |\n","|    time_elapsed         | 5281          |\n","|    total_timesteps      | 1828864       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024661384 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.181        |\n","|    explained_variance   | 0.863         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.58e+03      |\n","|    n_updates            | 8920          |\n","|    policy_gradient_loss | -2.91e-05     |\n","|    value_loss           | 2.55e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1830000, episode_reward=21489.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.15e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1830000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006875417 |\n","|    clip_fraction        | 0.00176      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.157       |\n","|    explained_variance   | 0.574        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.21e+04     |\n","|    n_updates            | 8930         |\n","|    policy_gradient_loss | -0.000842    |\n","|    value_loss           | 2.75e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 894     |\n","|    time_elapsed    | 5290    |\n","|    total_timesteps | 1830912 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 895          |\n","|    time_elapsed         | 5293         |\n","|    total_timesteps      | 1832960      |\n","| train/                  |              |\n","|    approx_kl            | 9.337769e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.107       |\n","|    explained_variance   | 0.618        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.05e+04     |\n","|    n_updates            | 8940         |\n","|    policy_gradient_loss | -0.000109    |\n","|    value_loss           | 1.33e+05     |\n","------------------------------------------\n","Eval num_timesteps=1835000, episode_reward=24004.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1835000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031155095 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.84          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 8950          |\n","|    policy_gradient_loss | -0.000831     |\n","|    value_loss           | 5.43e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 896     |\n","|    time_elapsed    | 5302    |\n","|    total_timesteps | 1835008 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 897          |\n","|    time_elapsed         | 5305         |\n","|    total_timesteps      | 1837056      |\n","| train/                  |              |\n","|    approx_kl            | 0.0013451881 |\n","|    clip_fraction        | 0.0107       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.155       |\n","|    explained_variance   | 0.655        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.25e+04     |\n","|    n_updates            | 8960         |\n","|    policy_gradient_loss | -0.00382     |\n","|    value_loss           | 4.56e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 898           |\n","|    time_elapsed         | 5308          |\n","|    total_timesteps      | 1839104       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010796712 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.228        |\n","|    explained_variance   | 0.788         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.68e+04      |\n","|    n_updates            | 8970          |\n","|    policy_gradient_loss | -0.000189     |\n","|    value_loss           | 3.67e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1840000, episode_reward=23667.45 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.37e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1840000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001801035 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.163       |\n","|    explained_variance   | 0.75         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.54e+03     |\n","|    n_updates            | 8980         |\n","|    policy_gradient_loss | -0.000185    |\n","|    value_loss           | 4.24e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 899     |\n","|    time_elapsed    | 5318    |\n","|    total_timesteps | 1841152 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 900           |\n","|    time_elapsed         | 5321          |\n","|    total_timesteps      | 1843200       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015525782 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.759         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 8990          |\n","|    policy_gradient_loss | -0.000327     |\n","|    value_loss           | 3.49e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1845000, episode_reward=23299.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.33e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1845000      |\n","| train/                  |              |\n","|    approx_kl            | 9.440142e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.114       |\n","|    explained_variance   | 0.641        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.19e+04     |\n","|    n_updates            | 9000         |\n","|    policy_gradient_loss | -0.000213    |\n","|    value_loss           | 1.28e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 901     |\n","|    time_elapsed    | 5330    |\n","|    total_timesteps | 1845248 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 902           |\n","|    time_elapsed         | 5333          |\n","|    total_timesteps      | 1847296       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014915678 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.808         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.93e+04      |\n","|    n_updates            | 9010          |\n","|    policy_gradient_loss | -0.000716     |\n","|    value_loss           | 3.54e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 903           |\n","|    time_elapsed         | 5336          |\n","|    total_timesteps      | 1849344       |\n","| train/                  |               |\n","|    approx_kl            | 5.0482136e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.687         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.8e+03       |\n","|    n_updates            | 9020          |\n","|    policy_gradient_loss | -0.000135     |\n","|    value_loss           | 3.81e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1850000, episode_reward=23690.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1850000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015558983 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.238        |\n","|    explained_variance   | 0.751         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.15e+03      |\n","|    n_updates            | 9030          |\n","|    policy_gradient_loss | -0.000309     |\n","|    value_loss           | 3.66e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 904     |\n","|    time_elapsed    | 5345    |\n","|    total_timesteps | 1851392 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 905           |\n","|    time_elapsed         | 5349          |\n","|    total_timesteps      | 1853440       |\n","| train/                  |               |\n","|    approx_kl            | 1.1803961e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.803         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.62e+03      |\n","|    n_updates            | 9040          |\n","|    policy_gradient_loss | -8.98e-05     |\n","|    value_loss           | 2.91e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1855000, episode_reward=22493.82 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1855000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013931215 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.778         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+04      |\n","|    n_updates            | 9050          |\n","|    policy_gradient_loss | -0.000401     |\n","|    value_loss           | 2.92e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 906     |\n","|    time_elapsed    | 5358    |\n","|    total_timesteps | 1855488 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 907          |\n","|    time_elapsed         | 5361         |\n","|    total_timesteps      | 1857536      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005950938 |\n","|    clip_fraction        | 0.00112      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.605        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.57e+04     |\n","|    n_updates            | 9060         |\n","|    policy_gradient_loss | -0.0014      |\n","|    value_loss           | 1.79e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 908           |\n","|    time_elapsed         | 5364          |\n","|    total_timesteps      | 1859584       |\n","| train/                  |               |\n","|    approx_kl            | 3.1511066e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.19         |\n","|    explained_variance   | 0.839         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.25e+04      |\n","|    n_updates            | 9070          |\n","|    policy_gradient_loss | -4.32e-05     |\n","|    value_loss           | 3.33e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1860000, episode_reward=22774.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 2.28e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 1860000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000111919566 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.175         |\n","|    explained_variance   | 0.735          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 3.48e+04       |\n","|    n_updates            | 9080           |\n","|    policy_gradient_loss | -0.000308      |\n","|    value_loss           | 5.49e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 909     |\n","|    time_elapsed    | 5374    |\n","|    total_timesteps | 1861632 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 910          |\n","|    time_elapsed         | 5378         |\n","|    total_timesteps      | 1863680      |\n","| train/                  |              |\n","|    approx_kl            | 0.0011689255 |\n","|    clip_fraction        | 0.00708      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.22        |\n","|    explained_variance   | 0.8          |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.02e+03     |\n","|    n_updates            | 9090         |\n","|    policy_gradient_loss | -0.0014      |\n","|    value_loss           | 3.27e+04     |\n","------------------------------------------\n","Eval num_timesteps=1865000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1865000       |\n","| train/                  |               |\n","|    approx_kl            | 1.1068187e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.732         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.72e+04      |\n","|    n_updates            | 9100          |\n","|    policy_gradient_loss | 1.73e-05      |\n","|    value_loss           | 3.74e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 911     |\n","|    time_elapsed    | 5387    |\n","|    total_timesteps | 1865728 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 912           |\n","|    time_elapsed         | 5390          |\n","|    total_timesteps      | 1867776       |\n","| train/                  |               |\n","|    approx_kl            | 1.1528144e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.686         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.75e+04      |\n","|    n_updates            | 9110          |\n","|    policy_gradient_loss | -0.000203     |\n","|    value_loss           | 4.23e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 913          |\n","|    time_elapsed         | 5393         |\n","|    total_timesteps      | 1869824      |\n","| train/                  |              |\n","|    approx_kl            | 8.394281e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.179       |\n","|    explained_variance   | 0.76         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.52e+04     |\n","|    n_updates            | 9120         |\n","|    policy_gradient_loss | -0.000336    |\n","|    value_loss           | 1.23e+05     |\n","------------------------------------------\n","Eval num_timesteps=1870000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1870000       |\n","| train/                  |               |\n","|    approx_kl            | 5.1218638e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.624         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.9e+03       |\n","|    n_updates            | 9130          |\n","|    policy_gradient_loss | -0.000119     |\n","|    value_loss           | 2.71e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 914     |\n","|    time_elapsed    | 5403    |\n","|    total_timesteps | 1871872 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 915           |\n","|    time_elapsed         | 5406          |\n","|    total_timesteps      | 1873920       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040411044 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.188        |\n","|    explained_variance   | 0.676         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 9140          |\n","|    policy_gradient_loss | -0.000371     |\n","|    value_loss           | 4.6e+04       |\n","-------------------------------------------\n","Eval num_timesteps=1875000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1875000       |\n","| train/                  |               |\n","|    approx_kl            | 4.2895146e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.221        |\n","|    explained_variance   | 0.805         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.95e+03      |\n","|    n_updates            | 9150          |\n","|    policy_gradient_loss | -0.000116     |\n","|    value_loss           | 3.19e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 916     |\n","|    time_elapsed    | 5415    |\n","|    total_timesteps | 1875968 |\n","--------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 346            |\n","|    iterations           | 917            |\n","|    time_elapsed         | 5418           |\n","|    total_timesteps      | 1878016        |\n","| train/                  |                |\n","|    approx_kl            | 0.000101585494 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.148         |\n","|    explained_variance   | 0.54           |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.36e+04       |\n","|    n_updates            | 9160           |\n","|    policy_gradient_loss | -0.000277      |\n","|    value_loss           | 3.98e+04       |\n","--------------------------------------------\n","Eval num_timesteps=1880000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.4e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1880000      |\n","| train/                  |              |\n","|    approx_kl            | 3.591302e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.553        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.8e+04      |\n","|    n_updates            | 9170         |\n","|    policy_gradient_loss | -0.000142    |\n","|    value_loss           | 7.66e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 918     |\n","|    time_elapsed    | 5427    |\n","|    total_timesteps | 1880064 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 346         |\n","|    iterations           | 919         |\n","|    time_elapsed         | 5430        |\n","|    total_timesteps      | 1882112     |\n","| train/                  |             |\n","|    approx_kl            | 2.02659e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.19       |\n","|    explained_variance   | 0.745       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 3.82e+04    |\n","|    n_updates            | 9180        |\n","|    policy_gradient_loss | -8.06e-05   |\n","|    value_loss           | 1.45e+05    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 920           |\n","|    time_elapsed         | 5434          |\n","|    total_timesteps      | 1884160       |\n","| train/                  |               |\n","|    approx_kl            | 1.3103359e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.146        |\n","|    explained_variance   | 0.767         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.39e+04      |\n","|    n_updates            | 9190          |\n","|    policy_gradient_loss | -4.08e-05     |\n","|    value_loss           | 3.17e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1885000, episode_reward=23728.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1885000       |\n","| train/                  |               |\n","|    approx_kl            | 1.0955497e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.761         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+04      |\n","|    n_updates            | 9200          |\n","|    policy_gradient_loss | -7.72e-05     |\n","|    value_loss           | 4.32e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 921     |\n","|    time_elapsed    | 5444    |\n","|    total_timesteps | 1886208 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 922           |\n","|    time_elapsed         | 5448          |\n","|    total_timesteps      | 1888256       |\n","| train/                  |               |\n","|    approx_kl            | 0.00045477322 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.19         |\n","|    explained_variance   | 0.813         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.95e+03      |\n","|    n_updates            | 9210          |\n","|    policy_gradient_loss | -0.00115      |\n","|    value_loss           | 2.45e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1890000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.4e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 1890000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002499725 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.594        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.61e+04     |\n","|    n_updates            | 9220         |\n","|    policy_gradient_loss | -0.000342    |\n","|    value_loss           | 3.09e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 923     |\n","|    time_elapsed    | 5457    |\n","|    total_timesteps | 1890304 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 924           |\n","|    time_elapsed         | 5460          |\n","|    total_timesteps      | 1892352       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025375924 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.125        |\n","|    explained_variance   | 0.71          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.62e+04      |\n","|    n_updates            | 9230          |\n","|    policy_gradient_loss | -0.000977     |\n","|    value_loss           | 1.13e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 925           |\n","|    time_elapsed         | 5464          |\n","|    total_timesteps      | 1894400       |\n","| train/                  |               |\n","|    approx_kl            | 4.1550753e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.728         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.97e+04      |\n","|    n_updates            | 9240          |\n","|    policy_gradient_loss | -6.1e-05      |\n","|    value_loss           | 6.87e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1895000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1895000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017032496 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.166        |\n","|    explained_variance   | 0.629         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.33e+04      |\n","|    n_updates            | 9250          |\n","|    policy_gradient_loss | -0.000331     |\n","|    value_loss           | 3.55e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 926     |\n","|    time_elapsed    | 5473    |\n","|    total_timesteps | 1896448 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 927           |\n","|    time_elapsed         | 5476          |\n","|    total_timesteps      | 1898496       |\n","| train/                  |               |\n","|    approx_kl            | 2.2205058e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.738         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 9260          |\n","|    policy_gradient_loss | 6.4e-06       |\n","|    value_loss           | 4.41e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1900000, episode_reward=24427.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.44e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1900000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005280021 |\n","|    clip_fraction        | 0.00259      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.176       |\n","|    explained_variance   | 0.708        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.36e+03     |\n","|    n_updates            | 9270         |\n","|    policy_gradient_loss | -0.000528    |\n","|    value_loss           | 4.73e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 928     |\n","|    time_elapsed    | 5485    |\n","|    total_timesteps | 1900544 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 929           |\n","|    time_elapsed         | 5488          |\n","|    total_timesteps      | 1902592       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017440313 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.552         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.91e+04      |\n","|    n_updates            | 9280          |\n","|    policy_gradient_loss | -0.000425     |\n","|    value_loss           | 4.12e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 930          |\n","|    time_elapsed         | 5492         |\n","|    total_timesteps      | 1904640      |\n","| train/                  |              |\n","|    approx_kl            | 3.740043e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.11        |\n","|    explained_variance   | 0.601        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.84e+04     |\n","|    n_updates            | 9290         |\n","|    policy_gradient_loss | -0.000161    |\n","|    value_loss           | 1.35e+05     |\n","------------------------------------------\n","Eval num_timesteps=1905000, episode_reward=24006.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 1905000       |\n","| train/                  |               |\n","|    approx_kl            | 3.9929844e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.225        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.4e+04       |\n","|    n_updates            | 9300          |\n","|    policy_gradient_loss | -0.000184     |\n","|    value_loss           | 6.23e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 931     |\n","|    time_elapsed    | 5502    |\n","|    total_timesteps | 1906688 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 932           |\n","|    time_elapsed         | 5505          |\n","|    total_timesteps      | 1908736       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036752102 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.143        |\n","|    explained_variance   | 0.691         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+04       |\n","|    n_updates            | 9310          |\n","|    policy_gradient_loss | -0.000598     |\n","|    value_loss           | 2.45e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1910000, episode_reward=22486.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1910000       |\n","| train/                  |               |\n","|    approx_kl            | 4.4448563e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.219        |\n","|    explained_variance   | 0.747         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.55e+04      |\n","|    n_updates            | 9320          |\n","|    policy_gradient_loss | -5.43e-05     |\n","|    value_loss           | 4.11e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 933     |\n","|    time_elapsed    | 5514    |\n","|    total_timesteps | 1910784 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 934           |\n","|    time_elapsed         | 5518          |\n","|    total_timesteps      | 1912832       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011897928 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.754         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 9330          |\n","|    policy_gradient_loss | -0.000202     |\n","|    value_loss           | 3.98e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 935           |\n","|    time_elapsed         | 5521          |\n","|    total_timesteps      | 1914880       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023732014 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.716         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.61e+03      |\n","|    n_updates            | 9340          |\n","|    policy_gradient_loss | -0.000433     |\n","|    value_loss           | 2.88e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1915000, episode_reward=22095.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1915000       |\n","| train/                  |               |\n","|    approx_kl            | 2.9572286e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.123        |\n","|    explained_variance   | 0.581         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.47e+04      |\n","|    n_updates            | 9350          |\n","|    policy_gradient_loss | -0.000143     |\n","|    value_loss           | 1.04e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 936     |\n","|    time_elapsed    | 5530    |\n","|    total_timesteps | 1916928 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 937          |\n","|    time_elapsed         | 5533         |\n","|    total_timesteps      | 1918976      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001806693 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.211       |\n","|    explained_variance   | 0.81         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.96e+04     |\n","|    n_updates            | 9360         |\n","|    policy_gradient_loss | -0.000582    |\n","|    value_loss           | 4.49e+04     |\n","------------------------------------------\n","Eval num_timesteps=1920000, episode_reward=22208.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.22e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1920000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00045844112 |\n","|    clip_fraction        | 0.00239       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.721         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.44e+04      |\n","|    n_updates            | 9370          |\n","|    policy_gradient_loss | -0.000917     |\n","|    value_loss           | 4.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 938     |\n","|    time_elapsed    | 5542    |\n","|    total_timesteps | 1921024 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 939          |\n","|    time_elapsed         | 5546         |\n","|    total_timesteps      | 1923072      |\n","| train/                  |              |\n","|    approx_kl            | 8.226809e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.226       |\n","|    explained_variance   | 0.778        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.06e+04     |\n","|    n_updates            | 9380         |\n","|    policy_gradient_loss | -5.99e-06    |\n","|    value_loss           | 3.96e+04     |\n","------------------------------------------\n","Eval num_timesteps=1925000, episode_reward=23728.20 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.37e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 1925000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000139465 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.138      |\n","|    explained_variance   | 0.7         |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 6.97e+04    |\n","|    n_updates            | 9390        |\n","|    policy_gradient_loss | -0.000127   |\n","|    value_loss           | 5.03e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 940     |\n","|    time_elapsed    | 5555    |\n","|    total_timesteps | 1925120 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 941           |\n","|    time_elapsed         | 5558          |\n","|    total_timesteps      | 1927168       |\n","| train/                  |               |\n","|    approx_kl            | 2.2725813e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.662         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.66e+03      |\n","|    n_updates            | 9400          |\n","|    policy_gradient_loss | -0.000156     |\n","|    value_loss           | 4.18e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 942           |\n","|    time_elapsed         | 5561          |\n","|    total_timesteps      | 1929216       |\n","| train/                  |               |\n","|    approx_kl            | 3.5177218e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.128        |\n","|    explained_variance   | 0.624         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.54e+04      |\n","|    n_updates            | 9410          |\n","|    policy_gradient_loss | -0.000145     |\n","|    value_loss           | 1.3e+05       |\n","-------------------------------------------\n","Eval num_timesteps=1930000, episode_reward=22099.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.21e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 1930000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000310985 |\n","|    clip_fraction        | 0.000439    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.192      |\n","|    explained_variance   | 0.829       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 9.36e+03    |\n","|    n_updates            | 9420        |\n","|    policy_gradient_loss | -0.000829   |\n","|    value_loss           | 2.88e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 943     |\n","|    time_elapsed    | 5570    |\n","|    total_timesteps | 1931264 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 944          |\n","|    time_elapsed         | 5574         |\n","|    total_timesteps      | 1933312      |\n","| train/                  |              |\n","|    approx_kl            | 6.314687e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.79         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.78e+03     |\n","|    n_updates            | 9430         |\n","|    policy_gradient_loss | -5.7e-05     |\n","|    value_loss           | 4.46e+04     |\n","------------------------------------------\n","Eval num_timesteps=1935000, episode_reward=22215.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.22e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1935000      |\n","| train/                  |              |\n","|    approx_kl            | 2.217284e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.219       |\n","|    explained_variance   | 0.739        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.16e+04     |\n","|    n_updates            | 9440         |\n","|    policy_gradient_loss | -0.000228    |\n","|    value_loss           | 3.26e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 945     |\n","|    time_elapsed    | 5583    |\n","|    total_timesteps | 1935360 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 946           |\n","|    time_elapsed         | 5586          |\n","|    total_timesteps      | 1937408       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046006462 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.655         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.2e+04       |\n","|    n_updates            | 9450          |\n","|    policy_gradient_loss | -0.00029      |\n","|    value_loss           | 3.93e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 947          |\n","|    time_elapsed         | 5589         |\n","|    total_timesteps      | 1939456      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002787473 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.15        |\n","|    explained_variance   | 0.568        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.79e+03     |\n","|    n_updates            | 9460         |\n","|    policy_gradient_loss | -0.000541    |\n","|    value_loss           | 5.19e+04     |\n","------------------------------------------\n","Eval num_timesteps=1940000, episode_reward=22807.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.28e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1940000       |\n","| train/                  |               |\n","|    approx_kl            | 4.0278916e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.169        |\n","|    explained_variance   | 0.666         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.06e+04      |\n","|    n_updates            | 9470          |\n","|    policy_gradient_loss | -0.000175     |\n","|    value_loss           | 2.14e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 948     |\n","|    time_elapsed    | 5598    |\n","|    total_timesteps | 1941504 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 949           |\n","|    time_elapsed         | 5601          |\n","|    total_timesteps      | 1943552       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024991998 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.652         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.14e+03      |\n","|    n_updates            | 9480          |\n","|    policy_gradient_loss | -0.000748     |\n","|    value_loss           | 3.68e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1945000, episode_reward=24790.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.48e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1945000       |\n","| train/                  |               |\n","|    approx_kl            | 4.4695917e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 9490          |\n","|    policy_gradient_loss | -3.2e-05      |\n","|    value_loss           | 5.2e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 950     |\n","|    time_elapsed    | 5611    |\n","|    total_timesteps | 1945600 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 951          |\n","|    time_elapsed         | 5615         |\n","|    total_timesteps      | 1947648      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007434803 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.228       |\n","|    explained_variance   | 0.751        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.03e+04     |\n","|    n_updates            | 9500         |\n","|    policy_gradient_loss | -0.00109     |\n","|    value_loss           | 3.22e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 952           |\n","|    time_elapsed         | 5618          |\n","|    total_timesteps      | 1949696       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012155142 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.646         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.24e+03      |\n","|    n_updates            | 9510          |\n","|    policy_gradient_loss | -0.000158     |\n","|    value_loss           | 4.12e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1950000, episode_reward=20824.66 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1950000       |\n","| train/                  |               |\n","|    approx_kl            | 1.4503486e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.07e+04      |\n","|    n_updates            | 9520          |\n","|    policy_gradient_loss | -0.000118     |\n","|    value_loss           | 5.79e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 953     |\n","|    time_elapsed    | 5627    |\n","|    total_timesteps | 1951744 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 954           |\n","|    time_elapsed         | 5630          |\n","|    total_timesteps      | 1953792       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030717722 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.74          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 9530          |\n","|    policy_gradient_loss | -0.000602     |\n","|    value_loss           | 7.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1955000, episode_reward=20161.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.02e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1955000      |\n","| train/                  |              |\n","|    approx_kl            | 3.158988e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.132       |\n","|    explained_variance   | 0.728        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.69e+04     |\n","|    n_updates            | 9540         |\n","|    policy_gradient_loss | -7.44e-05    |\n","|    value_loss           | 4.29e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 955     |\n","|    time_elapsed    | 5639    |\n","|    total_timesteps | 1955840 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 956          |\n","|    time_elapsed         | 5643         |\n","|    total_timesteps      | 1957888      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005301323 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.194       |\n","|    explained_variance   | 0.68         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.43e+04     |\n","|    n_updates            | 9550         |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 4.53e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 957           |\n","|    time_elapsed         | 5646          |\n","|    total_timesteps      | 1959936       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016564649 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.199        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 9560          |\n","|    policy_gradient_loss | -7.09e-05     |\n","|    value_loss           | 3.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1960000, episode_reward=22697.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.27e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1960000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027964066 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.617         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 9570          |\n","|    policy_gradient_loss | -0.000401     |\n","|    value_loss           | 3.12e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 958     |\n","|    time_elapsed    | 5655    |\n","|    total_timesteps | 1961984 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 959           |\n","|    time_elapsed         | 5658          |\n","|    total_timesteps      | 1964032       |\n","| train/                  |               |\n","|    approx_kl            | 0.00061079505 |\n","|    clip_fraction        | 0.00225       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.65e+04      |\n","|    n_updates            | 9580          |\n","|    policy_gradient_loss | -0.00188      |\n","|    value_loss           | 1.01e+05      |\n","-------------------------------------------\n","Eval num_timesteps=1965000, episode_reward=22208.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.22e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1965000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011045905 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.757         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.16e+04      |\n","|    n_updates            | 9590          |\n","|    policy_gradient_loss | -0.000283     |\n","|    value_loss           | 7.25e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 960     |\n","|    time_elapsed    | 5667    |\n","|    total_timesteps | 1966080 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 961           |\n","|    time_elapsed         | 5670          |\n","|    total_timesteps      | 1968128       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019023576 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.752         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.59e+03      |\n","|    n_updates            | 9600          |\n","|    policy_gradient_loss | -0.000195     |\n","|    value_loss           | 3.06e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1970000, episode_reward=22208.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.22e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1970000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006515322 |\n","|    clip_fraction        | 0.0021       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.198       |\n","|    explained_variance   | 0.73         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.14e+03     |\n","|    n_updates            | 9610         |\n","|    policy_gradient_loss | -0.00067     |\n","|    value_loss           | 3.48e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 962     |\n","|    time_elapsed    | 5680    |\n","|    total_timesteps | 1970176 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 963           |\n","|    time_elapsed         | 5683          |\n","|    total_timesteps      | 1972224       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015321793 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.763         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.54e+04      |\n","|    n_updates            | 9620          |\n","|    policy_gradient_loss | -0.000111     |\n","|    value_loss           | 3.75e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 964           |\n","|    time_elapsed         | 5687          |\n","|    total_timesteps      | 1974272       |\n","| train/                  |               |\n","|    approx_kl            | 1.7850893e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.601         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 9630          |\n","|    policy_gradient_loss | -0.000149     |\n","|    value_loss           | 3.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1975000, episode_reward=22095.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1975000       |\n","| train/                  |               |\n","|    approx_kl            | 1.6641832e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.621         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.93e+04      |\n","|    n_updates            | 9640          |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 1.12e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 965     |\n","|    time_elapsed    | 5696    |\n","|    total_timesteps | 1976320 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 966           |\n","|    time_elapsed         | 5699          |\n","|    total_timesteps      | 1978368       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039807585 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.226        |\n","|    explained_variance   | 0.797         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 9650          |\n","|    policy_gradient_loss | -0.00077      |\n","|    value_loss           | 7.03e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1980000, episode_reward=22095.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1980000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036016232 |\n","|    clip_fraction        | 0.00181       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.15         |\n","|    explained_variance   | 0.731         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.91e+03      |\n","|    n_updates            | 9660          |\n","|    policy_gradient_loss | -0.000614     |\n","|    value_loss           | 2.52e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 967     |\n","|    time_elapsed    | 5709    |\n","|    total_timesteps | 1980416 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 968           |\n","|    time_elapsed         | 5712          |\n","|    total_timesteps      | 1982464       |\n","| train/                  |               |\n","|    approx_kl            | 6.9117756e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.218        |\n","|    explained_variance   | 0.769         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 9670          |\n","|    policy_gradient_loss | -0.000199     |\n","|    value_loss           | 4.29e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 969           |\n","|    time_elapsed         | 5715          |\n","|    total_timesteps      | 1984512       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027675467 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.791         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 9680          |\n","|    policy_gradient_loss | -0.000334     |\n","|    value_loss           | 4.21e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1985000, episode_reward=22208.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.22e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 1985000      |\n","| train/                  |              |\n","|    approx_kl            | 7.571216e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.15        |\n","|    explained_variance   | 0.574        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.03e+03     |\n","|    n_updates            | 9690         |\n","|    policy_gradient_loss | -8.78e-05    |\n","|    value_loss           | 3.87e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 970     |\n","|    time_elapsed    | 5725    |\n","|    total_timesteps | 1986560 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 971          |\n","|    time_elapsed         | 5728         |\n","|    total_timesteps      | 1988608      |\n","| train/                  |              |\n","|    approx_kl            | 9.981793e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.124       |\n","|    explained_variance   | 0.613        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.5e+04      |\n","|    n_updates            | 9700         |\n","|    policy_gradient_loss | -0.00021     |\n","|    value_loss           | 1.01e+05     |\n","------------------------------------------\n","Eval num_timesteps=1990000, episode_reward=22697.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.27e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1990000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028287212 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.22         |\n","|    explained_variance   | 0.783         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.96e+04      |\n","|    n_updates            | 9710          |\n","|    policy_gradient_loss | -0.00044      |\n","|    value_loss           | 5.42e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 972     |\n","|    time_elapsed    | 5738    |\n","|    total_timesteps | 1990656 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 973           |\n","|    time_elapsed         | 5742          |\n","|    total_timesteps      | 1992704       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020615087 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.15         |\n","|    explained_variance   | 0.427         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.31e+04      |\n","|    n_updates            | 9720          |\n","|    policy_gradient_loss | -0.000441     |\n","|    value_loss           | 6.34e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 974           |\n","|    time_elapsed         | 5745          |\n","|    total_timesteps      | 1994752       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041062618 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.22         |\n","|    explained_variance   | 0.79          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.52e+03      |\n","|    n_updates            | 9730          |\n","|    policy_gradient_loss | -0.00038      |\n","|    value_loss           | 3.07e+04      |\n","-------------------------------------------\n","Eval num_timesteps=1995000, episode_reward=24500.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 1995000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030325004 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.784         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.11e+03      |\n","|    n_updates            | 9740          |\n","|    policy_gradient_loss | -0.000377     |\n","|    value_loss           | 2.91e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 975     |\n","|    time_elapsed    | 5755    |\n","|    total_timesteps | 1996800 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 976          |\n","|    time_elapsed         | 5758         |\n","|    total_timesteps      | 1998848      |\n","| train/                  |              |\n","|    approx_kl            | 7.928291e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.167       |\n","|    explained_variance   | 0.69         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.56e+04     |\n","|    n_updates            | 9750         |\n","|    policy_gradient_loss | -3.08e-05    |\n","|    value_loss           | 3.25e+04     |\n","------------------------------------------\n","Eval num_timesteps=2000000, episode_reward=24500.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2000000       |\n","| train/                  |               |\n","|    approx_kl            | 6.7316316e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.28e+04      |\n","|    n_updates            | 9760          |\n","|    policy_gradient_loss | -0.000125     |\n","|    value_loss           | 1.49e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 977     |\n","|    time_elapsed    | 5767    |\n","|    total_timesteps | 2000896 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 978           |\n","|    time_elapsed         | 5771          |\n","|    total_timesteps      | 2002944       |\n","| train/                  |               |\n","|    approx_kl            | 1.6513717e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.194        |\n","|    explained_variance   | 0.71          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 9770          |\n","|    policy_gradient_loss | -0.000114     |\n","|    value_loss           | 4.32e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 979           |\n","|    time_elapsed         | 5774          |\n","|    total_timesteps      | 2004992       |\n","| train/                  |               |\n","|    approx_kl            | 0.00070693385 |\n","|    clip_fraction        | 0.00239       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.157        |\n","|    explained_variance   | 0.713         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.61e+04      |\n","|    n_updates            | 9780          |\n","|    policy_gradient_loss | -0.000636     |\n","|    value_loss           | 4.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2005000, episode_reward=22690.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.27e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2005000       |\n","| train/                  |               |\n","|    approx_kl            | 6.5645436e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.223        |\n","|    explained_variance   | 0.767         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.28e+04      |\n","|    n_updates            | 9790          |\n","|    policy_gradient_loss | 4.74e-06      |\n","|    value_loss           | 3.55e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 980     |\n","|    time_elapsed    | 5784    |\n","|    total_timesteps | 2007040 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 981          |\n","|    time_elapsed         | 5788         |\n","|    total_timesteps      | 2009088      |\n","| train/                  |              |\n","|    approx_kl            | 0.0010375576 |\n","|    clip_fraction        | 0.00425      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.15        |\n","|    explained_variance   | 0.679        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.81e+03     |\n","|    n_updates            | 9800         |\n","|    policy_gradient_loss | -0.00154     |\n","|    value_loss           | 3.07e+04     |\n","------------------------------------------\n","Eval num_timesteps=2010000, episode_reward=20428.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 2.04e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 2010000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000111536094 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.156         |\n","|    explained_variance   | 0.603          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 2.49e+04       |\n","|    n_updates            | 9810           |\n","|    policy_gradient_loss | -0.000225      |\n","|    value_loss           | 3.41e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 982     |\n","|    time_elapsed    | 5798    |\n","|    total_timesteps | 2011136 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 983          |\n","|    time_elapsed         | 5801         |\n","|    total_timesteps      | 2013184      |\n","| train/                  |              |\n","|    approx_kl            | 4.787708e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.161       |\n","|    explained_variance   | 0.778        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.97e+04     |\n","|    n_updates            | 9820         |\n","|    policy_gradient_loss | -0.000134    |\n","|    value_loss           | 1.31e+05     |\n","------------------------------------------\n","Eval num_timesteps=2015000, episode_reward=21849.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2015000       |\n","| train/                  |               |\n","|    approx_kl            | 5.6296005e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.169        |\n","|    explained_variance   | 0.726         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 9830          |\n","|    policy_gradient_loss | -0.000331     |\n","|    value_loss           | 3.26e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 984     |\n","|    time_elapsed    | 5810    |\n","|    total_timesteps | 2015232 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 985           |\n","|    time_elapsed         | 5814          |\n","|    total_timesteps      | 2017280       |\n","| train/                  |               |\n","|    approx_kl            | 7.2977273e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.93e+04      |\n","|    n_updates            | 9840          |\n","|    policy_gradient_loss | 5.54e-06      |\n","|    value_loss           | 5.24e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 986           |\n","|    time_elapsed         | 5817          |\n","|    total_timesteps      | 2019328       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026653396 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.227        |\n","|    explained_variance   | 0.819         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.76e+03      |\n","|    n_updates            | 9850          |\n","|    policy_gradient_loss | -0.000343     |\n","|    value_loss           | 3.5e+04       |\n","-------------------------------------------\n","Eval num_timesteps=2020000, episode_reward=20887.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.09e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2020000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003594623 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.129       |\n","|    explained_variance   | 0.635        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.27e+04     |\n","|    n_updates            | 9860         |\n","|    policy_gradient_loss | -0.000482    |\n","|    value_loss           | 3.49e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 987     |\n","|    time_elapsed    | 5827    |\n","|    total_timesteps | 2021376 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 988           |\n","|    time_elapsed         | 5830          |\n","|    total_timesteps      | 2023424       |\n","| train/                  |               |\n","|    approx_kl            | 3.2006123e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.632         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.07e+04      |\n","|    n_updates            | 9870          |\n","|    policy_gradient_loss | -0.000201     |\n","|    value_loss           | 6.44e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2025000, episode_reward=21758.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2025000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007132718 |\n","|    clip_fraction        | 0.00273      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.207       |\n","|    explained_variance   | 0.776        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.09e+04     |\n","|    n_updates            | 9880         |\n","|    policy_gradient_loss | -0.00208     |\n","|    value_loss           | 7.99e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 989     |\n","|    time_elapsed    | 5839    |\n","|    total_timesteps | 2025472 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 990           |\n","|    time_elapsed         | 5842          |\n","|    total_timesteps      | 2027520       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041596955 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.66          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.61e+04      |\n","|    n_updates            | 9890          |\n","|    policy_gradient_loss | -0.00105      |\n","|    value_loss           | 3.51e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 991          |\n","|    time_elapsed         | 5846         |\n","|    total_timesteps      | 2029568      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004080626 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.191       |\n","|    explained_variance   | 0.752        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.06e+04     |\n","|    n_updates            | 9900         |\n","|    policy_gradient_loss | -0.000215    |\n","|    value_loss           | 4.13e+04     |\n","------------------------------------------\n","Eval num_timesteps=2030000, episode_reward=24134.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2030000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042011763 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.214        |\n","|    explained_variance   | 0.832         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.45e+03      |\n","|    n_updates            | 9910          |\n","|    policy_gradient_loss | -0.000512     |\n","|    value_loss           | 2.31e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 992     |\n","|    time_elapsed    | 5855    |\n","|    total_timesteps | 2031616 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 993           |\n","|    time_elapsed         | 5858          |\n","|    total_timesteps      | 2033664       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038722344 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.702         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.87e+03      |\n","|    n_updates            | 9920          |\n","|    policy_gradient_loss | -0.000385     |\n","|    value_loss           | 3.05e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2035000, episode_reward=21100.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.11e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2035000       |\n","| train/                  |               |\n","|    approx_kl            | 5.6658027e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.632         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.94e+04      |\n","|    n_updates            | 9930          |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 7.64e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 994     |\n","|    time_elapsed    | 5867    |\n","|    total_timesteps | 2035712 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 995           |\n","|    time_elapsed         | 5871          |\n","|    total_timesteps      | 2037760       |\n","| train/                  |               |\n","|    approx_kl            | 1.1705357e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.202        |\n","|    explained_variance   | 0.712         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.82e+04      |\n","|    n_updates            | 9940          |\n","|    policy_gradient_loss | -0.000107     |\n","|    value_loss           | 1.02e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 996          |\n","|    time_elapsed         | 5874         |\n","|    total_timesteps      | 2039808      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002724159 |\n","|    clip_fraction        | 0.00146      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.165       |\n","|    explained_variance   | 0.705        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.09e+04     |\n","|    n_updates            | 9950         |\n","|    policy_gradient_loss | -0.000352    |\n","|    value_loss           | 2.64e+04     |\n","------------------------------------------\n","Eval num_timesteps=2040000, episode_reward=23463.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.35e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2040000       |\n","| train/                  |               |\n","|    approx_kl            | 2.4112524e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.691         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.25e+04      |\n","|    n_updates            | 9960          |\n","|    policy_gradient_loss | -8.86e-05     |\n","|    value_loss           | 4.57e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 997     |\n","|    time_elapsed    | 5884    |\n","|    total_timesteps | 2041856 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 998          |\n","|    time_elapsed         | 5887         |\n","|    total_timesteps      | 2043904      |\n","| train/                  |              |\n","|    approx_kl            | 2.754241e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.181       |\n","|    explained_variance   | 0.788        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.67e+03     |\n","|    n_updates            | 9970         |\n","|    policy_gradient_loss | -5.77e-05    |\n","|    value_loss           | 2.95e+04     |\n","------------------------------------------\n","Eval num_timesteps=2045000, episode_reward=24516.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.45e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2045000      |\n","| train/                  |              |\n","|    approx_kl            | 9.562704e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.167       |\n","|    explained_variance   | 0.684        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.36e+04     |\n","|    n_updates            | 9980         |\n","|    policy_gradient_loss | -0.000138    |\n","|    value_loss           | 3.36e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 999     |\n","|    time_elapsed    | 5896    |\n","|    total_timesteps | 2045952 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1000          |\n","|    time_elapsed         | 5899          |\n","|    total_timesteps      | 2048000       |\n","| train/                  |               |\n","|    approx_kl            | 4.9073657e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.104        |\n","|    explained_variance   | 0.608         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.04e+04      |\n","|    n_updates            | 9990          |\n","|    policy_gradient_loss | -7.09e-05     |\n","|    value_loss           | 1.01e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2050000, episode_reward=23463.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.35e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2050000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037429176 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.226        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.45e+04      |\n","|    n_updates            | 10000         |\n","|    policy_gradient_loss | -0.000533     |\n","|    value_loss           | 5.37e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1001    |\n","|    time_elapsed    | 5908    |\n","|    total_timesteps | 2050048 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1002         |\n","|    time_elapsed         | 5911         |\n","|    total_timesteps      | 2052096      |\n","| train/                  |              |\n","|    approx_kl            | 6.250196e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.16        |\n","|    explained_variance   | 0.683        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.72e+03     |\n","|    n_updates            | 10010        |\n","|    policy_gradient_loss | -9.37e-05    |\n","|    value_loss           | 2.65e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1003         |\n","|    time_elapsed         | 5915         |\n","|    total_timesteps      | 2054144      |\n","| train/                  |              |\n","|    approx_kl            | 6.444074e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.214       |\n","|    explained_variance   | 0.763        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.17e+04     |\n","|    n_updates            | 10020        |\n","|    policy_gradient_loss | -4.46e-05    |\n","|    value_loss           | 4.12e+04     |\n","------------------------------------------\n","Eval num_timesteps=2055000, episode_reward=22806.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.28e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2055000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005008982 |\n","|    clip_fraction        | 0.000586     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.178       |\n","|    explained_variance   | 0.74         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.57e+03     |\n","|    n_updates            | 10030        |\n","|    policy_gradient_loss | -0.000481    |\n","|    value_loss           | 2.08e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1004    |\n","|    time_elapsed    | 5924    |\n","|    total_timesteps | 2056192 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1005          |\n","|    time_elapsed         | 5927          |\n","|    total_timesteps      | 2058240       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013425964 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.621         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.1e+03       |\n","|    n_updates            | 10040         |\n","|    policy_gradient_loss | -0.000247     |\n","|    value_loss           | 2.27e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2060000, episode_reward=22215.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.22e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2060000      |\n","| train/                  |              |\n","|    approx_kl            | 6.592195e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.116       |\n","|    explained_variance   | 0.668        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.31e+04     |\n","|    n_updates            | 10050        |\n","|    policy_gradient_loss | -0.000305    |\n","|    value_loss           | 1.05e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1006    |\n","|    time_elapsed    | 5936    |\n","|    total_timesteps | 2060288 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1007        |\n","|    time_elapsed         | 5939        |\n","|    total_timesteps      | 2062336     |\n","| train/                  |             |\n","|    approx_kl            | 7.27819e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.226      |\n","|    explained_variance   | 0.831       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.04e+04    |\n","|    n_updates            | 10060       |\n","|    policy_gradient_loss | -0.000214   |\n","|    value_loss           | 3.45e+04    |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1008         |\n","|    time_elapsed         | 5943         |\n","|    total_timesteps      | 2064384      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001251126 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.161       |\n","|    explained_variance   | 0.685        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.96e+04     |\n","|    n_updates            | 10070        |\n","|    policy_gradient_loss | -0.00019     |\n","|    value_loss           | 3.52e+04     |\n","------------------------------------------\n","Eval num_timesteps=2065000, episode_reward=21824.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2065000      |\n","| train/                  |              |\n","|    approx_kl            | 4.049836e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.223       |\n","|    explained_variance   | 0.835        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.18e+03     |\n","|    n_updates            | 10080        |\n","|    policy_gradient_loss | -0.000248    |\n","|    value_loss           | 3.36e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1009    |\n","|    time_elapsed    | 5952    |\n","|    total_timesteps | 2066432 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1010        |\n","|    time_elapsed         | 5955        |\n","|    total_timesteps      | 2068480     |\n","| train/                  |             |\n","|    approx_kl            | 6.07362e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.154      |\n","|    explained_variance   | 0.763       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 6.37e+03    |\n","|    n_updates            | 10090       |\n","|    policy_gradient_loss | -0.000382   |\n","|    value_loss           | 3.35e+04    |\n","-----------------------------------------\n","Eval num_timesteps=2070000, episode_reward=23809.79 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.38e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2070000       |\n","| train/                  |               |\n","|    approx_kl            | 7.5926626e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.08e+04      |\n","|    n_updates            | 10100         |\n","|    policy_gradient_loss | -0.000186     |\n","|    value_loss           | 3.3e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1011    |\n","|    time_elapsed    | 5964    |\n","|    total_timesteps | 2070528 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1012          |\n","|    time_elapsed         | 5968          |\n","|    total_timesteps      | 2072576       |\n","| train/                  |               |\n","|    approx_kl            | 1.2943085e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.52          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.9e+04       |\n","|    n_updates            | 10110         |\n","|    policy_gradient_loss | -9.27e-05     |\n","|    value_loss           | 8.85e+04      |\n","-------------------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 347            |\n","|    iterations           | 1013           |\n","|    time_elapsed         | 5971           |\n","|    total_timesteps      | 2074624        |\n","| train/                  |                |\n","|    approx_kl            | 0.000112749985 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.199         |\n","|    explained_variance   | 0.806          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.71e+04       |\n","|    n_updates            | 10120          |\n","|    policy_gradient_loss | -0.000303      |\n","|    value_loss           | 4.01e+04       |\n","--------------------------------------------\n","Eval num_timesteps=2075000, episode_reward=23299.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.33e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2075000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037553743 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.157        |\n","|    explained_variance   | 0.776         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.42e+04      |\n","|    n_updates            | 10130         |\n","|    policy_gradient_loss | -0.000539     |\n","|    value_loss           | 5.65e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1014    |\n","|    time_elapsed    | 5980    |\n","|    total_timesteps | 2076672 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1015          |\n","|    time_elapsed         | 5984          |\n","|    total_timesteps      | 2078720       |\n","| train/                  |               |\n","|    approx_kl            | 8.2420185e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.231        |\n","|    explained_variance   | 0.834         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.35e+03      |\n","|    n_updates            | 10140         |\n","|    policy_gradient_loss | -0.000154     |\n","|    value_loss           | 2.59e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2080000, episode_reward=23808.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.38e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2080000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038469172 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.15         |\n","|    explained_variance   | 0.721         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.44e+04      |\n","|    n_updates            | 10150         |\n","|    policy_gradient_loss | -0.000558     |\n","|    value_loss           | 2.89e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1016    |\n","|    time_elapsed    | 5993    |\n","|    total_timesteps | 2080768 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1017         |\n","|    time_elapsed         | 5996         |\n","|    total_timesteps      | 2082816      |\n","| train/                  |              |\n","|    approx_kl            | 7.000283e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.648        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.73e+03     |\n","|    n_updates            | 10160        |\n","|    policy_gradient_loss | -0.000239    |\n","|    value_loss           | 3.85e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1018         |\n","|    time_elapsed         | 5999         |\n","|    total_timesteps      | 2084864      |\n","| train/                  |              |\n","|    approx_kl            | 9.564601e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.144       |\n","|    explained_variance   | 0.831        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.95e+04     |\n","|    n_updates            | 10170        |\n","|    policy_gradient_loss | -0.000108    |\n","|    value_loss           | 7.4e+04      |\n","------------------------------------------\n","Eval num_timesteps=2085000, episode_reward=23808.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.38e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2085000       |\n","| train/                  |               |\n","|    approx_kl            | 4.8857008e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.181        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.09e+03      |\n","|    n_updates            | 10180         |\n","|    policy_gradient_loss | -0.000131     |\n","|    value_loss           | 3.87e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1019    |\n","|    time_elapsed    | 6009    |\n","|    total_timesteps | 2086912 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1020          |\n","|    time_elapsed         | 6012          |\n","|    total_timesteps      | 2088960       |\n","| train/                  |               |\n","|    approx_kl            | 0.00069973385 |\n","|    clip_fraction        | 0.00332       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.76          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.24e+04      |\n","|    n_updates            | 10190         |\n","|    policy_gradient_loss | -0.00122      |\n","|    value_loss           | 4.47e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2090000, episode_reward=23524.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.35e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2090000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0010695901 |\n","|    clip_fraction        | 0.0043       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.24        |\n","|    explained_variance   | 0.734        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.75e+03     |\n","|    n_updates            | 10200        |\n","|    policy_gradient_loss | -0.00156     |\n","|    value_loss           | 2.83e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1021    |\n","|    time_elapsed    | 6021    |\n","|    total_timesteps | 2091008 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1022         |\n","|    time_elapsed         | 6024         |\n","|    total_timesteps      | 2093056      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003506922 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.134       |\n","|    explained_variance   | 0.676        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.03e+04     |\n","|    n_updates            | 10210        |\n","|    policy_gradient_loss | -0.000505    |\n","|    value_loss           | 3.67e+04     |\n","------------------------------------------\n","Eval num_timesteps=2095000, episode_reward=21997.88 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.2e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2095000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006548314 |\n","|    clip_fraction        | 0.00342      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.142       |\n","|    explained_variance   | 0.598        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.92e+03     |\n","|    n_updates            | 10220        |\n","|    policy_gradient_loss | -0.00185     |\n","|    value_loss           | 3.49e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1023    |\n","|    time_elapsed    | 6034    |\n","|    total_timesteps | 2095104 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1024          |\n","|    time_elapsed         | 6037          |\n","|    total_timesteps      | 2097152       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032878047 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.205        |\n","|    explained_variance   | 0.699         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.46e+04      |\n","|    n_updates            | 10230         |\n","|    policy_gradient_loss | -0.000221     |\n","|    value_loss           | 1.24e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1025         |\n","|    time_elapsed         | 6041         |\n","|    total_timesteps      | 2099200      |\n","| train/                  |              |\n","|    approx_kl            | 8.867061e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.131       |\n","|    explained_variance   | 0.677        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.38e+03     |\n","|    n_updates            | 10240        |\n","|    policy_gradient_loss | -0.000286    |\n","|    value_loss           | 3.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=2100000, episode_reward=21865.27 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.19e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2100000      |\n","| train/                  |              |\n","|    approx_kl            | 2.428994e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.2         |\n","|    explained_variance   | 0.736        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.23e+04     |\n","|    n_updates            | 10250        |\n","|    policy_gradient_loss | -2.74e-05    |\n","|    value_loss           | 4.75e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1026    |\n","|    time_elapsed    | 6050    |\n","|    total_timesteps | 2101248 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1027          |\n","|    time_elapsed         | 6053          |\n","|    total_timesteps      | 2103296       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010788214 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.803         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.32e+03      |\n","|    n_updates            | 10260         |\n","|    policy_gradient_loss | -0.000336     |\n","|    value_loss           | 2.2e+04       |\n","-------------------------------------------\n","Eval num_timesteps=2105000, episode_reward=21607.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.16e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2105000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008105233 |\n","|    clip_fraction        | 0.00591      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.161       |\n","|    explained_variance   | 0.644        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.48e+04     |\n","|    n_updates            | 10270        |\n","|    policy_gradient_loss | -0.00172     |\n","|    value_loss           | 3.67e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1028    |\n","|    time_elapsed    | 6063    |\n","|    total_timesteps | 2105344 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1029          |\n","|    time_elapsed         | 6066          |\n","|    total_timesteps      | 2107392       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016557684 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.612         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 10280         |\n","|    policy_gradient_loss | -0.000523     |\n","|    value_loss           | 5.32e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1030          |\n","|    time_elapsed         | 6070          |\n","|    total_timesteps      | 2109440       |\n","| train/                  |               |\n","|    approx_kl            | 6.3098996e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.683         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.24e+04      |\n","|    n_updates            | 10290         |\n","|    policy_gradient_loss | -0.000283     |\n","|    value_loss           | 1.11e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2110000, episode_reward=21824.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2110000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002731682 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.159       |\n","|    explained_variance   | 0.674        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.66e+03     |\n","|    n_updates            | 10300        |\n","|    policy_gradient_loss | -0.000351    |\n","|    value_loss           | 2.81e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1031    |\n","|    time_elapsed    | 6079    |\n","|    total_timesteps | 2111488 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1032         |\n","|    time_elapsed         | 6083         |\n","|    total_timesteps      | 2113536      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002274407 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.214       |\n","|    explained_variance   | 0.719        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.53e+04     |\n","|    n_updates            | 10310        |\n","|    policy_gradient_loss | -0.000358    |\n","|    value_loss           | 4.87e+04     |\n","------------------------------------------\n","Eval num_timesteps=2115000, episode_reward=21824.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2115000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016706635 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.181        |\n","|    explained_variance   | 0.839         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.22e+03      |\n","|    n_updates            | 10320         |\n","|    policy_gradient_loss | -0.000171     |\n","|    value_loss           | 2.76e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1033    |\n","|    time_elapsed    | 6092    |\n","|    total_timesteps | 2115584 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1034          |\n","|    time_elapsed         | 6096          |\n","|    total_timesteps      | 2117632       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040140795 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.694         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.2e+04       |\n","|    n_updates            | 10330         |\n","|    policy_gradient_loss | -0.000606     |\n","|    value_loss           | 3.16e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1035          |\n","|    time_elapsed         | 6099          |\n","|    total_timesteps      | 2119680       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040115797 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.651         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.3e+04       |\n","|    n_updates            | 10340         |\n","|    policy_gradient_loss | -0.00143      |\n","|    value_loss           | 1.15e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2120000, episode_reward=21824.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2120000      |\n","| train/                  |              |\n","|    approx_kl            | 2.408601e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.219       |\n","|    explained_variance   | 0.723        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.74e+04     |\n","|    n_updates            | 10350        |\n","|    policy_gradient_loss | -5.55e-05    |\n","|    value_loss           | 5.71e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1036    |\n","|    time_elapsed    | 6109    |\n","|    total_timesteps | 2121728 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1037          |\n","|    time_elapsed         | 6112          |\n","|    total_timesteps      | 2123776       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048826972 |\n","|    clip_fraction        | 0.00244       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.07e+04      |\n","|    n_updates            | 10360         |\n","|    policy_gradient_loss | -0.000663     |\n","|    value_loss           | 2.87e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2125000, episode_reward=21711.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.17e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2125000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006164014 |\n","|    clip_fraction        | 0.00195      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.214       |\n","|    explained_variance   | 0.798        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.64e+04     |\n","|    n_updates            | 10370        |\n","|    policy_gradient_loss | -0.000859    |\n","|    value_loss           | 4.81e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1038    |\n","|    time_elapsed    | 6122    |\n","|    total_timesteps | 2125824 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1039          |\n","|    time_elapsed         | 6125          |\n","|    total_timesteps      | 2127872       |\n","| train/                  |               |\n","|    approx_kl            | 0.00077138835 |\n","|    clip_fraction        | 0.00186       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.773         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.69e+04      |\n","|    n_updates            | 10380         |\n","|    policy_gradient_loss | -0.00107      |\n","|    value_loss           | 2.78e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1040         |\n","|    time_elapsed         | 6129         |\n","|    total_timesteps      | 2129920      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004649487 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.159       |\n","|    explained_variance   | 0.647        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.97e+03     |\n","|    n_updates            | 10390        |\n","|    policy_gradient_loss | -0.000801    |\n","|    value_loss           | 3.25e+04     |\n","------------------------------------------\n","Eval num_timesteps=2130000, episode_reward=23222.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.32e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2130000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037240176 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.6           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.88e+04      |\n","|    n_updates            | 10400         |\n","|    policy_gradient_loss | -0.000561     |\n","|    value_loss           | 1.11e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1041    |\n","|    time_elapsed    | 6138    |\n","|    total_timesteps | 2131968 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1042         |\n","|    time_elapsed         | 6141         |\n","|    total_timesteps      | 2134016      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001218307 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.233       |\n","|    explained_variance   | 0.711        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.59e+04     |\n","|    n_updates            | 10410        |\n","|    policy_gradient_loss | -0.000316    |\n","|    value_loss           | 5.79e+04     |\n","------------------------------------------\n","Eval num_timesteps=2135000, episode_reward=23499.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.35e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2135000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041609563 |\n","|    clip_fraction        | 0.00151       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.26e+04      |\n","|    n_updates            | 10420         |\n","|    policy_gradient_loss | -0.000767     |\n","|    value_loss           | 4.03e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1043    |\n","|    time_elapsed    | 6152    |\n","|    total_timesteps | 2136064 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1044         |\n","|    time_elapsed         | 6156         |\n","|    total_timesteps      | 2138112      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005329173 |\n","|    clip_fraction        | 0.00146      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.231       |\n","|    explained_variance   | 0.815        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.96e+03     |\n","|    n_updates            | 10430        |\n","|    policy_gradient_loss | -0.000404    |\n","|    value_loss           | 3.32e+04     |\n","------------------------------------------\n","Eval num_timesteps=2140000, episode_reward=23539.79 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.35e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2140000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00071650045 |\n","|    clip_fraction        | 0.00254       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.681         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.73e+04      |\n","|    n_updates            | 10440         |\n","|    policy_gradient_loss | -0.0011       |\n","|    value_loss           | 4.83e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1045    |\n","|    time_elapsed    | 6166    |\n","|    total_timesteps | 2140160 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1046          |\n","|    time_elapsed         | 6169          |\n","|    total_timesteps      | 2142208       |\n","| train/                  |               |\n","|    approx_kl            | 3.2514217e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.656         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.98e+03      |\n","|    n_updates            | 10450         |\n","|    policy_gradient_loss | -0.000208     |\n","|    value_loss           | 3.61e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1047         |\n","|    time_elapsed         | 6173         |\n","|    total_timesteps      | 2144256      |\n","| train/                  |              |\n","|    approx_kl            | 9.457435e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.129       |\n","|    explained_variance   | 0.559        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.42e+04     |\n","|    n_updates            | 10460        |\n","|    policy_gradient_loss | -0.00036     |\n","|    value_loss           | 1.65e+05     |\n","------------------------------------------\n","Eval num_timesteps=2145000, episode_reward=21820.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2145000      |\n","| train/                  |              |\n","|    approx_kl            | 2.515383e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.203       |\n","|    explained_variance   | 0.786        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.87e+03     |\n","|    n_updates            | 10470        |\n","|    policy_gradient_loss | -0.000293    |\n","|    value_loss           | 4.35e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1048    |\n","|    time_elapsed    | 6182    |\n","|    total_timesteps | 2146304 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1049          |\n","|    time_elapsed         | 6186          |\n","|    total_timesteps      | 2148352       |\n","| train/                  |               |\n","|    approx_kl            | 2.7565577e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.669         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 10480         |\n","|    policy_gradient_loss | -4.34e-05     |\n","|    value_loss           | 5.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2150000, episode_reward=21820.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2150000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017531004 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.232        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.72e+03      |\n","|    n_updates            | 10490         |\n","|    policy_gradient_loss | -0.000349     |\n","|    value_loss           | 2.66e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1050    |\n","|    time_elapsed    | 6195    |\n","|    total_timesteps | 2150400 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1051          |\n","|    time_elapsed         | 6198          |\n","|    total_timesteps      | 2152448       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042443993 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.66          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.54e+04      |\n","|    n_updates            | 10500         |\n","|    policy_gradient_loss | -0.000757     |\n","|    value_loss           | 4.62e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1052          |\n","|    time_elapsed         | 6202          |\n","|    total_timesteps      | 2154496       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032002237 |\n","|    clip_fraction        | 0.00239       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.632         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.87e+03      |\n","|    n_updates            | 10510         |\n","|    policy_gradient_loss | -0.0014       |\n","|    value_loss           | 2.89e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2155000, episode_reward=22307.37 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.23e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2155000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040659076 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.14         |\n","|    explained_variance   | 0.763         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.64e+04      |\n","|    n_updates            | 10520         |\n","|    policy_gradient_loss | -0.000273     |\n","|    value_loss           | 8.48e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1053    |\n","|    time_elapsed    | 6211    |\n","|    total_timesteps | 2156544 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1054         |\n","|    time_elapsed         | 6215         |\n","|    total_timesteps      | 2158592      |\n","| train/                  |              |\n","|    approx_kl            | 4.938201e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.177       |\n","|    explained_variance   | 0.67         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.05e+04     |\n","|    n_updates            | 10530        |\n","|    policy_gradient_loss | -0.000303    |\n","|    value_loss           | 3.36e+04     |\n","------------------------------------------\n","Eval num_timesteps=2160000, episode_reward=22416.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.24e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2160000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024754475 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.747         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.7e+04       |\n","|    n_updates            | 10540         |\n","|    policy_gradient_loss | -0.000247     |\n","|    value_loss           | 3.9e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1055    |\n","|    time_elapsed    | 6224    |\n","|    total_timesteps | 2160640 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1056         |\n","|    time_elapsed         | 6227         |\n","|    total_timesteps      | 2162688      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006234548 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.24        |\n","|    explained_variance   | 0.743        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.38e+04     |\n","|    n_updates            | 10550        |\n","|    policy_gradient_loss | -0.000651    |\n","|    value_loss           | 4.16e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1057         |\n","|    time_elapsed         | 6231         |\n","|    total_timesteps      | 2164736      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004498003 |\n","|    clip_fraction        | 0.000586     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.13        |\n","|    explained_variance   | 0.72         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.05e+04     |\n","|    n_updates            | 10560        |\n","|    policy_gradient_loss | -0.000594    |\n","|    value_loss           | 4.31e+04     |\n","------------------------------------------\n","Eval num_timesteps=2165000, episode_reward=23095.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.31e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2165000      |\n","| train/                  |              |\n","|    approx_kl            | 6.654195e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.606        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.83e+04     |\n","|    n_updates            | 10570        |\n","|    policy_gradient_loss | -0.000348    |\n","|    value_loss           | 4.91e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1058    |\n","|    time_elapsed    | 6240    |\n","|    total_timesteps | 2166784 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1059          |\n","|    time_elapsed         | 6244          |\n","|    total_timesteps      | 2168832       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010499568 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.199        |\n","|    explained_variance   | 0.709         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.59e+04      |\n","|    n_updates            | 10580         |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 1.21e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2170000, episode_reward=22913.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.29e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2170000      |\n","| train/                  |              |\n","|    approx_kl            | 7.384489e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.13        |\n","|    explained_variance   | 0.701        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.28e+04     |\n","|    n_updates            | 10590        |\n","|    policy_gradient_loss | -0.00027     |\n","|    value_loss           | 2.26e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1060    |\n","|    time_elapsed    | 6253    |\n","|    total_timesteps | 2170880 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1061          |\n","|    time_elapsed         | 6257          |\n","|    total_timesteps      | 2172928       |\n","| train/                  |               |\n","|    approx_kl            | 0.00080439524 |\n","|    clip_fraction        | 0.00229       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.182        |\n","|    explained_variance   | 0.713         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.68e+04      |\n","|    n_updates            | 10600         |\n","|    policy_gradient_loss | -0.000494     |\n","|    value_loss           | 3.49e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1062         |\n","|    time_elapsed         | 6261         |\n","|    total_timesteps      | 2174976      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003010177 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.213       |\n","|    explained_variance   | 0.837        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.36e+03     |\n","|    n_updates            | 10610        |\n","|    policy_gradient_loss | -0.000776    |\n","|    value_loss           | 3.29e+04     |\n","------------------------------------------\n","Eval num_timesteps=2175000, episode_reward=21374.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.14e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2175000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037286492 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 10620         |\n","|    policy_gradient_loss | -0.000537     |\n","|    value_loss           | 3.7e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1063    |\n","|    time_elapsed    | 6270    |\n","|    total_timesteps | 2177024 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1064         |\n","|    time_elapsed         | 6275         |\n","|    total_timesteps      | 2179072      |\n","| train/                  |              |\n","|    approx_kl            | 7.115392e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.121       |\n","|    explained_variance   | 0.686        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.12e+04     |\n","|    n_updates            | 10630        |\n","|    policy_gradient_loss | -1.13e-05    |\n","|    value_loss           | 5.29e+04     |\n","------------------------------------------\n","Eval num_timesteps=2180000, episode_reward=18723.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2180000       |\n","| train/                  |               |\n","|    approx_kl            | 3.5196746e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.204        |\n","|    explained_variance   | 0.781         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.84e+04      |\n","|    n_updates            | 10640         |\n","|    policy_gradient_loss | -0.000145     |\n","|    value_loss           | 1.25e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1065    |\n","|    time_elapsed    | 6284    |\n","|    total_timesteps | 2181120 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1066          |\n","|    time_elapsed         | 6288          |\n","|    total_timesteps      | 2183168       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023667546 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.14         |\n","|    explained_variance   | 0.658         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 10650         |\n","|    policy_gradient_loss | -0.00019      |\n","|    value_loss           | 3.41e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2185000, episode_reward=20386.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2185000       |\n","| train/                  |               |\n","|    approx_kl            | 4.8702408e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.198        |\n","|    explained_variance   | 0.691         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.11e+04      |\n","|    n_updates            | 10660         |\n","|    policy_gradient_loss | -0.000127     |\n","|    value_loss           | 5.46e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1067    |\n","|    time_elapsed    | 6297    |\n","|    total_timesteps | 2185216 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1068          |\n","|    time_elapsed         | 6300          |\n","|    total_timesteps      | 2187264       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014234381 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.183        |\n","|    explained_variance   | 0.818         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 10670         |\n","|    policy_gradient_loss | -0.000428     |\n","|    value_loss           | 3.19e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1069          |\n","|    time_elapsed         | 6304          |\n","|    total_timesteps      | 2189312       |\n","| train/                  |               |\n","|    approx_kl            | 1.1483324e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.671         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.54e+04      |\n","|    n_updates            | 10680         |\n","|    policy_gradient_loss | -9.66e-05     |\n","|    value_loss           | 4.12e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2190000, episode_reward=20775.94 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.08e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2190000      |\n","| train/                  |              |\n","|    approx_kl            | 9.114301e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.605        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.56e+04     |\n","|    n_updates            | 10690        |\n","|    policy_gradient_loss | -3.17e-05    |\n","|    value_loss           | 1.01e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1070    |\n","|    time_elapsed    | 6313    |\n","|    total_timesteps | 2191360 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1071          |\n","|    time_elapsed         | 6316          |\n","|    total_timesteps      | 2193408       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043531417 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.219        |\n","|    explained_variance   | 0.795         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.04e+04      |\n","|    n_updates            | 10700         |\n","|    policy_gradient_loss | -0.000933     |\n","|    value_loss           | 4.96e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2195000, episode_reward=20891.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.09e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2195000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00056409487 |\n","|    clip_fraction        | 0.00151       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.159        |\n","|    explained_variance   | 0.62          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 10710         |\n","|    policy_gradient_loss | -0.000562     |\n","|    value_loss           | 2.71e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1072    |\n","|    time_elapsed    | 6325    |\n","|    total_timesteps | 2195456 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1073         |\n","|    time_elapsed         | 6328         |\n","|    total_timesteps      | 2197504      |\n","| train/                  |              |\n","|    approx_kl            | 0.0012040769 |\n","|    clip_fraction        | 0.00757      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.197       |\n","|    explained_variance   | 0.736        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.69e+03     |\n","|    n_updates            | 10720        |\n","|    policy_gradient_loss | -0.00208     |\n","|    value_loss           | 4.69e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1074          |\n","|    time_elapsed         | 6332          |\n","|    total_timesteps      | 2199552       |\n","| train/                  |               |\n","|    approx_kl            | 1.8372812e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.166        |\n","|    explained_variance   | 0.776         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.23e+03      |\n","|    n_updates            | 10730         |\n","|    policy_gradient_loss | -0.000125     |\n","|    value_loss           | 2.91e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2200000, episode_reward=19113.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2200000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011095972 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.557         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.71e+03      |\n","|    n_updates            | 10740         |\n","|    policy_gradient_loss | -0.000386     |\n","|    value_loss           | 3.66e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1075    |\n","|    time_elapsed    | 6342    |\n","|    total_timesteps | 2201600 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1076          |\n","|    time_elapsed         | 6345          |\n","|    total_timesteps      | 2203648       |\n","| train/                  |               |\n","|    approx_kl            | 2.5860965e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.111        |\n","|    explained_variance   | 0.546         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.22e+04      |\n","|    n_updates            | 10750         |\n","|    policy_gradient_loss | -0.000153     |\n","|    value_loss           | 1.31e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2205000, episode_reward=18945.45 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.89e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2205000      |\n","| train/                  |              |\n","|    approx_kl            | 1.374734e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.23        |\n","|    explained_variance   | 0.731        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.36e+04     |\n","|    n_updates            | 10760        |\n","|    policy_gradient_loss | -0.000186    |\n","|    value_loss           | 5.57e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1077    |\n","|    time_elapsed    | 6354    |\n","|    total_timesteps | 2205696 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1078          |\n","|    time_elapsed         | 6357          |\n","|    total_timesteps      | 2207744       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038669034 |\n","|    clip_fraction        | 0.00146       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.635         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.28e+04      |\n","|    n_updates            | 10770         |\n","|    policy_gradient_loss | -0.000628     |\n","|    value_loss           | 3.62e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1079          |\n","|    time_elapsed         | 6361          |\n","|    total_timesteps      | 2209792       |\n","| train/                  |               |\n","|    approx_kl            | 2.3266533e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.221        |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.82e+04      |\n","|    n_updates            | 10780         |\n","|    policy_gradient_loss | -8.71e-05     |\n","|    value_loss           | 3.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2210000, episode_reward=20269.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.03e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2210000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016906005 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.764         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 10790         |\n","|    policy_gradient_loss | -0.000125     |\n","|    value_loss           | 2.99e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1080    |\n","|    time_elapsed    | 6370    |\n","|    total_timesteps | 2211840 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1081         |\n","|    time_elapsed         | 6374         |\n","|    total_timesteps      | 2213888      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002806593 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.161       |\n","|    explained_variance   | 0.606        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.12e+04     |\n","|    n_updates            | 10800        |\n","|    policy_gradient_loss | -0.000183    |\n","|    value_loss           | 3.03e+04     |\n","------------------------------------------\n","Eval num_timesteps=2215000, episode_reward=19673.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.97e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2215000       |\n","| train/                  |               |\n","|    approx_kl            | 1.3134966e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.627         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.1e+04       |\n","|    n_updates            | 10810         |\n","|    policy_gradient_loss | -4.31e-05     |\n","|    value_loss           | 1.15e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1082    |\n","|    time_elapsed    | 6383    |\n","|    total_timesteps | 2215936 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1083         |\n","|    time_elapsed         | 6386         |\n","|    total_timesteps      | 2217984      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002370518 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.207       |\n","|    explained_variance   | 0.789        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.45e+03     |\n","|    n_updates            | 10820        |\n","|    policy_gradient_loss | -0.000568    |\n","|    value_loss           | 3e+04        |\n","------------------------------------------\n","Eval num_timesteps=2220000, episode_reward=20776.27 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2220000       |\n","| train/                  |               |\n","|    approx_kl            | 3.4633704e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.143        |\n","|    explained_variance   | 0.595         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.02e+04      |\n","|    n_updates            | 10830         |\n","|    policy_gradient_loss | -6.28e-07     |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1084    |\n","|    time_elapsed    | 6396    |\n","|    total_timesteps | 2220032 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1085          |\n","|    time_elapsed         | 6399          |\n","|    total_timesteps      | 2222080       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015686938 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.235        |\n","|    explained_variance   | 0.753         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.95e+03      |\n","|    n_updates            | 10840         |\n","|    policy_gradient_loss | -0.000131     |\n","|    value_loss           | 3.13e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1086          |\n","|    time_elapsed         | 6404          |\n","|    total_timesteps      | 2224128       |\n","| train/                  |               |\n","|    approx_kl            | 0.00063979917 |\n","|    clip_fraction        | 0.00347       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.14         |\n","|    explained_variance   | 0.761         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.99e+03      |\n","|    n_updates            | 10850         |\n","|    policy_gradient_loss | -0.00182      |\n","|    value_loss           | 3.88e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2225000, episode_reward=20957.10 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.1e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2225000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011860387 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.567         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.46e+03      |\n","|    n_updates            | 10860         |\n","|    policy_gradient_loss | -0.00051      |\n","|    value_loss           | 3.82e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1087    |\n","|    time_elapsed    | 6417    |\n","|    total_timesteps | 2226176 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1088          |\n","|    time_elapsed         | 6421          |\n","|    total_timesteps      | 2228224       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031730894 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.751         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.29e+04      |\n","|    n_updates            | 10870         |\n","|    policy_gradient_loss | -0.000343     |\n","|    value_loss           | 1.09e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2230000, episode_reward=21205.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.12e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2230000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010231673 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.778         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.54e+03      |\n","|    n_updates            | 10880         |\n","|    policy_gradient_loss | -0.000259     |\n","|    value_loss           | 2.93e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1089    |\n","|    time_elapsed    | 6431    |\n","|    total_timesteps | 2230272 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1090         |\n","|    time_elapsed         | 6434         |\n","|    total_timesteps      | 2232320      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005084089 |\n","|    clip_fraction        | 0.00122      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.164       |\n","|    explained_variance   | 0.741        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.13e+04     |\n","|    n_updates            | 10890        |\n","|    policy_gradient_loss | -0.000818    |\n","|    value_loss           | 3.74e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1091         |\n","|    time_elapsed         | 6438         |\n","|    total_timesteps      | 2234368      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002304441 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.234       |\n","|    explained_variance   | 0.766        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.7e+03      |\n","|    n_updates            | 10900        |\n","|    policy_gradient_loss | -0.000339    |\n","|    value_loss           | 2.74e+04     |\n","------------------------------------------\n","Eval num_timesteps=2235000, episode_reward=21226.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.12e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2235000      |\n","| train/                  |              |\n","|    approx_kl            | 9.542116e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.137       |\n","|    explained_variance   | 0.783        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.39e+03     |\n","|    n_updates            | 10910        |\n","|    policy_gradient_loss | -0.000232    |\n","|    value_loss           | 2.45e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1092    |\n","|    time_elapsed    | 6447    |\n","|    total_timesteps | 2236416 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1093          |\n","|    time_elapsed         | 6450          |\n","|    total_timesteps      | 2238464       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020639919 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.736         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 10920         |\n","|    policy_gradient_loss | -0.000357     |\n","|    value_loss           | 3.8e+04       |\n","-------------------------------------------\n","Eval num_timesteps=2240000, episode_reward=23092.37 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.31e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2240000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00071117305 |\n","|    clip_fraction        | 0.00366       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.772         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.93e+04      |\n","|    n_updates            | 10930         |\n","|    policy_gradient_loss | -0.00173      |\n","|    value_loss           | 7.9e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1094    |\n","|    time_elapsed    | 6460    |\n","|    total_timesteps | 2240512 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1095          |\n","|    time_elapsed         | 6463          |\n","|    total_timesteps      | 2242560       |\n","| train/                  |               |\n","|    approx_kl            | 2.8551614e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.741         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.31e+03      |\n","|    n_updates            | 10940         |\n","|    policy_gradient_loss | -0.000188     |\n","|    value_loss           | 3.38e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1096         |\n","|    time_elapsed         | 6467         |\n","|    total_timesteps      | 2244608      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005424584 |\n","|    clip_fraction        | 0.00171      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.176       |\n","|    explained_variance   | 0.723        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.96e+03     |\n","|    n_updates            | 10950        |\n","|    policy_gradient_loss | -0.000716    |\n","|    value_loss           | 4.01e+04     |\n","------------------------------------------\n","Eval num_timesteps=2245000, episode_reward=21205.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.12e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 2245000     |\n","| train/                  |             |\n","|    approx_kl            | 7.77496e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.214      |\n","|    explained_variance   | 0.832       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 5.85e+03    |\n","|    n_updates            | 10960       |\n","|    policy_gradient_loss | -0.000362   |\n","|    value_loss           | 2.61e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1097    |\n","|    time_elapsed    | 6476    |\n","|    total_timesteps | 2246656 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1098          |\n","|    time_elapsed         | 6480          |\n","|    total_timesteps      | 2248704       |\n","| train/                  |               |\n","|    approx_kl            | 2.5766232e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 10970         |\n","|    policy_gradient_loss | -4.9e-05      |\n","|    value_loss           | 4.18e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2250000, episode_reward=18555.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2250000       |\n","| train/                  |               |\n","|    approx_kl            | 1.2108125e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.129        |\n","|    explained_variance   | 0.654         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.84e+04      |\n","|    n_updates            | 10980         |\n","|    policy_gradient_loss | -0.000254     |\n","|    value_loss           | 6.3e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1099    |\n","|    time_elapsed    | 6489    |\n","|    total_timesteps | 2250752 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1100          |\n","|    time_elapsed         | 6492          |\n","|    total_timesteps      | 2252800       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021805678 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.678         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.22e+04      |\n","|    n_updates            | 10990         |\n","|    policy_gradient_loss | -0.00025      |\n","|    value_loss           | 1.24e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1101          |\n","|    time_elapsed         | 6496          |\n","|    total_timesteps      | 2254848       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015882222 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.72          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.61e+03      |\n","|    n_updates            | 11000         |\n","|    policy_gradient_loss | -0.000347     |\n","|    value_loss           | 2.1e+04       |\n","-------------------------------------------\n","Eval num_timesteps=2255000, episode_reward=20734.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.07e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2255000       |\n","| train/                  |               |\n","|    approx_kl            | 5.4166157e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.193        |\n","|    explained_variance   | 0.757         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.22e+03      |\n","|    n_updates            | 11010         |\n","|    policy_gradient_loss | -7.38e-05     |\n","|    value_loss           | 4.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1102    |\n","|    time_elapsed    | 6505    |\n","|    total_timesteps | 2256896 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1103          |\n","|    time_elapsed         | 6508          |\n","|    total_timesteps      | 2258944       |\n","| train/                  |               |\n","|    approx_kl            | 0.00063583243 |\n","|    clip_fraction        | 0.00308       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.188        |\n","|    explained_variance   | 0.84          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.45e+03      |\n","|    n_updates            | 11020         |\n","|    policy_gradient_loss | -0.00104      |\n","|    value_loss           | 2.69e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2260000, episode_reward=19753.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.98e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2260000      |\n","| train/                  |              |\n","|    approx_kl            | 1.604241e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.149       |\n","|    explained_variance   | 0.737        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.19e+04     |\n","|    n_updates            | 11030        |\n","|    policy_gradient_loss | -6.55e-05    |\n","|    value_loss           | 3.06e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1104    |\n","|    time_elapsed    | 6517    |\n","|    total_timesteps | 2260992 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1105          |\n","|    time_elapsed         | 6521          |\n","|    total_timesteps      | 2263040       |\n","| train/                  |               |\n","|    approx_kl            | 4.8202055e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.7           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.62e+04      |\n","|    n_updates            | 11040         |\n","|    policy_gradient_loss | -0.000102     |\n","|    value_loss           | 1.14e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2265000, episode_reward=20983.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.1e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2265000      |\n","| train/                  |              |\n","|    approx_kl            | 6.237559e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.212       |\n","|    explained_variance   | 0.766        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.14e+04     |\n","|    n_updates            | 11050        |\n","|    policy_gradient_loss | -0.000174    |\n","|    value_loss           | 6.88e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1106    |\n","|    time_elapsed    | 6530    |\n","|    total_timesteps | 2265088 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1107          |\n","|    time_elapsed         | 6533          |\n","|    total_timesteps      | 2267136       |\n","| train/                  |               |\n","|    approx_kl            | 0.00073637266 |\n","|    clip_fraction        | 0.00601       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.735         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.26e+03      |\n","|    n_updates            | 11060         |\n","|    policy_gradient_loss | -0.00128      |\n","|    value_loss           | 1.73e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1108          |\n","|    time_elapsed         | 6536          |\n","|    total_timesteps      | 2269184       |\n","| train/                  |               |\n","|    approx_kl            | 8.1018865e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.187        |\n","|    explained_variance   | 0.706         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.48e+04      |\n","|    n_updates            | 11070         |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 5.09e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2270000, episode_reward=20901.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.09e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2270000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003770199 |\n","|    clip_fraction        | 0.00151      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.17        |\n","|    explained_variance   | 0.732        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.75e+03     |\n","|    n_updates            | 11080        |\n","|    policy_gradient_loss | -0.000509    |\n","|    value_loss           | 2.98e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1109    |\n","|    time_elapsed    | 6546    |\n","|    total_timesteps | 2271232 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1110          |\n","|    time_elapsed         | 6549          |\n","|    total_timesteps      | 2273280       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047956363 |\n","|    clip_fraction        | 0.00181       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.603         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6e+03         |\n","|    n_updates            | 11090         |\n","|    policy_gradient_loss | -0.00107      |\n","|    value_loss           | 2.71e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2275000, episode_reward=20097.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.01e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2275000      |\n","| train/                  |              |\n","|    approx_kl            | 3.445166e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.103       |\n","|    explained_variance   | 0.598        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.25e+05     |\n","|    n_updates            | 11100        |\n","|    policy_gradient_loss | -2.77e-05    |\n","|    value_loss           | 1.07e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1111    |\n","|    time_elapsed    | 6558    |\n","|    total_timesteps | 2275328 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1112          |\n","|    time_elapsed         | 6561          |\n","|    total_timesteps      | 2277376       |\n","| train/                  |               |\n","|    approx_kl            | 5.1495124e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.222        |\n","|    explained_variance   | 0.704         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.98e+04      |\n","|    n_updates            | 11110         |\n","|    policy_gradient_loss | -0.000161     |\n","|    value_loss           | 5.36e+04      |\n","-------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 347        |\n","|    iterations           | 1113       |\n","|    time_elapsed         | 6565       |\n","|    total_timesteps      | 2279424    |\n","| train/                  |            |\n","|    approx_kl            | 0.00056549 |\n","|    clip_fraction        | 0.00288    |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.141     |\n","|    explained_variance   | 0.725      |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 9.44e+03   |\n","|    n_updates            | 11120      |\n","|    policy_gradient_loss | -0.00146   |\n","|    value_loss           | 2.93e+04   |\n","----------------------------------------\n","Eval num_timesteps=2280000, episode_reward=18967.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.9e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2280000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008255985 |\n","|    clip_fraction        | 0.00254      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.214       |\n","|    explained_variance   | 0.718        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.45e+03     |\n","|    n_updates            | 11130        |\n","|    policy_gradient_loss | -0.00148     |\n","|    value_loss           | 3.66e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1114    |\n","|    time_elapsed    | 6574    |\n","|    total_timesteps | 2281472 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1115          |\n","|    time_elapsed         | 6577          |\n","|    total_timesteps      | 2283520       |\n","| train/                  |               |\n","|    approx_kl            | 8.0579106e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.71          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.21e+04      |\n","|    n_updates            | 11140         |\n","|    policy_gradient_loss | -7.76e-05     |\n","|    value_loss           | 3.61e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2285000, episode_reward=18391.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2285000       |\n","| train/                  |               |\n","|    approx_kl            | 6.5371365e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.628         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.44e+04      |\n","|    n_updates            | 11150         |\n","|    policy_gradient_loss | -0.000134     |\n","|    value_loss           | 4.85e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1116    |\n","|    time_elapsed    | 6586    |\n","|    total_timesteps | 2285568 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1117         |\n","|    time_elapsed         | 6589         |\n","|    total_timesteps      | 2287616      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002311735 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.117       |\n","|    explained_variance   | 0.616        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.82e+04     |\n","|    n_updates            | 11160        |\n","|    policy_gradient_loss | -0.000548    |\n","|    value_loss           | 1.18e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1118          |\n","|    time_elapsed         | 6593          |\n","|    total_timesteps      | 2289664       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026020652 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 11170         |\n","|    policy_gradient_loss | -0.000305     |\n","|    value_loss           | 3.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2290000, episode_reward=17880.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.79e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2290000      |\n","| train/                  |              |\n","|    approx_kl            | 8.300305e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.135       |\n","|    explained_variance   | 0.674        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.34e+04     |\n","|    n_updates            | 11180        |\n","|    policy_gradient_loss | -0.000198    |\n","|    value_loss           | 4.04e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1119    |\n","|    time_elapsed    | 6602    |\n","|    total_timesteps | 2291712 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1120         |\n","|    time_elapsed         | 6605         |\n","|    total_timesteps      | 2293760      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004849227 |\n","|    clip_fraction        | 0.00146      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.228       |\n","|    explained_variance   | 0.802        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.59e+03     |\n","|    n_updates            | 11190        |\n","|    policy_gradient_loss | -0.000594    |\n","|    value_loss           | 3.48e+04     |\n","------------------------------------------\n","Eval num_timesteps=2295000, episode_reward=17880.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.79e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2295000       |\n","| train/                  |               |\n","|    approx_kl            | 2.4591602e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.787         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.13e+03      |\n","|    n_updates            | 11200         |\n","|    policy_gradient_loss | -0.000205     |\n","|    value_loss           | 3.54e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1121    |\n","|    time_elapsed    | 6615    |\n","|    total_timesteps | 2295808 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1122          |\n","|    time_elapsed         | 6618          |\n","|    total_timesteps      | 2297856       |\n","| train/                  |               |\n","|    approx_kl            | 5.5295415e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.669         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.81e+03      |\n","|    n_updates            | 11210         |\n","|    policy_gradient_loss | -0.00032      |\n","|    value_loss           | 3.75e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1123          |\n","|    time_elapsed         | 6622          |\n","|    total_timesteps      | 2299904       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031928637 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.137        |\n","|    explained_variance   | 0.742         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 11220         |\n","|    policy_gradient_loss | -0.00112      |\n","|    value_loss           | 8.42e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2300000, episode_reward=18555.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.86e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2300000      |\n","| train/                  |              |\n","|    approx_kl            | 6.685482e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.18        |\n","|    explained_variance   | 0.831        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.19e+04     |\n","|    n_updates            | 11230        |\n","|    policy_gradient_loss | -0.000213    |\n","|    value_loss           | 3e+04        |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1124    |\n","|    time_elapsed    | 6631    |\n","|    total_timesteps | 2301952 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1125          |\n","|    time_elapsed         | 6635          |\n","|    total_timesteps      | 2304000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037054953 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.751         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 11240         |\n","|    policy_gradient_loss | -0.000587     |\n","|    value_loss           | 5.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2305000, episode_reward=18555.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.86e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2305000      |\n","| train/                  |              |\n","|    approx_kl            | 9.211333e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.218       |\n","|    explained_variance   | 0.765        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.71e+04     |\n","|    n_updates            | 11250        |\n","|    policy_gradient_loss | -9.96e-05    |\n","|    value_loss           | 3.92e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1126    |\n","|    time_elapsed    | 6643    |\n","|    total_timesteps | 2306048 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1127         |\n","|    time_elapsed         | 6647         |\n","|    total_timesteps      | 2308096      |\n","| train/                  |              |\n","|    approx_kl            | 4.678045e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.136       |\n","|    explained_variance   | 0.755        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.13e+03     |\n","|    n_updates            | 11260        |\n","|    policy_gradient_loss | -0.000106    |\n","|    value_loss           | 2.36e+04     |\n","------------------------------------------\n","Eval num_timesteps=2310000, episode_reward=21373.59 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.14e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2310000       |\n","| train/                  |               |\n","|    approx_kl            | 2.6984984e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.133        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.92e+03      |\n","|    n_updates            | 11270         |\n","|    policy_gradient_loss | -0.000167     |\n","|    value_loss           | 3.7e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1128    |\n","|    time_elapsed    | 6656    |\n","|    total_timesteps | 2310144 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1129          |\n","|    time_elapsed         | 6659          |\n","|    total_timesteps      | 2312192       |\n","| train/                  |               |\n","|    approx_kl            | 6.3846936e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.181        |\n","|    explained_variance   | 0.705         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.3e+04       |\n","|    n_updates            | 11280         |\n","|    policy_gradient_loss | -0.000368     |\n","|    value_loss           | 1.67e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1130          |\n","|    time_elapsed         | 6662          |\n","|    total_timesteps      | 2314240       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024598045 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.137        |\n","|    explained_variance   | 0.633         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.83e+03      |\n","|    n_updates            | 11290         |\n","|    policy_gradient_loss | -0.000551     |\n","|    value_loss           | 3.31e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2315000, episode_reward=21373.59 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.14e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2315000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047170543 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.08e+04      |\n","|    n_updates            | 11300         |\n","|    policy_gradient_loss | -0.00045      |\n","|    value_loss           | 4.12e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1131    |\n","|    time_elapsed    | 6671    |\n","|    total_timesteps | 2316288 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1132        |\n","|    time_elapsed         | 6675        |\n","|    total_timesteps      | 2318336     |\n","| train/                  |             |\n","|    approx_kl            | 0.000679148 |\n","|    clip_fraction        | 0.00249     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.215      |\n","|    explained_variance   | 0.761       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 6.7e+03     |\n","|    n_updates            | 11310       |\n","|    policy_gradient_loss | -0.00138    |\n","|    value_loss           | 3.21e+04    |\n","-----------------------------------------\n","Eval num_timesteps=2320000, episode_reward=20699.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.07e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2320000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007207441 |\n","|    clip_fraction        | 0.0062       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.635        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.54e+04     |\n","|    n_updates            | 11320        |\n","|    policy_gradient_loss | -0.00118     |\n","|    value_loss           | 3.2e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1133    |\n","|    time_elapsed    | 6684    |\n","|    total_timesteps | 2320384 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1134          |\n","|    time_elapsed         | 6687          |\n","|    total_timesteps      | 2322432       |\n","| train/                  |               |\n","|    approx_kl            | 4.7868525e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.697         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.74e+04      |\n","|    n_updates            | 11330         |\n","|    policy_gradient_loss | -0.000127     |\n","|    value_loss           | 4.67e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1135          |\n","|    time_elapsed         | 6691          |\n","|    total_timesteps      | 2324480       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021063711 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.192        |\n","|    explained_variance   | 0.743         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.33e+04      |\n","|    n_updates            | 11340         |\n","|    policy_gradient_loss | -2.85e-05     |\n","|    value_loss           | 5.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2325000, episode_reward=20977.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.1e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2325000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024959832 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.66e+03      |\n","|    n_updates            | 11350         |\n","|    policy_gradient_loss | -0.00015      |\n","|    value_loss           | 3.22e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1136    |\n","|    time_elapsed    | 6700    |\n","|    total_timesteps | 2326528 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1137         |\n","|    time_elapsed         | 6703         |\n","|    total_timesteps      | 2328576      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002520189 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.184       |\n","|    explained_variance   | 0.786        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.02e+03     |\n","|    n_updates            | 11360        |\n","|    policy_gradient_loss | -0.000485    |\n","|    value_loss           | 4.35e+04     |\n","------------------------------------------\n","Eval num_timesteps=2330000, episode_reward=22289.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.23e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2330000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002262108 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.189       |\n","|    explained_variance   | 0.832        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.11e+03     |\n","|    n_updates            | 11370        |\n","|    policy_gradient_loss | -0.00034     |\n","|    value_loss           | 2.64e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1138    |\n","|    time_elapsed    | 6712    |\n","|    total_timesteps | 2330624 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1139        |\n","|    time_elapsed         | 6716        |\n","|    total_timesteps      | 2332672     |\n","| train/                  |             |\n","|    approx_kl            | 7.71973e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.154      |\n","|    explained_variance   | 0.655       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.51e+04    |\n","|    n_updates            | 11380       |\n","|    policy_gradient_loss | -0.000173   |\n","|    value_loss           | 3.77e+04    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1140          |\n","|    time_elapsed         | 6719          |\n","|    total_timesteps      | 2334720       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021329452 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.104        |\n","|    explained_variance   | 0.61          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.39e+04      |\n","|    n_updates            | 11390         |\n","|    policy_gradient_loss | -0.000968     |\n","|    value_loss           | 9.97e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2335000, episode_reward=21096.94 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.11e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2335000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00051212334 |\n","|    clip_fraction        | 0.00151       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.202        |\n","|    explained_variance   | 0.592         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.33e+04      |\n","|    n_updates            | 11400         |\n","|    policy_gradient_loss | -0.000692     |\n","|    value_loss           | 8.58e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1141    |\n","|    time_elapsed    | 6728    |\n","|    total_timesteps | 2336768 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1142          |\n","|    time_elapsed         | 6732          |\n","|    total_timesteps      | 2338816       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034807497 |\n","|    clip_fraction        | 0.00313       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.157        |\n","|    explained_variance   | 0.637         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 11410         |\n","|    policy_gradient_loss | -0.000632     |\n","|    value_loss           | 3.44e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2340000, episode_reward=22289.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.23e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2340000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029632472 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.774         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.29e+04      |\n","|    n_updates            | 11420         |\n","|    policy_gradient_loss | -8.87e-06     |\n","|    value_loss           | 5.17e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1143    |\n","|    time_elapsed    | 6741    |\n","|    total_timesteps | 2340864 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1144         |\n","|    time_elapsed         | 6745         |\n","|    total_timesteps      | 2342912      |\n","| train/                  |              |\n","|    approx_kl            | 6.910207e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.182       |\n","|    explained_variance   | 0.854        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.17e+03     |\n","|    n_updates            | 11430        |\n","|    policy_gradient_loss | -0.000174    |\n","|    value_loss           | 2.93e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1145         |\n","|    time_elapsed         | 6748         |\n","|    total_timesteps      | 2344960      |\n","| train/                  |              |\n","|    approx_kl            | 2.825557e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.147       |\n","|    explained_variance   | 0.596        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.25e+04     |\n","|    n_updates            | 11440        |\n","|    policy_gradient_loss | -0.000152    |\n","|    value_loss           | 2.98e+04     |\n","------------------------------------------\n","Eval num_timesteps=2345000, episode_reward=23070.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.31e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2345000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005707873 |\n","|    clip_fraction        | 0.00332      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0901      |\n","|    explained_variance   | 0.425        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.71e+04     |\n","|    n_updates            | 11450        |\n","|    policy_gradient_loss | -0.00218     |\n","|    value_loss           | 8.84e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1146    |\n","|    time_elapsed    | 6758    |\n","|    total_timesteps | 2347008 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1147          |\n","|    time_elapsed         | 6762          |\n","|    total_timesteps      | 2349056       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027720522 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.222        |\n","|    explained_variance   | 0.739         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.24e+04      |\n","|    n_updates            | 11460         |\n","|    policy_gradient_loss | -0.000501     |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2350000, episode_reward=22072.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2350000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00086659373 |\n","|    clip_fraction        | 0.004         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.652         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.14e+04      |\n","|    n_updates            | 11470         |\n","|    policy_gradient_loss | -0.00196      |\n","|    value_loss           | 3.84e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1148    |\n","|    time_elapsed    | 6771    |\n","|    total_timesteps | 2351104 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1149         |\n","|    time_elapsed         | 6774         |\n","|    total_timesteps      | 2353152      |\n","| train/                  |              |\n","|    approx_kl            | 5.349837e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.213       |\n","|    explained_variance   | 0.777        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.4e+04      |\n","|    n_updates            | 11480        |\n","|    policy_gradient_loss | -0.000194    |\n","|    value_loss           | 4.3e+04      |\n","------------------------------------------\n","Eval num_timesteps=2355000, episode_reward=21082.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.11e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 2355000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000516255 |\n","|    clip_fraction        | 0.00171     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.152      |\n","|    explained_variance   | 0.72        |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 9.7e+03     |\n","|    n_updates            | 11490       |\n","|    policy_gradient_loss | -0.00128    |\n","|    value_loss           | 4.09e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1150    |\n","|    time_elapsed    | 6783    |\n","|    total_timesteps | 2355200 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1151          |\n","|    time_elapsed         | 6787          |\n","|    total_timesteps      | 2357248       |\n","| train/                  |               |\n","|    approx_kl            | 6.0185295e-05 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.724         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.42e+03      |\n","|    n_updates            | 11500         |\n","|    policy_gradient_loss | -0.000408     |\n","|    value_loss           | 2.66e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1152          |\n","|    time_elapsed         | 6790          |\n","|    total_timesteps      | 2359296       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028165404 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0991       |\n","|    explained_variance   | 0.492         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.45e+04      |\n","|    n_updates            | 11510         |\n","|    policy_gradient_loss | -0.000794     |\n","|    value_loss           | 1.05e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2360000, episode_reward=20815.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2360000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021030832 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.208        |\n","|    explained_variance   | 0.768         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 11520         |\n","|    policy_gradient_loss | -0.000661     |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1153    |\n","|    time_elapsed    | 6799    |\n","|    total_timesteps | 2361344 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1154          |\n","|    time_elapsed         | 6803          |\n","|    total_timesteps      | 2363392       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048236825 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.62          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.31e+04      |\n","|    n_updates            | 11530         |\n","|    policy_gradient_loss | -0.000811     |\n","|    value_loss           | 4.91e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2365000, episode_reward=20777.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2365000       |\n","| train/                  |               |\n","|    approx_kl            | 1.2406963e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.229        |\n","|    explained_variance   | 0.791         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.31e+03      |\n","|    n_updates            | 11540         |\n","|    policy_gradient_loss | -5.76e-05     |\n","|    value_loss           | 2.59e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1155    |\n","|    time_elapsed    | 6811    |\n","|    total_timesteps | 2365440 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1156         |\n","|    time_elapsed         | 6815         |\n","|    total_timesteps      | 2367488      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002863831 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.128       |\n","|    explained_variance   | 0.811        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.68e+03     |\n","|    n_updates            | 11550        |\n","|    policy_gradient_loss | -0.000283    |\n","|    value_loss           | 2.34e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1157          |\n","|    time_elapsed         | 6818          |\n","|    total_timesteps      | 2369536       |\n","| train/                  |               |\n","|    approx_kl            | 4.6652858e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.698         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.79e+03      |\n","|    n_updates            | 11560         |\n","|    policy_gradient_loss | -0.000327     |\n","|    value_loss           | 3.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2370000, episode_reward=20665.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.07e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2370000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005795249 |\n","|    clip_fraction        | 0.00127      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.121       |\n","|    explained_variance   | 0.688        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.67e+04     |\n","|    n_updates            | 11570        |\n","|    policy_gradient_loss | -0.000967    |\n","|    value_loss           | 9.72e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1158    |\n","|    time_elapsed    | 6827    |\n","|    total_timesteps | 2371584 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1159          |\n","|    time_elapsed         | 6831          |\n","|    total_timesteps      | 2373632       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039472076 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.19         |\n","|    explained_variance   | 0.824         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.27e+03      |\n","|    n_updates            | 11580         |\n","|    policy_gradient_loss | -0.000883     |\n","|    value_loss           | 2.91e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2375000, episode_reward=20665.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.07e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2375000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008087872 |\n","|    clip_fraction        | 0.00464      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.154       |\n","|    explained_variance   | 0.731        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.27e+04     |\n","|    n_updates            | 11590        |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 4.7e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1160    |\n","|    time_elapsed    | 6840    |\n","|    total_timesteps | 2375680 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1161          |\n","|    time_elapsed         | 6843          |\n","|    total_timesteps      | 2377728       |\n","| train/                  |               |\n","|    approx_kl            | 2.9368995e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.794         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.73e+04      |\n","|    n_updates            | 11600         |\n","|    policy_gradient_loss | -1.28e-05     |\n","|    value_loss           | 3.27e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1162          |\n","|    time_elapsed         | 6847          |\n","|    total_timesteps      | 2379776       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021315966 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.15         |\n","|    explained_variance   | 0.791         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.45e+04      |\n","|    n_updates            | 11610         |\n","|    policy_gradient_loss | -0.000267     |\n","|    value_loss           | 3.58e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2380000, episode_reward=21339.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.13e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2380000       |\n","| train/                  |               |\n","|    approx_kl            | 2.3285684e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.693         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.6e+04       |\n","|    n_updates            | 11620         |\n","|    policy_gradient_loss | -7.88e-05     |\n","|    value_loss           | 4.45e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1163    |\n","|    time_elapsed    | 6855    |\n","|    total_timesteps | 2381824 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1164         |\n","|    time_elapsed         | 6859         |\n","|    total_timesteps      | 2383872      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005351199 |\n","|    clip_fraction        | 0.00186      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.168       |\n","|    explained_variance   | 0.674        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.82e+04     |\n","|    n_updates            | 11630        |\n","|    policy_gradient_loss | -0.00125     |\n","|    value_loss           | 1.25e+05     |\n","------------------------------------------\n","Eval num_timesteps=2385000, episode_reward=22120.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2385000       |\n","| train/                  |               |\n","|    approx_kl            | 1.6307895e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.65e+03      |\n","|    n_updates            | 11640         |\n","|    policy_gradient_loss | -9.43e-05     |\n","|    value_loss           | 3.39e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1165    |\n","|    time_elapsed    | 6868    |\n","|    total_timesteps | 2385920 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1166          |\n","|    time_elapsed         | 6871          |\n","|    total_timesteps      | 2387968       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042243584 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.166        |\n","|    explained_variance   | 0.565         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.5e+04       |\n","|    n_updates            | 11650         |\n","|    policy_gradient_loss | -0.000407     |\n","|    value_loss           | 4.81e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2390000, episode_reward=20838.88 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.08e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2390000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005128713 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.22        |\n","|    explained_variance   | 0.843        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.48e+04     |\n","|    n_updates            | 11660        |\n","|    policy_gradient_loss | -0.000945    |\n","|    value_loss           | 3.08e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1167    |\n","|    time_elapsed    | 6880    |\n","|    total_timesteps | 2390016 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1168          |\n","|    time_elapsed         | 6884          |\n","|    total_timesteps      | 2392064       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021730224 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.131        |\n","|    explained_variance   | 0.571         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.85e+03      |\n","|    n_updates            | 11670         |\n","|    policy_gradient_loss | -0.000224     |\n","|    value_loss           | 3.08e+04      |\n","-------------------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 347            |\n","|    iterations           | 1169           |\n","|    time_elapsed         | 6887           |\n","|    total_timesteps      | 2394112        |\n","| train/                  |                |\n","|    approx_kl            | 0.000112472044 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.121         |\n","|    explained_variance   | 0.694          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 3.3e+04        |\n","|    n_updates            | 11680          |\n","|    policy_gradient_loss | -0.000454      |\n","|    value_loss           | 6.61e+04       |\n","--------------------------------------------\n","Eval num_timesteps=2395000, episode_reward=21613.23 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2395000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013947228 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.82          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.41e+04      |\n","|    n_updates            | 11690         |\n","|    policy_gradient_loss | -0.000373     |\n","|    value_loss           | 7.75e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1170    |\n","|    time_elapsed    | 6896    |\n","|    total_timesteps | 2396160 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1171         |\n","|    time_elapsed         | 6899         |\n","|    total_timesteps      | 2398208      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005290229 |\n","|    clip_fraction        | 0.00308      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.133       |\n","|    explained_variance   | 0.694        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.12e+04     |\n","|    n_updates            | 11700        |\n","|    policy_gradient_loss | -0.000964    |\n","|    value_loss           | 3.18e+04     |\n","------------------------------------------\n","Eval num_timesteps=2400000, episode_reward=20448.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2400000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038079315 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+04      |\n","|    n_updates            | 11710         |\n","|    policy_gradient_loss | -0.000562     |\n","|    value_loss           | 4.02e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1172    |\n","|    time_elapsed    | 6908    |\n","|    total_timesteps | 2400256 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1173          |\n","|    time_elapsed         | 6912          |\n","|    total_timesteps      | 2402304       |\n","| train/                  |               |\n","|    approx_kl            | 1.9470812e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.198        |\n","|    explained_variance   | 0.887         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.87e+03      |\n","|    n_updates            | 11720         |\n","|    policy_gradient_loss | -0.000118     |\n","|    value_loss           | 1.97e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1174          |\n","|    time_elapsed         | 6915          |\n","|    total_timesteps      | 2404352       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026450446 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.56          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 11730         |\n","|    policy_gradient_loss | -0.000602     |\n","|    value_loss           | 3.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2405000, episode_reward=21492.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.15e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2405000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008112621 |\n","|    clip_fraction        | 0.0041       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0974      |\n","|    explained_variance   | 0.627        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+04     |\n","|    n_updates            | 11740        |\n","|    policy_gradient_loss | -0.00195     |\n","|    value_loss           | 4.97e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1175    |\n","|    time_elapsed    | 6924    |\n","|    total_timesteps | 2406400 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1176          |\n","|    time_elapsed         | 6927          |\n","|    total_timesteps      | 2408448       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047946486 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.199        |\n","|    explained_variance   | 0.748         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.02e+04      |\n","|    n_updates            | 11750         |\n","|    policy_gradient_loss | -0.000793     |\n","|    value_loss           | 7.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2410000, episode_reward=22285.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.23e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2410000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003628634 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.163       |\n","|    explained_variance   | 0.679        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.34e+03     |\n","|    n_updates            | 11760        |\n","|    policy_gradient_loss | -0.000746    |\n","|    value_loss           | 2.86e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1177    |\n","|    time_elapsed    | 6936    |\n","|    total_timesteps | 2410496 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1178          |\n","|    time_elapsed         | 6940          |\n","|    total_timesteps      | 2412544       |\n","| train/                  |               |\n","|    approx_kl            | 0.00065181043 |\n","|    clip_fraction        | 0.00293       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.19         |\n","|    explained_variance   | 0.723         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.45e+04      |\n","|    n_updates            | 11770         |\n","|    policy_gradient_loss | -0.000544     |\n","|    value_loss           | 4.5e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1179          |\n","|    time_elapsed         | 6943          |\n","|    total_timesteps      | 2414592       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046112182 |\n","|    clip_fraction        | 0.00127       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.182        |\n","|    explained_variance   | 0.8           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.48e+04      |\n","|    n_updates            | 11780         |\n","|    policy_gradient_loss | -0.00102      |\n","|    value_loss           | 3.55e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2415000, episode_reward=20565.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.06e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2415000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023282305 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.597         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.75e+03      |\n","|    n_updates            | 11790         |\n","|    policy_gradient_loss | -0.000338     |\n","|    value_loss           | 2.94e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1180    |\n","|    time_elapsed    | 6952    |\n","|    total_timesteps | 2416640 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1181         |\n","|    time_elapsed         | 6956         |\n","|    total_timesteps      | 2418688      |\n","| train/                  |              |\n","|    approx_kl            | 6.920978e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0798      |\n","|    explained_variance   | 0.492        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.27e+04     |\n","|    n_updates            | 11800        |\n","|    policy_gradient_loss | -2.16e-05    |\n","|    value_loss           | 1.25e+05     |\n","------------------------------------------\n","Eval num_timesteps=2420000, episode_reward=19811.56 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.98e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 2420000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000102818216 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.226         |\n","|    explained_variance   | 0.802          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.53e+04       |\n","|    n_updates            | 11810          |\n","|    policy_gradient_loss | -0.000104      |\n","|    value_loss           | 4.87e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1182    |\n","|    time_elapsed    | 6965    |\n","|    total_timesteps | 2420736 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1183          |\n","|    time_elapsed         | 6968          |\n","|    total_timesteps      | 2422784       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021361338 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.668         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.11e+03      |\n","|    n_updates            | 11820         |\n","|    policy_gradient_loss | -0.000277     |\n","|    value_loss           | 2.23e+04      |\n","-------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1184        |\n","|    time_elapsed         | 6972        |\n","|    total_timesteps      | 2424832     |\n","| train/                  |             |\n","|    approx_kl            | 0.001102356 |\n","|    clip_fraction        | 0.00762     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.218      |\n","|    explained_variance   | 0.787       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 6.36e+03    |\n","|    n_updates            | 11830       |\n","|    policy_gradient_loss | -0.00217    |\n","|    value_loss           | 4.63e+04    |\n","-----------------------------------------\n","Eval num_timesteps=2425000, episode_reward=19384.66 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2425000       |\n","| train/                  |               |\n","|    approx_kl            | 6.1845058e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.815         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.38e+03      |\n","|    n_updates            | 11840         |\n","|    policy_gradient_loss | 1.62e-05      |\n","|    value_loss           | 2.46e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1185    |\n","|    time_elapsed    | 6981    |\n","|    total_timesteps | 2426880 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1186         |\n","|    time_elapsed         | 6985         |\n","|    total_timesteps      | 2428928      |\n","| train/                  |              |\n","|    approx_kl            | 1.040264e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.153       |\n","|    explained_variance   | 0.698        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.07e+03     |\n","|    n_updates            | 11850        |\n","|    policy_gradient_loss | -7.27e-05    |\n","|    value_loss           | 2.75e+04     |\n","------------------------------------------\n","Eval num_timesteps=2430000, episode_reward=20104.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2430000       |\n","| train/                  |               |\n","|    approx_kl            | 7.7921926e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0921       |\n","|    explained_variance   | 0.422         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.2e+04       |\n","|    n_updates            | 11860         |\n","|    policy_gradient_loss | -0.000126     |\n","|    value_loss           | 1.33e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1187    |\n","|    time_elapsed    | 6994    |\n","|    total_timesteps | 2430976 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1188          |\n","|    time_elapsed         | 6998          |\n","|    total_timesteps      | 2433024       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029746958 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.217        |\n","|    explained_variance   | 0.827         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.18e+04      |\n","|    n_updates            | 11870         |\n","|    policy_gradient_loss | -0.000411     |\n","|    value_loss           | 3.38e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2435000, episode_reward=20201.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.02e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2435000       |\n","| train/                  |               |\n","|    approx_kl            | 4.5860943e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.667         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.78e+04      |\n","|    n_updates            | 11880         |\n","|    policy_gradient_loss | -0.000201     |\n","|    value_loss           | 4.48e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1189    |\n","|    time_elapsed    | 7006    |\n","|    total_timesteps | 2435072 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1190          |\n","|    time_elapsed         | 7010          |\n","|    total_timesteps      | 2437120       |\n","| train/                  |               |\n","|    approx_kl            | 4.5828347e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.224        |\n","|    explained_variance   | 0.842         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.32e+03      |\n","|    n_updates            | 11890         |\n","|    policy_gradient_loss | -4.3e-06      |\n","|    value_loss           | 4.18e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1191         |\n","|    time_elapsed         | 7014         |\n","|    total_timesteps      | 2439168      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007239225 |\n","|    clip_fraction        | 0.00435      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.141       |\n","|    explained_variance   | 0.725        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.46e+03     |\n","|    n_updates            | 11900        |\n","|    policy_gradient_loss | -0.00143     |\n","|    value_loss           | 3.48e+04     |\n","------------------------------------------\n","Eval num_timesteps=2440000, episode_reward=20430.80 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2440000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022500873 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.698         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.3e+04       |\n","|    n_updates            | 11910         |\n","|    policy_gradient_loss | -0.000607     |\n","|    value_loss           | 3.15e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1192    |\n","|    time_elapsed    | 7025    |\n","|    total_timesteps | 2441216 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1193          |\n","|    time_elapsed         | 7028          |\n","|    total_timesteps      | 2443264       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013494949 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.576         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.4e+05       |\n","|    n_updates            | 11920         |\n","|    policy_gradient_loss | -0.000175     |\n","|    value_loss           | 1.08e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2445000, episode_reward=20421.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.04e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2445000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001600777 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.195       |\n","|    explained_variance   | 0.819        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.44e+03     |\n","|    n_updates            | 11930        |\n","|    policy_gradient_loss | -0.000433    |\n","|    value_loss           | 2.63e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1194    |\n","|    time_elapsed    | 7038    |\n","|    total_timesteps | 2445312 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1195         |\n","|    time_elapsed         | 7042         |\n","|    total_timesteps      | 2447360      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003317667 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.155       |\n","|    explained_variance   | 0.744        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.74e+04     |\n","|    n_updates            | 11940        |\n","|    policy_gradient_loss | 5.23e-05     |\n","|    value_loss           | 6.06e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1196         |\n","|    time_elapsed         | 7046         |\n","|    total_timesteps      | 2449408      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003900339 |\n","|    clip_fraction        | 0.000586     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.221       |\n","|    explained_variance   | 0.823        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.06e+04     |\n","|    n_updates            | 11950        |\n","|    policy_gradient_loss | -0.000448    |\n","|    value_loss           | 3.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=2450000, episode_reward=19359.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2450000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00056981645 |\n","|    clip_fraction        | 0.00112       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.772         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.44e+03      |\n","|    n_updates            | 11960         |\n","|    policy_gradient_loss | -0.000488     |\n","|    value_loss           | 2.41e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1197    |\n","|    time_elapsed    | 7056    |\n","|    total_timesteps | 2451456 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1198          |\n","|    time_elapsed         | 7060          |\n","|    total_timesteps      | 2453504       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027135087 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.752         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.2e+04       |\n","|    n_updates            | 11970         |\n","|    policy_gradient_loss | -0.000625     |\n","|    value_loss           | 3.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2455000, episode_reward=18216.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.82e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2455000      |\n","| train/                  |              |\n","|    approx_kl            | 9.785776e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.153       |\n","|    explained_variance   | 0.782        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.88e+04     |\n","|    n_updates            | 11980        |\n","|    policy_gradient_loss | -6.97e-05    |\n","|    value_loss           | 8.61e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1199    |\n","|    time_elapsed    | 7069    |\n","|    total_timesteps | 2455552 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1200          |\n","|    time_elapsed         | 7073          |\n","|    total_timesteps      | 2457600       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034301906 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.624         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.83e+04      |\n","|    n_updates            | 11990         |\n","|    policy_gradient_loss | -0.000678     |\n","|    value_loss           | 2.88e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1201          |\n","|    time_elapsed         | 7077          |\n","|    total_timesteps      | 2459648       |\n","| train/                  |               |\n","|    approx_kl            | 1.1766882e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.9e+03       |\n","|    n_updates            | 12000         |\n","|    policy_gradient_loss | -6.64e-05     |\n","|    value_loss           | 4.51e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2460000, episode_reward=20358.12 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2460000       |\n","| train/                  |               |\n","|    approx_kl            | 2.7223898e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.227        |\n","|    explained_variance   | 0.817         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.34e+03      |\n","|    n_updates            | 12010         |\n","|    policy_gradient_loss | -7.03e-05     |\n","|    value_loss           | 2.65e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1202    |\n","|    time_elapsed    | 7087    |\n","|    total_timesteps | 2461696 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1203         |\n","|    time_elapsed         | 7090         |\n","|    total_timesteps      | 2463744      |\n","| train/                  |              |\n","|    approx_kl            | 8.919026e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.13        |\n","|    explained_variance   | 0.708        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.42e+04     |\n","|    n_updates            | 12020        |\n","|    policy_gradient_loss | -0.000168    |\n","|    value_loss           | 3.31e+04     |\n","------------------------------------------\n","Eval num_timesteps=2465000, episode_reward=21832.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2465000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002785687 |\n","|    clip_fraction        | 0.00112      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.132       |\n","|    explained_variance   | 0.747        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.36e+04     |\n","|    n_updates            | 12030        |\n","|    policy_gradient_loss | -0.00132     |\n","|    value_loss           | 5e+04        |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1204    |\n","|    time_elapsed    | 7100    |\n","|    total_timesteps | 2465792 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1205          |\n","|    time_elapsed         | 7104          |\n","|    total_timesteps      | 2467840       |\n","| train/                  |               |\n","|    approx_kl            | 1.1000899e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.758         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.15e+04      |\n","|    n_updates            | 12040         |\n","|    policy_gradient_loss | -8.86e-05     |\n","|    value_loss           | 9.58e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1206         |\n","|    time_elapsed         | 7108         |\n","|    total_timesteps      | 2469888      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007108612 |\n","|    clip_fraction        | 0.0042       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.13        |\n","|    explained_variance   | 0.695        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.25e+03     |\n","|    n_updates            | 12050        |\n","|    policy_gradient_loss | -0.00165     |\n","|    value_loss           | 2.17e+04     |\n","------------------------------------------\n","Eval num_timesteps=2470000, episode_reward=20843.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.08e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2470000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002279306 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.19        |\n","|    explained_variance   | 0.74         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.73e+04     |\n","|    n_updates            | 12060        |\n","|    policy_gradient_loss | -0.000437    |\n","|    value_loss           | 3.67e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1207    |\n","|    time_elapsed    | 7118    |\n","|    total_timesteps | 2471936 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1208          |\n","|    time_elapsed         | 7121          |\n","|    total_timesteps      | 2473984       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027426466 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.204        |\n","|    explained_variance   | 0.848         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 12070         |\n","|    policy_gradient_loss | -0.000386     |\n","|    value_loss           | 2.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2475000, episode_reward=21713.48 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.17e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2475000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00052859285 |\n","|    clip_fraction        | 0.00122       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.631         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.01e+04      |\n","|    n_updates            | 12080         |\n","|    policy_gradient_loss | -0.000669     |\n","|    value_loss           | 3.21e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1209    |\n","|    time_elapsed    | 7131    |\n","|    total_timesteps | 2476032 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1210          |\n","|    time_elapsed         | 7135          |\n","|    total_timesteps      | 2478080       |\n","| train/                  |               |\n","|    approx_kl            | 2.5347515e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0975       |\n","|    explained_variance   | 0.763         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.45e+04      |\n","|    n_updates            | 12090         |\n","|    policy_gradient_loss | -0.000199     |\n","|    value_loss           | 4.57e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2480000, episode_reward=21519.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.15e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2480000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00050826883 |\n","|    clip_fraction        | 0.00166       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.191        |\n","|    explained_variance   | 0.736         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.16e+04      |\n","|    n_updates            | 12100         |\n","|    policy_gradient_loss | -0.00114      |\n","|    value_loss           | 8.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1211    |\n","|    time_elapsed    | 7144    |\n","|    total_timesteps | 2480128 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1212          |\n","|    time_elapsed         | 7148          |\n","|    total_timesteps      | 2482176       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033836594 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.523         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.65e+04      |\n","|    n_updates            | 12110         |\n","|    policy_gradient_loss | -0.00048      |\n","|    value_loss           | 2.87e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1213          |\n","|    time_elapsed         | 7151          |\n","|    total_timesteps      | 2484224       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032017363 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.188        |\n","|    explained_variance   | 0.71          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.11e+03      |\n","|    n_updates            | 12120         |\n","|    policy_gradient_loss | 0.000192      |\n","|    value_loss           | 3.88e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2485000, episode_reward=19363.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2485000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021263474 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.185        |\n","|    explained_variance   | 0.842         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 12130         |\n","|    policy_gradient_loss | -0.000297     |\n","|    value_loss           | 2.71e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1214    |\n","|    time_elapsed    | 7161    |\n","|    total_timesteps | 2486272 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1215        |\n","|    time_elapsed         | 7164        |\n","|    total_timesteps      | 2488320     |\n","| train/                  |             |\n","|    approx_kl            | 2.69897e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.154      |\n","|    explained_variance   | 0.709       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.01e+04    |\n","|    n_updates            | 12140       |\n","|    policy_gradient_loss | -0.00016    |\n","|    value_loss           | 2.07e+04    |\n","-----------------------------------------\n","Eval num_timesteps=2490000, episode_reward=19636.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.96e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2490000      |\n","| train/                  |              |\n","|    approx_kl            | 6.828632e-07 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0784      |\n","|    explained_variance   | 0.459        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.16e+04     |\n","|    n_updates            | 12150        |\n","|    policy_gradient_loss | 2.56e-05     |\n","|    value_loss           | 5.3e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1216    |\n","|    time_elapsed    | 7174    |\n","|    total_timesteps | 2490368 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1217          |\n","|    time_elapsed         | 7178          |\n","|    total_timesteps      | 2492416       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047354607 |\n","|    clip_fraction        | 0.0022        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.218        |\n","|    explained_variance   | 0.716         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 12160         |\n","|    policy_gradient_loss | -0.000761     |\n","|    value_loss           | 7.47e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1218          |\n","|    time_elapsed         | 7181          |\n","|    total_timesteps      | 2494464       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025368395 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.7           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.98e+03      |\n","|    n_updates            | 12170         |\n","|    policy_gradient_loss | -0.000876     |\n","|    value_loss           | 2.36e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2495000, episode_reward=17949.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.79e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 2495000     |\n","| train/                  |             |\n","|    approx_kl            | 0.001080488 |\n","|    clip_fraction        | 0.00874     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.206      |\n","|    explained_variance   | 0.824       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 9.28e+03    |\n","|    n_updates            | 12180       |\n","|    policy_gradient_loss | -0.00274    |\n","|    value_loss           | 4.49e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1219    |\n","|    time_elapsed    | 7191    |\n","|    total_timesteps | 2496512 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1220          |\n","|    time_elapsed         | 7194          |\n","|    total_timesteps      | 2498560       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038675952 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.747         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9e+03         |\n","|    n_updates            | 12190         |\n","|    policy_gradient_loss | -0.00038      |\n","|    value_loss           | 3.01e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2500000, episode_reward=16610.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.66e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2500000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00067154743 |\n","|    clip_fraction        | 0.0022        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.675         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.51e+03      |\n","|    n_updates            | 12200         |\n","|    policy_gradient_loss | -0.00105      |\n","|    value_loss           | 2.68e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1221    |\n","|    time_elapsed    | 7205    |\n","|    total_timesteps | 2500608 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 347         |\n","|    iterations           | 1222        |\n","|    time_elapsed         | 7209        |\n","|    total_timesteps      | 2502656     |\n","| train/                  |             |\n","|    approx_kl            | 6.33903e-05 |\n","|    clip_fraction        | 4.88e-05    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.0761     |\n","|    explained_variance   | 0.344       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.38e+04    |\n","|    n_updates            | 12210       |\n","|    policy_gradient_loss | -0.000351   |\n","|    value_loss           | 6.77e+04    |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1223         |\n","|    time_elapsed         | 7212         |\n","|    total_timesteps      | 2504704      |\n","| train/                  |              |\n","|    approx_kl            | 5.615424e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.218       |\n","|    explained_variance   | 0.678        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.85e+03     |\n","|    n_updates            | 12220        |\n","|    policy_gradient_loss | -0.000232    |\n","|    value_loss           | 5.02e+04     |\n","------------------------------------------\n","Eval num_timesteps=2505000, episode_reward=16725.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.67e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2505000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00060281344 |\n","|    clip_fraction        | 0.00503       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.143        |\n","|    explained_variance   | 0.589         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.52e+03      |\n","|    n_updates            | 12230         |\n","|    policy_gradient_loss | -0.00167      |\n","|    value_loss           | 2.55e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1224    |\n","|    time_elapsed    | 7222    |\n","|    total_timesteps | 2506752 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1225         |\n","|    time_elapsed         | 7225         |\n","|    total_timesteps      | 2508800      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002718545 |\n","|    clip_fraction        | 0.00156      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.203       |\n","|    explained_variance   | 0.812        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.49e+04     |\n","|    n_updates            | 12240        |\n","|    policy_gradient_loss | -0.000394    |\n","|    value_loss           | 4.77e+04     |\n","------------------------------------------\n","Eval num_timesteps=2510000, episode_reward=15914.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.59e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2510000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039018356 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.738         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.37e+03      |\n","|    n_updates            | 12250         |\n","|    policy_gradient_loss | -0.00062      |\n","|    value_loss           | 3.07e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1226    |\n","|    time_elapsed    | 7236    |\n","|    total_timesteps | 2510848 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1227          |\n","|    time_elapsed         | 7239          |\n","|    total_timesteps      | 2512896       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024807127 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.544         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.22e+04      |\n","|    n_updates            | 12260         |\n","|    policy_gradient_loss | -0.000325     |\n","|    value_loss           | 3.65e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1228          |\n","|    time_elapsed         | 7242          |\n","|    total_timesteps      | 2514944       |\n","| train/                  |               |\n","|    approx_kl            | 2.8061622e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0891       |\n","|    explained_variance   | 0.633         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.75e+04      |\n","|    n_updates            | 12270         |\n","|    policy_gradient_loss | 1.48e-06      |\n","|    value_loss           | 1.45e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2515000, episode_reward=18655.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2515000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040961648 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.86          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.08e+03      |\n","|    n_updates            | 12280         |\n","|    policy_gradient_loss | -0.00113      |\n","|    value_loss           | 2.8e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1229    |\n","|    time_elapsed    | 7252    |\n","|    total_timesteps | 2516992 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1230         |\n","|    time_elapsed         | 7257         |\n","|    total_timesteps      | 2519040      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005195207 |\n","|    clip_fraction        | 0.0022       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.774        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.12e+04     |\n","|    n_updates            | 12290        |\n","|    policy_gradient_loss | -0.000875    |\n","|    value_loss           | 4.51e+04     |\n","------------------------------------------\n","Eval num_timesteps=2520000, episode_reward=19945.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.99e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2520000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006339109 |\n","|    clip_fraction        | 0.00386      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.213       |\n","|    explained_variance   | 0.83         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.61e+03     |\n","|    n_updates            | 12300        |\n","|    policy_gradient_loss | -0.00122     |\n","|    value_loss           | 2.73e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1231    |\n","|    time_elapsed    | 7268    |\n","|    total_timesteps | 2521088 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1232          |\n","|    time_elapsed         | 7272          |\n","|    total_timesteps      | 2523136       |\n","| train/                  |               |\n","|    approx_kl            | 4.3540203e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.13         |\n","|    explained_variance   | 0.623         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.5e+04       |\n","|    n_updates            | 12310         |\n","|    policy_gradient_loss | -3.87e-05     |\n","|    value_loss           | 4.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2525000, episode_reward=20549.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.05e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2525000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00050451816 |\n","|    clip_fraction        | 0.00259       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.507         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.29e+04      |\n","|    n_updates            | 12320         |\n","|    policy_gradient_loss | -0.00175      |\n","|    value_loss           | 5.39e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1233    |\n","|    time_elapsed    | 7281    |\n","|    total_timesteps | 2525184 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1234          |\n","|    time_elapsed         | 7285          |\n","|    total_timesteps      | 2527232       |\n","| train/                  |               |\n","|    approx_kl            | 1.8125284e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.736         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.01e+04      |\n","|    n_updates            | 12330         |\n","|    policy_gradient_loss | -0.000143     |\n","|    value_loss           | 1.33e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1235          |\n","|    time_elapsed         | 7289          |\n","|    total_timesteps      | 2529280       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046883032 |\n","|    clip_fraction        | 0.00171       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.172        |\n","|    explained_variance   | 0.686         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.55e+04      |\n","|    n_updates            | 12340         |\n","|    policy_gradient_loss | -0.00145      |\n","|    value_loss           | 3.18e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2530000, episode_reward=19862.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.99e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2530000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033720487 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.728         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.67e+04      |\n","|    n_updates            | 12350         |\n","|    policy_gradient_loss | -0.00144      |\n","|    value_loss           | 4.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1236    |\n","|    time_elapsed    | 7299    |\n","|    total_timesteps | 2531328 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1237          |\n","|    time_elapsed         | 7302          |\n","|    total_timesteps      | 2533376       |\n","| train/                  |               |\n","|    approx_kl            | 4.8761547e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.231        |\n","|    explained_variance   | 0.776         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.32e+04      |\n","|    n_updates            | 12360         |\n","|    policy_gradient_loss | -0.000314     |\n","|    value_loss           | 3.45e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2535000, episode_reward=19862.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.99e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2535000       |\n","| train/                  |               |\n","|    approx_kl            | 7.2537805e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.104        |\n","|    explained_variance   | 0.648         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.2e+03       |\n","|    n_updates            | 12370         |\n","|    policy_gradient_loss | -5.45e-05     |\n","|    value_loss           | 3.61e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1238    |\n","|    time_elapsed    | 7312    |\n","|    total_timesteps | 2535424 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1239          |\n","|    time_elapsed         | 7315          |\n","|    total_timesteps      | 2537472       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014069848 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.72          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.2e+03       |\n","|    n_updates            | 12380         |\n","|    policy_gradient_loss | -1.65e-05     |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1240          |\n","|    time_elapsed         | 7319          |\n","|    total_timesteps      | 2539520       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014218793 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.709         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.27e+04      |\n","|    n_updates            | 12390         |\n","|    policy_gradient_loss | 0.000108      |\n","|    value_loss           | 1.37e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2540000, episode_reward=19530.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2540000       |\n","| train/                  |               |\n","|    approx_kl            | 4.6536094e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.727         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.1e+03       |\n","|    n_updates            | 12400         |\n","|    policy_gradient_loss | -1.4e-05      |\n","|    value_loss           | 2.08e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1241    |\n","|    time_elapsed    | 7330    |\n","|    total_timesteps | 2541568 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1242          |\n","|    time_elapsed         | 7334          |\n","|    total_timesteps      | 2543616       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018077504 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.477         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.32e+03      |\n","|    n_updates            | 12410         |\n","|    policy_gradient_loss | 2.26e-05      |\n","|    value_loss           | 4.77e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2545000, episode_reward=15986.27 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.6e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2545000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039631728 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.214        |\n","|    explained_variance   | 0.788         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.92e+04      |\n","|    n_updates            | 12420         |\n","|    policy_gradient_loss | -0.000835     |\n","|    value_loss           | 4.74e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1243    |\n","|    time_elapsed    | 7344    |\n","|    total_timesteps | 2545664 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1244         |\n","|    time_elapsed         | 7347         |\n","|    total_timesteps      | 2547712      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007738555 |\n","|    clip_fraction        | 0.00669      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.129       |\n","|    explained_variance   | 0.66         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.09e+04     |\n","|    n_updates            | 12430        |\n","|    policy_gradient_loss | -0.00143     |\n","|    value_loss           | 2.72e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1245          |\n","|    time_elapsed         | 7351          |\n","|    total_timesteps      | 2549760       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011130181 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0769       |\n","|    explained_variance   | 0.66          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 12440         |\n","|    policy_gradient_loss | -0.000461     |\n","|    value_loss           | 3.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2550000, episode_reward=17291.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.73e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2550000      |\n","| train/                  |              |\n","|    approx_kl            | 3.186491e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.174       |\n","|    explained_variance   | 0.661        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.13e+04     |\n","|    n_updates            | 12450        |\n","|    policy_gradient_loss | -5.69e-05    |\n","|    value_loss           | 1.51e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1246    |\n","|    time_elapsed    | 7361    |\n","|    total_timesteps | 2551808 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1247         |\n","|    time_elapsed         | 7365         |\n","|    total_timesteps      | 2553856      |\n","| train/                  |              |\n","|    approx_kl            | 0.0010388315 |\n","|    clip_fraction        | 0.00493      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.137       |\n","|    explained_variance   | 0.54         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.83e+03     |\n","|    n_updates            | 12460        |\n","|    policy_gradient_loss | -0.00147     |\n","|    value_loss           | 2.56e+04     |\n","------------------------------------------\n","Eval num_timesteps=2555000, episode_reward=16675.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.67e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2555000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025495986 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.157        |\n","|    explained_variance   | 0.547         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.25e+04      |\n","|    n_updates            | 12470         |\n","|    policy_gradient_loss | -0.000832     |\n","|    value_loss           | 4.16e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1248    |\n","|    time_elapsed    | 7374    |\n","|    total_timesteps | 2555904 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1249         |\n","|    time_elapsed         | 7378         |\n","|    total_timesteps      | 2557952      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007861451 |\n","|    clip_fraction        | 0.00552      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.174       |\n","|    explained_variance   | 0.742        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.36e+04     |\n","|    n_updates            | 12480        |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 5.84e+04     |\n","------------------------------------------\n","Eval num_timesteps=2560000, episode_reward=18772.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2560000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028265885 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.607         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.6e+03       |\n","|    n_updates            | 12490         |\n","|    policy_gradient_loss | -0.000218     |\n","|    value_loss           | 3.99e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1250    |\n","|    time_elapsed    | 7388    |\n","|    total_timesteps | 2560000 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1251         |\n","|    time_elapsed         | 7392         |\n","|    total_timesteps      | 2562048      |\n","| train/                  |              |\n","|    approx_kl            | 1.283444e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0619      |\n","|    explained_variance   | 0.144        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.11e+04     |\n","|    n_updates            | 12500        |\n","|    policy_gradient_loss | -7.28e-05    |\n","|    value_loss           | 1.11e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1252          |\n","|    time_elapsed         | 7396          |\n","|    total_timesteps      | 2564096       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031003452 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.194        |\n","|    explained_variance   | 0.771         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.97e+04      |\n","|    n_updates            | 12510         |\n","|    policy_gradient_loss | -0.000329     |\n","|    value_loss           | 6e+04         |\n","-------------------------------------------\n","Eval num_timesteps=2565000, episode_reward=16385.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2565000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033155302 |\n","|    clip_fraction        | 0.00264       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.639         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.38e+03      |\n","|    n_updates            | 12520         |\n","|    policy_gradient_loss | -0.001        |\n","|    value_loss           | 2.5e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1253    |\n","|    time_elapsed    | 7405    |\n","|    total_timesteps | 2566144 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1254          |\n","|    time_elapsed         | 7409          |\n","|    total_timesteps      | 2568192       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018340154 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.166        |\n","|    explained_variance   | 0.769         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.96e+03      |\n","|    n_updates            | 12530         |\n","|    policy_gradient_loss | -0.000472     |\n","|    value_loss           | 4.39e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2570000, episode_reward=16818.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.68e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2570000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014698497 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.159        |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.07e+04      |\n","|    n_updates            | 12540         |\n","|    policy_gradient_loss | -0.000168     |\n","|    value_loss           | 5.82e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1255    |\n","|    time_elapsed    | 7419    |\n","|    total_timesteps | 2570240 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1256         |\n","|    time_elapsed         | 7423         |\n","|    total_timesteps      | 2572288      |\n","| train/                  |              |\n","|    approx_kl            | 7.008726e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.125       |\n","|    explained_variance   | 0.558        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.14e+03     |\n","|    n_updates            | 12550        |\n","|    policy_gradient_loss | -0.000345    |\n","|    value_loss           | 2.99e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1257          |\n","|    time_elapsed         | 7426          |\n","|    total_timesteps      | 2574336       |\n","| train/                  |               |\n","|    approx_kl            | 5.0520815e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0538       |\n","|    explained_variance   | 0.299         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.46e+04      |\n","|    n_updates            | 12560         |\n","|    policy_gradient_loss | -0.000341     |\n","|    value_loss           | 1.52e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2575000, episode_reward=16385.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2575000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031523829 |\n","|    clip_fraction        | 0.00161       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.218        |\n","|    explained_variance   | 0.743         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.73e+04      |\n","|    n_updates            | 12570         |\n","|    policy_gradient_loss | -0.000815     |\n","|    value_loss           | 5.58e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1258    |\n","|    time_elapsed    | 7436    |\n","|    total_timesteps | 2576384 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1259         |\n","|    time_elapsed         | 7439         |\n","|    total_timesteps      | 2578432      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006781934 |\n","|    clip_fraction        | 0.00366      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.121       |\n","|    explained_variance   | 0.63         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.3e+03      |\n","|    n_updates            | 12580        |\n","|    policy_gradient_loss | -0.00106     |\n","|    value_loss           | 2.19e+04     |\n","------------------------------------------\n","Eval num_timesteps=2580000, episode_reward=16679.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.67e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2580000      |\n","| train/                  |              |\n","|    approx_kl            | 7.914126e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.197       |\n","|    explained_variance   | 0.74         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.77e+04     |\n","|    n_updates            | 12590        |\n","|    policy_gradient_loss | -0.000185    |\n","|    value_loss           | 4.04e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1260    |\n","|    time_elapsed    | 7450    |\n","|    total_timesteps | 2580480 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1261         |\n","|    time_elapsed         | 7453         |\n","|    total_timesteps      | 2582528      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007048078 |\n","|    clip_fraction        | 0.00322      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.12        |\n","|    explained_variance   | 0.643        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.26e+04     |\n","|    n_updates            | 12600        |\n","|    policy_gradient_loss | -0.00149     |\n","|    value_loss           | 5.51e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1262          |\n","|    time_elapsed         | 7457          |\n","|    total_timesteps      | 2584576       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029911712 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.642         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.25e+03      |\n","|    n_updates            | 12610         |\n","|    policy_gradient_loss | -0.000732     |\n","|    value_loss           | 1.89e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2585000, episode_reward=16675.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.67e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2585000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018262194 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0678       |\n","|    explained_variance   | 0.406         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.58e+04      |\n","|    n_updates            | 12620         |\n","|    policy_gradient_loss | -0.00076      |\n","|    value_loss           | 1.59e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1263    |\n","|    time_elapsed    | 7467    |\n","|    total_timesteps | 2586624 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1264         |\n","|    time_elapsed         | 7471         |\n","|    total_timesteps      | 2588672      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001962333 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.205       |\n","|    explained_variance   | 0.84         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.83e+03     |\n","|    n_updates            | 12630        |\n","|    policy_gradient_loss | -0.000458    |\n","|    value_loss           | 2.94e+04     |\n","------------------------------------------\n","Eval num_timesteps=2590000, episode_reward=14378.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2590000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037809895 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.538         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.91e+04      |\n","|    n_updates            | 12640         |\n","|    policy_gradient_loss | -0.000398     |\n","|    value_loss           | 2.95e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1265    |\n","|    time_elapsed    | 7480    |\n","|    total_timesteps | 2590720 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1266          |\n","|    time_elapsed         | 7484          |\n","|    total_timesteps      | 2592768       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030521475 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.213        |\n","|    explained_variance   | 0.722         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.08e+04      |\n","|    n_updates            | 12650         |\n","|    policy_gradient_loss | -0.000486     |\n","|    value_loss           | 3.91e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1267          |\n","|    time_elapsed         | 7488          |\n","|    total_timesteps      | 2594816       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033211868 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.619         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.42e+03      |\n","|    n_updates            | 12660         |\n","|    policy_gradient_loss | -0.000838     |\n","|    value_loss           | 5.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2595000, episode_reward=16351.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2595000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019897838 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.312         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.69e+04      |\n","|    n_updates            | 12670         |\n","|    policy_gradient_loss | -0.000721     |\n","|    value_loss           | 5.45e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1268    |\n","|    time_elapsed    | 7498    |\n","|    total_timesteps | 2596864 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1269         |\n","|    time_elapsed         | 7502         |\n","|    total_timesteps      | 2598912      |\n","| train/                  |              |\n","|    approx_kl            | 7.741322e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0882      |\n","|    explained_variance   | 0.727        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.25e+04     |\n","|    n_updates            | 12680        |\n","|    policy_gradient_loss | -0.000106    |\n","|    value_loss           | 1.05e+05     |\n","------------------------------------------\n","Eval num_timesteps=2600000, episode_reward=15718.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.57e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2600000      |\n","| train/                  |              |\n","|    approx_kl            | 8.868953e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.174       |\n","|    explained_variance   | 0.635        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.02e+03     |\n","|    n_updates            | 12690        |\n","|    policy_gradient_loss | -0.000457    |\n","|    value_loss           | 3.23e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1270    |\n","|    time_elapsed    | 7512    |\n","|    total_timesteps | 2600960 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1271         |\n","|    time_elapsed         | 7516         |\n","|    total_timesteps      | 2603008      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004481895 |\n","|    clip_fraction        | 0.00288      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.108       |\n","|    explained_variance   | 0.661        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.78e+03     |\n","|    n_updates            | 12700        |\n","|    policy_gradient_loss | -0.00101     |\n","|    value_loss           | 2.74e+04     |\n","------------------------------------------\n","Eval num_timesteps=2605000, episode_reward=15718.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2605000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022773037 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.232        |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.78e+04      |\n","|    n_updates            | 12710         |\n","|    policy_gradient_loss | -0.000287     |\n","|    value_loss           | 5.23e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1272    |\n","|    time_elapsed    | 7526    |\n","|    total_timesteps | 2605056 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1273          |\n","|    time_elapsed         | 7529          |\n","|    total_timesteps      | 2607104       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030823387 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.094        |\n","|    explained_variance   | 0.717         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.59e+04      |\n","|    n_updates            | 12720         |\n","|    policy_gradient_loss | -0.000547     |\n","|    value_loss           | 3.77e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1274          |\n","|    time_elapsed         | 7533          |\n","|    total_timesteps      | 2609152       |\n","| train/                  |               |\n","|    approx_kl            | 1.1231226e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.105        |\n","|    explained_variance   | 0.451         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.96e+04      |\n","|    n_updates            | 12730         |\n","|    policy_gradient_loss | -0.000185     |\n","|    value_loss           | 4.24e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2610000, episode_reward=15718.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.57e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2610000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005822108 |\n","|    clip_fraction        | 0.00415      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.156       |\n","|    explained_variance   | 0.808        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.88e+04     |\n","|    n_updates            | 12740        |\n","|    policy_gradient_loss | -0.00145     |\n","|    value_loss           | 4.42e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1275    |\n","|    time_elapsed    | 7543    |\n","|    total_timesteps | 2611200 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1276          |\n","|    time_elapsed         | 7547          |\n","|    total_timesteps      | 2613248       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023849597 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.109        |\n","|    explained_variance   | 0.635         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 12750         |\n","|    policy_gradient_loss | -0.000516     |\n","|    value_loss           | 4.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2615000, episode_reward=18412.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.84e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2615000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007101486 |\n","|    clip_fraction        | 0.00723      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.132       |\n","|    explained_variance   | 0.6          |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.15e+04     |\n","|    n_updates            | 12760        |\n","|    policy_gradient_loss | -0.00196     |\n","|    value_loss           | 5.12e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1277    |\n","|    time_elapsed    | 7557    |\n","|    total_timesteps | 2615296 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1278          |\n","|    time_elapsed         | 7561          |\n","|    total_timesteps      | 2617344       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033551067 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.211        |\n","|    explained_variance   | 0.793         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.94e+03      |\n","|    n_updates            | 12770         |\n","|    policy_gradient_loss | -0.000505     |\n","|    value_loss           | 4.49e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1279          |\n","|    time_elapsed         | 7565          |\n","|    total_timesteps      | 2619392       |\n","| train/                  |               |\n","|    approx_kl            | 3.3196353e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.51e+04      |\n","|    n_updates            | 12780         |\n","|    policy_gradient_loss | -0.0002       |\n","|    value_loss           | 5.81e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2620000, episode_reward=17756.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.78e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2620000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012659119 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0755       |\n","|    explained_variance   | 0.724         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.99e+03      |\n","|    n_updates            | 12790         |\n","|    policy_gradient_loss | -0.000656     |\n","|    value_loss           | 2.66e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1280    |\n","|    time_elapsed    | 7575    |\n","|    total_timesteps | 2621440 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1281          |\n","|    time_elapsed         | 7578          |\n","|    total_timesteps      | 2623488       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025475645 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.734         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.97e+04      |\n","|    n_updates            | 12800         |\n","|    policy_gradient_loss | -0.000591     |\n","|    value_loss           | 9.11e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2625000, episode_reward=17293.88 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.73e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2625000       |\n","| train/                  |               |\n","|    approx_kl            | 3.0095252e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.123        |\n","|    explained_variance   | 0.579         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.41e+03      |\n","|    n_updates            | 12810         |\n","|    policy_gradient_loss | -0.000212     |\n","|    value_loss           | 2.43e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1282    |\n","|    time_elapsed    | 7589    |\n","|    total_timesteps | 2625536 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1283          |\n","|    time_elapsed         | 7593          |\n","|    total_timesteps      | 2627584       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046332387 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.684         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 12820         |\n","|    policy_gradient_loss | -0.00056      |\n","|    value_loss           | 4.05e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1284          |\n","|    time_elapsed         | 7597          |\n","|    total_timesteps      | 2629632       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020143046 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.177        |\n","|    explained_variance   | 0.818         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.94e+04      |\n","|    n_updates            | 12830         |\n","|    policy_gradient_loss | -0.000562     |\n","|    value_loss           | 4.35e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2630000, episode_reward=17014.74 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2630000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025988705 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.572         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.06e+03      |\n","|    n_updates            | 12840         |\n","|    policy_gradient_loss | -0.000421     |\n","|    value_loss           | 3.73e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1285    |\n","|    time_elapsed    | 7607    |\n","|    total_timesteps | 2631680 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1286          |\n","|    time_elapsed         | 7611          |\n","|    total_timesteps      | 2633728       |\n","| train/                  |               |\n","|    approx_kl            | 6.5476896e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0657       |\n","|    explained_variance   | 0.459         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.71e+03      |\n","|    n_updates            | 12850         |\n","|    policy_gradient_loss | -0.000224     |\n","|    value_loss           | 7.96e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2635000, episode_reward=16351.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2635000       |\n","| train/                  |               |\n","|    approx_kl            | 1.9481551e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.779         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.61e+04      |\n","|    n_updates            | 12860         |\n","|    policy_gradient_loss | -0.000274     |\n","|    value_loss           | 5.52e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1287    |\n","|    time_elapsed    | 7621    |\n","|    total_timesteps | 2635776 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1288          |\n","|    time_elapsed         | 7625          |\n","|    total_timesteps      | 2637824       |\n","| train/                  |               |\n","|    approx_kl            | 4.2636588e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.657         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.57e+03      |\n","|    n_updates            | 12870         |\n","|    policy_gradient_loss | -0.000193     |\n","|    value_loss           | 2.62e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1289          |\n","|    time_elapsed         | 7629          |\n","|    total_timesteps      | 2639872       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024012756 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.159        |\n","|    explained_variance   | 0.792         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.42e+04      |\n","|    n_updates            | 12880         |\n","|    policy_gradient_loss | -0.000312     |\n","|    value_loss           | 4.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2640000, episode_reward=16924.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.69e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2640000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005466907 |\n","|    clip_fraction        | 0.00186      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.154       |\n","|    explained_variance   | 0.692        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.3e+04      |\n","|    n_updates            | 12890        |\n","|    policy_gradient_loss | -0.000915    |\n","|    value_loss           | 4.8e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1290    |\n","|    time_elapsed    | 7639    |\n","|    total_timesteps | 2641920 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1291         |\n","|    time_elapsed         | 7643         |\n","|    total_timesteps      | 2643968      |\n","| train/                  |              |\n","|    approx_kl            | 1.893373e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.12        |\n","|    explained_variance   | 0.581        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.41e+04     |\n","|    n_updates            | 12900        |\n","|    policy_gradient_loss | -0.000106    |\n","|    value_loss           | 3.44e+04     |\n","------------------------------------------\n","Eval num_timesteps=2645000, episode_reward=17208.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.72e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2645000      |\n","| train/                  |              |\n","|    approx_kl            | 8.695788e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0539      |\n","|    explained_variance   | 0.525        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.69e+05     |\n","|    n_updates            | 12910        |\n","|    policy_gradient_loss | -0.000199    |\n","|    value_loss           | 1.41e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1292    |\n","|    time_elapsed    | 7654    |\n","|    total_timesteps | 2646016 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1293          |\n","|    time_elapsed         | 7658          |\n","|    total_timesteps      | 2648064       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012043203 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.206        |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.08e+04      |\n","|    n_updates            | 12920         |\n","|    policy_gradient_loss | -0.000386     |\n","|    value_loss           | 4.75e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2650000, episode_reward=18226.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.82e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2650000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037536255 |\n","|    clip_fraction        | 0.00264       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.124        |\n","|    explained_variance   | 0.716         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.87e+03      |\n","|    n_updates            | 12930         |\n","|    policy_gradient_loss | -0.000624     |\n","|    value_loss           | 1.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1294    |\n","|    time_elapsed    | 7668    |\n","|    total_timesteps | 2650112 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 345         |\n","|    iterations           | 1295        |\n","|    time_elapsed         | 7671        |\n","|    total_timesteps      | 2652160     |\n","| train/                  |             |\n","|    approx_kl            | 4.21975e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.191      |\n","|    explained_variance   | 0.769       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.52e+04    |\n","|    n_updates            | 12940       |\n","|    policy_gradient_loss | -0.000214   |\n","|    value_loss           | 3.71e+04    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1296          |\n","|    time_elapsed         | 7675          |\n","|    total_timesteps      | 2654208       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026982906 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.541         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 12950         |\n","|    policy_gradient_loss | -0.000817     |\n","|    value_loss           | 6.25e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2655000, episode_reward=15866.62 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.59e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2655000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002517995 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.624        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.46e+03     |\n","|    n_updates            | 12960        |\n","|    policy_gradient_loss | -0.000497    |\n","|    value_loss           | 1.91e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1297    |\n","|    time_elapsed    | 7685    |\n","|    total_timesteps | 2656256 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1298          |\n","|    time_elapsed         | 7689          |\n","|    total_timesteps      | 2658304       |\n","| train/                  |               |\n","|    approx_kl            | 3.9631675e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0551       |\n","|    explained_variance   | 0.533         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.39e+04      |\n","|    n_updates            | 12970         |\n","|    policy_gradient_loss | -0.00012      |\n","|    value_loss           | 1.6e+05       |\n","-------------------------------------------\n","Eval num_timesteps=2660000, episode_reward=16135.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.61e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2660000       |\n","| train/                  |               |\n","|    approx_kl            | 1.4179124e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.831         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.43e+03      |\n","|    n_updates            | 12980         |\n","|    policy_gradient_loss | -5.38e-05     |\n","|    value_loss           | 3.1e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1299    |\n","|    time_elapsed    | 7699    |\n","|    total_timesteps | 2660352 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1300         |\n","|    time_elapsed         | 7703         |\n","|    total_timesteps      | 2662400      |\n","| train/                  |              |\n","|    approx_kl            | 8.736484e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.114       |\n","|    explained_variance   | 0.663        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.07e+04     |\n","|    n_updates            | 12990        |\n","|    policy_gradient_loss | -1.89e-05    |\n","|    value_loss           | 2.33e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1301         |\n","|    time_elapsed         | 7707         |\n","|    total_timesteps      | 2664448      |\n","| train/                  |              |\n","|    approx_kl            | 8.438827e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.209       |\n","|    explained_variance   | 0.772        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.1e+03      |\n","|    n_updates            | 13000        |\n","|    policy_gradient_loss | -0.000197    |\n","|    value_loss           | 4.1e+04      |\n","------------------------------------------\n","Eval num_timesteps=2665000, episode_reward=18147.09 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.81e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2665000       |\n","| train/                  |               |\n","|    approx_kl            | 3.1192612e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.112        |\n","|    explained_variance   | 0.507         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.26e+03      |\n","|    n_updates            | 13010         |\n","|    policy_gradient_loss | -1.94e-05     |\n","|    value_loss           | 5.08e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1302    |\n","|    time_elapsed    | 7717    |\n","|    total_timesteps | 2666496 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1303          |\n","|    time_elapsed         | 7720          |\n","|    total_timesteps      | 2668544       |\n","| train/                  |               |\n","|    approx_kl            | 3.7452206e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.129        |\n","|    explained_variance   | 0.698         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+05       |\n","|    n_updates            | 13020         |\n","|    policy_gradient_loss | -1.45e-05     |\n","|    value_loss           | 9.62e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2670000, episode_reward=17853.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.79e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2670000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004322763 |\n","|    clip_fraction        | 0.00298      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0832      |\n","|    explained_variance   | 0.803        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.68e+04     |\n","|    n_updates            | 13030        |\n","|    policy_gradient_loss | -0.00186     |\n","|    value_loss           | 1.05e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1304    |\n","|    time_elapsed    | 7730    |\n","|    total_timesteps | 2670592 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1305          |\n","|    time_elapsed         | 7734          |\n","|    total_timesteps      | 2672640       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030522095 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.653         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.72e+04      |\n","|    n_updates            | 13040         |\n","|    policy_gradient_loss | -0.00108      |\n","|    value_loss           | 5.26e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1306          |\n","|    time_elapsed         | 7737          |\n","|    total_timesteps      | 2674688       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026806523 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.669         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.95e+03      |\n","|    n_updates            | 13050         |\n","|    policy_gradient_loss | -0.000339     |\n","|    value_loss           | 3.59e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2675000, episode_reward=19598.70 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2675000       |\n","| train/                  |               |\n","|    approx_kl            | 3.3742515e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.227        |\n","|    explained_variance   | 0.79          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.77e+04      |\n","|    n_updates            | 13060         |\n","|    policy_gradient_loss | -5.79e-05     |\n","|    value_loss           | 4.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1307    |\n","|    time_elapsed    | 7749    |\n","|    total_timesteps | 2676736 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 345         |\n","|    iterations           | 1308        |\n","|    time_elapsed         | 7753        |\n","|    total_timesteps      | 2678784     |\n","| train/                  |             |\n","|    approx_kl            | 8.54113e-06 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.102      |\n","|    explained_variance   | 0.715       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.97e+04    |\n","|    n_updates            | 13070       |\n","|    policy_gradient_loss | 2.04e-05    |\n","|    value_loss           | 3.28e+04    |\n","-----------------------------------------\n","Eval num_timesteps=2680000, episode_reward=20376.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 1.97e+03   |\n","|    mean_reward          | 2.04e+04   |\n","| time/                   |            |\n","|    total_timesteps      | 2680000    |\n","| train/                  |            |\n","|    approx_kl            | 7.4479e-05 |\n","|    clip_fraction        | 0.000146   |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.112     |\n","|    explained_variance   | 0.425      |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 1.22e+04   |\n","|    n_updates            | 13080      |\n","|    policy_gradient_loss | -0.000457  |\n","|    value_loss           | 5.5e+04    |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1309    |\n","|    time_elapsed    | 7763    |\n","|    total_timesteps | 2680832 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1310         |\n","|    time_elapsed         | 7766         |\n","|    total_timesteps      | 2682880      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004497896 |\n","|    clip_fraction        | 0.00259      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.151       |\n","|    explained_variance   | 0.786        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.95e+04     |\n","|    n_updates            | 13090        |\n","|    policy_gradient_loss | -0.00147     |\n","|    value_loss           | 1.46e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1311         |\n","|    time_elapsed         | 7770         |\n","|    total_timesteps      | 2684928      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001481153 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.117       |\n","|    explained_variance   | 0.673        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.61e+03     |\n","|    n_updates            | 13100        |\n","|    policy_gradient_loss | -0.000122    |\n","|    value_loss           | 1.81e+04     |\n","------------------------------------------\n","Eval num_timesteps=2685000, episode_reward=18220.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.82e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2685000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013260686 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.133        |\n","|    explained_variance   | 0.485         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.69e+04      |\n","|    n_updates            | 13110         |\n","|    policy_gradient_loss | 0.000187      |\n","|    value_loss           | 9.34e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1312    |\n","|    time_elapsed    | 7780    |\n","|    total_timesteps | 2686976 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1313         |\n","|    time_elapsed         | 7784         |\n","|    total_timesteps      | 2689024      |\n","| train/                  |              |\n","|    approx_kl            | 8.447369e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.208       |\n","|    explained_variance   | 0.835        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 13120        |\n","|    policy_gradient_loss | -0.00021     |\n","|    value_loss           | 3.6e+04      |\n","------------------------------------------\n","Eval num_timesteps=2690000, episode_reward=16391.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.64e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2690000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005677184 |\n","|    clip_fraction        | 0.00313      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.133       |\n","|    explained_variance   | 0.68         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.09e+03     |\n","|    n_updates            | 13130        |\n","|    policy_gradient_loss | -0.000595    |\n","|    value_loss           | 3.52e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1314    |\n","|    time_elapsed    | 7793    |\n","|    total_timesteps | 2691072 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1315          |\n","|    time_elapsed         | 7797          |\n","|    total_timesteps      | 2693120       |\n","| train/                  |               |\n","|    approx_kl            | 8.7032706e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0879       |\n","|    explained_variance   | 0.524         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.66e+04      |\n","|    n_updates            | 13140         |\n","|    policy_gradient_loss | -0.000204     |\n","|    value_loss           | 7.29e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2695000, episode_reward=16335.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.63e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2695000      |\n","| train/                  |              |\n","|    approx_kl            | 9.009562e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.169       |\n","|    explained_variance   | 0.806        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.27e+04     |\n","|    n_updates            | 13150        |\n","|    policy_gradient_loss | -0.000155    |\n","|    value_loss           | 7.32e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1316    |\n","|    time_elapsed    | 7807    |\n","|    total_timesteps | 2695168 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1317          |\n","|    time_elapsed         | 7811          |\n","|    total_timesteps      | 2697216       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023423921 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.566         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.69e+03      |\n","|    n_updates            | 13160         |\n","|    policy_gradient_loss | -0.000178     |\n","|    value_loss           | 2.62e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1318          |\n","|    time_elapsed         | 7815          |\n","|    total_timesteps      | 2699264       |\n","| train/                  |               |\n","|    approx_kl            | 0.00045707694 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.05e+04      |\n","|    n_updates            | 13170         |\n","|    policy_gradient_loss | -9.89e-05     |\n","|    value_loss           | 7.13e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2700000, episode_reward=19552.53 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2700000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00088443165 |\n","|    clip_fraction        | 0.00483       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.846         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.52e+04      |\n","|    n_updates            | 13180         |\n","|    policy_gradient_loss | -0.00177      |\n","|    value_loss           | 3.69e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1319    |\n","|    time_elapsed    | 7824    |\n","|    total_timesteps | 2701312 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1320          |\n","|    time_elapsed         | 7828          |\n","|    total_timesteps      | 2703360       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020384038 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.685         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 13190         |\n","|    policy_gradient_loss | -0.000599     |\n","|    value_loss           | 3.79e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2705000, episode_reward=19079.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.91e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 2705000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000109942135 |\n","|    clip_fraction        | 4.88e-05       |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.0744        |\n","|    explained_variance   | 0.483          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 3.15e+04       |\n","|    n_updates            | 13200          |\n","|    policy_gradient_loss | -0.000332      |\n","|    value_loss           | 6.56e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1321    |\n","|    time_elapsed    | 7838    |\n","|    total_timesteps | 2705408 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1322          |\n","|    time_elapsed         | 7841          |\n","|    total_timesteps      | 2707456       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032584614 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.787         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.03e+03      |\n","|    n_updates            | 13210         |\n","|    policy_gradient_loss | -0.00123      |\n","|    value_loss           | 4.35e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1323          |\n","|    time_elapsed         | 7845          |\n","|    total_timesteps      | 2709504       |\n","| train/                  |               |\n","|    approx_kl            | 9.2954084e-05 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.61          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.09e+04      |\n","|    n_updates            | 13220         |\n","|    policy_gradient_loss | -0.000284     |\n","|    value_loss           | 1.76e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2710000, episode_reward=17144.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.71e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2710000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1593587e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.765         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 13230         |\n","|    policy_gradient_loss | -1.2e-05      |\n","|    value_loss           | 4.52e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1324    |\n","|    time_elapsed    | 7856    |\n","|    total_timesteps | 2711552 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1325         |\n","|    time_elapsed         | 7859         |\n","|    total_timesteps      | 2713600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005149158 |\n","|    clip_fraction        | 0.00103      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.716        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.31e+04     |\n","|    n_updates            | 13240        |\n","|    policy_gradient_loss | -0.000408    |\n","|    value_loss           | 5.7e+04      |\n","------------------------------------------\n","Eval num_timesteps=2715000, episode_reward=18019.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2715000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046340364 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.627         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.46e+03      |\n","|    n_updates            | 13250         |\n","|    policy_gradient_loss | -0.000779     |\n","|    value_loss           | 3.27e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1326    |\n","|    time_elapsed    | 7870    |\n","|    total_timesteps | 2715648 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1327          |\n","|    time_elapsed         | 7874          |\n","|    total_timesteps      | 2717696       |\n","| train/                  |               |\n","|    approx_kl            | 7.5348944e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0602       |\n","|    explained_variance   | 0.618         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.27e+04      |\n","|    n_updates            | 13260         |\n","|    policy_gradient_loss | -2.99e-05     |\n","|    value_loss           | 8.38e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1328          |\n","|    time_elapsed         | 7877          |\n","|    total_timesteps      | 2719744       |\n","| train/                  |               |\n","|    approx_kl            | 9.1335125e-05 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.818         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.68e+03      |\n","|    n_updates            | 13270         |\n","|    policy_gradient_loss | -0.000532     |\n","|    value_loss           | 3.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2720000, episode_reward=19382.35 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2720000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00076482806 |\n","|    clip_fraction        | 0.00356       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.672         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.51e+03      |\n","|    n_updates            | 13280         |\n","|    policy_gradient_loss | -0.00146      |\n","|    value_loss           | 2.84e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1329    |\n","|    time_elapsed    | 7888    |\n","|    total_timesteps | 2721792 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1330         |\n","|    time_elapsed         | 7891         |\n","|    total_timesteps      | 2723840      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005718644 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.185       |\n","|    explained_variance   | 0.726        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.2e+04      |\n","|    n_updates            | 13290        |\n","|    policy_gradient_loss | -0.000987    |\n","|    value_loss           | 4.49e+04     |\n","------------------------------------------\n","Eval num_timesteps=2725000, episode_reward=15718.85 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2725000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027142066 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.121        |\n","|    explained_variance   | 0.625         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.29e+04      |\n","|    n_updates            | 13300         |\n","|    policy_gradient_loss | -0.000856     |\n","|    value_loss           | 5.72e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1331    |\n","|    time_elapsed    | 7901    |\n","|    total_timesteps | 2725888 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1332          |\n","|    time_elapsed         | 7905          |\n","|    total_timesteps      | 2727936       |\n","| train/                  |               |\n","|    approx_kl            | 5.5998884e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.125        |\n","|    explained_variance   | 0.58          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.62e+03      |\n","|    n_updates            | 13310         |\n","|    policy_gradient_loss | -0.000239     |\n","|    value_loss           | 2.23e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1333          |\n","|    time_elapsed         | 7909          |\n","|    total_timesteps      | 2729984       |\n","| train/                  |               |\n","|    approx_kl            | 4.7559442e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.054        |\n","|    explained_variance   | 0.659         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.14e+04      |\n","|    n_updates            | 13320         |\n","|    policy_gradient_loss | -1.65e-05     |\n","|    value_loss           | 7.72e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2730000, episode_reward=16386.05 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2730000       |\n","| train/                  |               |\n","|    approx_kl            | 3.5209407e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.824         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 13330         |\n","|    policy_gradient_loss | -0.000155     |\n","|    value_loss           | 3.82e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1334    |\n","|    time_elapsed    | 7919    |\n","|    total_timesteps | 2732032 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1335          |\n","|    time_elapsed         | 7922          |\n","|    total_timesteps      | 2734080       |\n","| train/                  |               |\n","|    approx_kl            | 1.8619321e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.753         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.05e+03      |\n","|    n_updates            | 13340         |\n","|    policy_gradient_loss | -0.000122     |\n","|    value_loss           | 2.25e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2735000, episode_reward=15021.98 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2735000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00068392255 |\n","|    clip_fraction        | 0.0041        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.794         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.39e+04      |\n","|    n_updates            | 13350         |\n","|    policy_gradient_loss | -0.00191      |\n","|    value_loss           | 3.95e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1336    |\n","|    time_elapsed    | 7933    |\n","|    total_timesteps | 2736128 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1337          |\n","|    time_elapsed         | 7936          |\n","|    total_timesteps      | 2738176       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024446315 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0979       |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.67e+03      |\n","|    n_updates            | 13360         |\n","|    policy_gradient_loss | -0.000506     |\n","|    value_loss           | 5.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2740000, episode_reward=15741.39 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2740000       |\n","| train/                  |               |\n","|    approx_kl            | 2.9829505e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.64e+04      |\n","|    n_updates            | 13370         |\n","|    policy_gradient_loss | -0.00022      |\n","|    value_loss           | 8.68e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1338    |\n","|    time_elapsed    | 7946    |\n","|    total_timesteps | 2740224 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1339          |\n","|    time_elapsed         | 7950          |\n","|    total_timesteps      | 2742272       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040159837 |\n","|    clip_fraction        | 0.004         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0733       |\n","|    explained_variance   | 0.872         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.85e+03      |\n","|    n_updates            | 13380         |\n","|    policy_gradient_loss | -0.00177      |\n","|    value_loss           | 2.51e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1340         |\n","|    time_elapsed         | 7955         |\n","|    total_timesteps      | 2744320      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001494041 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.171       |\n","|    explained_variance   | 0.82         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.52e+03     |\n","|    n_updates            | 13390        |\n","|    policy_gradient_loss | -0.000537    |\n","|    value_loss           | 2.6e+04      |\n","------------------------------------------\n","Eval num_timesteps=2745000, episode_reward=15233.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.52e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2745000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00056825235 |\n","|    clip_fraction        | 0.0041        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.598         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.41e+04      |\n","|    n_updates            | 13400         |\n","|    policy_gradient_loss | -0.00121      |\n","|    value_loss           | 2.76e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1341    |\n","|    time_elapsed    | 7965    |\n","|    total_timesteps | 2746368 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1342          |\n","|    time_elapsed         | 7968          |\n","|    total_timesteps      | 2748416       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043930407 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.214        |\n","|    explained_variance   | 0.756         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 13410         |\n","|    policy_gradient_loss | -0.000725     |\n","|    value_loss           | 4.72e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2750000, episode_reward=18625.94 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2750000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00069637725 |\n","|    clip_fraction        | 0.00601       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.101        |\n","|    explained_variance   | 0.747         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.26e+03      |\n","|    n_updates            | 13420         |\n","|    policy_gradient_loss | -0.00106      |\n","|    value_loss           | 2.99e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1343    |\n","|    time_elapsed    | 7978    |\n","|    total_timesteps | 2750464 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1344         |\n","|    time_elapsed         | 7982         |\n","|    total_timesteps      | 2752512      |\n","| train/                  |              |\n","|    approx_kl            | 2.506288e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.105       |\n","|    explained_variance   | 0.433        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.57e+04     |\n","|    n_updates            | 13430        |\n","|    policy_gradient_loss | -0.000257    |\n","|    value_loss           | 4.33e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1345          |\n","|    time_elapsed         | 7986          |\n","|    total_timesteps      | 2754560       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010443694 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.778         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.14e+04      |\n","|    n_updates            | 13440         |\n","|    policy_gradient_loss | -0.000315     |\n","|    value_loss           | 1.38e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2755000, episode_reward=19540.87 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2755000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021714249 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.61          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.02e+03      |\n","|    n_updates            | 13450         |\n","|    policy_gradient_loss | -0.000556     |\n","|    value_loss           | 2.08e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1346    |\n","|    time_elapsed    | 7996    |\n","|    total_timesteps | 2756608 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1347          |\n","|    time_elapsed         | 8000          |\n","|    total_timesteps      | 2758656       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015561254 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.124        |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.64e+04      |\n","|    n_updates            | 13460         |\n","|    policy_gradient_loss | -0.000197     |\n","|    value_loss           | 4.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2760000, episode_reward=17692.91 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.77e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2760000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027898722 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.203        |\n","|    explained_variance   | 0.843         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.93e+03      |\n","|    n_updates            | 13470         |\n","|    policy_gradient_loss | -0.000589     |\n","|    value_loss           | 4.24e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1348    |\n","|    time_elapsed    | 8011    |\n","|    total_timesteps | 2760704 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1349          |\n","|    time_elapsed         | 8015          |\n","|    total_timesteps      | 2762752       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013008417 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.628         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.64e+04      |\n","|    n_updates            | 13480         |\n","|    policy_gradient_loss | -0.000363     |\n","|    value_loss           | 4.32e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1350         |\n","|    time_elapsed         | 8018         |\n","|    total_timesteps      | 2764800      |\n","| train/                  |              |\n","|    approx_kl            | 8.375777e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0834      |\n","|    explained_variance   | 0.323        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.34e+04     |\n","|    n_updates            | 13490        |\n","|    policy_gradient_loss | -0.000259    |\n","|    value_loss           | 7.76e+04     |\n","------------------------------------------\n","Eval num_timesteps=2765000, episode_reward=17025.70 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2765000       |\n","| train/                  |               |\n","|    approx_kl            | 4.2089872e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.782         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.83e+04      |\n","|    n_updates            | 13500         |\n","|    policy_gradient_loss | -0.000265     |\n","|    value_loss           | 1.28e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1351    |\n","|    time_elapsed    | 8027    |\n","|    total_timesteps | 2766848 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1352          |\n","|    time_elapsed         | 8031          |\n","|    total_timesteps      | 2768896       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015835743 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.665         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.1e+03       |\n","|    n_updates            | 13510         |\n","|    policy_gradient_loss | -0.000354     |\n","|    value_loss           | 1.84e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2770000, episode_reward=17958.73 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2770000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016819226 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.143        |\n","|    explained_variance   | 0.517         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+04      |\n","|    n_updates            | 13520         |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 6.7e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1353    |\n","|    time_elapsed    | 8040    |\n","|    total_timesteps | 2770944 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1354         |\n","|    time_elapsed         | 8044         |\n","|    total_timesteps      | 2772992      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007568308 |\n","|    clip_fraction        | 0.00234      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.184       |\n","|    explained_variance   | 0.798        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.1e+04      |\n","|    n_updates            | 13530        |\n","|    policy_gradient_loss | -0.00104     |\n","|    value_loss           | 4.68e+04     |\n","------------------------------------------\n","Eval num_timesteps=2775000, episode_reward=15572.35 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2775000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021236899 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.121        |\n","|    explained_variance   | 0.666         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.21e+03      |\n","|    n_updates            | 13540         |\n","|    policy_gradient_loss | -0.000342     |\n","|    value_loss           | 2.85e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1355    |\n","|    time_elapsed    | 8054    |\n","|    total_timesteps | 2775040 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1356          |\n","|    time_elapsed         | 8058          |\n","|    total_timesteps      | 2777088       |\n","| train/                  |               |\n","|    approx_kl            | 3.0835508e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0606       |\n","|    explained_variance   | 0.367         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.81e+03      |\n","|    n_updates            | 13550         |\n","|    policy_gradient_loss | -8.6e-05      |\n","|    value_loss           | 6.54e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1357         |\n","|    time_elapsed         | 8062         |\n","|    total_timesteps      | 2779136      |\n","| train/                  |              |\n","|    approx_kl            | 6.940274e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.158       |\n","|    explained_variance   | 0.793        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.18e+04     |\n","|    n_updates            | 13560        |\n","|    policy_gradient_loss | -5.84e-06    |\n","|    value_loss           | 8.61e+04     |\n","------------------------------------------\n","Eval num_timesteps=2780000, episode_reward=17029.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.7e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2780000      |\n","| train/                  |              |\n","|    approx_kl            | 9.437592e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.15        |\n","|    explained_variance   | 0.74         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.89e+03     |\n","|    n_updates            | 13570        |\n","|    policy_gradient_loss | -0.00028     |\n","|    value_loss           | 1.54e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1358    |\n","|    time_elapsed    | 8071    |\n","|    total_timesteps | 2781184 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1359          |\n","|    time_elapsed         | 8075          |\n","|    total_timesteps      | 2783232       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030030293 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.717         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.14e+04      |\n","|    n_updates            | 13580         |\n","|    policy_gradient_loss | -0.000633     |\n","|    value_loss           | 3.89e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2785000, episode_reward=17029.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.7e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2785000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002223673 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.164       |\n","|    explained_variance   | 0.786        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.05e+04     |\n","|    n_updates            | 13590        |\n","|    policy_gradient_loss | -4.87e-05    |\n","|    value_loss           | 4.85e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1360    |\n","|    time_elapsed    | 8084    |\n","|    total_timesteps | 2785280 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1361         |\n","|    time_elapsed         | 8087         |\n","|    total_timesteps      | 2787328      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005906081 |\n","|    clip_fraction        | 0.00337      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.116       |\n","|    explained_variance   | 0.638        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.28e+04     |\n","|    n_updates            | 13600        |\n","|    policy_gradient_loss | -0.00112     |\n","|    value_loss           | 1.75e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1362          |\n","|    time_elapsed         | 8091          |\n","|    total_timesteps      | 2789376       |\n","| train/                  |               |\n","|    approx_kl            | 1.8174469e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0539       |\n","|    explained_variance   | 0.491         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.59e+05      |\n","|    n_updates            | 13610         |\n","|    policy_gradient_loss | 6.56e-06      |\n","|    value_loss           | 1.51e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2790000, episode_reward=17029.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2790000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00061718276 |\n","|    clip_fraction        | 0.00234       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.187        |\n","|    explained_variance   | 0.856         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.55e+04      |\n","|    n_updates            | 13620         |\n","|    policy_gradient_loss | -0.000833     |\n","|    value_loss           | 4.77e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1363    |\n","|    time_elapsed    | 8100    |\n","|    total_timesteps | 2791424 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1364         |\n","|    time_elapsed         | 8104         |\n","|    total_timesteps      | 2793472      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003086083 |\n","|    clip_fraction        | 0.00112      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.702        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.96e+03     |\n","|    n_updates            | 13630        |\n","|    policy_gradient_loss | -0.00108     |\n","|    value_loss           | 1.96e+04     |\n","------------------------------------------\n","Eval num_timesteps=2795000, episode_reward=17367.92 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.74e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 2795000     |\n","| train/                  |             |\n","|    approx_kl            | 3.89615e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.179      |\n","|    explained_variance   | 0.775       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.32e+04    |\n","|    n_updates            | 13640       |\n","|    policy_gradient_loss | -0.000215   |\n","|    value_loss           | 3.06e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1365    |\n","|    time_elapsed    | 8114    |\n","|    total_timesteps | 2795520 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1366          |\n","|    time_elapsed         | 8118          |\n","|    total_timesteps      | 2797568       |\n","| train/                  |               |\n","|    approx_kl            | 4.9554248e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.606         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.33e+04      |\n","|    n_updates            | 13650         |\n","|    policy_gradient_loss | -0.000358     |\n","|    value_loss           | 4.84e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1367          |\n","|    time_elapsed         | 8121          |\n","|    total_timesteps      | 2799616       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036175168 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.125        |\n","|    explained_variance   | 0.606         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.98e+03      |\n","|    n_updates            | 13660         |\n","|    policy_gradient_loss | -0.000398     |\n","|    value_loss           | 1.94e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2800000, episode_reward=17029.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.7e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2800000      |\n","| train/                  |              |\n","|    approx_kl            | 3.934247e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0506      |\n","|    explained_variance   | 0.482        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.65e+04     |\n","|    n_updates            | 13670        |\n","|    policy_gradient_loss | -0.000194    |\n","|    value_loss           | 1.06e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1368    |\n","|    time_elapsed    | 8130    |\n","|    total_timesteps | 2801664 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1369          |\n","|    time_elapsed         | 8134          |\n","|    total_timesteps      | 2803712       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042855335 |\n","|    clip_fraction        | 0.00195       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.193        |\n","|    explained_variance   | 0.822         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 13680         |\n","|    policy_gradient_loss | -0.00146      |\n","|    value_loss           | 4.62e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2805000, episode_reward=17029.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.7e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2805000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0010378016 |\n","|    clip_fraction        | 0.00952      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.11        |\n","|    explained_variance   | 0.782        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.51e+03     |\n","|    n_updates            | 13690        |\n","|    policy_gradient_loss | -0.00199     |\n","|    value_loss           | 1.56e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1370    |\n","|    time_elapsed    | 8143    |\n","|    total_timesteps | 2805760 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 344         |\n","|    iterations           | 1371        |\n","|    time_elapsed         | 8146        |\n","|    total_timesteps      | 2807808     |\n","| train/                  |             |\n","|    approx_kl            | 2.66344e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.2        |\n","|    explained_variance   | 0.816       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 7.17e+03    |\n","|    n_updates            | 13700       |\n","|    policy_gradient_loss | -0.000115   |\n","|    value_loss           | 3.03e+04    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1372          |\n","|    time_elapsed         | 8149          |\n","|    total_timesteps      | 2809856       |\n","| train/                  |               |\n","|    approx_kl            | 0.00085545215 |\n","|    clip_fraction        | 0.00303       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0995       |\n","|    explained_variance   | 0.605         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 13710         |\n","|    policy_gradient_loss | -0.00109      |\n","|    value_loss           | 4.94e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2810000, episode_reward=19164.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.92e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2810000      |\n","| train/                  |              |\n","|    approx_kl            | 9.530323e-05 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.122       |\n","|    explained_variance   | 0.317        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.57e+04     |\n","|    n_updates            | 13720        |\n","|    policy_gradient_loss | -0.000579    |\n","|    value_loss           | 4.42e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1373    |\n","|    time_elapsed    | 8158    |\n","|    total_timesteps | 2811904 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1374         |\n","|    time_elapsed         | 8162         |\n","|    total_timesteps      | 2813952      |\n","| train/                  |              |\n","|    approx_kl            | 2.555389e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.075       |\n","|    explained_variance   | 0.73         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.37e+04     |\n","|    n_updates            | 13730        |\n","|    policy_gradient_loss | -8.52e-06    |\n","|    value_loss           | 1.14e+05     |\n","------------------------------------------\n","Eval num_timesteps=2815000, episode_reward=18181.62 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.82e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2815000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002461062 |\n","|    clip_fraction        | 0.000586     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.176       |\n","|    explained_variance   | 0.844        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.07e+03     |\n","|    n_updates            | 13740        |\n","|    policy_gradient_loss | -0.000959    |\n","|    value_loss           | 1.69e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1375    |\n","|    time_elapsed    | 8172    |\n","|    total_timesteps | 2816000 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1376         |\n","|    time_elapsed         | 8175         |\n","|    total_timesteps      | 2818048      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007116159 |\n","|    clip_fraction        | 0.00483      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.106       |\n","|    explained_variance   | 0.685        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.04e+03     |\n","|    n_updates            | 13750        |\n","|    policy_gradient_loss | -0.00125     |\n","|    value_loss           | 2.86e+04     |\n","------------------------------------------\n","Eval num_timesteps=2820000, episode_reward=18035.12 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2820000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018065335 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.196        |\n","|    explained_variance   | 0.774         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.84e+04      |\n","|    n_updates            | 13760         |\n","|    policy_gradient_loss | -0.000433     |\n","|    value_loss           | 4.26e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1377    |\n","|    time_elapsed    | 8184    |\n","|    total_timesteps | 2820096 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1378         |\n","|    time_elapsed         | 8188         |\n","|    total_timesteps      | 2822144      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005801317 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.671        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.15e+04     |\n","|    n_updates            | 13770        |\n","|    policy_gradient_loss | -0.00036     |\n","|    value_loss           | 3.5e+04      |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1379         |\n","|    time_elapsed         | 8191         |\n","|    total_timesteps      | 2824192      |\n","| train/                  |              |\n","|    approx_kl            | 9.018317e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.103       |\n","|    explained_variance   | 0.623        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.08e+05     |\n","|    n_updates            | 13780        |\n","|    policy_gradient_loss | -4.47e-06    |\n","|    value_loss           | 8.5e+04      |\n","------------------------------------------\n","Eval num_timesteps=2825000, episode_reward=18648.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2825000       |\n","| train/                  |               |\n","|    approx_kl            | 9.6380885e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.125        |\n","|    explained_variance   | 0.852         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.97e+04      |\n","|    n_updates            | 13790         |\n","|    policy_gradient_loss | -0.000121     |\n","|    value_loss           | 8.84e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1380    |\n","|    time_elapsed    | 8200    |\n","|    total_timesteps | 2826240 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1381         |\n","|    time_elapsed         | 8204         |\n","|    total_timesteps      | 2828288      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004090284 |\n","|    clip_fraction        | 0.00225      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.126       |\n","|    explained_variance   | 0.523        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.19e+03     |\n","|    n_updates            | 13800        |\n","|    policy_gradient_loss | -0.00152     |\n","|    value_loss           | 3.53e+04     |\n","------------------------------------------\n","Eval num_timesteps=2830000, episode_reward=18462.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.85e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2830000      |\n","| train/                  |              |\n","|    approx_kl            | 7.695213e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.111       |\n","|    explained_variance   | 0.726        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.88e+03     |\n","|    n_updates            | 13810        |\n","|    policy_gradient_loss | -0.000541    |\n","|    value_loss           | 3.93e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1382    |\n","|    time_elapsed    | 8213    |\n","|    total_timesteps | 2830336 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1383         |\n","|    time_elapsed         | 8217         |\n","|    total_timesteps      | 2832384      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004245859 |\n","|    clip_fraction        | 0.000879     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.208       |\n","|    explained_variance   | 0.815        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.1e+04      |\n","|    n_updates            | 13820        |\n","|    policy_gradient_loss | -0.000663    |\n","|    value_loss           | 3.32e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1384          |\n","|    time_elapsed         | 8221          |\n","|    total_timesteps      | 2834432       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025256636 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.704         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.13e+04      |\n","|    n_updates            | 13830         |\n","|    policy_gradient_loss | -0.000309     |\n","|    value_loss           | 3.78e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2835000, episode_reward=20839.52 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.08e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2835000      |\n","| train/                  |              |\n","|    approx_kl            | 9.098585e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0814      |\n","|    explained_variance   | 0.702        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.78e+03     |\n","|    n_updates            | 13840        |\n","|    policy_gradient_loss | -1.83e-05    |\n","|    value_loss           | 6.27e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1385    |\n","|    time_elapsed    | 8232    |\n","|    total_timesteps | 2836480 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1386          |\n","|    time_elapsed         | 8235          |\n","|    total_timesteps      | 2838528       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019435826 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.804         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.6e+04       |\n","|    n_updates            | 13850         |\n","|    policy_gradient_loss | -0.000333     |\n","|    value_loss           | 9.28e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2840000, episode_reward=21678.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.17e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2840000       |\n","| train/                  |               |\n","|    approx_kl            | 9.5709256e-05 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.104        |\n","|    explained_variance   | 0.671         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.71e+03      |\n","|    n_updates            | 13860         |\n","|    policy_gradient_loss | -0.000281     |\n","|    value_loss           | 2.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1387    |\n","|    time_elapsed    | 8244    |\n","|    total_timesteps | 2840576 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1388          |\n","|    time_elapsed         | 8247          |\n","|    total_timesteps      | 2842624       |\n","| train/                  |               |\n","|    approx_kl            | 1.3951969e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.592         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.93e+04      |\n","|    n_updates            | 13870         |\n","|    policy_gradient_loss | -5.53e-05     |\n","|    value_loss           | 5.65e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1389          |\n","|    time_elapsed         | 8251          |\n","|    total_timesteps      | 2844672       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016717394 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.177        |\n","|    explained_variance   | 0.829         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.23e+03      |\n","|    n_updates            | 13880         |\n","|    policy_gradient_loss | -5.71e-05     |\n","|    value_loss           | 3.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2845000, episode_reward=21972.23 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2845000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041469454 |\n","|    clip_fraction        | 0.00244       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.698         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.59e+04      |\n","|    n_updates            | 13890         |\n","|    policy_gradient_loss | -0.000698     |\n","|    value_loss           | 2.8e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1390    |\n","|    time_elapsed    | 8260    |\n","|    total_timesteps | 2846720 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1391          |\n","|    time_elapsed         | 8263          |\n","|    total_timesteps      | 2848768       |\n","| train/                  |               |\n","|    approx_kl            | 2.0515348e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0678       |\n","|    explained_variance   | 0.48          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 13900         |\n","|    policy_gradient_loss | 3.4e-05       |\n","|    value_loss           | 6.22e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2850000, episode_reward=21972.23 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 2850000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024023853 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.13e+04      |\n","|    n_updates            | 13910         |\n","|    policy_gradient_loss | -0.000773     |\n","|    value_loss           | 1.02e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1392    |\n","|    time_elapsed    | 8273    |\n","|    total_timesteps | 2850816 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1393          |\n","|    time_elapsed         | 8276          |\n","|    total_timesteps      | 2852864       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044210505 |\n","|    clip_fraction        | 0.0019        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.711         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.07e+03      |\n","|    n_updates            | 13920         |\n","|    policy_gradient_loss | -0.00107      |\n","|    value_loss           | 1.77e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1394          |\n","|    time_elapsed         | 8280          |\n","|    total_timesteps      | 2854912       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024218939 |\n","|    clip_fraction        | 0.00215       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.565         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 13930         |\n","|    policy_gradient_loss | -0.000981     |\n","|    value_loss           | 3.85e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2855000, episode_reward=20795.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2855000       |\n","| train/                  |               |\n","|    approx_kl            | 5.9213577e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.819         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.95e+03      |\n","|    n_updates            | 13940         |\n","|    policy_gradient_loss | -5.65e-05     |\n","|    value_loss           | 4.78e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1395    |\n","|    time_elapsed    | 8290    |\n","|    total_timesteps | 2856960 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1396         |\n","|    time_elapsed         | 8293         |\n","|    total_timesteps      | 2859008      |\n","| train/                  |              |\n","|    approx_kl            | 8.540222e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.116       |\n","|    explained_variance   | 0.486        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.56e+04     |\n","|    n_updates            | 13950        |\n","|    policy_gradient_loss | -0.000117    |\n","|    value_loss           | 3.97e+04     |\n","------------------------------------------\n","Eval num_timesteps=2860000, episode_reward=20795.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.08e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2860000       |\n","| train/                  |               |\n","|    approx_kl            | 1.3651967e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0511       |\n","|    explained_variance   | 0.764         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.45e+03      |\n","|    n_updates            | 13960         |\n","|    policy_gradient_loss | -9.29e-05     |\n","|    value_loss           | 6.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1397    |\n","|    time_elapsed    | 8303    |\n","|    total_timesteps | 2861056 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1398          |\n","|    time_elapsed         | 8306          |\n","|    total_timesteps      | 2863104       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041774602 |\n","|    clip_fraction        | 0.00337       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.191        |\n","|    explained_variance   | 0.763         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.4e+04       |\n","|    n_updates            | 13970         |\n","|    policy_gradient_loss | -0.00252      |\n","|    value_loss           | 9.96e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2865000, episode_reward=21303.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.13e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2865000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026218066 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.35e+03      |\n","|    n_updates            | 13980         |\n","|    policy_gradient_loss | -0.0011       |\n","|    value_loss           | 2.21e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1399    |\n","|    time_elapsed    | 8315    |\n","|    total_timesteps | 2865152 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1400          |\n","|    time_elapsed         | 8318          |\n","|    total_timesteps      | 2867200       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032865827 |\n","|    clip_fraction        | 0.00151       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.753         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.09e+04      |\n","|    n_updates            | 13990         |\n","|    policy_gradient_loss | -0.000917     |\n","|    value_loss           | 4.2e+04       |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1401         |\n","|    time_elapsed         | 8321         |\n","|    total_timesteps      | 2869248      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004574909 |\n","|    clip_fraction        | 0.00244      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.133       |\n","|    explained_variance   | 0.537        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.46e+04     |\n","|    n_updates            | 14000        |\n","|    policy_gradient_loss | -0.000394    |\n","|    value_loss           | 5.43e+04     |\n","------------------------------------------\n","Eval num_timesteps=2870000, episode_reward=19530.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2870000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046306368 |\n","|    clip_fraction        | 0.00229       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.128        |\n","|    explained_variance   | 0.544         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.55e+03      |\n","|    n_updates            | 14010         |\n","|    policy_gradient_loss | -0.00104      |\n","|    value_loss           | 3.03e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1402    |\n","|    time_elapsed    | 8331    |\n","|    total_timesteps | 2871296 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1403          |\n","|    time_elapsed         | 8334          |\n","|    total_timesteps      | 2873344       |\n","| train/                  |               |\n","|    approx_kl            | 1.5652622e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0528       |\n","|    explained_variance   | 0.523         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.49e+04      |\n","|    n_updates            | 14020         |\n","|    policy_gradient_loss | -7.07e-05     |\n","|    value_loss           | 1.94e+05      |\n","-------------------------------------------\n","Eval num_timesteps=2875000, episode_reward=16919.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.69e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2875000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013809261 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.194        |\n","|    explained_variance   | 0.812         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.44e+04      |\n","|    n_updates            | 14030         |\n","|    policy_gradient_loss | -0.000394     |\n","|    value_loss           | 3.61e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1404    |\n","|    time_elapsed    | 8344    |\n","|    total_timesteps | 2875392 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1405         |\n","|    time_elapsed         | 8347         |\n","|    total_timesteps      | 2877440      |\n","| train/                  |              |\n","|    approx_kl            | 0.0016940864 |\n","|    clip_fraction        | 0.0166       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.126       |\n","|    explained_variance   | 0.797        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.87e+03     |\n","|    n_updates            | 14040        |\n","|    policy_gradient_loss | -0.00343     |\n","|    value_loss           | 1.56e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1406          |\n","|    time_elapsed         | 8350          |\n","|    total_timesteps      | 2879488       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013987764 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.195        |\n","|    explained_variance   | 0.733         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.35e+04      |\n","|    n_updates            | 14050         |\n","|    policy_gradient_loss | -0.000219     |\n","|    value_loss           | 3.32e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2880000, episode_reward=19042.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.9e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 2880000      |\n","| train/                  |              |\n","|    approx_kl            | 4.218312e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.112       |\n","|    explained_variance   | 0.43         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.48e+04     |\n","|    n_updates            | 14060        |\n","|    policy_gradient_loss | -5.08e-05    |\n","|    value_loss           | 5.31e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1407    |\n","|    time_elapsed    | 8359    |\n","|    total_timesteps | 2881536 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1408          |\n","|    time_elapsed         | 8363          |\n","|    total_timesteps      | 2883584       |\n","| train/                  |               |\n","|    approx_kl            | 3.9522332e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.432         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.66e+04      |\n","|    n_updates            | 14070         |\n","|    policy_gradient_loss | -0.00018      |\n","|    value_loss           | 3.83e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2885000, episode_reward=18442.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2885000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033242896 |\n","|    clip_fraction        | 0.00254       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0739       |\n","|    explained_variance   | 0.699         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.14e+04      |\n","|    n_updates            | 14080         |\n","|    policy_gradient_loss | -0.00153      |\n","|    value_loss           | 1.52e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1409    |\n","|    time_elapsed    | 8373    |\n","|    total_timesteps | 2885632 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1410         |\n","|    time_elapsed         | 8376         |\n","|    total_timesteps      | 2887680      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002081941 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.179       |\n","|    explained_variance   | 0.829        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.42e+03     |\n","|    n_updates            | 14090        |\n","|    policy_gradient_loss | -0.000253    |\n","|    value_loss           | 2.21e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1411          |\n","|    time_elapsed         | 8379          |\n","|    total_timesteps      | 2889728       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016689458 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.732         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.07e+04      |\n","|    n_updates            | 14100         |\n","|    policy_gradient_loss | -0.000125     |\n","|    value_loss           | 2.15e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2890000, episode_reward=17599.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.76e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2890000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018264062 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.192        |\n","|    explained_variance   | 0.785         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.67e+04      |\n","|    n_updates            | 14110         |\n","|    policy_gradient_loss | 0.000118      |\n","|    value_loss           | 5.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1412    |\n","|    time_elapsed    | 8388    |\n","|    total_timesteps | 2891776 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1413          |\n","|    time_elapsed         | 8392          |\n","|    total_timesteps      | 2893824       |\n","| train/                  |               |\n","|    approx_kl            | 0.00067859615 |\n","|    clip_fraction        | 0.00513       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.692         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 14120         |\n","|    policy_gradient_loss | -0.00134      |\n","|    value_loss           | 3.44e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2895000, episode_reward=17105.31 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.71e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2895000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001234163 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.112       |\n","|    explained_variance   | 0.192        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.73e+04     |\n","|    n_updates            | 14130        |\n","|    policy_gradient_loss | -0.000117    |\n","|    value_loss           | 5.87e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1414    |\n","|    time_elapsed    | 8401    |\n","|    total_timesteps | 2895872 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1415          |\n","|    time_elapsed         | 8404          |\n","|    total_timesteps      | 2897920       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010723685 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.119        |\n","|    explained_variance   | 0.798         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.99e+04      |\n","|    n_updates            | 14140         |\n","|    policy_gradient_loss | -0.000602     |\n","|    value_loss           | 1.33e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1416          |\n","|    time_elapsed         | 8407          |\n","|    total_timesteps      | 2899968       |\n","| train/                  |               |\n","|    approx_kl            | 0.00051867776 |\n","|    clip_fraction        | 0.00298       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.697         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.27e+03      |\n","|    n_updates            | 14150         |\n","|    policy_gradient_loss | -0.00101      |\n","|    value_loss           | 2.14e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2900000, episode_reward=16322.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.63e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2900000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009545183 |\n","|    clip_fraction        | 0.00762      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.505        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.88e+04     |\n","|    n_updates            | 14160        |\n","|    policy_gradient_loss | -0.000313    |\n","|    value_loss           | 7.28e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1417    |\n","|    time_elapsed    | 8416    |\n","|    total_timesteps | 2902016 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1418          |\n","|    time_elapsed         | 8420          |\n","|    total_timesteps      | 2904064       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044423732 |\n","|    clip_fraction        | 0.00254       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.21         |\n","|    explained_variance   | 0.795         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.47e+03      |\n","|    n_updates            | 14170         |\n","|    policy_gradient_loss | -0.000825     |\n","|    value_loss           | 4.43e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2905000, episode_reward=15369.50 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.54e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2905000       |\n","| train/                  |               |\n","|    approx_kl            | 3.1470612e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.691         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.12e+04      |\n","|    n_updates            | 14180         |\n","|    policy_gradient_loss | -4e-05        |\n","|    value_loss           | 4.6e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1419    |\n","|    time_elapsed    | 8429    |\n","|    total_timesteps | 2906112 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1420          |\n","|    time_elapsed         | 8432          |\n","|    total_timesteps      | 2908160       |\n","| train/                  |               |\n","|    approx_kl            | 3.9844424e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0991       |\n","|    explained_variance   | 0.34          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.23e+04      |\n","|    n_updates            | 14190         |\n","|    policy_gradient_loss | -6.56e-06     |\n","|    value_loss           | 6.09e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2910000, episode_reward=14530.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2910000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038058878 |\n","|    clip_fraction        | 0.0022        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.83          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.81e+04      |\n","|    n_updates            | 14200         |\n","|    policy_gradient_loss | -0.00148      |\n","|    value_loss           | 6.48e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1421    |\n","|    time_elapsed    | 8442    |\n","|    total_timesteps | 2910208 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1422          |\n","|    time_elapsed         | 8445          |\n","|    total_timesteps      | 2912256       |\n","| train/                  |               |\n","|    approx_kl            | 2.2285676e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.685         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.09e+03      |\n","|    n_updates            | 14210         |\n","|    policy_gradient_loss | -0.000106     |\n","|    value_loss           | 2.08e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1423          |\n","|    time_elapsed         | 8448          |\n","|    total_timesteps      | 2914304       |\n","| train/                  |               |\n","|    approx_kl            | 0.00071772875 |\n","|    clip_fraction        | 0.00322       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.676         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.35e+03      |\n","|    n_updates            | 14220         |\n","|    policy_gradient_loss | -0.00134      |\n","|    value_loss           | 4.39e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2915000, episode_reward=16118.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.61e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2915000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00055773475 |\n","|    clip_fraction        | 0.002         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.178        |\n","|    explained_variance   | 0.78          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.84e+04      |\n","|    n_updates            | 14230         |\n","|    policy_gradient_loss | -0.00121      |\n","|    value_loss           | 5.09e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1424    |\n","|    time_elapsed    | 8457    |\n","|    total_timesteps | 2916352 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1425         |\n","|    time_elapsed         | 8460         |\n","|    total_timesteps      | 2918400      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008399767 |\n","|    clip_fraction        | 0.00347      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.131       |\n","|    explained_variance   | 0.56         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.95e+04     |\n","|    n_updates            | 14240        |\n","|    policy_gradient_loss | -0.00109     |\n","|    value_loss           | 3.57e+04     |\n","------------------------------------------\n","Eval num_timesteps=2920000, episode_reward=16154.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.62e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 2920000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000487531 |\n","|    clip_fraction        | 0.00244     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.0713     |\n","|    explained_variance   | 0.512       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 7.86e+03    |\n","|    n_updates            | 14250       |\n","|    policy_gradient_loss | -0.00143    |\n","|    value_loss           | 4.31e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1426    |\n","|    time_elapsed    | 8470    |\n","|    total_timesteps | 2920448 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1427         |\n","|    time_elapsed         | 8473         |\n","|    total_timesteps      | 2922496      |\n","| train/                  |              |\n","|    approx_kl            | 2.635445e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.164       |\n","|    explained_variance   | 0.664        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.84e+04     |\n","|    n_updates            | 14260        |\n","|    policy_gradient_loss | -0.000128    |\n","|    value_loss           | 1.49e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1428          |\n","|    time_elapsed         | 8477          |\n","|    total_timesteps      | 2924544       |\n","| train/                  |               |\n","|    approx_kl            | 0.00059087016 |\n","|    clip_fraction        | 0.00454       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.78e+03      |\n","|    n_updates            | 14270         |\n","|    policy_gradient_loss | -0.00136      |\n","|    value_loss           | 2.35e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2925000, episode_reward=14391.23 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2925000       |\n","| train/                  |               |\n","|    approx_kl            | 1.2880162e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.146        |\n","|    explained_variance   | 0.607         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.68e+04      |\n","|    n_updates            | 14280         |\n","|    policy_gradient_loss | -6.74e-05     |\n","|    value_loss           | 7.6e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1429    |\n","|    time_elapsed    | 8487    |\n","|    total_timesteps | 2926592 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1430         |\n","|    time_elapsed         | 8491         |\n","|    total_timesteps      | 2928640      |\n","| train/                  |              |\n","|    approx_kl            | 0.0010148613 |\n","|    clip_fraction        | 0.00518      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.814        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.32e+04     |\n","|    n_updates            | 14290        |\n","|    policy_gradient_loss | -0.00202     |\n","|    value_loss           | 4.93e+04     |\n","------------------------------------------\n","Eval num_timesteps=2930000, episode_reward=18505.88 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2930000       |\n","| train/                  |               |\n","|    approx_kl            | 1.2170873e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.58          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.18e+03      |\n","|    n_updates            | 14300         |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 4.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1431    |\n","|    time_elapsed    | 8500    |\n","|    total_timesteps | 2930688 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1432          |\n","|    time_elapsed         | 8503          |\n","|    total_timesteps      | 2932736       |\n","| train/                  |               |\n","|    approx_kl            | 1.1571945e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.056        |\n","|    explained_variance   | 0.279         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.83e+04      |\n","|    n_updates            | 14310         |\n","|    policy_gradient_loss | -4.41e-06     |\n","|    value_loss           | 1.11e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1433          |\n","|    time_elapsed         | 8506          |\n","|    total_timesteps      | 2934784       |\n","| train/                  |               |\n","|    approx_kl            | 7.3262665e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.184        |\n","|    explained_variance   | 0.76          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.36e+04      |\n","|    n_updates            | 14320         |\n","|    policy_gradient_loss | -0.00016      |\n","|    value_loss           | 6.21e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2935000, episode_reward=16118.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.61e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2935000       |\n","| train/                  |               |\n","|    approx_kl            | 5.2124436e-05 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.31e+03      |\n","|    n_updates            | 14330         |\n","|    policy_gradient_loss | -0.000315     |\n","|    value_loss           | 1.83e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1434    |\n","|    time_elapsed    | 8516    |\n","|    total_timesteps | 2936832 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1435          |\n","|    time_elapsed         | 8519          |\n","|    total_timesteps      | 2938880       |\n","| train/                  |               |\n","|    approx_kl            | 0.00067671074 |\n","|    clip_fraction        | 0.0042        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.693         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.86e+04      |\n","|    n_updates            | 14340         |\n","|    policy_gradient_loss | -0.00101      |\n","|    value_loss           | 7.83e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2940000, episode_reward=15738.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2940000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036989636 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.688         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.23e+04      |\n","|    n_updates            | 14350         |\n","|    policy_gradient_loss | -0.000468     |\n","|    value_loss           | 5.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1436    |\n","|    time_elapsed    | 8528    |\n","|    total_timesteps | 2940928 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1437          |\n","|    time_elapsed         | 8532          |\n","|    total_timesteps      | 2942976       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021028816 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.568         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.68e+04      |\n","|    n_updates            | 14360         |\n","|    policy_gradient_loss | -0.00058      |\n","|    value_loss           | 3.54e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2945000, episode_reward=14358.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2945000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026247388 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0601       |\n","|    explained_variance   | 0.272         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.78e+04      |\n","|    n_updates            | 14370         |\n","|    policy_gradient_loss | -0.000773     |\n","|    value_loss           | 8.51e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1438    |\n","|    time_elapsed    | 8541    |\n","|    total_timesteps | 2945024 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1439          |\n","|    time_elapsed         | 8544          |\n","|    total_timesteps      | 2947072       |\n","| train/                  |               |\n","|    approx_kl            | 4.8462854e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.764         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 14380         |\n","|    policy_gradient_loss | -0.000304     |\n","|    value_loss           | 4.78e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 344          |\n","|    iterations           | 1440         |\n","|    time_elapsed         | 8548         |\n","|    total_timesteps      | 2949120      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003765833 |\n","|    clip_fraction        | 0.00249      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.614        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.09e+04     |\n","|    n_updates            | 14390        |\n","|    policy_gradient_loss | -0.000953    |\n","|    value_loss           | 3.71e+04     |\n","------------------------------------------\n","Eval num_timesteps=2950000, episode_reward=15749.62 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.57e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2950000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003826847 |\n","|    clip_fraction        | 0.000488     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.191       |\n","|    explained_variance   | 0.791        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.01e+03     |\n","|    n_updates            | 14400        |\n","|    policy_gradient_loss | -0.000224    |\n","|    value_loss           | 3.57e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1441    |\n","|    time_elapsed    | 8557    |\n","|    total_timesteps | 2951168 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 344         |\n","|    iterations           | 1442        |\n","|    time_elapsed         | 8560        |\n","|    total_timesteps      | 2953216     |\n","| train/                  |             |\n","|    approx_kl            | 2.71186e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.12       |\n","|    explained_variance   | 0.563       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 8.73e+03    |\n","|    n_updates            | 14410       |\n","|    policy_gradient_loss | -0.000272   |\n","|    value_loss           | 5.14e+04    |\n","-----------------------------------------\n","Eval num_timesteps=2955000, episode_reward=17599.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.76e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 2955000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000630687 |\n","|    clip_fraction        | 0.00488     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.131      |\n","|    explained_variance   | 0.587       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 5.94e+03    |\n","|    n_updates            | 14420       |\n","|    policy_gradient_loss | -0.00109    |\n","|    value_loss           | 3.93e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1443    |\n","|    time_elapsed    | 8569    |\n","|    total_timesteps | 2955264 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1444          |\n","|    time_elapsed         | 8573          |\n","|    total_timesteps      | 2957312       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021627275 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0705       |\n","|    explained_variance   | 0.518         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.41e+04      |\n","|    n_updates            | 14430         |\n","|    policy_gradient_loss | -0.000882     |\n","|    value_loss           | 1.57e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1445         |\n","|    time_elapsed         | 8576         |\n","|    total_timesteps      | 2959360      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003121204 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.184       |\n","|    explained_variance   | 0.881        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.81e+03     |\n","|    n_updates            | 14440        |\n","|    policy_gradient_loss | -0.00129     |\n","|    value_loss           | 2.56e+04     |\n","------------------------------------------\n","Eval num_timesteps=2960000, episode_reward=18108.16 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.81e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2960000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009064804 |\n","|    clip_fraction        | 0.00688      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.121       |\n","|    explained_variance   | 0.682        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.22e+03     |\n","|    n_updates            | 14450        |\n","|    policy_gradient_loss | -0.00179     |\n","|    value_loss           | 2.72e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1446    |\n","|    time_elapsed    | 8585    |\n","|    total_timesteps | 2961408 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1447         |\n","|    time_elapsed         | 8589         |\n","|    total_timesteps      | 2963456      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005888273 |\n","|    clip_fraction        | 0.00269      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.192       |\n","|    explained_variance   | 0.787        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.32e+04     |\n","|    n_updates            | 14460        |\n","|    policy_gradient_loss | -0.00107     |\n","|    value_loss           | 3.21e+04     |\n","------------------------------------------\n","Eval num_timesteps=2965000, episode_reward=18754.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2965000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026796106 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.128        |\n","|    explained_variance   | 0.513         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.89e+04      |\n","|    n_updates            | 14470         |\n","|    policy_gradient_loss | -4.52e-05     |\n","|    value_loss           | 5.94e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1448    |\n","|    time_elapsed    | 8598    |\n","|    total_timesteps | 2965504 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 344           |\n","|    iterations           | 1449          |\n","|    time_elapsed         | 8601          |\n","|    total_timesteps      | 2967552       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017864036 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.416         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.63e+03      |\n","|    n_updates            | 14480         |\n","|    policy_gradient_loss | -0.00062      |\n","|    value_loss           | 5.73e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1450         |\n","|    time_elapsed         | 8605         |\n","|    total_timesteps      | 2969600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004069733 |\n","|    clip_fraction        | 0.00137      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.104       |\n","|    explained_variance   | 0.791        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.01e+04     |\n","|    n_updates            | 14490        |\n","|    policy_gradient_loss | -0.000895    |\n","|    value_loss           | 8.6e+04      |\n","------------------------------------------\n","Eval num_timesteps=2970000, episode_reward=18590.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2970000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023802908 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.605         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.21e+04      |\n","|    n_updates            | 14500         |\n","|    policy_gradient_loss | -0.000617     |\n","|    value_loss           | 4.15e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1451    |\n","|    time_elapsed    | 8614    |\n","|    total_timesteps | 2971648 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1452          |\n","|    time_elapsed         | 8617          |\n","|    total_timesteps      | 2973696       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046672166 |\n","|    clip_fraction        | 0.00313       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.124        |\n","|    explained_variance   | 0.61          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 14510         |\n","|    policy_gradient_loss | -0.00106      |\n","|    value_loss           | 4.22e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2975000, episode_reward=14590.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.46e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2975000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00051387516 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.212        |\n","|    explained_variance   | 0.798         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.15e+04      |\n","|    n_updates            | 14520         |\n","|    policy_gradient_loss | -0.000508     |\n","|    value_loss           | 4.27e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1453    |\n","|    time_elapsed    | 8626    |\n","|    total_timesteps | 2975744 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1454         |\n","|    time_elapsed         | 8630         |\n","|    total_timesteps      | 2977792      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004987739 |\n","|    clip_fraction        | 0.00127      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.596        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.37e+04     |\n","|    n_updates            | 14530        |\n","|    policy_gradient_loss | -0.00057     |\n","|    value_loss           | 4.61e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1455          |\n","|    time_elapsed         | 8633          |\n","|    total_timesteps      | 2979840       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013085076 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.102        |\n","|    explained_variance   | 0.436         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 14540         |\n","|    policy_gradient_loss | -0.000288     |\n","|    value_loss           | 4.92e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2980000, episode_reward=14735.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.47e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2980000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024153612 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.766         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.4e+04       |\n","|    n_updates            | 14550         |\n","|    policy_gradient_loss | -0.000738     |\n","|    value_loss           | 1.04e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1456    |\n","|    time_elapsed    | 8642    |\n","|    total_timesteps | 2981888 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1457          |\n","|    time_elapsed         | 8645          |\n","|    total_timesteps      | 2983936       |\n","| train/                  |               |\n","|    approx_kl            | 3.5691774e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.505         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.74e+03      |\n","|    n_updates            | 14560         |\n","|    policy_gradient_loss | -7.49e-05     |\n","|    value_loss           | 2.39e+04      |\n","-------------------------------------------\n","Eval num_timesteps=2985000, episode_reward=13627.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.36e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 2985000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009347466 |\n","|    clip_fraction        | 0.00571      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.156       |\n","|    explained_variance   | 0.639        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.04e+04     |\n","|    n_updates            | 14570        |\n","|    policy_gradient_loss | -0.00107     |\n","|    value_loss           | 4.22e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1458    |\n","|    time_elapsed    | 8655    |\n","|    total_timesteps | 2985984 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1459         |\n","|    time_elapsed         | 8658         |\n","|    total_timesteps      | 2988032      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005223893 |\n","|    clip_fraction        | 0.00137      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.188       |\n","|    explained_variance   | 0.827        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.83e+04     |\n","|    n_updates            | 14580        |\n","|    policy_gradient_loss | -0.000568    |\n","|    value_loss           | 3.62e+04     |\n","------------------------------------------\n","Eval num_timesteps=2990000, episode_reward=14341.43 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.43e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2990000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021224847 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.128        |\n","|    explained_variance   | 0.537         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.81e+03      |\n","|    n_updates            | 14590         |\n","|    policy_gradient_loss | -0.000219     |\n","|    value_loss           | 4.3e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 344     |\n","|    iterations      | 1460    |\n","|    time_elapsed    | 8667    |\n","|    total_timesteps | 2990080 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1461          |\n","|    time_elapsed         | 8671          |\n","|    total_timesteps      | 2992128       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013481503 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0773       |\n","|    explained_variance   | 0.639         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.26e+04      |\n","|    n_updates            | 14600         |\n","|    policy_gradient_loss | -0.000547     |\n","|    value_loss           | 5.32e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1462         |\n","|    time_elapsed         | 8674         |\n","|    total_timesteps      | 2994176      |\n","| train/                  |              |\n","|    approx_kl            | 3.744266e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.159       |\n","|    explained_variance   | 0.846        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.4e+04      |\n","|    n_updates            | 14610        |\n","|    policy_gradient_loss | -0.000248    |\n","|    value_loss           | 5.51e+04     |\n","------------------------------------------\n","Eval num_timesteps=2995000, episode_reward=16369.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 2995000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047691134 |\n","|    clip_fraction        | 0.00249       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.708         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.38e+04      |\n","|    n_updates            | 14620         |\n","|    policy_gradient_loss | -0.000474     |\n","|    value_loss           | 1.92e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1463    |\n","|    time_elapsed    | 8683    |\n","|    total_timesteps | 2996224 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1464          |\n","|    time_elapsed         | 8686          |\n","|    total_timesteps      | 2998272       |\n","| train/                  |               |\n","|    approx_kl            | 0.00068730634 |\n","|    clip_fraction        | 0.00503       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.655         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.21e+04      |\n","|    n_updates            | 14630         |\n","|    policy_gradient_loss | -0.00201      |\n","|    value_loss           | 4.03e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3000000, episode_reward=17777.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.78e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3000000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032639745 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.17         |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.61e+03      |\n","|    n_updates            | 14640         |\n","|    policy_gradient_loss | -0.000788     |\n","|    value_loss           | 3.65e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1465    |\n","|    time_elapsed    | 8695    |\n","|    total_timesteps | 3000320 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1466          |\n","|    time_elapsed         | 8698          |\n","|    total_timesteps      | 3002368       |\n","| train/                  |               |\n","|    approx_kl            | 2.3610424e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.128        |\n","|    explained_variance   | 0.588         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.74e+04      |\n","|    n_updates            | 14650         |\n","|    policy_gradient_loss | -0.000312     |\n","|    value_loss           | 3.79e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1467          |\n","|    time_elapsed         | 8702          |\n","|    total_timesteps      | 3004416       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018146541 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0555       |\n","|    explained_variance   | 0.491         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.24e+04      |\n","|    n_updates            | 14660         |\n","|    policy_gradient_loss | -0.000611     |\n","|    value_loss           | 1.02e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3005000, episode_reward=18739.98 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3005000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016745785 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.182        |\n","|    explained_variance   | 0.666         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+05      |\n","|    n_updates            | 14670         |\n","|    policy_gradient_loss | -0.000307     |\n","|    value_loss           | 1.02e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1468    |\n","|    time_elapsed    | 8711    |\n","|    total_timesteps | 3006464 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1469          |\n","|    time_elapsed         | 8714          |\n","|    total_timesteps      | 3008512       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021026173 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.775         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.66e+03      |\n","|    n_updates            | 14680         |\n","|    policy_gradient_loss | -0.000585     |\n","|    value_loss           | 1.52e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3010000, episode_reward=18739.98 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3010000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018633294 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.166        |\n","|    explained_variance   | 0.813         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+04       |\n","|    n_updates            | 14690         |\n","|    policy_gradient_loss | -0.000224     |\n","|    value_loss           | 3.77e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1470    |\n","|    time_elapsed    | 8723    |\n","|    total_timesteps | 3010560 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1471          |\n","|    time_elapsed         | 8727          |\n","|    total_timesteps      | 3012608       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014506973 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.577         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.24e+04      |\n","|    n_updates            | 14700         |\n","|    policy_gradient_loss | -0.000107     |\n","|    value_loss           | 5.78e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1472          |\n","|    time_elapsed         | 8730          |\n","|    total_timesteps      | 3014656       |\n","| train/                  |               |\n","|    approx_kl            | 7.8653364e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.121        |\n","|    explained_variance   | 0.58          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.53e+03      |\n","|    n_updates            | 14710         |\n","|    policy_gradient_loss | -0.000131     |\n","|    value_loss           | 3.32e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3015000, episode_reward=19504.57 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3015000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039582732 |\n","|    clip_fraction        | 0.00278       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0455       |\n","|    explained_variance   | 0.511         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.01e+05      |\n","|    n_updates            | 14720         |\n","|    policy_gradient_loss | -0.0014       |\n","|    value_loss           | 1.32e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1473    |\n","|    time_elapsed    | 8739    |\n","|    total_timesteps | 3016704 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1474          |\n","|    time_elapsed         | 8742          |\n","|    total_timesteps      | 3018752       |\n","| train/                  |               |\n","|    approx_kl            | 7.0874084e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.199        |\n","|    explained_variance   | 0.774         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.85e+03      |\n","|    n_updates            | 14730         |\n","|    policy_gradient_loss | -0.000299     |\n","|    value_loss           | 4.1e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3020000, episode_reward=18542.88 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3020000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032607646 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.124        |\n","|    explained_variance   | 0.74          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.54e+03      |\n","|    n_updates            | 14740         |\n","|    policy_gradient_loss | -0.000307     |\n","|    value_loss           | 2.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1475    |\n","|    time_elapsed    | 8751    |\n","|    total_timesteps | 3020800 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1476         |\n","|    time_elapsed         | 8755         |\n","|    total_timesteps      | 3022848      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002718727 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.181       |\n","|    explained_variance   | 0.813        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.91e+04     |\n","|    n_updates            | 14750        |\n","|    policy_gradient_loss | -0.000737    |\n","|    value_loss           | 3.68e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1477         |\n","|    time_elapsed         | 8758         |\n","|    total_timesteps      | 3024896      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006903296 |\n","|    clip_fraction        | 0.0041       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.123       |\n","|    explained_variance   | 0.661        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.58e+04     |\n","|    n_updates            | 14760        |\n","|    policy_gradient_loss | -0.000691    |\n","|    value_loss           | 4.61e+04     |\n","------------------------------------------\n","Eval num_timesteps=3025000, episode_reward=18698.81 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3025000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030845974 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.543         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.36e+03      |\n","|    n_updates            | 14770         |\n","|    policy_gradient_loss | -0.000796     |\n","|    value_loss           | 2.58e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1478    |\n","|    time_elapsed    | 8768    |\n","|    total_timesteps | 3026944 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1479          |\n","|    time_elapsed         | 8772          |\n","|    total_timesteps      | 3028992       |\n","| train/                  |               |\n","|    approx_kl            | 1.2846605e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0672       |\n","|    explained_variance   | 0.564         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.8e+04       |\n","|    n_updates            | 14780         |\n","|    policy_gradient_loss | -2.44e-05     |\n","|    value_loss           | 1.3e+05       |\n","-------------------------------------------\n","Eval num_timesteps=3030000, episode_reward=20390.71 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.04e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3030000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003082989 |\n","|    clip_fraction        | 0.00107      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.186       |\n","|    explained_variance   | 0.797        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.41e+04     |\n","|    n_updates            | 14790        |\n","|    policy_gradient_loss | -0.00127     |\n","|    value_loss           | 4.47e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1480    |\n","|    time_elapsed    | 8781    |\n","|    total_timesteps | 3031040 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1481         |\n","|    time_elapsed         | 8784         |\n","|    total_timesteps      | 3033088      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001106915 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.108       |\n","|    explained_variance   | 0.659        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.44e+03     |\n","|    n_updates            | 14800        |\n","|    policy_gradient_loss | -0.000611    |\n","|    value_loss           | 5.37e+04     |\n","------------------------------------------\n","Eval num_timesteps=3035000, episode_reward=18549.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3035000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027894587 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.751         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.73e+03      |\n","|    n_updates            | 14810         |\n","|    policy_gradient_loss | -0.000444     |\n","|    value_loss           | 5.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1482    |\n","|    time_elapsed    | 8793    |\n","|    total_timesteps | 3035136 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1483         |\n","|    time_elapsed         | 8797         |\n","|    total_timesteps      | 3037184      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005481426 |\n","|    clip_fraction        | 0.00181      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.117       |\n","|    explained_variance   | 0.609        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.21e+04     |\n","|    n_updates            | 14820        |\n","|    policy_gradient_loss | -0.000432    |\n","|    value_loss           | 5.33e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1484          |\n","|    time_elapsed         | 8800          |\n","|    total_timesteps      | 3039232       |\n","| train/                  |               |\n","|    approx_kl            | 1.2480828e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.418         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.08e+04      |\n","|    n_updates            | 14830         |\n","|    policy_gradient_loss | -0.000155     |\n","|    value_loss           | 9.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3040000, episode_reward=18680.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3040000       |\n","| train/                  |               |\n","|    approx_kl            | 5.3781958e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0869       |\n","|    explained_variance   | 0.753         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.78e+04      |\n","|    n_updates            | 14840         |\n","|    policy_gradient_loss | -0.000263     |\n","|    value_loss           | 1.51e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1485    |\n","|    time_elapsed    | 8809    |\n","|    total_timesteps | 3041280 |\n","--------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 345            |\n","|    iterations           | 1486           |\n","|    time_elapsed         | 8813           |\n","|    total_timesteps      | 3043328        |\n","| train/                  |                |\n","|    approx_kl            | 0.000118051306 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.161         |\n","|    explained_variance   | 0.653          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 4.09e+03       |\n","|    n_updates            | 14850          |\n","|    policy_gradient_loss | -0.000419      |\n","|    value_loss           | 4.08e+04       |\n","--------------------------------------------\n","Eval num_timesteps=3045000, episode_reward=17847.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.78e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3045000      |\n","| train/                  |              |\n","|    approx_kl            | 8.924963e-05 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.106       |\n","|    explained_variance   | 0.485        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.52e+03     |\n","|    n_updates            | 14860        |\n","|    policy_gradient_loss | 0.00017      |\n","|    value_loss           | 6.28e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1487    |\n","|    time_elapsed    | 8822    |\n","|    total_timesteps | 3045376 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1488          |\n","|    time_elapsed         | 8826          |\n","|    total_timesteps      | 3047424       |\n","| train/                  |               |\n","|    approx_kl            | 4.5231776e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.219        |\n","|    explained_variance   | 0.779         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.24e+03      |\n","|    n_updates            | 14870         |\n","|    policy_gradient_loss | -0.000104     |\n","|    value_loss           | 3.83e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1489         |\n","|    time_elapsed         | 8829         |\n","|    total_timesteps      | 3049472      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002197721 |\n","|    clip_fraction        | 0.00083      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0976      |\n","|    explained_variance   | 0.706        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.18e+04     |\n","|    n_updates            | 14880        |\n","|    policy_gradient_loss | -0.000444    |\n","|    value_loss           | 3.98e+04     |\n","------------------------------------------\n","Eval num_timesteps=3050000, episode_reward=18254.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.83e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3050000      |\n","| train/                  |              |\n","|    approx_kl            | 5.422166e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.1         |\n","|    explained_variance   | 0.56         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.57e+03     |\n","|    n_updates            | 14890        |\n","|    policy_gradient_loss | -0.00023     |\n","|    value_loss           | 6.04e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1490    |\n","|    time_elapsed    | 8838    |\n","|    total_timesteps | 3051520 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1491          |\n","|    time_elapsed         | 8842          |\n","|    total_timesteps      | 3053568       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046623382 |\n","|    clip_fraction        | 0.00181       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.807         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+04      |\n","|    n_updates            | 14900         |\n","|    policy_gradient_loss | -0.00108      |\n","|    value_loss           | 9.99e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3055000, episode_reward=17919.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.79e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3055000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022732676 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0977       |\n","|    explained_variance   | 0.636         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 14910         |\n","|    policy_gradient_loss | -0.000399     |\n","|    value_loss           | 2.83e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1492    |\n","|    time_elapsed    | 8851    |\n","|    total_timesteps | 3055616 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1493          |\n","|    time_elapsed         | 8854          |\n","|    total_timesteps      | 3057664       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022838148 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.682         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.48e+04      |\n","|    n_updates            | 14920         |\n","|    policy_gradient_loss | -0.000191     |\n","|    value_loss           | 4.38e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1494          |\n","|    time_elapsed         | 8858          |\n","|    total_timesteps      | 3059712       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041400403 |\n","|    clip_fraction        | 0.002         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.198        |\n","|    explained_variance   | 0.838         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.13e+03      |\n","|    n_updates            | 14930         |\n","|    policy_gradient_loss | -0.000611     |\n","|    value_loss           | 3.18e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3060000, episode_reward=19027.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.9e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3060000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018809174 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.605         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.07e+04      |\n","|    n_updates            | 14940         |\n","|    policy_gradient_loss | -0.000468     |\n","|    value_loss           | 3.69e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1495    |\n","|    time_elapsed    | 8867    |\n","|    total_timesteps | 3061760 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1496          |\n","|    time_elapsed         | 8870          |\n","|    total_timesteps      | 3063808       |\n","| train/                  |               |\n","|    approx_kl            | 4.7383714e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0695       |\n","|    explained_variance   | 0.551         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.45e+03      |\n","|    n_updates            | 14950         |\n","|    policy_gradient_loss | -0.000281     |\n","|    value_loss           | 6.17e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3065000, episode_reward=19027.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.9e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3065000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016067276 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.8e+05       |\n","|    n_updates            | 14960         |\n","|    policy_gradient_loss | -0.000344     |\n","|    value_loss           | 1.64e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1497    |\n","|    time_elapsed    | 8880    |\n","|    total_timesteps | 3065856 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1498         |\n","|    time_elapsed         | 8883         |\n","|    total_timesteps      | 3067904      |\n","| train/                  |              |\n","|    approx_kl            | 2.820362e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.126       |\n","|    explained_variance   | 0.702        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.46e+03     |\n","|    n_updates            | 14970        |\n","|    policy_gradient_loss | -0.000165    |\n","|    value_loss           | 2.11e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1499          |\n","|    time_elapsed         | 8887          |\n","|    total_timesteps      | 3069952       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034389787 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.708         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.24e+04      |\n","|    n_updates            | 14980         |\n","|    policy_gradient_loss | -0.00038      |\n","|    value_loss           | 3.6e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3070000, episode_reward=19290.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.93e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3070000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1969463e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.16         |\n","|    explained_variance   | 0.8           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.13e+04      |\n","|    n_updates            | 14990         |\n","|    policy_gradient_loss | -0.000144     |\n","|    value_loss           | 3.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1500    |\n","|    time_elapsed    | 8896    |\n","|    total_timesteps | 3072000 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1501          |\n","|    time_elapsed         | 8900          |\n","|    total_timesteps      | 3074048       |\n","| train/                  |               |\n","|    approx_kl            | 0.00093006226 |\n","|    clip_fraction        | 0.0061        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.513         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.03e+04      |\n","|    n_updates            | 15000         |\n","|    policy_gradient_loss | -0.00149      |\n","|    value_loss           | 4.2e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3075000, episode_reward=19096.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3075000       |\n","| train/                  |               |\n","|    approx_kl            | 3.4322438e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0545       |\n","|    explained_variance   | 0.547         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.98e+04      |\n","|    n_updates            | 15010         |\n","|    policy_gradient_loss | -1.01e-05     |\n","|    value_loss           | 1.24e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1502    |\n","|    time_elapsed    | 8909    |\n","|    total_timesteps | 3076096 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1503          |\n","|    time_elapsed         | 8912          |\n","|    total_timesteps      | 3078144       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029747802 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.766         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.26e+04      |\n","|    n_updates            | 15020         |\n","|    policy_gradient_loss | -0.000505     |\n","|    value_loss           | 6.77e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3080000, episode_reward=16879.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.69e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3080000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048259526 |\n","|    clip_fraction        | 0.00293       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.9e+03       |\n","|    n_updates            | 15030         |\n","|    policy_gradient_loss | -0.00131      |\n","|    value_loss           | 1.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1504    |\n","|    time_elapsed    | 8921    |\n","|    total_timesteps | 3080192 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1505          |\n","|    time_elapsed         | 8925          |\n","|    total_timesteps      | 3082240       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014716637 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.785         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.44e+03      |\n","|    n_updates            | 15040         |\n","|    policy_gradient_loss | -3.74e-05     |\n","|    value_loss           | 3.84e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1506          |\n","|    time_elapsed         | 8928          |\n","|    total_timesteps      | 3084288       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046847793 |\n","|    clip_fraction        | 0.00313       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.655         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.53e+03      |\n","|    n_updates            | 15050         |\n","|    policy_gradient_loss | -0.000549     |\n","|    value_loss           | 3.79e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3085000, episode_reward=20058.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.01e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3085000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00086447527 |\n","|    clip_fraction        | 0.00552       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.9e+03       |\n","|    n_updates            | 15060         |\n","|    policy_gradient_loss | -0.00138      |\n","|    value_loss           | 2.31e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1507    |\n","|    time_elapsed    | 8937    |\n","|    total_timesteps | 3086336 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1508         |\n","|    time_elapsed         | 8940         |\n","|    total_timesteps      | 3088384      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002079712 |\n","|    clip_fraction        | 0.000684     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0396      |\n","|    explained_variance   | 0.516        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.99e+04     |\n","|    n_updates            | 15070        |\n","|    policy_gradient_loss | -6.48e-05    |\n","|    value_loss           | 1.05e+05     |\n","------------------------------------------\n","Eval num_timesteps=3090000, episode_reward=18695.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.87e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3090000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00057849236 |\n","|    clip_fraction        | 0.00264       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.194        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.05e+03      |\n","|    n_updates            | 15080         |\n","|    policy_gradient_loss | -0.000985     |\n","|    value_loss           | 5.68e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1509    |\n","|    time_elapsed    | 8949    |\n","|    total_timesteps | 3090432 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1510         |\n","|    time_elapsed         | 8953         |\n","|    total_timesteps      | 3092480      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006083506 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.116       |\n","|    explained_variance   | 0.662        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.69e+03     |\n","|    n_updates            | 15090        |\n","|    policy_gradient_loss | -0.000849    |\n","|    value_loss           | 2.56e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1511          |\n","|    time_elapsed         | 8957          |\n","|    total_timesteps      | 3094528       |\n","| train/                  |               |\n","|    approx_kl            | 8.9428766e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.805         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.11e+03      |\n","|    n_updates            | 15100         |\n","|    policy_gradient_loss | -0.000226     |\n","|    value_loss           | 3.57e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3095000, episode_reward=19211.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.92e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3095000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008352618 |\n","|    clip_fraction        | 0.00669      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.12        |\n","|    explained_variance   | 0.668        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.02e+03     |\n","|    n_updates            | 15110        |\n","|    policy_gradient_loss | -0.00164     |\n","|    value_loss           | 4.56e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1512    |\n","|    time_elapsed    | 8966    |\n","|    total_timesteps | 3096576 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1513          |\n","|    time_elapsed         | 8969          |\n","|    total_timesteps      | 3098624       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025268222 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.119        |\n","|    explained_variance   | 0.558         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.2e+04       |\n","|    n_updates            | 15120         |\n","|    policy_gradient_loss | -0.000161     |\n","|    value_loss           | 4e+04         |\n","-------------------------------------------\n","Eval num_timesteps=3100000, episode_reward=19096.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.91e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3100000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002928341 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0576      |\n","|    explained_variance   | 0.588        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.69e+04     |\n","|    n_updates            | 15130        |\n","|    policy_gradient_loss | -0.000569    |\n","|    value_loss           | 8.96e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1514    |\n","|    time_elapsed    | 8978    |\n","|    total_timesteps | 3100672 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1515          |\n","|    time_elapsed         | 8981          |\n","|    total_timesteps      | 3102720       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011977629 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.18         |\n","|    explained_variance   | 0.852         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.79e+03      |\n","|    n_updates            | 15140         |\n","|    policy_gradient_loss | -0.000542     |\n","|    value_loss           | 2.61e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1516          |\n","|    time_elapsed         | 8985          |\n","|    total_timesteps      | 3104768       |\n","| train/                  |               |\n","|    approx_kl            | 9.7494194e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.109        |\n","|    explained_variance   | 0.676         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.55e+03      |\n","|    n_updates            | 15150         |\n","|    policy_gradient_loss | -6.26e-06     |\n","|    value_loss           | 5.79e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3105000, episode_reward=18315.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.83e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3105000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016238168 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.191        |\n","|    explained_variance   | 0.728         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.55e+04      |\n","|    n_updates            | 15160         |\n","|    policy_gradient_loss | -0.000256     |\n","|    value_loss           | 5.51e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1517    |\n","|    time_elapsed    | 8993    |\n","|    total_timesteps | 3106816 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 345         |\n","|    iterations           | 1518        |\n","|    time_elapsed         | 8997        |\n","|    total_timesteps      | 3108864     |\n","| train/                  |             |\n","|    approx_kl            | 0.000510833 |\n","|    clip_fraction        | 0.00205     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.112      |\n","|    explained_variance   | 0.721       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.1e+04     |\n","|    n_updates            | 15170       |\n","|    policy_gradient_loss | -0.00098    |\n","|    value_loss           | 3.48e+04    |\n","-----------------------------------------\n","Eval num_timesteps=3110000, episode_reward=19139.30 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3110000       |\n","| train/                  |               |\n","|    approx_kl            | 8.2751736e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.549         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.35e+04      |\n","|    n_updates            | 15180         |\n","|    policy_gradient_loss | -0.000332     |\n","|    value_loss           | 7.25e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1519    |\n","|    time_elapsed    | 9006    |\n","|    total_timesteps | 3110912 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1520          |\n","|    time_elapsed         | 9009          |\n","|    total_timesteps      | 3112960       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032191927 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.077        |\n","|    explained_variance   | 0.748         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.93e+04      |\n","|    n_updates            | 15190         |\n","|    policy_gradient_loss | -0.00067      |\n","|    value_loss           | 1.41e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3115000, episode_reward=18553.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3115000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030089015 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.745         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.69e+03      |\n","|    n_updates            | 15200         |\n","|    policy_gradient_loss | -0.000817     |\n","|    value_loss           | 2.91e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1521    |\n","|    time_elapsed    | 9018    |\n","|    total_timesteps | 3115008 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1522         |\n","|    time_elapsed         | 9022         |\n","|    total_timesteps      | 3117056      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004241942 |\n","|    clip_fraction        | 0.00469      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.103       |\n","|    explained_variance   | 0.576        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.88e+03     |\n","|    n_updates            | 15210        |\n","|    policy_gradient_loss | -0.00199     |\n","|    value_loss           | 2.08e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1523         |\n","|    time_elapsed         | 9025         |\n","|    total_timesteps      | 3119104      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007181497 |\n","|    clip_fraction        | 0.00474      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.212       |\n","|    explained_variance   | 0.772        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.38e+03     |\n","|    n_updates            | 15220        |\n","|    policy_gradient_loss | -0.00111     |\n","|    value_loss           | 5.49e+04     |\n","------------------------------------------\n","Eval num_timesteps=3120000, episode_reward=18141.42 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.81e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3120000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032536982 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0914       |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.28e+04      |\n","|    n_updates            | 15230         |\n","|    policy_gradient_loss | -0.000646     |\n","|    value_loss           | 4.4e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1524    |\n","|    time_elapsed    | 9035    |\n","|    total_timesteps | 3121152 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1525          |\n","|    time_elapsed         | 9038          |\n","|    total_timesteps      | 3123200       |\n","| train/                  |               |\n","|    approx_kl            | 3.5781093e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.098        |\n","|    explained_variance   | 0.332         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.17e+03      |\n","|    n_updates            | 15240         |\n","|    policy_gradient_loss | -0.000223     |\n","|    value_loss           | 9.72e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3125000, episode_reward=17983.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3125000       |\n","| train/                  |               |\n","|    approx_kl            | 5.0465635e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.819         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.65e+04      |\n","|    n_updates            | 15250         |\n","|    policy_gradient_loss | -0.000253     |\n","|    value_loss           | 7.71e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1526    |\n","|    time_elapsed    | 9047    |\n","|    total_timesteps | 3125248 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1527          |\n","|    time_elapsed         | 9050          |\n","|    total_timesteps      | 3127296       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029843193 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.103        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.37e+03      |\n","|    n_updates            | 15260         |\n","|    policy_gradient_loss | -0.000252     |\n","|    value_loss           | 1.82e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1528          |\n","|    time_elapsed         | 9053          |\n","|    total_timesteps      | 3129344       |\n","| train/                  |               |\n","|    approx_kl            | 4.9014372e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.735         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2e+04         |\n","|    n_updates            | 15270         |\n","|    policy_gradient_loss | -0.00027      |\n","|    value_loss           | 4.34e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3130000, episode_reward=17016.92 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3130000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015333405 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.189        |\n","|    explained_variance   | 0.817         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.48e+03      |\n","|    n_updates            | 15280         |\n","|    policy_gradient_loss | 2.03e-05      |\n","|    value_loss           | 3.13e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1529    |\n","|    time_elapsed    | 9063    |\n","|    total_timesteps | 3131392 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1530          |\n","|    time_elapsed         | 9066          |\n","|    total_timesteps      | 3133440       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033138273 |\n","|    clip_fraction        | 0.00122       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.622         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.2e+03       |\n","|    n_updates            | 15290         |\n","|    policy_gradient_loss | -0.000238     |\n","|    value_loss           | 3.87e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3135000, episode_reward=19096.36 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.91e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3135000       |\n","| train/                  |               |\n","|    approx_kl            | 2.3741159e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0677       |\n","|    explained_variance   | 0.679         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.24e+04      |\n","|    n_updates            | 15300         |\n","|    policy_gradient_loss | -7.25e-05     |\n","|    value_loss           | 7.44e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1531    |\n","|    time_elapsed    | 9076    |\n","|    total_timesteps | 3135488 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1532          |\n","|    time_elapsed         | 9080          |\n","|    total_timesteps      | 3137536       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022460561 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.784         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.65e+04      |\n","|    n_updates            | 15310         |\n","|    policy_gradient_loss | -0.000514     |\n","|    value_loss           | 1.02e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1533          |\n","|    time_elapsed         | 9084          |\n","|    total_timesteps      | 3139584       |\n","| train/                  |               |\n","|    approx_kl            | 0.00038595824 |\n","|    clip_fraction        | 0.00278       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.11         |\n","|    explained_variance   | 0.541         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.69e+04      |\n","|    n_updates            | 15320         |\n","|    policy_gradient_loss | -0.000581     |\n","|    value_loss           | 4.53e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3140000, episode_reward=18365.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.84e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3140000       |\n","| train/                  |               |\n","|    approx_kl            | 7.9297286e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.754         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.5e+04       |\n","|    n_updates            | 15330         |\n","|    policy_gradient_loss | -0.000243     |\n","|    value_loss           | 3.33e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1534    |\n","|    time_elapsed    | 9093    |\n","|    total_timesteps | 3141632 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1535          |\n","|    time_elapsed         | 9096          |\n","|    total_timesteps      | 3143680       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039431677 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.817         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.12e+04      |\n","|    n_updates            | 15340         |\n","|    policy_gradient_loss | -0.00083      |\n","|    value_loss           | 4.95e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3145000, episode_reward=19717.27 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.97e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3145000      |\n","| train/                  |              |\n","|    approx_kl            | 8.102134e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.114       |\n","|    explained_variance   | 0.593        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.7e+04      |\n","|    n_updates            | 15350        |\n","|    policy_gradient_loss | -0.00054     |\n","|    value_loss           | 4.42e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1536    |\n","|    time_elapsed    | 9105    |\n","|    total_timesteps | 3145728 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1537         |\n","|    time_elapsed         | 9109         |\n","|    total_timesteps      | 3147776      |\n","| train/                  |              |\n","|    approx_kl            | 7.469635e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0624      |\n","|    explained_variance   | 0.489        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.99e+04     |\n","|    n_updates            | 15360        |\n","|    policy_gradient_loss | -0.00015     |\n","|    value_loss           | 6.75e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1538          |\n","|    time_elapsed         | 9112          |\n","|    total_timesteps      | 3149824       |\n","| train/                  |               |\n","|    approx_kl            | 1.3519835e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.807         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.74e+04      |\n","|    n_updates            | 15370         |\n","|    policy_gradient_loss | 1.3e-05       |\n","|    value_loss           | 5.38e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3150000, episode_reward=17968.05 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3150000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027366824 |\n","|    clip_fraction        | 0.00146       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.129        |\n","|    explained_variance   | 0.772         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.12e+03      |\n","|    n_updates            | 15380         |\n","|    policy_gradient_loss | -0.000496     |\n","|    value_loss           | 1.77e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1539    |\n","|    time_elapsed    | 9121    |\n","|    total_timesteps | 3151872 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1540          |\n","|    time_elapsed         | 9125          |\n","|    total_timesteps      | 3153920       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044521297 |\n","|    clip_fraction        | 0.00146       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.13e+04      |\n","|    n_updates            | 15390         |\n","|    policy_gradient_loss | -0.000948     |\n","|    value_loss           | 4.45e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3155000, episode_reward=17144.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.71e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3155000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036519152 |\n","|    clip_fraction        | 0.00186       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.764         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.11e+04      |\n","|    n_updates            | 15400         |\n","|    policy_gradient_loss | -0.000928     |\n","|    value_loss           | 5.12e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1541    |\n","|    time_elapsed    | 9135    |\n","|    total_timesteps | 3155968 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1542         |\n","|    time_elapsed         | 9138         |\n","|    total_timesteps      | 3158016      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002999296 |\n","|    clip_fraction        | 0.00146      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.103       |\n","|    explained_variance   | 0.676        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.91e+03     |\n","|    n_updates            | 15410        |\n","|    policy_gradient_loss | -0.000742    |\n","|    value_loss           | 2.54e+04     |\n","------------------------------------------\n","Eval num_timesteps=3160000, episode_reward=19211.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3160000       |\n","| train/                  |               |\n","|    approx_kl            | 7.7718636e-05 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0487       |\n","|    explained_variance   | 0.428         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.95e+04      |\n","|    n_updates            | 15420         |\n","|    policy_gradient_loss | -0.000493     |\n","|    value_loss           | 7.69e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1543    |\n","|    time_elapsed    | 9147    |\n","|    total_timesteps | 3160064 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1544          |\n","|    time_elapsed         | 9151          |\n","|    total_timesteps      | 3162112       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018584874 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.18         |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.84e+03      |\n","|    n_updates            | 15430         |\n","|    policy_gradient_loss | -0.000393     |\n","|    value_loss           | 5.41e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1545         |\n","|    time_elapsed         | 9155         |\n","|    total_timesteps      | 3164160      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004756924 |\n","|    clip_fraction        | 0.0042       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.72         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.79e+03     |\n","|    n_updates            | 15440        |\n","|    policy_gradient_loss | -0.000934    |\n","|    value_loss           | 1.82e+04     |\n","------------------------------------------\n","Eval num_timesteps=3165000, episode_reward=17016.92 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3165000       |\n","| train/                  |               |\n","|    approx_kl            | 1.7124257e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.167        |\n","|    explained_variance   | 0.849         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.24e+03      |\n","|    n_updates            | 15450         |\n","|    policy_gradient_loss | -4.98e-05     |\n","|    value_loss           | 3.03e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1546    |\n","|    time_elapsed    | 9163    |\n","|    total_timesteps | 3166208 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1547          |\n","|    time_elapsed         | 9167          |\n","|    total_timesteps      | 3168256       |\n","| train/                  |               |\n","|    approx_kl            | 7.3383795e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.113        |\n","|    explained_variance   | 0.6           |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.84e+03      |\n","|    n_updates            | 15460         |\n","|    policy_gradient_loss | -4.44e-05     |\n","|    value_loss           | 5.38e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3170000, episode_reward=18807.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3170000      |\n","| train/                  |              |\n","|    approx_kl            | 6.057619e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.503        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.24e+03     |\n","|    n_updates            | 15470        |\n","|    policy_gradient_loss | -0.000266    |\n","|    value_loss           | 3.01e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1548    |\n","|    time_elapsed    | 9175    |\n","|    total_timesteps | 3170304 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1549         |\n","|    time_elapsed         | 9179         |\n","|    total_timesteps      | 3172352      |\n","| train/                  |              |\n","|    approx_kl            | 7.792492e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0515      |\n","|    explained_variance   | 0.548        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.85e+04     |\n","|    n_updates            | 15480        |\n","|    policy_gradient_loss | 4.49e-05     |\n","|    value_loss           | 2.07e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1550          |\n","|    time_elapsed         | 9182          |\n","|    total_timesteps      | 3174400       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022625696 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.896         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.55e+03      |\n","|    n_updates            | 15490         |\n","|    policy_gradient_loss | -0.000441     |\n","|    value_loss           | 2.16e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3175000, episode_reward=17968.05 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.8e+04     |\n","| time/                   |             |\n","|    total_timesteps      | 3175000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000276091 |\n","|    clip_fraction        | 0.00181     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.105      |\n","|    explained_variance   | 0.75        |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 4.5e+03     |\n","|    n_updates            | 15500       |\n","|    policy_gradient_loss | -0.000572   |\n","|    value_loss           | 1.79e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1551    |\n","|    time_elapsed    | 9192    |\n","|    total_timesteps | 3176448 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1552          |\n","|    time_elapsed         | 9196          |\n","|    total_timesteps      | 3178496       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030810293 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.183        |\n","|    explained_variance   | 0.761         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.2e+03       |\n","|    n_updates            | 15510         |\n","|    policy_gradient_loss | -0.000453     |\n","|    value_loss           | 3.25e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3180000, episode_reward=16177.80 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.62e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3180000       |\n","| train/                  |               |\n","|    approx_kl            | 2.5632384e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.103        |\n","|    explained_variance   | 0.68          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.94e+03      |\n","|    n_updates            | 15520         |\n","|    policy_gradient_loss | -0.000147     |\n","|    value_loss           | 4.45e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1553    |\n","|    time_elapsed    | 9205    |\n","|    total_timesteps | 3180544 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1554         |\n","|    time_elapsed         | 9208         |\n","|    total_timesteps      | 3182592      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001652888 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.116       |\n","|    explained_variance   | 0.442        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.33e+04     |\n","|    n_updates            | 15530        |\n","|    policy_gradient_loss | -0.000584    |\n","|    value_loss           | 6.09e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1555          |\n","|    time_elapsed         | 9212          |\n","|    total_timesteps      | 3184640       |\n","| train/                  |               |\n","|    approx_kl            | 5.8511796e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0682       |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.4e+04       |\n","|    n_updates            | 15540         |\n","|    policy_gradient_loss | -0.000108     |\n","|    value_loss           | 1.06e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3185000, episode_reward=16181.80 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.62e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3185000       |\n","| train/                  |               |\n","|    approx_kl            | 3.9079954e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.717         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.96e+04      |\n","|    n_updates            | 15550         |\n","|    policy_gradient_loss | -0.00032      |\n","|    value_loss           | 4.1e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1556    |\n","|    time_elapsed    | 9221    |\n","|    total_timesteps | 3186688 |\n","--------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 345            |\n","|    iterations           | 1557           |\n","|    time_elapsed         | 9224           |\n","|    total_timesteps      | 3188736        |\n","| train/                  |                |\n","|    approx_kl            | 0.000114243885 |\n","|    clip_fraction        | 9.77e-05       |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.104         |\n","|    explained_variance   | 0.71           |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 8.9e+03        |\n","|    n_updates            | 15560          |\n","|    policy_gradient_loss | -0.000774      |\n","|    value_loss           | 2.55e+04       |\n","--------------------------------------------\n","Eval num_timesteps=3190000, episode_reward=16724.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.67e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3190000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009764815 |\n","|    clip_fraction        | 0.00342      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.203       |\n","|    explained_variance   | 0.768        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.48e+04     |\n","|    n_updates            | 15570        |\n","|    policy_gradient_loss | -0.00114     |\n","|    value_loss           | 4.44e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1558    |\n","|    time_elapsed    | 9233    |\n","|    total_timesteps | 3190784 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1559          |\n","|    time_elapsed         | 9237          |\n","|    total_timesteps      | 3192832       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028613955 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0988       |\n","|    explained_variance   | 0.659         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 15580         |\n","|    policy_gradient_loss | -0.000137     |\n","|    value_loss           | 3.38e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1560          |\n","|    time_elapsed         | 9240          |\n","|    total_timesteps      | 3194880       |\n","| train/                  |               |\n","|    approx_kl            | 7.1561662e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.096        |\n","|    explained_variance   | 0.499         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.92e+04      |\n","|    n_updates            | 15590         |\n","|    policy_gradient_loss | -7.54e-05     |\n","|    value_loss           | 1.11e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3195000, episode_reward=17016.92 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.7e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 3195000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005195036 |\n","|    clip_fraction        | 0.00298      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.124       |\n","|    explained_variance   | 0.839        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.82e+04     |\n","|    n_updates            | 15600        |\n","|    policy_gradient_loss | -0.00167     |\n","|    value_loss           | 7.99e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1561    |\n","|    time_elapsed    | 9250    |\n","|    total_timesteps | 3196928 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1562         |\n","|    time_elapsed         | 9253         |\n","|    total_timesteps      | 3198976      |\n","| train/                  |              |\n","|    approx_kl            | 8.495562e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.105       |\n","|    explained_variance   | 0.611        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.64e+03     |\n","|    n_updates            | 15610        |\n","|    policy_gradient_loss | -0.000435    |\n","|    value_loss           | 2.38e+04     |\n","------------------------------------------\n","Eval num_timesteps=3200000, episode_reward=16177.80 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.62e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3200000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043651357 |\n","|    clip_fraction        | 0.00186       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.119        |\n","|    explained_variance   | 0.678         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.03e+04      |\n","|    n_updates            | 15620         |\n","|    policy_gradient_loss | -0.000773     |\n","|    value_loss           | 3.31e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1563    |\n","|    time_elapsed    | 9263    |\n","|    total_timesteps | 3201024 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1564          |\n","|    time_elapsed         | 9266          |\n","|    total_timesteps      | 3203072       |\n","| train/                  |               |\n","|    approx_kl            | 0.00072687515 |\n","|    clip_fraction        | 0.00215       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.189        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.28e+03      |\n","|    n_updates            | 15630         |\n","|    policy_gradient_loss | -0.00117      |\n","|    value_loss           | 3.51e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3205000, episode_reward=19046.94 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.9e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3205000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037954637 |\n","|    clip_fraction        | 0.00156       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.627         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.42e+04      |\n","|    n_updates            | 15640         |\n","|    policy_gradient_loss | -0.000651     |\n","|    value_loss           | 4.11e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1565    |\n","|    time_elapsed    | 9275    |\n","|    total_timesteps | 3205120 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1566         |\n","|    time_elapsed         | 9278         |\n","|    total_timesteps      | 3207168      |\n","| train/                  |              |\n","|    approx_kl            | 1.797016e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0707      |\n","|    explained_variance   | 0.697        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.57e+04     |\n","|    n_updates            | 15650        |\n","|    policy_gradient_loss | -3.94e-05    |\n","|    value_loss           | 6.92e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1567          |\n","|    time_elapsed         | 9282          |\n","|    total_timesteps      | 3209216       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018336167 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.812         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.2e+04       |\n","|    n_updates            | 15660         |\n","|    policy_gradient_loss | -0.00026      |\n","|    value_loss           | 1.4e+05       |\n","-------------------------------------------\n","Eval num_timesteps=3210000, episode_reward=18530.33 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3210000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015233032 |\n","|    clip_fraction        | 0.00234       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.102        |\n","|    explained_variance   | 0.774         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.67e+03      |\n","|    n_updates            | 15670         |\n","|    policy_gradient_loss | -0.000735     |\n","|    value_loss           | 1.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1568    |\n","|    time_elapsed    | 9291    |\n","|    total_timesteps | 3211264 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1569          |\n","|    time_elapsed         | 9295          |\n","|    total_timesteps      | 3213312       |\n","| train/                  |               |\n","|    approx_kl            | 4.3827225e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.146        |\n","|    explained_variance   | 0.667         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 15680         |\n","|    policy_gradient_loss | -1.36e-05     |\n","|    value_loss           | 3.71e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3215000, episode_reward=16056.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.61e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3215000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005511212 |\n","|    clip_fraction        | 0.00083      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.167       |\n","|    explained_variance   | 0.847        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.72e+04     |\n","|    n_updates            | 15690        |\n","|    policy_gradient_loss | -0.000237    |\n","|    value_loss           | 3.93e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1570    |\n","|    time_elapsed    | 9306    |\n","|    total_timesteps | 3215360 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 345         |\n","|    iterations           | 1571        |\n","|    time_elapsed         | 9309        |\n","|    total_timesteps      | 3217408     |\n","| train/                  |             |\n","|    approx_kl            | 8.74066e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.111      |\n","|    explained_variance   | 0.673       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 9.96e+03    |\n","|    n_updates            | 15700       |\n","|    policy_gradient_loss | -0.000484   |\n","|    value_loss           | 3.08e+04    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1572          |\n","|    time_elapsed         | 9313          |\n","|    total_timesteps      | 3219456       |\n","| train/                  |               |\n","|    approx_kl            | 3.0731142e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0545       |\n","|    explained_variance   | 0.712         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.02e+04      |\n","|    n_updates            | 15710         |\n","|    policy_gradient_loss | 7.84e-06      |\n","|    value_loss           | 7.68e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3220000, episode_reward=18487.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3220000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021357258 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.847         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.85e+03      |\n","|    n_updates            | 15720         |\n","|    policy_gradient_loss | -0.000375     |\n","|    value_loss           | 8.02e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1573    |\n","|    time_elapsed    | 9322    |\n","|    total_timesteps | 3221504 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1574         |\n","|    time_elapsed         | 9325         |\n","|    total_timesteps      | 3223552      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004307325 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.134       |\n","|    explained_variance   | 0.772        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.06e+03     |\n","|    n_updates            | 15730        |\n","|    policy_gradient_loss | -0.000879    |\n","|    value_loss           | 1.48e+04     |\n","------------------------------------------\n","Eval num_timesteps=3225000, episode_reward=18036.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3225000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1902262e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.853         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.54e+04      |\n","|    n_updates            | 15740         |\n","|    policy_gradient_loss | -4.1e-05      |\n","|    value_loss           | 3.56e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1575    |\n","|    time_elapsed    | 9334    |\n","|    total_timesteps | 3225600 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1576          |\n","|    time_elapsed         | 9338          |\n","|    total_timesteps      | 3227648       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015586545 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.797         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.34e+03      |\n","|    n_updates            | 15750         |\n","|    policy_gradient_loss | -9.11e-05     |\n","|    value_loss           | 5.19e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1577          |\n","|    time_elapsed         | 9341          |\n","|    total_timesteps      | 3229696       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022400488 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.102        |\n","|    explained_variance   | 0.639         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.79e+03      |\n","|    n_updates            | 15760         |\n","|    policy_gradient_loss | -0.000373     |\n","|    value_loss           | 2.45e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3230000, episode_reward=18971.78 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.9e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 3230000      |\n","| train/                  |              |\n","|    approx_kl            | 9.944936e-05 |\n","|    clip_fraction        | 0.000244     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0437      |\n","|    explained_variance   | 0.432        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.72e+04     |\n","|    n_updates            | 15770        |\n","|    policy_gradient_loss | -0.000209    |\n","|    value_loss           | 9.48e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1578    |\n","|    time_elapsed    | 9350    |\n","|    total_timesteps | 3231744 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1579         |\n","|    time_elapsed         | 9354         |\n","|    total_timesteps      | 3233792      |\n","| train/                  |              |\n","|    approx_kl            | 7.811093e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.175       |\n","|    explained_variance   | 0.883        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.08e+03     |\n","|    n_updates            | 15780        |\n","|    policy_gradient_loss | -0.00031     |\n","|    value_loss           | 3.05e+04     |\n","------------------------------------------\n","Eval num_timesteps=3235000, episode_reward=16674.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.67e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3235000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006396872 |\n","|    clip_fraction        | 0.00386      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.112       |\n","|    explained_variance   | 0.767        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.16e+03     |\n","|    n_updates            | 15790        |\n","|    policy_gradient_loss | -0.000939    |\n","|    value_loss           | 1.55e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1580    |\n","|    time_elapsed    | 9363    |\n","|    total_timesteps | 3235840 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1581         |\n","|    time_elapsed         | 9367         |\n","|    total_timesteps      | 3237888      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006064748 |\n","|    clip_fraction        | 0.00381      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.856        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.91e+03     |\n","|    n_updates            | 15800        |\n","|    policy_gradient_loss | -0.00104     |\n","|    value_loss           | 4.05e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1582          |\n","|    time_elapsed         | 9371          |\n","|    total_timesteps      | 3239936       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034102073 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.119        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.71e+04      |\n","|    n_updates            | 15810         |\n","|    policy_gradient_loss | -0.00029      |\n","|    value_loss           | 4.62e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3240000, episode_reward=18468.87 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.85e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3240000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020601769 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.663         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.27e+03      |\n","|    n_updates            | 15820         |\n","|    policy_gradient_loss | -0.000596     |\n","|    value_loss           | 1.89e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1583    |\n","|    time_elapsed    | 9380    |\n","|    total_timesteps | 3241984 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1584          |\n","|    time_elapsed         | 9384          |\n","|    total_timesteps      | 3244032       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012143765 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0398       |\n","|    explained_variance   | 0.573         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.56e+04      |\n","|    n_updates            | 15830         |\n","|    policy_gradient_loss | -0.000482     |\n","|    value_loss           | 1.09e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3245000, episode_reward=13563.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.36e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3245000       |\n","| train/                  |               |\n","|    approx_kl            | 4.7213223e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.838         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.01e+03      |\n","|    n_updates            | 15840         |\n","|    policy_gradient_loss | -0.000265     |\n","|    value_loss           | 3.94e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1585    |\n","|    time_elapsed    | 9393    |\n","|    total_timesteps | 3246080 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1586         |\n","|    time_elapsed         | 9396         |\n","|    total_timesteps      | 3248128      |\n","| train/                  |              |\n","|    approx_kl            | 9.417048e-05 |\n","|    clip_fraction        | 0.000439     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.101       |\n","|    explained_variance   | 0.768        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.5e+03      |\n","|    n_updates            | 15850        |\n","|    policy_gradient_loss | -0.000393    |\n","|    value_loss           | 1.73e+04     |\n","------------------------------------------\n","Eval num_timesteps=3250000, episode_reward=12368.80 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.24e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3250000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00035088867 |\n","|    clip_fraction        | 0.0019        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.185        |\n","|    explained_variance   | 0.785         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.71e+04      |\n","|    n_updates            | 15860         |\n","|    policy_gradient_loss | -0.00104      |\n","|    value_loss           | 8.42e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1587    |\n","|    time_elapsed    | 9405    |\n","|    total_timesteps | 3250176 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1588         |\n","|    time_elapsed         | 9408         |\n","|    total_timesteps      | 3252224      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003747412 |\n","|    clip_fraction        | 0.00264      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0923      |\n","|    explained_variance   | 0.673        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.58e+04     |\n","|    n_updates            | 15870        |\n","|    policy_gradient_loss | -0.000872    |\n","|    value_loss           | 4.21e+04     |\n","------------------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 345            |\n","|    iterations           | 1589           |\n","|    time_elapsed         | 9412           |\n","|    total_timesteps      | 3254272        |\n","| train/                  |                |\n","|    approx_kl            | 0.000111192756 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.105         |\n","|    explained_variance   | 0.645          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 6.08e+04       |\n","|    n_updates            | 15880          |\n","|    policy_gradient_loss | -0.000377      |\n","|    value_loss           | 5.29e+04       |\n","--------------------------------------------\n","Eval num_timesteps=3255000, episode_reward=11252.87 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.13e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3255000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011700415 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0564       |\n","|    explained_variance   | 0.786         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.6e+04       |\n","|    n_updates            | 15890         |\n","|    policy_gradient_loss | -0.000559     |\n","|    value_loss           | 4.73e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1590    |\n","|    time_elapsed    | 9421    |\n","|    total_timesteps | 3256320 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1591          |\n","|    time_elapsed         | 9425          |\n","|    total_timesteps      | 3258368       |\n","| train/                  |               |\n","|    approx_kl            | 1.0957767e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.713         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.54e+03      |\n","|    n_updates            | 15900         |\n","|    policy_gradient_loss | -3.89e-05     |\n","|    value_loss           | 4.17e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3260000, episode_reward=12539.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3260000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011308651 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0975       |\n","|    explained_variance   | 0.668         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.04e+03      |\n","|    n_updates            | 15910         |\n","|    policy_gradient_loss | -0.000275     |\n","|    value_loss           | 2.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1592    |\n","|    time_elapsed    | 9434    |\n","|    total_timesteps | 3260416 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1593          |\n","|    time_elapsed         | 9437          |\n","|    total_timesteps      | 3262464       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012067196 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.192        |\n","|    explained_variance   | 0.81          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 15920         |\n","|    policy_gradient_loss | -0.00037      |\n","|    value_loss           | 3.87e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1594         |\n","|    time_elapsed         | 9441         |\n","|    total_timesteps      | 3264512      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002628035 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0972      |\n","|    explained_variance   | 0.684        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.15e+04     |\n","|    n_updates            | 15930        |\n","|    policy_gradient_loss | -0.000472    |\n","|    value_loss           | 3.35e+04     |\n","------------------------------------------\n","Eval num_timesteps=3265000, episode_reward=12484.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3265000       |\n","| train/                  |               |\n","|    approx_kl            | 2.2421795e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0906       |\n","|    explained_variance   | 0.647         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.37e+03      |\n","|    n_updates            | 15940         |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 7.38e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1595    |\n","|    time_elapsed    | 9450    |\n","|    total_timesteps | 3266560 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1596         |\n","|    time_elapsed         | 9454         |\n","|    total_timesteps      | 3268608      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002542221 |\n","|    clip_fraction        | 0.00137      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.832        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.71e+04     |\n","|    n_updates            | 15950        |\n","|    policy_gradient_loss | -0.000842    |\n","|    value_loss           | 7.53e+04     |\n","------------------------------------------\n","Eval num_timesteps=3270000, episode_reward=12539.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.25e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3270000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1088868e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.592         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.63e+03      |\n","|    n_updates            | 15960         |\n","|    policy_gradient_loss | -0.000108     |\n","|    value_loss           | 4.15e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1597    |\n","|    time_elapsed    | 9463    |\n","|    total_timesteps | 3270656 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1598         |\n","|    time_elapsed         | 9466         |\n","|    total_timesteps      | 3272704      |\n","| train/                  |              |\n","|    approx_kl            | 3.981698e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.106       |\n","|    explained_variance   | 0.775        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.04e+04     |\n","|    n_updates            | 15970        |\n","|    policy_gradient_loss | -7.38e-05    |\n","|    value_loss           | 3.49e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1599         |\n","|    time_elapsed         | 9470         |\n","|    total_timesteps      | 3274752      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007145612 |\n","|    clip_fraction        | 0.00483      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.189       |\n","|    explained_variance   | 0.835        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.61e+03     |\n","|    n_updates            | 15980        |\n","|    policy_gradient_loss | -0.00162     |\n","|    value_loss           | 2.97e+04     |\n","------------------------------------------\n","Eval num_timesteps=3275000, episode_reward=17348.16 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.73e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3275000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046082863 |\n","|    clip_fraction        | 0.00249       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.678         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.03e+03      |\n","|    n_updates            | 15990         |\n","|    policy_gradient_loss | -0.000596     |\n","|    value_loss           | 3.27e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1600    |\n","|    time_elapsed    | 9478    |\n","|    total_timesteps | 3276800 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1601         |\n","|    time_elapsed         | 9482         |\n","|    total_timesteps      | 3278848      |\n","| train/                  |              |\n","|    approx_kl            | 7.764436e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0662      |\n","|    explained_variance   | 0.528        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.72e+04     |\n","|    n_updates            | 16000        |\n","|    policy_gradient_loss | -0.000157    |\n","|    value_loss           | 7.8e+04      |\n","------------------------------------------\n","Eval num_timesteps=3280000, episode_reward=19194.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.92e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3280000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006685617 |\n","|    clip_fraction        | 0.00425      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.133       |\n","|    explained_variance   | 0.835        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.79e+03     |\n","|    n_updates            | 16010        |\n","|    policy_gradient_loss | -0.00152     |\n","|    value_loss           | 3.71e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1602    |\n","|    time_elapsed    | 9491    |\n","|    total_timesteps | 3280896 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1603          |\n","|    time_elapsed         | 9495          |\n","|    total_timesteps      | 3282944       |\n","| train/                  |               |\n","|    approx_kl            | 3.6297017e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0941       |\n","|    explained_variance   | 0.634         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.97e+04      |\n","|    n_updates            | 16020         |\n","|    policy_gradient_loss | -0.000129     |\n","|    value_loss           | 3.61e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1604          |\n","|    time_elapsed         | 9498          |\n","|    total_timesteps      | 3284992       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019157448 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.759         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.13e+04      |\n","|    n_updates            | 16030         |\n","|    policy_gradient_loss | -0.000177     |\n","|    value_loss           | 4.24e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3285000, episode_reward=16153.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.62e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3285000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012863104 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.848         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.8e+04       |\n","|    n_updates            | 16040         |\n","|    policy_gradient_loss | -0.000257     |\n","|    value_loss           | 4.07e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1605    |\n","|    time_elapsed    | 9508    |\n","|    total_timesteps | 3287040 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1606         |\n","|    time_elapsed         | 9512         |\n","|    total_timesteps      | 3289088      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006081614 |\n","|    clip_fraction        | 0.00547      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.114       |\n","|    explained_variance   | 0.745        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.17e+03     |\n","|    n_updates            | 16050        |\n","|    policy_gradient_loss | -0.00134     |\n","|    value_loss           | 2.53e+04     |\n","------------------------------------------\n","Eval num_timesteps=3290000, episode_reward=11526.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.15e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3290000      |\n","| train/                  |              |\n","|    approx_kl            | 8.812902e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0487      |\n","|    explained_variance   | 0.6          |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.19e+03     |\n","|    n_updates            | 16060        |\n","|    policy_gradient_loss | -5.19e-05    |\n","|    value_loss           | 5.08e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1607    |\n","|    time_elapsed    | 9521    |\n","|    total_timesteps | 3291136 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1608          |\n","|    time_elapsed         | 9524          |\n","|    total_timesteps      | 3293184       |\n","| train/                  |               |\n","|    approx_kl            | 6.4432505e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.873         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.52e+03      |\n","|    n_updates            | 16070         |\n","|    policy_gradient_loss | -0.000525     |\n","|    value_loss           | 2.92e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3295000, episode_reward=16674.08 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.67e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3295000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027242547 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.712         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.54e+03      |\n","|    n_updates            | 16080         |\n","|    policy_gradient_loss | -0.000357     |\n","|    value_loss           | 1.58e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1609    |\n","|    time_elapsed    | 9533    |\n","|    total_timesteps | 3295232 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1610         |\n","|    time_elapsed         | 9537         |\n","|    total_timesteps      | 3297280      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008343498 |\n","|    clip_fraction        | 0.0105       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.126       |\n","|    explained_variance   | 0.725        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.55e+04     |\n","|    n_updates            | 16090        |\n","|    policy_gradient_loss | -0.00397     |\n","|    value_loss           | 4.21e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1611          |\n","|    time_elapsed         | 9540          |\n","|    total_timesteps      | 3299328       |\n","| train/                  |               |\n","|    approx_kl            | 1.7390877e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.827         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 16100         |\n","|    policy_gradient_loss | -0.000109     |\n","|    value_loss           | 4.89e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3300000, episode_reward=12985.95 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.3e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3300000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018474029 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.101        |\n","|    explained_variance   | 0.636         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.59e+03      |\n","|    n_updates            | 16110         |\n","|    policy_gradient_loss | -0.00045      |\n","|    value_loss           | 2.35e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1612    |\n","|    time_elapsed    | 9549    |\n","|    total_timesteps | 3301376 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1613          |\n","|    time_elapsed         | 9553          |\n","|    total_timesteps      | 3303424       |\n","| train/                  |               |\n","|    approx_kl            | 1.7728918e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.04         |\n","|    explained_variance   | 0.735         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.43e+03      |\n","|    n_updates            | 16120         |\n","|    policy_gradient_loss | -0.000181     |\n","|    value_loss           | 5.07e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3305000, episode_reward=12588.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.26e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3305000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001243036 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.168       |\n","|    explained_variance   | 0.873        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.21e+04     |\n","|    n_updates            | 16130        |\n","|    policy_gradient_loss | -0.000231    |\n","|    value_loss           | 3.6e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1614    |\n","|    time_elapsed    | 9563    |\n","|    total_timesteps | 3305472 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1615          |\n","|    time_elapsed         | 9566          |\n","|    total_timesteps      | 3307520       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012148984 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.755         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.74e+03      |\n","|    n_updates            | 16140         |\n","|    policy_gradient_loss | -0.000589     |\n","|    value_loss           | 1.83e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1616          |\n","|    time_elapsed         | 9570          |\n","|    total_timesteps      | 3309568       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014610222 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.838         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.03e+03      |\n","|    n_updates            | 16150         |\n","|    policy_gradient_loss | -0.00112      |\n","|    value_loss           | 3.48e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3310000, episode_reward=13154.45 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.32e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3310000       |\n","| train/                  |               |\n","|    approx_kl            | 1.7046987e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.677         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.72e+03      |\n","|    n_updates            | 16160         |\n","|    policy_gradient_loss | 7.21e-06      |\n","|    value_loss           | 4.11e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1617    |\n","|    time_elapsed    | 9579    |\n","|    total_timesteps | 3311616 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1618         |\n","|    time_elapsed         | 9583         |\n","|    total_timesteps      | 3313664      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005286039 |\n","|    clip_fraction        | 0.00156      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.114       |\n","|    explained_variance   | 0.584        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.3e+03      |\n","|    n_updates            | 16170        |\n","|    policy_gradient_loss | -0.000725    |\n","|    value_loss           | 3.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=3315000, episode_reward=12092.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.21e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3315000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016400649 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0322       |\n","|    explained_variance   | 0.677         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.94e+04      |\n","|    n_updates            | 16180         |\n","|    policy_gradient_loss | -0.00103      |\n","|    value_loss           | 5.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1619    |\n","|    time_elapsed    | 9592    |\n","|    total_timesteps | 3315712 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1620          |\n","|    time_elapsed         | 9595          |\n","|    total_timesteps      | 3317760       |\n","| train/                  |               |\n","|    approx_kl            | 2.3958972e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.857         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.32e+03      |\n","|    n_updates            | 16190         |\n","|    policy_gradient_loss | -0.000167     |\n","|    value_loss           | 2.41e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1621         |\n","|    time_elapsed         | 9598         |\n","|    total_timesteps      | 3319808      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004674903 |\n","|    clip_fraction        | 0.00244      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.105       |\n","|    explained_variance   | 0.752        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.62e+03     |\n","|    n_updates            | 16200        |\n","|    policy_gradient_loss | -0.000669    |\n","|    value_loss           | 1.57e+04     |\n","------------------------------------------\n","Eval num_timesteps=3320000, episode_reward=14262.99 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.43e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3320000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00091749034 |\n","|    clip_fraction        | 0.00688       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.185        |\n","|    explained_variance   | 0.852         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.26e+03      |\n","|    n_updates            | 16210         |\n","|    policy_gradient_loss | -0.00209      |\n","|    value_loss           | 3.36e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1622    |\n","|    time_elapsed    | 9608    |\n","|    total_timesteps | 3321856 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1623         |\n","|    time_elapsed         | 9611         |\n","|    total_timesteps      | 3323904      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004961699 |\n","|    clip_fraction        | 0.000977     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0844      |\n","|    explained_variance   | 0.645        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 16220        |\n","|    policy_gradient_loss | -0.000391    |\n","|    value_loss           | 4.46e+04     |\n","------------------------------------------\n","Eval num_timesteps=3325000, episode_reward=14034.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3325000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043822473 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.689         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.51e+04      |\n","|    n_updates            | 16230         |\n","|    policy_gradient_loss | -0.00072      |\n","|    value_loss           | 2.91e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1624    |\n","|    time_elapsed    | 9621    |\n","|    total_timesteps | 3325952 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1625          |\n","|    time_elapsed         | 9624          |\n","|    total_timesteps      | 3328000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019670464 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0476       |\n","|    explained_variance   | 0.77          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.01e+04      |\n","|    n_updates            | 16240         |\n","|    policy_gradient_loss | -0.000654     |\n","|    value_loss           | 4.7e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3330000, episode_reward=14937.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3330000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023138741 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.838         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.81e+03      |\n","|    n_updates            | 16250         |\n","|    policy_gradient_loss | -0.000782     |\n","|    value_loss           | 3e+04         |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1626    |\n","|    time_elapsed    | 9634    |\n","|    total_timesteps | 3330048 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1627         |\n","|    time_elapsed         | 9637         |\n","|    total_timesteps      | 3332096      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007851585 |\n","|    clip_fraction        | 0.00469      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.101       |\n","|    explained_variance   | 0.794        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.07e+04     |\n","|    n_updates            | 16260        |\n","|    policy_gradient_loss | -0.000821    |\n","|    value_loss           | 3.26e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1628          |\n","|    time_elapsed         | 9641          |\n","|    total_timesteps      | 3334144       |\n","| train/                  |               |\n","|    approx_kl            | 0.00028048115 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.186        |\n","|    explained_variance   | 0.842         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.13e+03      |\n","|    n_updates            | 16270         |\n","|    policy_gradient_loss | -0.000334     |\n","|    value_loss           | 4.47e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3335000, episode_reward=14548.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.45e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 3335000     |\n","| train/                  |             |\n","|    approx_kl            | 2.05143e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.108      |\n","|    explained_variance   | 0.776       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.58e+04    |\n","|    n_updates            | 16280       |\n","|    policy_gradient_loss | -5.03e-05   |\n","|    value_loss           | 3.87e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1629    |\n","|    time_elapsed    | 9650    |\n","|    total_timesteps | 3336192 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1630          |\n","|    time_elapsed         | 9653          |\n","|    total_timesteps      | 3338240       |\n","| train/                  |               |\n","|    approx_kl            | 2.6717316e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0907       |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.95e+04      |\n","|    n_updates            | 16290         |\n","|    policy_gradient_loss | -5.64e-05     |\n","|    value_loss           | 5.68e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3340000, episode_reward=14548.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.45e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 3340000     |\n","| train/                  |             |\n","|    approx_kl            | 4.41086e-05 |\n","|    clip_fraction        | 0           |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.0969     |\n","|    explained_variance   | 0.768       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.24e+04    |\n","|    n_updates            | 16300       |\n","|    policy_gradient_loss | -1.98e-05   |\n","|    value_loss           | 7.69e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1631    |\n","|    time_elapsed    | 9662    |\n","|    total_timesteps | 3340288 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1632          |\n","|    time_elapsed         | 9666          |\n","|    total_timesteps      | 3342336       |\n","| train/                  |               |\n","|    approx_kl            | 6.9380796e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.121        |\n","|    explained_variance   | 0.564         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+04      |\n","|    n_updates            | 16310         |\n","|    policy_gradient_loss | -0.000355     |\n","|    value_loss           | 3.35e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1633          |\n","|    time_elapsed         | 9669          |\n","|    total_timesteps      | 3344384       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047688553 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.102        |\n","|    explained_variance   | 0.787         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.68e+04      |\n","|    n_updates            | 16320         |\n","|    policy_gradient_loss | -0.000557     |\n","|    value_loss           | 2.97e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3345000, episode_reward=14548.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.45e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 3345000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000109405286 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.199         |\n","|    explained_variance   | 0.805          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.64e+04       |\n","|    n_updates            | 16330          |\n","|    policy_gradient_loss | -0.000108      |\n","|    value_loss           | 3.08e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1634    |\n","|    time_elapsed    | 9678    |\n","|    total_timesteps | 3346432 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1635         |\n","|    time_elapsed         | 9681         |\n","|    total_timesteps      | 3348480      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005568069 |\n","|    clip_fraction        | 0.00244      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.107       |\n","|    explained_variance   | 0.72         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.84e+03     |\n","|    n_updates            | 16340        |\n","|    policy_gradient_loss | -0.000582    |\n","|    value_loss           | 3.19e+04     |\n","------------------------------------------\n","Eval num_timesteps=3350000, episode_reward=14434.10 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.44e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3350000      |\n","| train/                  |              |\n","|    approx_kl            | 8.313218e-07 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.065       |\n","|    explained_variance   | 0.759        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.31e+04     |\n","|    n_updates            | 16350        |\n","|    policy_gradient_loss | 7.36e-06     |\n","|    value_loss           | 6.18e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1636    |\n","|    time_elapsed    | 9691    |\n","|    total_timesteps | 3350528 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1637          |\n","|    time_elapsed         | 9695          |\n","|    total_timesteps      | 3352576       |\n","| train/                  |               |\n","|    approx_kl            | 4.3204433e-05 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.129        |\n","|    explained_variance   | 0.854         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.73e+03      |\n","|    n_updates            | 16360         |\n","|    policy_gradient_loss | -0.000228     |\n","|    value_loss           | 3.74e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1638          |\n","|    time_elapsed         | 9698          |\n","|    total_timesteps      | 3354624       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016289935 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.092        |\n","|    explained_variance   | 0.633         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.22e+04      |\n","|    n_updates            | 16370         |\n","|    policy_gradient_loss | -0.000293     |\n","|    value_loss           | 4.53e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3355000, episode_reward=14822.37 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.48e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3355000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037133016 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.79          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.05e+04      |\n","|    n_updates            | 16380         |\n","|    policy_gradient_loss | -0.000584     |\n","|    value_loss           | 3.87e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1639    |\n","|    time_elapsed    | 9707    |\n","|    total_timesteps | 3356672 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1640          |\n","|    time_elapsed         | 9711          |\n","|    total_timesteps      | 3358720       |\n","| train/                  |               |\n","|    approx_kl            | 0.00052780967 |\n","|    clip_fraction        | 0.00415       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.858         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.51e+03      |\n","|    n_updates            | 16390         |\n","|    policy_gradient_loss | -0.000858     |\n","|    value_loss           | 3.64e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3360000, episode_reward=13850.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.39e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3360000       |\n","| train/                  |               |\n","|    approx_kl            | 2.6395835e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.623         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.77e+03      |\n","|    n_updates            | 16400         |\n","|    policy_gradient_loss | -8.48e-05     |\n","|    value_loss           | 2.38e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1641    |\n","|    time_elapsed    | 9720    |\n","|    total_timesteps | 3360768 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1642         |\n","|    time_elapsed         | 9723         |\n","|    total_timesteps      | 3362816      |\n","| train/                  |              |\n","|    approx_kl            | 7.779483e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.048       |\n","|    explained_variance   | 0.699        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.79e+03     |\n","|    n_updates            | 16410        |\n","|    policy_gradient_loss | -0.000236    |\n","|    value_loss           | 5.29e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1643         |\n","|    time_elapsed         | 9727         |\n","|    total_timesteps      | 3364864      |\n","| train/                  |              |\n","|    approx_kl            | 9.341806e-05 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.132       |\n","|    explained_variance   | 0.867        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.27e+03     |\n","|    n_updates            | 16420        |\n","|    policy_gradient_loss | -0.000425    |\n","|    value_loss           | 5.73e+04     |\n","------------------------------------------\n","Eval num_timesteps=3365000, episode_reward=12267.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.23e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3365000       |\n","| train/                  |               |\n","|    approx_kl            | 2.6261434e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.133        |\n","|    explained_variance   | 0.694         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.86e+03      |\n","|    n_updates            | 16430         |\n","|    policy_gradient_loss | -0.000211     |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1644    |\n","|    time_elapsed    | 9735    |\n","|    total_timesteps | 3366912 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 345         |\n","|    iterations           | 1645        |\n","|    time_elapsed         | 9739        |\n","|    total_timesteps      | 3368960     |\n","| train/                  |             |\n","|    approx_kl            | 0.000318733 |\n","|    clip_fraction        | 0.00156     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.13       |\n","|    explained_variance   | 0.769       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.63e+04    |\n","|    n_updates            | 16440       |\n","|    policy_gradient_loss | -0.000501   |\n","|    value_loss           | 3.28e+04    |\n","-----------------------------------------\n","Eval num_timesteps=3370000, episode_reward=12267.17 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.23e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3370000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017466454 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.151        |\n","|    explained_variance   | 0.837         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.26e+03      |\n","|    n_updates            | 16450         |\n","|    policy_gradient_loss | -9.87e-05     |\n","|    value_loss           | 3.72e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1646    |\n","|    time_elapsed    | 9748    |\n","|    total_timesteps | 3371008 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1647          |\n","|    time_elapsed         | 9752          |\n","|    total_timesteps      | 3373056       |\n","| train/                  |               |\n","|    approx_kl            | 0.00065437634 |\n","|    clip_fraction        | 0.00273       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.615         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.31e+03      |\n","|    n_updates            | 16460         |\n","|    policy_gradient_loss | -0.000854     |\n","|    value_loss           | 2.52e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3375000, episode_reward=11775.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3375000       |\n","| train/                  |               |\n","|    approx_kl            | 1.3654935e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0362       |\n","|    explained_variance   | 0.762         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.32e+03      |\n","|    n_updates            | 16470         |\n","|    policy_gradient_loss | -0.000117     |\n","|    value_loss           | 4.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1648    |\n","|    time_elapsed    | 9761    |\n","|    total_timesteps | 3375104 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1649         |\n","|    time_elapsed         | 9764         |\n","|    total_timesteps      | 3377152      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002161822 |\n","|    clip_fraction        | 0.00083      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.167       |\n","|    explained_variance   | 0.798        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.98e+04     |\n","|    n_updates            | 16480        |\n","|    policy_gradient_loss | -0.000683    |\n","|    value_loss           | 6.18e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1650          |\n","|    time_elapsed         | 9768          |\n","|    total_timesteps      | 3379200       |\n","| train/                  |               |\n","|    approx_kl            | 0.00063920463 |\n","|    clip_fraction        | 0.00376       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.113        |\n","|    explained_variance   | 0.796         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.44e+03      |\n","|    n_updates            | 16490         |\n","|    policy_gradient_loss | -0.00166      |\n","|    value_loss           | 1.55e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3380000, episode_reward=14434.10 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3380000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00051760324 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.158        |\n","|    explained_variance   | 0.881         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1e+04         |\n","|    n_updates            | 16500         |\n","|    policy_gradient_loss | -0.000515     |\n","|    value_loss           | 3.98e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1651    |\n","|    time_elapsed    | 9776    |\n","|    total_timesteps | 3381248 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1652          |\n","|    time_elapsed         | 9780          |\n","|    total_timesteps      | 3383296       |\n","| train/                  |               |\n","|    approx_kl            | 0.00078368135 |\n","|    clip_fraction        | 0.00439       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.744         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 16510         |\n","|    policy_gradient_loss | -0.00166      |\n","|    value_loss           | 4.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3385000, episode_reward=11878.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3385000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012401611 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.558         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.05e+03      |\n","|    n_updates            | 16520         |\n","|    policy_gradient_loss | -0.000506     |\n","|    value_loss           | 2.37e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1653    |\n","|    time_elapsed    | 9789    |\n","|    total_timesteps | 3385344 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1654         |\n","|    time_elapsed         | 9792         |\n","|    total_timesteps      | 3387392      |\n","| train/                  |              |\n","|    approx_kl            | 7.489015e-05 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0301      |\n","|    explained_variance   | 0.593        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.63e+04     |\n","|    n_updates            | 16530        |\n","|    policy_gradient_loss | -0.000221    |\n","|    value_loss           | 1.03e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1655          |\n","|    time_elapsed         | 9795          |\n","|    total_timesteps      | 3389440       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046338738 |\n","|    clip_fraction        | 0.00122       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.174        |\n","|    explained_variance   | 0.855         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.57e+03      |\n","|    n_updates            | 16540         |\n","|    policy_gradient_loss | -0.000645     |\n","|    value_loss           | 3.19e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3390000, episode_reward=11928.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3390000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023836087 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.101        |\n","|    explained_variance   | 0.746         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.53e+04      |\n","|    n_updates            | 16550         |\n","|    policy_gradient_loss | -0.000385     |\n","|    value_loss           | 2.4e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1656    |\n","|    time_elapsed    | 9805    |\n","|    total_timesteps | 3391488 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1657          |\n","|    time_elapsed         | 9808          |\n","|    total_timesteps      | 3393536       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011942105 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.818         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 16560         |\n","|    policy_gradient_loss | -0.000154     |\n","|    value_loss           | 4.11e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3395000, episode_reward=11928.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3395000       |\n","| train/                  |               |\n","|    approx_kl            | 7.5632124e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0938       |\n","|    explained_variance   | 0.605         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.25e+04      |\n","|    n_updates            | 16570         |\n","|    policy_gradient_loss | -2.45e-05     |\n","|    value_loss           | 5.34e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1658    |\n","|    time_elapsed    | 9818    |\n","|    total_timesteps | 3395584 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1659          |\n","|    time_elapsed         | 9821          |\n","|    total_timesteps      | 3397632       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030714515 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.55          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.96e+03      |\n","|    n_updates            | 16580         |\n","|    policy_gradient_loss | -0.000405     |\n","|    value_loss           | 3.11e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1660          |\n","|    time_elapsed         | 9824          |\n","|    total_timesteps      | 3399680       |\n","| train/                  |               |\n","|    approx_kl            | 5.8902922e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0531       |\n","|    explained_variance   | 0.669         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.17e+04      |\n","|    n_updates            | 16590         |\n","|    policy_gradient_loss | -0.000176     |\n","|    value_loss           | 1.2e+05       |\n","-------------------------------------------\n","Eval num_timesteps=3400000, episode_reward=13775.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.38e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3400000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003755349 |\n","|    clip_fraction        | 0.000977     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.161       |\n","|    explained_variance   | 0.704        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.78e+04     |\n","|    n_updates            | 16600        |\n","|    policy_gradient_loss | -0.000324    |\n","|    value_loss           | 3.98e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1661    |\n","|    time_elapsed    | 9833    |\n","|    total_timesteps | 3401728 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1662         |\n","|    time_elapsed         | 9837         |\n","|    total_timesteps      | 3403776      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005321484 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0964      |\n","|    explained_variance   | 0.809        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.56e+03     |\n","|    n_updates            | 16610        |\n","|    policy_gradient_loss | -0.000855    |\n","|    value_loss           | 1.75e+04     |\n","------------------------------------------\n","Eval num_timesteps=3405000, episode_reward=14528.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3405000       |\n","| train/                  |               |\n","|    approx_kl            | 1.8209335e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.169        |\n","|    explained_variance   | 0.793         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.18e+04      |\n","|    n_updates            | 16620         |\n","|    policy_gradient_loss | -9.85e-05     |\n","|    value_loss           | 3e+04         |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1663    |\n","|    time_elapsed    | 9846    |\n","|    total_timesteps | 3405824 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1664          |\n","|    time_elapsed         | 9849          |\n","|    total_timesteps      | 3407872       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025079318 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.712         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.4e+04       |\n","|    n_updates            | 16630         |\n","|    policy_gradient_loss | -9.24e-05     |\n","|    value_loss           | 4.09e+04      |\n","-------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 346         |\n","|    iterations           | 1665        |\n","|    time_elapsed         | 9852        |\n","|    total_timesteps      | 3409920     |\n","| train/                  |             |\n","|    approx_kl            | 0.000129422 |\n","|    clip_fraction        | 0.000146    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.0905     |\n","|    explained_variance   | 0.651       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 2.32e+04    |\n","|    n_updates            | 16640       |\n","|    policy_gradient_loss | -0.00018    |\n","|    value_loss           | 6.41e+04    |\n","-----------------------------------------\n","Eval num_timesteps=3410000, episode_reward=14890.67 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.49e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3410000      |\n","| train/                  |              |\n","|    approx_kl            | 8.055882e-05 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0933      |\n","|    explained_variance   | 0.876        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.99e+03     |\n","|    n_updates            | 16650        |\n","|    policy_gradient_loss | -0.000284    |\n","|    value_loss           | 2.73e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1666    |\n","|    time_elapsed    | 9862    |\n","|    total_timesteps | 3411968 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1667          |\n","|    time_elapsed         | 9865          |\n","|    total_timesteps      | 3414016       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026456604 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.123        |\n","|    explained_variance   | 0.613         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+04      |\n","|    n_updates            | 16660         |\n","|    policy_gradient_loss | -0.000188     |\n","|    value_loss           | 3.05e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3415000, episode_reward=15029.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3415000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033961664 |\n","|    clip_fraction        | 0.00137       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0942       |\n","|    explained_variance   | 0.768         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.85e+03      |\n","|    n_updates            | 16670         |\n","|    policy_gradient_loss | -0.000262     |\n","|    value_loss           | 2.39e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1668    |\n","|    time_elapsed    | 9875    |\n","|    total_timesteps | 3416064 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 345          |\n","|    iterations           | 1669         |\n","|    time_elapsed         | 9879         |\n","|    total_timesteps      | 3418112      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004326726 |\n","|    clip_fraction        | 0.002        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.196       |\n","|    explained_variance   | 0.767        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.82e+03     |\n","|    n_updates            | 16680        |\n","|    policy_gradient_loss | -0.000395    |\n","|    value_loss           | 2.69e+04     |\n","------------------------------------------\n","Eval num_timesteps=3420000, episode_reward=14914.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3420000       |\n","| train/                  |               |\n","|    approx_kl            | 1.0570075e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0914       |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.13e+04      |\n","|    n_updates            | 16690         |\n","|    policy_gradient_loss | -3.17e-05     |\n","|    value_loss           | 3.27e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1670    |\n","|    time_elapsed    | 9888    |\n","|    total_timesteps | 3420160 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 345           |\n","|    iterations           | 1671          |\n","|    time_elapsed         | 9891          |\n","|    total_timesteps      | 3422208       |\n","| train/                  |               |\n","|    approx_kl            | 2.7884555e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0788       |\n","|    explained_variance   | 0.683         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.24e+03      |\n","|    n_updates            | 16700         |\n","|    policy_gradient_loss | -3.29e-05     |\n","|    value_loss           | 4.65e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1672          |\n","|    time_elapsed         | 9895          |\n","|    total_timesteps      | 3424256       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020807408 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.133        |\n","|    explained_variance   | 0.769         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.31e+04      |\n","|    n_updates            | 16710         |\n","|    policy_gradient_loss | -0.000271     |\n","|    value_loss           | 7.08e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3425000, episode_reward=14395.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3425000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032102378 |\n","|    clip_fraction        | 0.00112       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0851       |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.25e+03      |\n","|    n_updates            | 16720         |\n","|    policy_gradient_loss | -0.000444     |\n","|    value_loss           | 1.77e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1673    |\n","|    time_elapsed    | 9904    |\n","|    total_timesteps | 3426304 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1674          |\n","|    time_elapsed         | 9907          |\n","|    total_timesteps      | 3428352       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018828938 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.131        |\n","|    explained_variance   | 0.747         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.29e+04      |\n","|    n_updates            | 16730         |\n","|    policy_gradient_loss | -0.000397     |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3430000, episode_reward=14067.71 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3430000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034018108 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.843         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.2e+03       |\n","|    n_updates            | 16740         |\n","|    policy_gradient_loss | -0.00149      |\n","|    value_loss           | 3.63e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1675    |\n","|    time_elapsed    | 9916    |\n","|    total_timesteps | 3430400 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1676          |\n","|    time_elapsed         | 9919          |\n","|    total_timesteps      | 3432448       |\n","| train/                  |               |\n","|    approx_kl            | 6.7506306e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.661         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.17e+03      |\n","|    n_updates            | 16750         |\n","|    policy_gradient_loss | -8.56e-05     |\n","|    value_loss           | 3.09e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1677          |\n","|    time_elapsed         | 9923          |\n","|    total_timesteps      | 3434496       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027223444 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0512       |\n","|    explained_variance   | 0.562         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.93e+03      |\n","|    n_updates            | 16760         |\n","|    policy_gradient_loss | -0.000184     |\n","|    value_loss           | 3.3e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3435000, episode_reward=14606.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.46e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3435000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018537338 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.788         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.01e+04      |\n","|    n_updates            | 16770         |\n","|    policy_gradient_loss | -0.000329     |\n","|    value_loss           | 7.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1678    |\n","|    time_elapsed    | 9932    |\n","|    total_timesteps | 3436544 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1679         |\n","|    time_elapsed         | 9936         |\n","|    total_timesteps      | 3438592      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002837403 |\n","|    clip_fraction        | 0.00249      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.122       |\n","|    explained_variance   | 0.754        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.98e+03     |\n","|    n_updates            | 16780        |\n","|    policy_gradient_loss | -0.000521    |\n","|    value_loss           | 2.16e+04     |\n","------------------------------------------\n","Eval num_timesteps=3440000, episode_reward=14606.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.46e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3440000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006884893 |\n","|    clip_fraction        | 0.00581      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.13        |\n","|    explained_variance   | 0.716        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 16790        |\n","|    policy_gradient_loss | -0.00166     |\n","|    value_loss           | 3.67e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1680    |\n","|    time_elapsed    | 9944    |\n","|    total_timesteps | 3440640 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1681         |\n","|    time_elapsed         | 9948         |\n","|    total_timesteps      | 3442688      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008501763 |\n","|    clip_fraction        | 0.00317      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.155       |\n","|    explained_variance   | 0.839        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.57e+04     |\n","|    n_updates            | 16800        |\n","|    policy_gradient_loss | -0.00147     |\n","|    value_loss           | 3.92e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1682          |\n","|    time_elapsed         | 9951          |\n","|    total_timesteps      | 3444736       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010476925 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.105        |\n","|    explained_variance   | 0.693         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.85e+03      |\n","|    n_updates            | 16810         |\n","|    policy_gradient_loss | -0.000213     |\n","|    value_loss           | 2.19e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3445000, episode_reward=13983.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.4e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3445000       |\n","| train/                  |               |\n","|    approx_kl            | 2.3592904e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0411       |\n","|    explained_variance   | 0.801         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.8e+04       |\n","|    n_updates            | 16820         |\n","|    policy_gradient_loss | -0.000247     |\n","|    value_loss           | 5.03e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1683    |\n","|    time_elapsed    | 9960    |\n","|    total_timesteps | 3446784 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1684         |\n","|    time_elapsed         | 9963         |\n","|    total_timesteps      | 3448832      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002430513 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.16        |\n","|    explained_variance   | 0.857        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.53e+03     |\n","|    n_updates            | 16830        |\n","|    policy_gradient_loss | -0.000672    |\n","|    value_loss           | 4.35e+04     |\n","------------------------------------------\n","Eval num_timesteps=3450000, episode_reward=12549.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.25e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3450000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001808748 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.118       |\n","|    explained_variance   | 0.792        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.63e+03     |\n","|    n_updates            | 16840        |\n","|    policy_gradient_loss | -0.00045     |\n","|    value_loss           | 1.24e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1685    |\n","|    time_elapsed    | 9973    |\n","|    total_timesteps | 3450880 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1686          |\n","|    time_elapsed         | 9976          |\n","|    total_timesteps      | 3452928       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024446973 |\n","|    clip_fraction        | 0.00156       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.153        |\n","|    explained_variance   | 0.857         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.1e+04       |\n","|    n_updates            | 16850         |\n","|    policy_gradient_loss | -0.000834     |\n","|    value_loss           | 3.56e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1687          |\n","|    time_elapsed         | 9979          |\n","|    total_timesteps      | 3454976       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020647311 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.721         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.39e+04      |\n","|    n_updates            | 16860         |\n","|    policy_gradient_loss | -0.000107     |\n","|    value_loss           | 3.75e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3455000, episode_reward=14946.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3455000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016443612 |\n","|    clip_fraction        | 0.000928      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.109        |\n","|    explained_variance   | 0.614         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.72e+03      |\n","|    n_updates            | 16870         |\n","|    policy_gradient_loss | -0.000377     |\n","|    value_loss           | 1.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1688    |\n","|    time_elapsed    | 9988    |\n","|    total_timesteps | 3457024 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1689          |\n","|    time_elapsed         | 9992          |\n","|    total_timesteps      | 3459072       |\n","| train/                  |               |\n","|    approx_kl            | 9.7932934e-05 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.026        |\n","|    explained_variance   | 0.477         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.4e+03       |\n","|    n_updates            | 16880         |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 7e+04         |\n","-------------------------------------------\n","Eval num_timesteps=3460000, episode_reward=14946.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.49e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3460000      |\n","| train/                  |              |\n","|    approx_kl            | 4.557526e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.181       |\n","|    explained_variance   | 0.838        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 16890        |\n","|    policy_gradient_loss | -0.000432    |\n","|    value_loss           | 4.68e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1690    |\n","|    time_elapsed    | 10002   |\n","|    total_timesteps | 3461120 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1691         |\n","|    time_elapsed         | 10005        |\n","|    total_timesteps      | 3463168      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002632977 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.103       |\n","|    explained_variance   | 0.767        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.55e+03     |\n","|    n_updates            | 16900        |\n","|    policy_gradient_loss | -0.000476    |\n","|    value_loss           | 1.73e+04     |\n","------------------------------------------\n","Eval num_timesteps=3465000, episode_reward=12152.24 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.22e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3465000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00073833426 |\n","|    clip_fraction        | 0.00386       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.852         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.63e+04      |\n","|    n_updates            | 16910         |\n","|    policy_gradient_loss | -0.00166      |\n","|    value_loss           | 3.07e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 345     |\n","|    iterations      | 1692    |\n","|    time_elapsed    | 10015   |\n","|    total_timesteps | 3465216 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1693         |\n","|    time_elapsed         | 10018        |\n","|    total_timesteps      | 3467264      |\n","| train/                  |              |\n","|    approx_kl            | 7.086652e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.104       |\n","|    explained_variance   | 0.725        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.02e+04     |\n","|    n_updates            | 16920        |\n","|    policy_gradient_loss | -6.07e-05    |\n","|    value_loss           | 3.41e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1694          |\n","|    time_elapsed         | 10022         |\n","|    total_timesteps      | 3469312       |\n","| train/                  |               |\n","|    approx_kl            | 0.00045508813 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.694         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.49e+03      |\n","|    n_updates            | 16930         |\n","|    policy_gradient_loss | -0.000511     |\n","|    value_loss           | 1.42e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3470000, episode_reward=11878.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3470000       |\n","| train/                  |               |\n","|    approx_kl            | 7.1282266e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0391       |\n","|    explained_variance   | 0.748         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 16940         |\n","|    policy_gradient_loss | -5.82e-05     |\n","|    value_loss           | 6.3e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1695    |\n","|    time_elapsed    | 10031   |\n","|    total_timesteps | 3471360 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1696          |\n","|    time_elapsed         | 10034         |\n","|    total_timesteps      | 3473408       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019364574 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.853         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.28e+03      |\n","|    n_updates            | 16950         |\n","|    policy_gradient_loss | -0.000952     |\n","|    value_loss           | 3.68e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3475000, episode_reward=11992.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3475000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029604783 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.101        |\n","|    explained_variance   | 0.764         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.85e+03      |\n","|    n_updates            | 16960         |\n","|    policy_gradient_loss | -0.000179     |\n","|    value_loss           | 2.08e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1697    |\n","|    time_elapsed    | 10043   |\n","|    total_timesteps | 3475456 |\n","--------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 346         |\n","|    iterations           | 1698        |\n","|    time_elapsed         | 10047       |\n","|    total_timesteps      | 3477504     |\n","| train/                  |             |\n","|    approx_kl            | 0.000286024 |\n","|    clip_fraction        | 0.000928    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.173      |\n","|    explained_variance   | 0.855       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 6.31e+03    |\n","|    n_updates            | 16970       |\n","|    policy_gradient_loss | -0.000758   |\n","|    value_loss           | 2.58e+04    |\n","-----------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1699          |\n","|    time_elapsed         | 10051         |\n","|    total_timesteps      | 3479552       |\n","| train/                  |               |\n","|    approx_kl            | 0.00057853904 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.101        |\n","|    explained_variance   | 0.747         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.21e+04      |\n","|    n_updates            | 16980         |\n","|    policy_gradient_loss | -0.00038      |\n","|    value_loss           | 4.06e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3480000, episode_reward=11992.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.2e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3480000       |\n","| train/                  |               |\n","|    approx_kl            | 2.1071173e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0983       |\n","|    explained_variance   | 0.824         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.32e+03      |\n","|    n_updates            | 16990         |\n","|    policy_gradient_loss | -9.47e-05     |\n","|    value_loss           | 5.89e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1700    |\n","|    time_elapsed    | 10060   |\n","|    total_timesteps | 3481600 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1701          |\n","|    time_elapsed         | 10063         |\n","|    total_timesteps      | 3483648       |\n","| train/                  |               |\n","|    approx_kl            | 5.9365353e-05 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0682       |\n","|    explained_variance   | 0.908         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.32e+03      |\n","|    n_updates            | 17000         |\n","|    policy_gradient_loss | -0.000485     |\n","|    value_loss           | 2.03e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3485000, episode_reward=11878.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.19e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3485000       |\n","| train/                  |               |\n","|    approx_kl            | 3.0994357e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.686         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.72e+03      |\n","|    n_updates            | 17010         |\n","|    policy_gradient_loss | -0.000211     |\n","|    value_loss           | 1.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1702    |\n","|    time_elapsed    | 10072   |\n","|    total_timesteps | 3485696 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1703         |\n","|    time_elapsed         | 10076        |\n","|    total_timesteps      | 3487744      |\n","| train/                  |              |\n","|    approx_kl            | 4.982314e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0949      |\n","|    explained_variance   | 0.796        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.23e+03     |\n","|    n_updates            | 17020        |\n","|    policy_gradient_loss | -8.48e-06    |\n","|    value_loss           | 2.65e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1704          |\n","|    time_elapsed         | 10079         |\n","|    total_timesteps      | 3489792       |\n","| train/                  |               |\n","|    approx_kl            | 0.00066057115 |\n","|    clip_fraction        | 0.00269       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.199        |\n","|    explained_variance   | 0.841         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.01e+03      |\n","|    n_updates            | 17030         |\n","|    policy_gradient_loss | -0.00121      |\n","|    value_loss           | 2.58e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3490000, episode_reward=13085.10 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.31e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3490000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00064995897 |\n","|    clip_fraction        | 0.00503       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0882       |\n","|    explained_variance   | 0.799         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.11e+04      |\n","|    n_updates            | 17040         |\n","|    policy_gradient_loss | -0.000811     |\n","|    value_loss           | 2.79e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1705    |\n","|    time_elapsed    | 10088   |\n","|    total_timesteps | 3491840 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1706          |\n","|    time_elapsed         | 10091         |\n","|    total_timesteps      | 3493888       |\n","| train/                  |               |\n","|    approx_kl            | 2.3751636e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0836       |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.95e+04      |\n","|    n_updates            | 17050         |\n","|    policy_gradient_loss | -7.6e-05      |\n","|    value_loss           | 7.07e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3495000, episode_reward=12597.31 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.26e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3495000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003642427 |\n","|    clip_fraction        | 0.00229      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.896        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.67e+03     |\n","|    n_updates            | 17060        |\n","|    policy_gradient_loss | -0.000829    |\n","|    value_loss           | 2.14e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1707    |\n","|    time_elapsed    | 10100   |\n","|    total_timesteps | 3495936 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1708          |\n","|    time_elapsed         | 10104         |\n","|    total_timesteps      | 3497984       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011325197 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0833       |\n","|    explained_variance   | 0.673         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.28e+03      |\n","|    n_updates            | 17070         |\n","|    policy_gradient_loss | -0.00036      |\n","|    value_loss           | 2.39e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3500000, episode_reward=11824.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.18e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3500000       |\n","| train/                  |               |\n","|    approx_kl            | 2.8186478e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.811         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.31e+04      |\n","|    n_updates            | 17080         |\n","|    policy_gradient_loss | 6.66e-07      |\n","|    value_loss           | 4.72e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1709    |\n","|    time_elapsed    | 10113   |\n","|    total_timesteps | 3500032 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1710         |\n","|    time_elapsed         | 10117        |\n","|    total_timesteps      | 3502080      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005509714 |\n","|    clip_fraction        | 0.00127      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.178       |\n","|    explained_variance   | 0.876        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.89e+03     |\n","|    n_updates            | 17090        |\n","|    policy_gradient_loss | -0.000877    |\n","|    value_loss           | 3.28e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1711         |\n","|    time_elapsed         | 10120        |\n","|    total_timesteps      | 3504128      |\n","| train/                  |              |\n","|    approx_kl            | 6.436327e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.106       |\n","|    explained_variance   | 0.551        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.09e+04     |\n","|    n_updates            | 17100        |\n","|    policy_gradient_loss | -0.000209    |\n","|    value_loss           | 3.55e+04     |\n","------------------------------------------\n","Eval num_timesteps=3505000, episode_reward=13165.57 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.32e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3505000      |\n","| train/                  |              |\n","|    approx_kl            | 4.725822e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0493      |\n","|    explained_variance   | 0.788        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.21e+03     |\n","|    n_updates            | 17110        |\n","|    policy_gradient_loss | -2.4e-05     |\n","|    value_loss           | 5.41e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1712    |\n","|    time_elapsed    | 10129   |\n","|    total_timesteps | 3506176 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1713          |\n","|    time_elapsed         | 10132         |\n","|    total_timesteps      | 3508224       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047571142 |\n","|    clip_fraction        | 0.00288       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.129        |\n","|    explained_variance   | 0.898         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.09e+04      |\n","|    n_updates            | 17120         |\n","|    policy_gradient_loss | -0.001        |\n","|    value_loss           | 2.85e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3510000, episode_reward=13214.70 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.32e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 3510000        |\n","| train/                  |                |\n","|    approx_kl            | 0.000102028716 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.116         |\n","|    explained_variance   | 0.77           |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 3.05e+03       |\n","|    n_updates            | 17130          |\n","|    policy_gradient_loss | -0.000213      |\n","|    value_loss           | 1.86e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1714    |\n","|    time_elapsed    | 10141   |\n","|    total_timesteps | 3510272 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1715          |\n","|    time_elapsed         | 10145         |\n","|    total_timesteps      | 3512320       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039608325 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.798         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.92e+04      |\n","|    n_updates            | 17140         |\n","|    policy_gradient_loss | -0.000651     |\n","|    value_loss           | 4.1e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1716          |\n","|    time_elapsed         | 10148         |\n","|    total_timesteps      | 3514368       |\n","| train/                  |               |\n","|    approx_kl            | 2.0357664e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.148        |\n","|    explained_variance   | 0.875         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.77e+03      |\n","|    n_updates            | 17150         |\n","|    policy_gradient_loss | -9.44e-05     |\n","|    value_loss           | 3.24e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3515000, episode_reward=15292.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.53e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3515000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013005955 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.579         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.33e+03      |\n","|    n_updates            | 17160         |\n","|    policy_gradient_loss | -0.000233     |\n","|    value_loss           | 2.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1717    |\n","|    time_elapsed    | 10157   |\n","|    total_timesteps | 3516416 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1718          |\n","|    time_elapsed         | 10160         |\n","|    total_timesteps      | 3518464       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011826042 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0392       |\n","|    explained_variance   | 0.782         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.06e+03      |\n","|    n_updates            | 17170         |\n","|    policy_gradient_loss | -0.000916     |\n","|    value_loss           | 4.28e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3520000, episode_reward=19436.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.94e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3520000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00054903346 |\n","|    clip_fraction        | 0.0043        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.777         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.34e+04      |\n","|    n_updates            | 17180         |\n","|    policy_gradient_loss | -0.00233      |\n","|    value_loss           | 8.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1719    |\n","|    time_elapsed    | 10169   |\n","|    total_timesteps | 3520512 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1720          |\n","|    time_elapsed         | 10173         |\n","|    total_timesteps      | 3522560       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018497891 |\n","|    clip_fraction        | 0.00156       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.834         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.4e+03       |\n","|    n_updates            | 17190         |\n","|    policy_gradient_loss | -0.000616     |\n","|    value_loss           | 1.04e+04      |\n","-------------------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 346            |\n","|    iterations           | 1721           |\n","|    time_elapsed         | 10177          |\n","|    total_timesteps      | 3524608        |\n","| train/                  |                |\n","|    approx_kl            | 0.000107754604 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.139         |\n","|    explained_variance   | 0.853          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 1.33e+04       |\n","|    n_updates            | 17200          |\n","|    policy_gradient_loss | -0.000405      |\n","|    value_loss           | 3.41e+04       |\n","--------------------------------------------\n","Eval num_timesteps=3525000, episode_reward=19921.60 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.99e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3525000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017333866 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.725         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 17210         |\n","|    policy_gradient_loss | -0.000649     |\n","|    value_loss           | 4.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1722    |\n","|    time_elapsed    | 10185   |\n","|    total_timesteps | 3526656 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1723          |\n","|    time_elapsed         | 10189         |\n","|    total_timesteps      | 3528704       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017503326 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.103        |\n","|    explained_variance   | 0.618         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.18e+04      |\n","|    n_updates            | 17220         |\n","|    policy_gradient_loss | -0.000334     |\n","|    value_loss           | 2.36e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3530000, episode_reward=19214.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.92e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3530000      |\n","| train/                  |              |\n","|    approx_kl            | 4.705158e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0311      |\n","|    explained_variance   | 0.472        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.83e+04     |\n","|    n_updates            | 17230        |\n","|    policy_gradient_loss | -7.38e-05    |\n","|    value_loss           | 1.42e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1724    |\n","|    time_elapsed    | 10197   |\n","|    total_timesteps | 3530752 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1725          |\n","|    time_elapsed         | 10201         |\n","|    total_timesteps      | 3532800       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039525348 |\n","|    clip_fraction        | 0.00112       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.841         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.61e+04      |\n","|    n_updates            | 17240         |\n","|    policy_gradient_loss | -0.000903     |\n","|    value_loss           | 4.23e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1726         |\n","|    time_elapsed         | 10204        |\n","|    total_timesteps      | 3534848      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005301291 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.107       |\n","|    explained_variance   | 0.768        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.6e+03      |\n","|    n_updates            | 17250        |\n","|    policy_gradient_loss | -0.000191    |\n","|    value_loss           | 2.11e+04     |\n","------------------------------------------\n","Eval num_timesteps=3535000, episode_reward=15923.68 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.59e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3535000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004787196 |\n","|    clip_fraction        | 0.00308      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.159       |\n","|    explained_variance   | 0.886        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.54e+04     |\n","|    n_updates            | 17260        |\n","|    policy_gradient_loss | -0.000851    |\n","|    value_loss           | 3.16e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1727    |\n","|    time_elapsed    | 10213   |\n","|    total_timesteps | 3536896 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1728          |\n","|    time_elapsed         | 10217         |\n","|    total_timesteps      | 3538944       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025467874 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.655         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.96e+03      |\n","|    n_updates            | 17270         |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 4.07e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3540000, episode_reward=15868.25 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.59e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3540000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014104106 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.104        |\n","|    explained_variance   | 0.652         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.7e+04       |\n","|    n_updates            | 17280         |\n","|    policy_gradient_loss | -0.000489     |\n","|    value_loss           | 2.56e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1729    |\n","|    time_elapsed    | 10226   |\n","|    total_timesteps | 3540992 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1730         |\n","|    time_elapsed         | 10229        |\n","|    total_timesteps      | 3543040      |\n","| train/                  |              |\n","|    approx_kl            | 8.121968e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0452      |\n","|    explained_variance   | 0.664        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.82e+05     |\n","|    n_updates            | 17290        |\n","|    policy_gradient_loss | -0.000361    |\n","|    value_loss           | 1.19e+05     |\n","------------------------------------------\n","Eval num_timesteps=3545000, episode_reward=15348.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.53e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3545000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025952436 |\n","|    clip_fraction        | 0.000586      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.168        |\n","|    explained_variance   | 0.921         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.77e+04      |\n","|    n_updates            | 17300         |\n","|    policy_gradient_loss | -0.000521     |\n","|    value_loss           | 1.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1731    |\n","|    time_elapsed    | 10239   |\n","|    total_timesteps | 3545088 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1732          |\n","|    time_elapsed         | 10242         |\n","|    total_timesteps      | 3547136       |\n","| train/                  |               |\n","|    approx_kl            | 0.00060247316 |\n","|    clip_fraction        | 0.00303       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0925       |\n","|    explained_variance   | 0.829         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.95e+03      |\n","|    n_updates            | 17310         |\n","|    policy_gradient_loss | -0.000574     |\n","|    value_loss           | 1.59e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1733          |\n","|    time_elapsed         | 10245         |\n","|    total_timesteps      | 3549184       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019221668 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.178        |\n","|    explained_variance   | 0.806         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.01e+04      |\n","|    n_updates            | 17320         |\n","|    policy_gradient_loss | -0.00052      |\n","|    value_loss           | 3.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3550000, episode_reward=16417.11 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.64e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3550000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00083409366 |\n","|    clip_fraction        | 0.00693       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.102        |\n","|    explained_variance   | 0.784         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.06e+04      |\n","|    n_updates            | 17330         |\n","|    policy_gradient_loss | -0.00188      |\n","|    value_loss           | 3.74e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1734    |\n","|    time_elapsed    | 10255   |\n","|    total_timesteps | 3551232 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1735         |\n","|    time_elapsed         | 10258        |\n","|    total_timesteps      | 3553280      |\n","| train/                  |              |\n","|    approx_kl            | 6.991223e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0991      |\n","|    explained_variance   | 0.759        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.55e+04     |\n","|    n_updates            | 17340        |\n","|    policy_gradient_loss | -0.000334    |\n","|    value_loss           | 7.64e+04     |\n","------------------------------------------\n","Eval num_timesteps=3555000, episode_reward=14961.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3555000       |\n","| train/                  |               |\n","|    approx_kl            | 1.5695288e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0691       |\n","|    explained_variance   | 0.824         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.82e+04      |\n","|    n_updates            | 17350         |\n","|    policy_gradient_loss | 1.5e-05       |\n","|    value_loss           | 8.18e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1736    |\n","|    time_elapsed    | 10267   |\n","|    total_timesteps | 3555328 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1737          |\n","|    time_elapsed         | 10270         |\n","|    total_timesteps      | 3557376       |\n","| train/                  |               |\n","|    approx_kl            | 3.8619153e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.142        |\n","|    explained_variance   | 0.734         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.1e+03       |\n","|    n_updates            | 17360         |\n","|    policy_gradient_loss | -0.000127     |\n","|    value_loss           | 1.71e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1738         |\n","|    time_elapsed         | 10274        |\n","|    total_timesteps      | 3559424      |\n","| train/                  |              |\n","|    approx_kl            | 3.329653e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0977      |\n","|    explained_variance   | 0.793        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.7e+03      |\n","|    n_updates            | 17370        |\n","|    policy_gradient_loss | -0.000112    |\n","|    value_loss           | 2.32e+04     |\n","------------------------------------------\n","Eval num_timesteps=3560000, episode_reward=15261.76 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.53e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3560000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033926478 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.201        |\n","|    explained_variance   | 0.812         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.84e+03      |\n","|    n_updates            | 17380         |\n","|    policy_gradient_loss | -0.000699     |\n","|    value_loss           | 3.7e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1739    |\n","|    time_elapsed    | 10283   |\n","|    total_timesteps | 3561472 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1740         |\n","|    time_elapsed         | 10286        |\n","|    total_timesteps      | 3563520      |\n","| train/                  |              |\n","|    approx_kl            | 9.837246e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0852      |\n","|    explained_variance   | 0.753        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.82e+03     |\n","|    n_updates            | 17390        |\n","|    policy_gradient_loss | -0.000197    |\n","|    value_loss           | 3.08e+04     |\n","------------------------------------------\n","Eval num_timesteps=3565000, episode_reward=15594.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.56e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3565000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013270008 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0872       |\n","|    explained_variance   | 0.769         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.56e+04      |\n","|    n_updates            | 17400         |\n","|    policy_gradient_loss | -0.000527     |\n","|    value_loss           | 4.77e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1741    |\n","|    time_elapsed    | 10296   |\n","|    total_timesteps | 3565568 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1742          |\n","|    time_elapsed         | 10299         |\n","|    total_timesteps      | 3567616       |\n","| train/                  |               |\n","|    approx_kl            | 1.6174221e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.93e+03      |\n","|    n_updates            | 17410         |\n","|    policy_gradient_loss | 6.83e-05      |\n","|    value_loss           | 6.75e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1743         |\n","|    time_elapsed         | 10303        |\n","|    total_timesteps      | 3569664      |\n","| train/                  |              |\n","|    approx_kl            | 7.075121e-05 |\n","|    clip_fraction        | 0.000439     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0858      |\n","|    explained_variance   | 0.748        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.13e+03     |\n","|    n_updates            | 17420        |\n","|    policy_gradient_loss | -0.000324    |\n","|    value_loss           | 1.3e+04      |\n","------------------------------------------\n","Eval num_timesteps=3570000, episode_reward=15483.69 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.55e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3570000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006221053 |\n","|    clip_fraction        | 0.0061       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.118       |\n","|    explained_variance   | 0.822        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.67e+03     |\n","|    n_updates            | 17430        |\n","|    policy_gradient_loss | -0.00125     |\n","|    value_loss           | 3.3e+04      |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1744    |\n","|    time_elapsed    | 10312   |\n","|    total_timesteps | 3571712 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1745          |\n","|    time_elapsed         | 10315         |\n","|    total_timesteps      | 3573760       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020740795 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.183        |\n","|    explained_variance   | 0.873         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.67e+03      |\n","|    n_updates            | 17440         |\n","|    policy_gradient_loss | -0.000513     |\n","|    value_loss           | 2.47e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3575000, episode_reward=18834.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.88e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3575000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00045741716 |\n","|    clip_fraction        | 0.0041        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.112        |\n","|    explained_variance   | 0.771         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.2e+03       |\n","|    n_updates            | 17450         |\n","|    policy_gradient_loss | -0.00125      |\n","|    value_loss           | 2.22e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1746    |\n","|    time_elapsed    | 10325   |\n","|    total_timesteps | 3575808 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1747          |\n","|    time_elapsed         | 10328         |\n","|    total_timesteps      | 3577856       |\n","| train/                  |               |\n","|    approx_kl            | 3.5342935e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0561       |\n","|    explained_variance   | 0.581         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.43e+04      |\n","|    n_updates            | 17460         |\n","|    policy_gradient_loss | -0.00023      |\n","|    value_loss           | 9.72e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1748          |\n","|    time_elapsed         | 10331         |\n","|    total_timesteps      | 3579904       |\n","| train/                  |               |\n","|    approx_kl            | 5.5712502e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.876         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.01e+04      |\n","|    n_updates            | 17470         |\n","|    policy_gradient_loss | -0.000208     |\n","|    value_loss           | 4.7e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3580000, episode_reward=15244.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.52e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3580000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029688058 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.106        |\n","|    explained_variance   | 0.711         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.65e+03      |\n","|    n_updates            | 17480         |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 3e+04         |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1749    |\n","|    time_elapsed    | 10340   |\n","|    total_timesteps | 3581952 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1750         |\n","|    time_elapsed         | 10344        |\n","|    total_timesteps      | 3584000      |\n","| train/                  |              |\n","|    approx_kl            | 5.548945e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.139       |\n","|    explained_variance   | 0.782        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.16e+04     |\n","|    n_updates            | 17490        |\n","|    policy_gradient_loss | -0.000317    |\n","|    value_loss           | 3.98e+04     |\n","------------------------------------------\n","Eval num_timesteps=3585000, episode_reward=18834.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.88e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3585000      |\n","| train/                  |              |\n","|    approx_kl            | 6.472482e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.151       |\n","|    explained_variance   | 0.872        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.1e+03      |\n","|    n_updates            | 17500        |\n","|    policy_gradient_loss | -9.39e-05    |\n","|    value_loss           | 3.39e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1751    |\n","|    time_elapsed    | 10353   |\n","|    total_timesteps | 3586048 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1752         |\n","|    time_elapsed         | 10357        |\n","|    total_timesteps      | 3588096      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003443901 |\n","|    clip_fraction        | 0.00215      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.111       |\n","|    explained_variance   | 0.746        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.33e+03     |\n","|    n_updates            | 17510        |\n","|    policy_gradient_loss | -0.000963    |\n","|    value_loss           | 3.37e+04     |\n","------------------------------------------\n","Eval num_timesteps=3590000, episode_reward=14827.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.48e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3590000       |\n","| train/                  |               |\n","|    approx_kl            | 8.2332845e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0459       |\n","|    explained_variance   | 0.835         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.33e+04      |\n","|    n_updates            | 17520         |\n","|    policy_gradient_loss | -0.000427     |\n","|    value_loss           | 4.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1753    |\n","|    time_elapsed    | 10366   |\n","|    total_timesteps | 3590144 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1754          |\n","|    time_elapsed         | 10370         |\n","|    total_timesteps      | 3592192       |\n","| train/                  |               |\n","|    approx_kl            | 4.1140942e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.15         |\n","|    explained_variance   | 0.757         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.31e+04      |\n","|    n_updates            | 17530         |\n","|    policy_gradient_loss | -0.000148     |\n","|    value_loss           | 8.29e+04      |\n","-------------------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 346            |\n","|    iterations           | 1755           |\n","|    time_elapsed         | 10373          |\n","|    total_timesteps      | 3594240        |\n","| train/                  |                |\n","|    approx_kl            | 0.000115376315 |\n","|    clip_fraction        | 0.000342       |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.127         |\n","|    explained_variance   | 0.719          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 4.36e+03       |\n","|    n_updates            | 17540          |\n","|    policy_gradient_loss | -0.00017       |\n","|    value_loss           | 1.74e+04       |\n","--------------------------------------------\n","Eval num_timesteps=3595000, episode_reward=14827.72 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.48e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3595000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018439084 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.855         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.16e+04      |\n","|    n_updates            | 17550         |\n","|    policy_gradient_loss | -0.000325     |\n","|    value_loss           | 3.23e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1756    |\n","|    time_elapsed    | 10382   |\n","|    total_timesteps | 3596288 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1757         |\n","|    time_elapsed         | 10385        |\n","|    total_timesteps      | 3598336      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008571613 |\n","|    clip_fraction        | 0.00518      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.136       |\n","|    explained_variance   | 0.721        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.78e+04     |\n","|    n_updates            | 17560        |\n","|    policy_gradient_loss | -0.000939    |\n","|    value_loss           | 4.83e+04     |\n","------------------------------------------\n","Eval num_timesteps=3600000, episode_reward=17897.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.79e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3600000       |\n","| train/                  |               |\n","|    approx_kl            | 3.3325603e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.105        |\n","|    explained_variance   | 0.678         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.13e+04      |\n","|    n_updates            | 17570         |\n","|    policy_gradient_loss | -0.000216     |\n","|    value_loss           | 2.35e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1758    |\n","|    time_elapsed    | 10394   |\n","|    total_timesteps | 3600384 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1759          |\n","|    time_elapsed         | 10398         |\n","|    total_timesteps      | 3602432       |\n","| train/                  |               |\n","|    approx_kl            | 2.6386726e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0351       |\n","|    explained_variance   | 0.552         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.47e+05      |\n","|    n_updates            | 17580         |\n","|    policy_gradient_loss | -9.91e-05     |\n","|    value_loss           | 1.32e+05      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1760         |\n","|    time_elapsed         | 10401        |\n","|    total_timesteps      | 3604480      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001864119 |\n","|    clip_fraction        | 0.00142      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.175       |\n","|    explained_variance   | 0.823        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 17590        |\n","|    policy_gradient_loss | -0.000924    |\n","|    value_loss           | 4.25e+04     |\n","------------------------------------------\n","Eval num_timesteps=3605000, episode_reward=14538.13 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.45e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3605000      |\n","| train/                  |              |\n","|    approx_kl            | 4.566068e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.107       |\n","|    explained_variance   | 0.58         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.62e+03     |\n","|    n_updates            | 17600        |\n","|    policy_gradient_loss | -0.000353    |\n","|    value_loss           | 2.15e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1761    |\n","|    time_elapsed    | 10410   |\n","|    total_timesteps | 3606528 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1762          |\n","|    time_elapsed         | 10414         |\n","|    total_timesteps      | 3608576       |\n","| train/                  |               |\n","|    approx_kl            | 0.00048135748 |\n","|    clip_fraction        | 0.002         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.867         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.69e+03      |\n","|    n_updates            | 17610         |\n","|    policy_gradient_loss | -0.00102      |\n","|    value_loss           | 2.64e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3610000, episode_reward=14756.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.48e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3610000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034673928 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.653         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.14e+03      |\n","|    n_updates            | 17620         |\n","|    policy_gradient_loss | -0.00056      |\n","|    value_loss           | 4.16e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1763    |\n","|    time_elapsed    | 10423   |\n","|    total_timesteps | 3610624 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1764          |\n","|    time_elapsed         | 10427         |\n","|    total_timesteps      | 3612672       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017783485 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.616         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.72e+03      |\n","|    n_updates            | 17630         |\n","|    policy_gradient_loss | -0.000236     |\n","|    value_loss           | 2.06e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1765         |\n","|    time_elapsed         | 10431        |\n","|    total_timesteps      | 3614720      |\n","| train/                  |              |\n","|    approx_kl            | 7.899181e-05 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0437      |\n","|    explained_variance   | 0.472        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.9e+04      |\n","|    n_updates            | 17640        |\n","|    policy_gradient_loss | -0.000307    |\n","|    value_loss           | 1.73e+05     |\n","------------------------------------------\n","Eval num_timesteps=3615000, episode_reward=17088.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.71e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3615000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014233124 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.165        |\n","|    explained_variance   | 0.823         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.09e+03      |\n","|    n_updates            | 17650         |\n","|    policy_gradient_loss | -0.000457     |\n","|    value_loss           | 2.86e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1766    |\n","|    time_elapsed    | 10440   |\n","|    total_timesteps | 3616768 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1767          |\n","|    time_elapsed         | 10444         |\n","|    total_timesteps      | 3618816       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032957364 |\n","|    clip_fraction        | 0.00254       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0979       |\n","|    explained_variance   | 0.776         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.85e+03      |\n","|    n_updates            | 17660         |\n","|    policy_gradient_loss | -0.000922     |\n","|    value_loss           | 2.13e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3620000, episode_reward=15240.97 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.52e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3620000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043829394 |\n","|    clip_fraction        | 0.00107       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.797         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.72e+03      |\n","|    n_updates            | 17670         |\n","|    policy_gradient_loss | -0.000255     |\n","|    value_loss           | 2.82e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1768    |\n","|    time_elapsed    | 10452   |\n","|    total_timesteps | 3620864 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1769          |\n","|    time_elapsed         | 10456         |\n","|    total_timesteps      | 3622912       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023867618 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0989       |\n","|    explained_variance   | 0.704         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.72e+03      |\n","|    n_updates            | 17680         |\n","|    policy_gradient_loss | -0.000368     |\n","|    value_loss           | 3.73e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1770          |\n","|    time_elapsed         | 10459         |\n","|    total_timesteps      | 3624960       |\n","| train/                  |               |\n","|    approx_kl            | 5.5709475e-05 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.105        |\n","|    explained_variance   | 0.641         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.22e+04      |\n","|    n_updates            | 17690         |\n","|    policy_gradient_loss | -0.000317     |\n","|    value_loss           | 4.88e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3625000, episode_reward=15049.65 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.5e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 3625000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002178037 |\n","|    clip_fraction        | 0.000586     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0617      |\n","|    explained_variance   | 0.826        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.77e+04     |\n","|    n_updates            | 17700        |\n","|    policy_gradient_loss | -0.00065     |\n","|    value_loss           | 5.96e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1771    |\n","|    time_elapsed    | 10468   |\n","|    total_timesteps | 3627008 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1772          |\n","|    time_elapsed         | 10472         |\n","|    total_timesteps      | 3629056       |\n","| train/                  |               |\n","|    approx_kl            | 1.6479025e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.776         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.02e+03      |\n","|    n_updates            | 17710         |\n","|    policy_gradient_loss | -7.48e-05     |\n","|    value_loss           | 1.86e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3630000, episode_reward=14076.49 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.41e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3630000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00033615998 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0937       |\n","|    explained_variance   | 0.748         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.13e+03      |\n","|    n_updates            | 17720         |\n","|    policy_gradient_loss | -0.000119     |\n","|    value_loss           | 1.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1773    |\n","|    time_elapsed    | 10480   |\n","|    total_timesteps | 3631104 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1774          |\n","|    time_elapsed         | 10484         |\n","|    total_timesteps      | 3633152       |\n","| train/                  |               |\n","|    approx_kl            | 5.5862474e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.197        |\n","|    explained_variance   | 0.83          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.43e+04      |\n","|    n_updates            | 17730         |\n","|    policy_gradient_loss | 8.45e-06      |\n","|    value_loss           | 3.16e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3635000, episode_reward=15037.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3635000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026736618 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0831       |\n","|    explained_variance   | 0.777         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.78e+03      |\n","|    n_updates            | 17740         |\n","|    policy_gradient_loss | -1.56e-05     |\n","|    value_loss           | 2.42e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1775    |\n","|    time_elapsed    | 10493   |\n","|    total_timesteps | 3635200 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1776          |\n","|    time_elapsed         | 10497         |\n","|    total_timesteps      | 3637248       |\n","| train/                  |               |\n","|    approx_kl            | 4.9261056e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0856       |\n","|    explained_variance   | 0.573         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.51e+04      |\n","|    n_updates            | 17750         |\n","|    policy_gradient_loss | 3.36e-05      |\n","|    value_loss           | 5.16e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1777          |\n","|    time_elapsed         | 10500         |\n","|    total_timesteps      | 3639296       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012483899 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.119        |\n","|    explained_variance   | 0.761         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.36e+04      |\n","|    n_updates            | 17760         |\n","|    policy_gradient_loss | -0.00111      |\n","|    value_loss           | 1.29e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3640000, episode_reward=14709.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.47e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3640000       |\n","| train/                  |               |\n","|    approx_kl            | 2.7470553e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0914       |\n","|    explained_variance   | 0.67          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.84e+03      |\n","|    n_updates            | 17770         |\n","|    policy_gradient_loss | -0.000119     |\n","|    value_loss           | 1.72e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1778    |\n","|    time_elapsed    | 10509   |\n","|    total_timesteps | 3641344 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1779          |\n","|    time_elapsed         | 10513         |\n","|    total_timesteps      | 3643392       |\n","| train/                  |               |\n","|    approx_kl            | 6.3903863e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.104        |\n","|    explained_variance   | 0.804         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.46e+03      |\n","|    n_updates            | 17780         |\n","|    policy_gradient_loss | 2.38e-05      |\n","|    value_loss           | 2.42e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3645000, episode_reward=15037.14 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3645000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030351873 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.18         |\n","|    explained_variance   | 0.882         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.55e+03      |\n","|    n_updates            | 17790         |\n","|    policy_gradient_loss | -0.00048      |\n","|    value_loss           | 2.53e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1780    |\n","|    time_elapsed    | 10521   |\n","|    total_timesteps | 3645440 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1781          |\n","|    time_elapsed         | 10525         |\n","|    total_timesteps      | 3647488       |\n","| train/                  |               |\n","|    approx_kl            | 0.00019279035 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.112        |\n","|    explained_variance   | 0.722         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.66e+03      |\n","|    n_updates            | 17800         |\n","|    policy_gradient_loss | -0.000336     |\n","|    value_loss           | 2.79e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1782         |\n","|    time_elapsed         | 10528        |\n","|    total_timesteps      | 3649536      |\n","| train/                  |              |\n","|    approx_kl            | 6.114249e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0563      |\n","|    explained_variance   | 0.685        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.03e+03     |\n","|    n_updates            | 17810        |\n","|    policy_gradient_loss | -9.29e-05    |\n","|    value_loss           | 5.57e+04     |\n","------------------------------------------\n","Eval num_timesteps=3650000, episode_reward=14905.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3650000       |\n","| train/                  |               |\n","|    approx_kl            | 2.3579836e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.836         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.44e+04      |\n","|    n_updates            | 17820         |\n","|    policy_gradient_loss | -3.27e-05     |\n","|    value_loss           | 6.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1783    |\n","|    time_elapsed    | 10538   |\n","|    total_timesteps | 3651584 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1784         |\n","|    time_elapsed         | 10541        |\n","|    total_timesteps      | 3653632      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006562935 |\n","|    clip_fraction        | 0.00498      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0908      |\n","|    explained_variance   | 0.752        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.95e+03     |\n","|    n_updates            | 17830        |\n","|    policy_gradient_loss | -0.00147     |\n","|    value_loss           | 1.7e+04      |\n","------------------------------------------\n","Eval num_timesteps=3655000, episode_reward=14905.83 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.49e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3655000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00062323536 |\n","|    clip_fraction        | 0.00298       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.136        |\n","|    explained_variance   | 0.775         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.62e+04      |\n","|    n_updates            | 17840         |\n","|    policy_gradient_loss | -0.00131      |\n","|    value_loss           | 3.42e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1785    |\n","|    time_elapsed    | 10551   |\n","|    total_timesteps | 3655680 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1786         |\n","|    time_elapsed         | 10554        |\n","|    total_timesteps      | 3657728      |\n","| train/                  |              |\n","|    approx_kl            | 0.0008227421 |\n","|    clip_fraction        | 0.00513      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.152       |\n","|    explained_variance   | 0.877        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.35e+03     |\n","|    n_updates            | 17850        |\n","|    policy_gradient_loss | -0.00133     |\n","|    value_loss           | 2.83e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1787          |\n","|    time_elapsed         | 10558         |\n","|    total_timesteps      | 3659776       |\n","| train/                  |               |\n","|    approx_kl            | 3.3948658e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.103        |\n","|    explained_variance   | 0.695         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.39e+03      |\n","|    n_updates            | 17860         |\n","|    policy_gradient_loss | -0.000102     |\n","|    value_loss           | 4.06e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3660000, episode_reward=18884.37 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.89e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3660000      |\n","| train/                  |              |\n","|    approx_kl            | 3.985013e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0508      |\n","|    explained_variance   | 0.773        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.92e+03     |\n","|    n_updates            | 17870        |\n","|    policy_gradient_loss | -8.49e-05    |\n","|    value_loss           | 4.57e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1788    |\n","|    time_elapsed    | 10567   |\n","|    total_timesteps | 3661824 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1789          |\n","|    time_elapsed         | 10570         |\n","|    total_timesteps      | 3663872       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030713296 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.149        |\n","|    explained_variance   | 0.81          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.76e+04      |\n","|    n_updates            | 17880         |\n","|    policy_gradient_loss | -0.000771     |\n","|    value_loss           | 9.19e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3665000, episode_reward=15232.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.52e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3665000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027822654 |\n","|    clip_fraction        | 0.00205       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.121        |\n","|    explained_variance   | 0.809         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.53e+03      |\n","|    n_updates            | 17890         |\n","|    policy_gradient_loss | -0.000591     |\n","|    value_loss           | 1.11e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1790    |\n","|    time_elapsed    | 10579   |\n","|    total_timesteps | 3665920 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1791          |\n","|    time_elapsed         | 10583         |\n","|    total_timesteps      | 3667968       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031338874 |\n","|    clip_fraction        | 0.0019        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.131        |\n","|    explained_variance   | 0.875         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.78e+04      |\n","|    n_updates            | 17900         |\n","|    policy_gradient_loss | -0.000751     |\n","|    value_loss           | 2.8e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3670000, episode_reward=17393.29 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.74e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3670000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00053034606 |\n","|    clip_fraction        | 0.0021        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.755         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.49e+04      |\n","|    n_updates            | 17910         |\n","|    policy_gradient_loss | -0.000323     |\n","|    value_loss           | 3.62e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1792    |\n","|    time_elapsed    | 10592   |\n","|    total_timesteps | 3670016 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1793          |\n","|    time_elapsed         | 10595         |\n","|    total_timesteps      | 3672064       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015040324 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.097        |\n","|    explained_variance   | 0.69          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.05e+03      |\n","|    n_updates            | 17920         |\n","|    policy_gradient_loss | -0.000369     |\n","|    value_loss           | 2.24e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1794         |\n","|    time_elapsed         | 10599        |\n","|    total_timesteps      | 3674112      |\n","| train/                  |              |\n","|    approx_kl            | 9.405095e-05 |\n","|    clip_fraction        | 0.000342     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0441      |\n","|    explained_variance   | 0.678        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.03e+04     |\n","|    n_updates            | 17930        |\n","|    policy_gradient_loss | -0.000104    |\n","|    value_loss           | 1.43e+05     |\n","------------------------------------------\n","Eval num_timesteps=3675000, episode_reward=23135.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.31e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3675000      |\n","| train/                  |              |\n","|    approx_kl            | 8.733419e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.171       |\n","|    explained_variance   | 0.793        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.08e+04     |\n","|    n_updates            | 17940        |\n","|    policy_gradient_loss | -0.000174    |\n","|    value_loss           | 4.55e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1795    |\n","|    time_elapsed    | 10608   |\n","|    total_timesteps | 3676160 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1796          |\n","|    time_elapsed         | 10612         |\n","|    total_timesteps      | 3678208       |\n","| train/                  |               |\n","|    approx_kl            | 0.00060615735 |\n","|    clip_fraction        | 0.00298       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.105        |\n","|    explained_variance   | 0.737         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.75e+03      |\n","|    n_updates            | 17950         |\n","|    policy_gradient_loss | -0.00107      |\n","|    value_loss           | 1.93e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3680000, episode_reward=19893.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.99e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3680000      |\n","| train/                  |              |\n","|    approx_kl            | 9.180038e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.156       |\n","|    explained_variance   | 0.892        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.64e+04     |\n","|    n_updates            | 17960        |\n","|    policy_gradient_loss | -0.000222    |\n","|    value_loss           | 2.91e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1797    |\n","|    time_elapsed    | 10621   |\n","|    total_timesteps | 3680256 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1798          |\n","|    time_elapsed         | 10624         |\n","|    total_timesteps      | 3682304       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015538675 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.11         |\n","|    explained_variance   | 0.742         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.88e+04      |\n","|    n_updates            | 17970         |\n","|    policy_gradient_loss | -0.000392     |\n","|    value_loss           | 2.92e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1799          |\n","|    time_elapsed         | 10628         |\n","|    total_timesteps      | 3684352       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034130845 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.739         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.04e+03      |\n","|    n_updates            | 17980         |\n","|    policy_gradient_loss | -0.000454     |\n","|    value_loss           | 1.23e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3685000, episode_reward=23135.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.31e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3685000       |\n","| train/                  |               |\n","|    approx_kl            | 2.5756308e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0478       |\n","|    explained_variance   | 0.68          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.15e+04      |\n","|    n_updates            | 17990         |\n","|    policy_gradient_loss | -0.000155     |\n","|    value_loss           | 1.51e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1800    |\n","|    time_elapsed    | 10637   |\n","|    total_timesteps | 3686400 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1801         |\n","|    time_elapsed         | 10640        |\n","|    total_timesteps      | 3688448      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005220183 |\n","|    clip_fraction        | 0.00132      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.897        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.13e+03     |\n","|    n_updates            | 18000        |\n","|    policy_gradient_loss | -0.000894    |\n","|    value_loss           | 2.63e+04     |\n","------------------------------------------\n","Eval num_timesteps=3690000, episode_reward=23708.58 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.37e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3690000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013283698 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0998       |\n","|    explained_variance   | 0.811         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.78e+03      |\n","|    n_updates            | 18010         |\n","|    policy_gradient_loss | -0.00013      |\n","|    value_loss           | 1.65e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1802    |\n","|    time_elapsed    | 10649   |\n","|    total_timesteps | 3690496 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1803          |\n","|    time_elapsed         | 10653         |\n","|    total_timesteps      | 3692544       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040208214 |\n","|    clip_fraction        | 0.00132       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.842         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.78e+03      |\n","|    n_updates            | 18020         |\n","|    policy_gradient_loss | -0.000597     |\n","|    value_loss           | 2.78e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1804          |\n","|    time_elapsed         | 10656         |\n","|    total_timesteps      | 3694592       |\n","| train/                  |               |\n","|    approx_kl            | 5.2354066e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0998       |\n","|    explained_variance   | 0.701         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.19e+04      |\n","|    n_updates            | 18030         |\n","|    policy_gradient_loss | -8.25e-05     |\n","|    value_loss           | 5.31e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3695000, episode_reward=19815.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.98e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3695000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001795511 |\n","|    clip_fraction        | 0.000244     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.113       |\n","|    explained_variance   | 0.744        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.84e+03     |\n","|    n_updates            | 18040        |\n","|    policy_gradient_loss | -0.000747    |\n","|    value_loss           | 4.75e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1805    |\n","|    time_elapsed    | 10666   |\n","|    total_timesteps | 3696640 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1806         |\n","|    time_elapsed         | 10669        |\n","|    total_timesteps      | 3698688      |\n","| train/                  |              |\n","|    approx_kl            | 2.094108e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0665      |\n","|    explained_variance   | 0.762        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.18e+04     |\n","|    n_updates            | 18050        |\n","|    policy_gradient_loss | 1.15e-05     |\n","|    value_loss           | 1.56e+05     |\n","------------------------------------------\n","Eval num_timesteps=3700000, episode_reward=18036.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.8e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3700000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044842053 |\n","|    clip_fraction        | 0.00244       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.146        |\n","|    explained_variance   | 0.891         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.64e+03      |\n","|    n_updates            | 18060         |\n","|    policy_gradient_loss | -0.000768     |\n","|    value_loss           | 1.34e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1807    |\n","|    time_elapsed    | 10678   |\n","|    total_timesteps | 3700736 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1808          |\n","|    time_elapsed         | 10682         |\n","|    total_timesteps      | 3702784       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010556809 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.102        |\n","|    explained_variance   | 0.789         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.1e+03       |\n","|    n_updates            | 18070         |\n","|    policy_gradient_loss | -0.00035      |\n","|    value_loss           | 2.4e+04       |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1809          |\n","|    time_elapsed         | 10685         |\n","|    total_timesteps      | 3704832       |\n","| train/                  |               |\n","|    approx_kl            | 0.00047787087 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.187        |\n","|    explained_variance   | 0.848         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.31e+03      |\n","|    n_updates            | 18080         |\n","|    policy_gradient_loss | -0.000667     |\n","|    value_loss           | 4.33e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3705000, episode_reward=19815.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.98e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3705000       |\n","| train/                  |               |\n","|    approx_kl            | 4.3033273e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0965       |\n","|    explained_variance   | 0.749         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.22e+03      |\n","|    n_updates            | 18090         |\n","|    policy_gradient_loss | -0.000108     |\n","|    value_loss           | 2.92e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1810    |\n","|    time_elapsed    | 10694   |\n","|    total_timesteps | 3706880 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1811          |\n","|    time_elapsed         | 10698         |\n","|    total_timesteps      | 3708928       |\n","| train/                  |               |\n","|    approx_kl            | 9.2144066e-05 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0913       |\n","|    explained_variance   | 0.711         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.96e+04      |\n","|    n_updates            | 18100         |\n","|    policy_gradient_loss | -0.000701     |\n","|    value_loss           | 5.41e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3710000, episode_reward=19378.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.94e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3710000      |\n","| train/                  |              |\n","|    approx_kl            | 7.433546e-05 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.119       |\n","|    explained_variance   | 0.806        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.27e+04     |\n","|    n_updates            | 18110        |\n","|    policy_gradient_loss | -0.00014     |\n","|    value_loss           | 8.59e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1812    |\n","|    time_elapsed    | 10707   |\n","|    total_timesteps | 3710976 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1813         |\n","|    time_elapsed         | 10710        |\n","|    total_timesteps      | 3713024      |\n","| train/                  |              |\n","|    approx_kl            | 7.263539e-05 |\n","|    clip_fraction        | 9.77e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0968      |\n","|    explained_variance   | 0.739        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.12e+03     |\n","|    n_updates            | 18120        |\n","|    policy_gradient_loss | -0.000251    |\n","|    value_loss           | 2.01e+04     |\n","------------------------------------------\n","Eval num_timesteps=3715000, episode_reward=19815.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","--------------------------------------------\n","| eval/                   |                |\n","|    mean_ep_length       | 1.97e+03       |\n","|    mean_reward          | 1.98e+04       |\n","| time/                   |                |\n","|    total_timesteps      | 3715000        |\n","| train/                  |                |\n","|    approx_kl            | 1.25764345e-05 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.114         |\n","|    explained_variance   | 0.765          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 9.92e+03       |\n","|    n_updates            | 18130          |\n","|    policy_gradient_loss | -8.75e-05      |\n","|    value_loss           | 3.77e+04       |\n","--------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1814    |\n","|    time_elapsed    | 10719   |\n","|    total_timesteps | 3715072 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1815          |\n","|    time_elapsed         | 10723         |\n","|    total_timesteps      | 3717120       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027079775 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.87          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.16e+03      |\n","|    n_updates            | 18140         |\n","|    policy_gradient_loss | -1.15e-05     |\n","|    value_loss           | 2.84e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1816         |\n","|    time_elapsed         | 10726        |\n","|    total_timesteps      | 3719168      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001880133 |\n","|    clip_fraction        | 0.000293     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.109       |\n","|    explained_variance   | 0.614        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.26e+04     |\n","|    n_updates            | 18150        |\n","|    policy_gradient_loss | -0.000221    |\n","|    value_loss           | 4.84e+04     |\n","------------------------------------------\n","Eval num_timesteps=3720000, episode_reward=18036.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 1.8e+04      |\n","| time/                   |              |\n","|    total_timesteps      | 3720000      |\n","| train/                  |              |\n","|    approx_kl            | 6.762857e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0725      |\n","|    explained_variance   | 0.387        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.64e+04     |\n","|    n_updates            | 18160        |\n","|    policy_gradient_loss | -3.88e-05    |\n","|    value_loss           | 9.11e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1817    |\n","|    time_elapsed    | 10735   |\n","|    total_timesteps | 3721216 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1818         |\n","|    time_elapsed         | 10739        |\n","|    total_timesteps      | 3723264      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003392332 |\n","|    clip_fraction        | 0.00146      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.135       |\n","|    explained_variance   | 0.797        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.46e+04     |\n","|    n_updates            | 18170        |\n","|    policy_gradient_loss | -0.000793    |\n","|    value_loss           | 6.55e+04     |\n","------------------------------------------\n","Eval num_timesteps=3725000, episode_reward=17871.94 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.79e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3725000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00056039816 |\n","|    clip_fraction        | 0.00303       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0969       |\n","|    explained_variance   | 0.667         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.19e+03      |\n","|    n_updates            | 18180         |\n","|    policy_gradient_loss | -0.000706     |\n","|    value_loss           | 2.48e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1819    |\n","|    time_elapsed    | 10748   |\n","|    total_timesteps | 3725312 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1820          |\n","|    time_elapsed         | 10751         |\n","|    total_timesteps      | 3727360       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018274228 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.794         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.75e+03      |\n","|    n_updates            | 18190         |\n","|    policy_gradient_loss | -0.000149     |\n","|    value_loss           | 3.34e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1821          |\n","|    time_elapsed         | 10755         |\n","|    total_timesteps      | 3729408       |\n","| train/                  |               |\n","|    approx_kl            | 0.00054891984 |\n","|    clip_fraction        | 0.00352       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.155        |\n","|    explained_variance   | 0.854         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.37e+04      |\n","|    n_updates            | 18200         |\n","|    policy_gradient_loss | -0.0014       |\n","|    value_loss           | 3.39e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3730000, episode_reward=18559.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.86e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3730000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00041693336 |\n","|    clip_fraction        | 0.00083       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.112        |\n","|    explained_variance   | 0.73          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.49e+03      |\n","|    n_updates            | 18210         |\n","|    policy_gradient_loss | -0.000466     |\n","|    value_loss           | 1.95e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1822    |\n","|    time_elapsed    | 10764   |\n","|    total_timesteps | 3731456 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1823         |\n","|    time_elapsed         | 10767        |\n","|    total_timesteps      | 3733504      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003581375 |\n","|    clip_fraction        | 0.00137      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0607      |\n","|    explained_variance   | 0.381        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.56e+04     |\n","|    n_updates            | 18220        |\n","|    policy_gradient_loss | -0.000441    |\n","|    value_loss           | 6.56e+04     |\n","------------------------------------------\n","Eval num_timesteps=3735000, episode_reward=18559.02 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 1.86e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 3735000     |\n","| train/                  |             |\n","|    approx_kl            | 0.000293809 |\n","|    clip_fraction        | 0.000684    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.145      |\n","|    explained_variance   | 0.814       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.58e+04    |\n","|    n_updates            | 18230       |\n","|    policy_gradient_loss | -0.000556   |\n","|    value_loss           | 4.61e+04    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1824    |\n","|    time_elapsed    | 10777   |\n","|    total_timesteps | 3735552 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1825         |\n","|    time_elapsed         | 10780        |\n","|    total_timesteps      | 3737600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002965407 |\n","|    clip_fraction        | 0.0019       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.124       |\n","|    explained_variance   | 0.717        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.87e+03     |\n","|    n_updates            | 18240        |\n","|    policy_gradient_loss | -0.000805    |\n","|    value_loss           | 1.86e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1826         |\n","|    time_elapsed         | 10783        |\n","|    total_timesteps      | 3739648      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003127494 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.137       |\n","|    explained_variance   | 0.781        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.03e+04     |\n","|    n_updates            | 18250        |\n","|    policy_gradient_loss | -0.000262    |\n","|    value_loss           | 2.95e+04     |\n","------------------------------------------\n","Eval num_timesteps=3740000, episode_reward=20637.46 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","----------------------------------------\n","| eval/                   |            |\n","|    mean_ep_length       | 1.97e+03   |\n","|    mean_reward          | 2.06e+04   |\n","| time/                   |            |\n","|    total_timesteps      | 3740000    |\n","| train/                  |            |\n","|    approx_kl            | 0.00078971 |\n","|    clip_fraction        | 0.00322    |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.142     |\n","|    explained_variance   | 0.799      |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 8.03e+03   |\n","|    n_updates            | 18260      |\n","|    policy_gradient_loss | -0.00175   |\n","|    value_loss           | 3.63e+04   |\n","----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1827    |\n","|    time_elapsed    | 10793   |\n","|    total_timesteps | 3741696 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1828         |\n","|    time_elapsed         | 10796        |\n","|    total_timesteps      | 3743744      |\n","| train/                  |              |\n","|    approx_kl            | 1.963554e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.105       |\n","|    explained_variance   | 0.69         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4e+03        |\n","|    n_updates            | 18270        |\n","|    policy_gradient_loss | -0.000111    |\n","|    value_loss           | 1.88e+04     |\n","------------------------------------------\n","Eval num_timesteps=3745000, episode_reward=20174.61 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-----------------------------------------\n","| eval/                   |             |\n","|    mean_ep_length       | 1.97e+03    |\n","|    mean_reward          | 2.02e+04    |\n","| time/                   |             |\n","|    total_timesteps      | 3745000     |\n","| train/                  |             |\n","|    approx_kl            | 5.64738e-05 |\n","|    clip_fraction        | 9.77e-05    |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.0451     |\n","|    explained_variance   | 0.411       |\n","|    learning_rate        | 0.001       |\n","|    loss                 | 1.57e+05    |\n","|    n_updates            | 18280       |\n","|    policy_gradient_loss | -8.34e-05   |\n","|    value_loss           | 1.62e+05    |\n","-----------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1829    |\n","|    time_elapsed    | 10805   |\n","|    total_timesteps | 3745792 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1830         |\n","|    time_elapsed         | 10809        |\n","|    total_timesteps      | 3747840      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001261915 |\n","|    clip_fraction        | 0.000146     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.162       |\n","|    explained_variance   | 0.853        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.55e+04     |\n","|    n_updates            | 18290        |\n","|    policy_gradient_loss | -0.000479    |\n","|    value_loss           | 3.83e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1831         |\n","|    time_elapsed         | 10812        |\n","|    total_timesteps      | 3749888      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002450255 |\n","|    clip_fraction        | 0.000928     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.108       |\n","|    explained_variance   | 0.775        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.14e+03     |\n","|    n_updates            | 18300        |\n","|    policy_gradient_loss | -0.000525    |\n","|    value_loss           | 2.15e+04     |\n","------------------------------------------\n","Eval num_timesteps=3750000, episode_reward=17862.56 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.79e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3750000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00055410183 |\n","|    clip_fraction        | 0.00317       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.847         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.5e+03       |\n","|    n_updates            | 18310         |\n","|    policy_gradient_loss | -0.00127      |\n","|    value_loss           | 3.64e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1832    |\n","|    time_elapsed    | 10821   |\n","|    total_timesteps | 3751936 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1833          |\n","|    time_elapsed         | 10824         |\n","|    total_timesteps      | 3753984       |\n","| train/                  |               |\n","|    approx_kl            | 0.00059614226 |\n","|    clip_fraction        | 0.00571       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.703         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.87e+03      |\n","|    n_updates            | 18320         |\n","|    policy_gradient_loss | -0.000831     |\n","|    value_loss           | 4.35e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3755000, episode_reward=24428.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.44e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3755000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002577641 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.12        |\n","|    explained_variance   | 0.669        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.16e+04     |\n","|    n_updates            | 18330        |\n","|    policy_gradient_loss | -0.000194    |\n","|    value_loss           | 2.94e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1834    |\n","|    time_elapsed    | 10833   |\n","|    total_timesteps | 3756032 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1835         |\n","|    time_elapsed         | 10837        |\n","|    total_timesteps      | 3758080      |\n","| train/                  |              |\n","|    approx_kl            | 4.270172e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0533      |\n","|    explained_variance   | 0.58         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.98e+04     |\n","|    n_updates            | 18340        |\n","|    policy_gradient_loss | -3.48e-05    |\n","|    value_loss           | 1.01e+05     |\n","------------------------------------------\n","Eval num_timesteps=3760000, episode_reward=24509.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3760000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044466413 |\n","|    clip_fraction        | 0.0019        |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.161        |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.76e+03      |\n","|    n_updates            | 18350         |\n","|    policy_gradient_loss | -0.00107      |\n","|    value_loss           | 2.47e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1836    |\n","|    time_elapsed    | 10845   |\n","|    total_timesteps | 3760128 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1837          |\n","|    time_elapsed         | 10849         |\n","|    total_timesteps      | 3762176       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023635899 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.666         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.98e+03      |\n","|    n_updates            | 18360         |\n","|    policy_gradient_loss | -0.000255     |\n","|    value_loss           | 2.88e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1838          |\n","|    time_elapsed         | 10852         |\n","|    total_timesteps      | 3764224       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018026764 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.177        |\n","|    explained_variance   | 0.707         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.72e+04      |\n","|    n_updates            | 18370         |\n","|    policy_gradient_loss | -0.000181     |\n","|    value_loss           | 7.83e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3765000, episode_reward=24428.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.44e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3765000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003897981 |\n","|    clip_fraction        | 0.00112      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.101       |\n","|    explained_variance   | 0.662        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.18e+04     |\n","|    n_updates            | 18380        |\n","|    policy_gradient_loss | -0.000756    |\n","|    value_loss           | 5.13e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1839    |\n","|    time_elapsed    | 10862   |\n","|    total_timesteps | 3766272 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1840          |\n","|    time_elapsed         | 10865         |\n","|    total_timesteps      | 3768320       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025349212 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.705         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.9e+04       |\n","|    n_updates            | 18390         |\n","|    policy_gradient_loss | -0.000806     |\n","|    value_loss           | 5.75e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3770000, episode_reward=24428.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3770000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00035583967 |\n","|    clip_fraction        | 0.00283       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0728       |\n","|    explained_variance   | 0.597         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.33e+04      |\n","|    n_updates            | 18400         |\n","|    policy_gradient_loss | -0.00143      |\n","|    value_loss           | 1.22e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1841    |\n","|    time_elapsed    | 10874   |\n","|    total_timesteps | 3770368 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1842          |\n","|    time_elapsed         | 10877         |\n","|    total_timesteps      | 3772416       |\n","| train/                  |               |\n","|    approx_kl            | 0.00015471099 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.147        |\n","|    explained_variance   | 0.863         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.06e+03      |\n","|    n_updates            | 18410         |\n","|    policy_gradient_loss | -0.000278     |\n","|    value_loss           | 1.62e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1843         |\n","|    time_elapsed         | 10881        |\n","|    total_timesteps      | 3774464      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005349774 |\n","|    clip_fraction        | 0.00283      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.112       |\n","|    explained_variance   | 0.632        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.3e+03      |\n","|    n_updates            | 18420        |\n","|    policy_gradient_loss | -0.000724    |\n","|    value_loss           | 3.13e+04     |\n","------------------------------------------\n","Eval num_timesteps=3775000, episode_reward=24536.47 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.45e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3775000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037058897 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.179        |\n","|    explained_variance   | 0.809         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.11e+04      |\n","|    n_updates            | 18430         |\n","|    policy_gradient_loss | -0.000308     |\n","|    value_loss           | 3.3e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1844    |\n","|    time_elapsed    | 10892   |\n","|    total_timesteps | 3776512 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1845         |\n","|    time_elapsed         | 10895        |\n","|    total_timesteps      | 3778560      |\n","| train/                  |              |\n","|    approx_kl            | 3.152399e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.11        |\n","|    explained_variance   | 0.643        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.49e+04     |\n","|    n_updates            | 18440        |\n","|    policy_gradient_loss | -0.000248    |\n","|    value_loss           | 3.47e+04     |\n","------------------------------------------\n","Eval num_timesteps=3780000, episode_reward=24428.38 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.44e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3780000      |\n","| train/                  |              |\n","|    approx_kl            | 8.815923e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0947      |\n","|    explained_variance   | 0.735        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.71e+03     |\n","|    n_updates            | 18450        |\n","|    policy_gradient_loss | -0.000286    |\n","|    value_loss           | 6.66e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1846    |\n","|    time_elapsed    | 10904   |\n","|    total_timesteps | 3780608 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1847          |\n","|    time_elapsed         | 10908         |\n","|    total_timesteps      | 3782656       |\n","| train/                  |               |\n","|    approx_kl            | 0.00023811212 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.119        |\n","|    explained_variance   | 0.718         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.16e+04      |\n","|    n_updates            | 18460         |\n","|    policy_gradient_loss | -0.00038      |\n","|    value_loss           | 8.88e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1848          |\n","|    time_elapsed         | 10911         |\n","|    total_timesteps      | 3784704       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011003055 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.681         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.69e+03      |\n","|    n_updates            | 18470         |\n","|    policy_gradient_loss | -9.28e-05     |\n","|    value_loss           | 2.27e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3785000, episode_reward=24967.37 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.5e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3785000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018398819 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.122        |\n","|    explained_variance   | 0.629         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.62e+04      |\n","|    n_updates            | 18480         |\n","|    policy_gradient_loss | 0.000246      |\n","|    value_loss           | 8.05e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1849    |\n","|    time_elapsed    | 10920   |\n","|    total_timesteps | 3786752 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1850         |\n","|    time_elapsed         | 10924        |\n","|    total_timesteps      | 3788800      |\n","| train/                  |              |\n","|    approx_kl            | 0.0007951354 |\n","|    clip_fraction        | 0.00356      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.181       |\n","|    explained_variance   | 0.839        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.69e+03     |\n","|    n_updates            | 18490        |\n","|    policy_gradient_loss | -0.0012      |\n","|    value_loss           | 3e+04        |\n","------------------------------------------\n","Eval num_timesteps=3790000, episode_reward=19493.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3790000       |\n","| train/                  |               |\n","|    approx_kl            | 2.0633568e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.112        |\n","|    explained_variance   | 0.64          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.26e+04      |\n","|    n_updates            | 18500         |\n","|    policy_gradient_loss | -8.33e-05     |\n","|    value_loss           | 3.69e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1851    |\n","|    time_elapsed    | 10933   |\n","|    total_timesteps | 3790848 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1852         |\n","|    time_elapsed         | 10936        |\n","|    total_timesteps      | 3792896      |\n","| train/                  |              |\n","|    approx_kl            | 7.868107e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0763      |\n","|    explained_variance   | 0.483        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.01e+04     |\n","|    n_updates            | 18510        |\n","|    policy_gradient_loss | -0.000111    |\n","|    value_loss           | 6.7e+04      |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1853          |\n","|    time_elapsed         | 10939         |\n","|    total_timesteps      | 3794944       |\n","| train/                  |               |\n","|    approx_kl            | 0.00042804668 |\n","|    clip_fraction        | 0.00327       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.138        |\n","|    explained_variance   | 0.711         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.24e+03      |\n","|    n_updates            | 18520         |\n","|    policy_gradient_loss | -0.00188      |\n","|    value_loss           | 6.6e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3795000, episode_reward=25310.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.53e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3795000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00036473208 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.101        |\n","|    explained_variance   | 0.687         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.5e+03       |\n","|    n_updates            | 18530         |\n","|    policy_gradient_loss | -0.000196     |\n","|    value_loss           | 1.83e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1854    |\n","|    time_elapsed    | 10948   |\n","|    total_timesteps | 3796992 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1855          |\n","|    time_elapsed         | 10953         |\n","|    total_timesteps      | 3799040       |\n","| train/                  |               |\n","|    approx_kl            | 0.00022041472 |\n","|    clip_fraction        | 0.00142       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.141        |\n","|    explained_variance   | 0.771         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.07e+04      |\n","|    n_updates            | 18540         |\n","|    policy_gradient_loss | -0.000807     |\n","|    value_loss           | 2.76e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3800000, episode_reward=21334.07 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.13e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3800000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025125293 |\n","|    clip_fraction        | 0.000488      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.156        |\n","|    explained_variance   | 0.82          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.09e+04      |\n","|    n_updates            | 18550         |\n","|    policy_gradient_loss | -0.000395     |\n","|    value_loss           | 3.9e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1856    |\n","|    time_elapsed    | 10963   |\n","|    total_timesteps | 3801088 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1857          |\n","|    time_elapsed         | 10966         |\n","|    total_timesteps      | 3803136       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011038323 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.121        |\n","|    explained_variance   | 0.72          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.52e+03      |\n","|    n_updates            | 18560         |\n","|    policy_gradient_loss | -0.00019      |\n","|    value_loss           | 3.51e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3805000, episode_reward=24359.55 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.44e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3805000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010204932 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0612       |\n","|    explained_variance   | 0.458         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.35e+03      |\n","|    n_updates            | 18570         |\n","|    policy_gradient_loss | -0.000277     |\n","|    value_loss           | 4.51e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1858    |\n","|    time_elapsed    | 10975   |\n","|    total_timesteps | 3805184 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1859          |\n","|    time_elapsed         | 10978         |\n","|    total_timesteps      | 3807232       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034393158 |\n","|    clip_fraction        | 0.000684      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.144        |\n","|    explained_variance   | 0.724         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.81e+04      |\n","|    n_updates            | 18580         |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 7.71e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1860         |\n","|    time_elapsed         | 10982        |\n","|    total_timesteps      | 3809280      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006952137 |\n","|    clip_fraction        | 0.00596      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.122       |\n","|    explained_variance   | 0.695        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.27e+03     |\n","|    n_updates            | 18590        |\n","|    policy_gradient_loss | -0.00232     |\n","|    value_loss           | 2.97e+04     |\n","------------------------------------------\n","Eval num_timesteps=3810000, episode_reward=21819.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.18e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3810000      |\n","| train/                  |              |\n","|    approx_kl            | 4.339384e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.133       |\n","|    explained_variance   | 0.759        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.12e+03     |\n","|    n_updates            | 18600        |\n","|    policy_gradient_loss | -0.000317    |\n","|    value_loss           | 3.55e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1861    |\n","|    time_elapsed    | 10991   |\n","|    total_timesteps | 3811328 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1862          |\n","|    time_elapsed         | 10994         |\n","|    total_timesteps      | 3813376       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027865355 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.152        |\n","|    explained_variance   | 0.85          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.39e+03      |\n","|    n_updates            | 18610         |\n","|    policy_gradient_loss | -0.000372     |\n","|    value_loss           | 3.73e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3815000, episode_reward=20873.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.09e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3815000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010490205 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.111        |\n","|    explained_variance   | 0.636         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.29e+03      |\n","|    n_updates            | 18620         |\n","|    policy_gradient_loss | -8.67e-05     |\n","|    value_loss           | 3.72e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1863    |\n","|    time_elapsed    | 11003   |\n","|    total_timesteps | 3815424 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1864          |\n","|    time_elapsed         | 11007         |\n","|    total_timesteps      | 3817472       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026401173 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0475       |\n","|    explained_variance   | 0.465         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.5e+04       |\n","|    n_updates            | 18630         |\n","|    policy_gradient_loss | -0.00133      |\n","|    value_loss           | 1.47e+05      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1865          |\n","|    time_elapsed         | 11010         |\n","|    total_timesteps      | 3819520       |\n","| train/                  |               |\n","|    approx_kl            | 0.00044340958 |\n","|    clip_fraction        | 0.00166       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.169        |\n","|    explained_variance   | 0.824         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.59e+03      |\n","|    n_updates            | 18640         |\n","|    policy_gradient_loss | -0.00126      |\n","|    value_loss           | 4.79e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3820000, episode_reward=19191.77 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.92e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3820000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014110951 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.11         |\n","|    explained_variance   | 0.768         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.42e+03      |\n","|    n_updates            | 18650         |\n","|    policy_gradient_loss | -0.000136     |\n","|    value_loss           | 1.82e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1866    |\n","|    time_elapsed    | 11019   |\n","|    total_timesteps | 3821568 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1867          |\n","|    time_elapsed         | 11023         |\n","|    total_timesteps      | 3823616       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020261461 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.162        |\n","|    explained_variance   | 0.861         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.7e+04       |\n","|    n_updates            | 18660         |\n","|    policy_gradient_loss | -0.000341     |\n","|    value_loss           | 3.04e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3825000, episode_reward=21874.34 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.19e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3825000      |\n","| train/                  |              |\n","|    approx_kl            | 9.523373e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.119       |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.92e+04     |\n","|    n_updates            | 18670        |\n","|    policy_gradient_loss | -0.000202    |\n","|    value_loss           | 4.91e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1868    |\n","|    time_elapsed    | 11031   |\n","|    total_timesteps | 3825664 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1869         |\n","|    time_elapsed         | 11035        |\n","|    total_timesteps      | 3827712      |\n","| train/                  |              |\n","|    approx_kl            | 5.937586e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.114       |\n","|    explained_variance   | 0.69         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 3.53e+03     |\n","|    n_updates            | 18680        |\n","|    policy_gradient_loss | -0.000163    |\n","|    value_loss           | 2.15e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1870          |\n","|    time_elapsed         | 11038         |\n","|    total_timesteps      | 3829760       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021321466 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0497       |\n","|    explained_variance   | 0.527         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.54e+04      |\n","|    n_updates            | 18690         |\n","|    policy_gradient_loss | -0.00039      |\n","|    value_loss           | 1.43e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3830000, episode_reward=21594.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3830000       |\n","| train/                  |               |\n","|    approx_kl            | 1.1068303e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.17         |\n","|    explained_variance   | 0.885         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.13e+04      |\n","|    n_updates            | 18700         |\n","|    policy_gradient_loss | -7.22e-05     |\n","|    value_loss           | 2.62e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1871    |\n","|    time_elapsed    | 11048   |\n","|    total_timesteps | 3831808 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1872          |\n","|    time_elapsed         | 11052         |\n","|    total_timesteps      | 3833856       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039025483 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.806         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.48e+03      |\n","|    n_updates            | 18710         |\n","|    policy_gradient_loss | -0.000414     |\n","|    value_loss           | 1.4e+04       |\n","-------------------------------------------\n","Eval num_timesteps=3835000, episode_reward=25479.16 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.55e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3835000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020951248 |\n","|    clip_fraction        | 4.88e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.174        |\n","|    explained_variance   | 0.887         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.36e+03      |\n","|    n_updates            | 18720         |\n","|    policy_gradient_loss | -0.000254     |\n","|    value_loss           | 2.75e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1873    |\n","|    time_elapsed    | 11061   |\n","|    total_timesteps | 3835904 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1874          |\n","|    time_elapsed         | 11064         |\n","|    total_timesteps      | 3837952       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014543615 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0967       |\n","|    explained_variance   | 0.727         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.01e+03      |\n","|    n_updates            | 18730         |\n","|    policy_gradient_loss | -0.000131     |\n","|    value_loss           | 4.41e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3840000, episode_reward=21590.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3840000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00012876967 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.114        |\n","|    explained_variance   | 0.537         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.59e+03      |\n","|    n_updates            | 18740         |\n","|    policy_gradient_loss | -0.000805     |\n","|    value_loss           | 3.28e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1875    |\n","|    time_elapsed    | 11073   |\n","|    total_timesteps | 3840000 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1876         |\n","|    time_elapsed         | 11076        |\n","|    total_timesteps      | 3842048      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004016804 |\n","|    clip_fraction        | 0.00186      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.067       |\n","|    explained_variance   | 0.579        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.56e+04     |\n","|    n_updates            | 18750        |\n","|    policy_gradient_loss | -0.000642    |\n","|    value_loss           | 1.42e+05     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1877         |\n","|    time_elapsed         | 11080        |\n","|    total_timesteps      | 3844096      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004021019 |\n","|    clip_fraction        | 0.00181      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.156       |\n","|    explained_variance   | 0.894        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.27e+04     |\n","|    n_updates            | 18760        |\n","|    policy_gradient_loss | -0.000916    |\n","|    value_loss           | 2.02e+04     |\n","------------------------------------------\n","Eval num_timesteps=3845000, episode_reward=24341.54 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.43e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3845000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003771686 |\n","|    clip_fraction        | 0.00205      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.102       |\n","|    explained_variance   | 0.735        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.42e+03     |\n","|    n_updates            | 18770        |\n","|    policy_gradient_loss | -0.000525    |\n","|    value_loss           | 1.91e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1878    |\n","|    time_elapsed    | 11089   |\n","|    total_timesteps | 3846144 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1879          |\n","|    time_elapsed         | 11092         |\n","|    total_timesteps      | 3848192       |\n","| train/                  |               |\n","|    approx_kl            | 0.00049590913 |\n","|    clip_fraction        | 0.00356       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.173        |\n","|    explained_variance   | 0.82          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.21e+04      |\n","|    n_updates            | 18780         |\n","|    policy_gradient_loss | -0.000241     |\n","|    value_loss           | 3.85e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3850000, episode_reward=21318.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.13e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3850000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010821459 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.759         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.17e+04      |\n","|    n_updates            | 18790         |\n","|    policy_gradient_loss | -0.00016      |\n","|    value_loss           | 3.71e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1880    |\n","|    time_elapsed    | 11101   |\n","|    total_timesteps | 3850240 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1881          |\n","|    time_elapsed         | 11105         |\n","|    total_timesteps      | 3852288       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020028636 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0943       |\n","|    explained_variance   | 0.742         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.09e+04      |\n","|    n_updates            | 18800         |\n","|    policy_gradient_loss | -0.000783     |\n","|    value_loss           | 5.64e+04      |\n","-------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 346        |\n","|    iterations           | 1882       |\n","|    time_elapsed         | 11108      |\n","|    total_timesteps      | 3854336    |\n","| train/                  |            |\n","|    approx_kl            | 6.7182e-05 |\n","|    clip_fraction        | 9.77e-05   |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.105     |\n","|    explained_variance   | 0.8        |\n","|    learning_rate        | 0.001      |\n","|    loss                 | 1.91e+04   |\n","|    n_updates            | 18810      |\n","|    policy_gradient_loss | -0.000188  |\n","|    value_loss           | 7.89e+04   |\n","----------------------------------------\n","Eval num_timesteps=3855000, episode_reward=21594.00 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3855000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00010010591 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.117        |\n","|    explained_variance   | 0.686         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.07e+03      |\n","|    n_updates            | 18820         |\n","|    policy_gradient_loss | -0.000309     |\n","|    value_loss           | 2.21e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1883    |\n","|    time_elapsed    | 11117   |\n","|    total_timesteps | 3856384 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1884         |\n","|    time_elapsed         | 11120        |\n","|    total_timesteps      | 3858432      |\n","| train/                  |              |\n","|    approx_kl            | 0.0002987448 |\n","|    clip_fraction        | 0.00137      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.115       |\n","|    explained_variance   | 0.794        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1e+04        |\n","|    n_updates            | 18830        |\n","|    policy_gradient_loss | -0.00074     |\n","|    value_loss           | 3.04e+04     |\n","------------------------------------------\n","Eval num_timesteps=3860000, episode_reward=21642.79 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.16e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3860000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005601088 |\n","|    clip_fraction        | 0.002        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.188       |\n","|    explained_variance   | 0.847        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.21e+03     |\n","|    n_updates            | 18840        |\n","|    policy_gradient_loss | -0.00088     |\n","|    value_loss           | 3.25e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1885    |\n","|    time_elapsed    | 11129   |\n","|    total_timesteps | 3860480 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1886         |\n","|    time_elapsed         | 11133        |\n","|    total_timesteps      | 3862528      |\n","| train/                  |              |\n","|    approx_kl            | 0.0004633016 |\n","|    clip_fraction        | 0.00229      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.108       |\n","|    explained_variance   | 0.751        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 9.75e+03     |\n","|    n_updates            | 18850        |\n","|    policy_gradient_loss | -0.000398    |\n","|    value_loss           | 4.85e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1887         |\n","|    time_elapsed         | 11137        |\n","|    total_timesteps      | 3864576      |\n","| train/                  |              |\n","|    approx_kl            | 4.797388e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0831      |\n","|    explained_variance   | 0.62         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.81e+04     |\n","|    n_updates            | 18860        |\n","|    policy_gradient_loss | -4.03e-05    |\n","|    value_loss           | 6.06e+04     |\n","------------------------------------------\n","Eval num_timesteps=3865000, episode_reward=19468.21 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.95e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3865000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00016542245 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.132        |\n","|    explained_variance   | 0.809         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.98e+04      |\n","|    n_updates            | 18870         |\n","|    policy_gradient_loss | -0.000396     |\n","|    value_loss           | 6.25e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1888    |\n","|    time_elapsed    | 11146   |\n","|    total_timesteps | 3866624 |\n","--------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 346            |\n","|    iterations           | 1889           |\n","|    time_elapsed         | 11150          |\n","|    total_timesteps      | 3868672        |\n","| train/                  |                |\n","|    approx_kl            | 0.000106682885 |\n","|    clip_fraction        | 0              |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.101         |\n","|    explained_variance   | 0.792          |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 3.61e+03       |\n","|    n_updates            | 18880          |\n","|    policy_gradient_loss | -1.45e-05      |\n","|    value_loss           | 1.65e+04       |\n","--------------------------------------------\n","Eval num_timesteps=3870000, episode_reward=22084.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.21e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3870000      |\n","| train/                  |              |\n","|    approx_kl            | 7.087452e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.143       |\n","|    explained_variance   | 0.742        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.37e+04     |\n","|    n_updates            | 18890        |\n","|    policy_gradient_loss | -5.14e-05    |\n","|    value_loss           | 4e+04        |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1890    |\n","|    time_elapsed    | 11159   |\n","|    total_timesteps | 3870720 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1891          |\n","|    time_elapsed         | 11162         |\n","|    total_timesteps      | 3872768       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018825516 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.892         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+04      |\n","|    n_updates            | 18900         |\n","|    policy_gradient_loss | -0.000177     |\n","|    value_loss           | 3.06e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1892          |\n","|    time_elapsed         | 11166         |\n","|    total_timesteps      | 3874816       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020985148 |\n","|    clip_fraction        | 9.77e-05      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.62          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.85e+04      |\n","|    n_updates            | 18910         |\n","|    policy_gradient_loss | -0.000135     |\n","|    value_loss           | 3.22e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3875000, episode_reward=23518.32 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.35e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3875000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00030526196 |\n","|    clip_fraction        | 0.00127       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0583       |\n","|    explained_variance   | 0.489         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.71e+04      |\n","|    n_updates            | 18920         |\n","|    policy_gradient_loss | -0.000771     |\n","|    value_loss           | 8.63e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1893    |\n","|    time_elapsed    | 11175   |\n","|    total_timesteps | 3876864 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1894          |\n","|    time_elapsed         | 11178         |\n","|    total_timesteps      | 3878912       |\n","| train/                  |               |\n","|    approx_kl            | 0.00017078887 |\n","|    clip_fraction        | 0.000781      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.838         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.25e+04      |\n","|    n_updates            | 18930         |\n","|    policy_gradient_loss | -0.000475     |\n","|    value_loss           | 5.36e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3880000, episode_reward=21433.37 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.14e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3880000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0005706918 |\n","|    clip_fraction        | 0.00293      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.127       |\n","|    explained_variance   | 0.712        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.07e+03     |\n","|    n_updates            | 18940        |\n","|    policy_gradient_loss | -0.000672    |\n","|    value_loss           | 1.96e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1895    |\n","|    time_elapsed    | 11187   |\n","|    total_timesteps | 3880960 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1896          |\n","|    time_elapsed         | 11191         |\n","|    total_timesteps      | 3883008       |\n","| train/                  |               |\n","|    approx_kl            | 0.00034922603 |\n","|    clip_fraction        | 0.00269       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.139        |\n","|    explained_variance   | 0.722         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.01e+04      |\n","|    n_updates            | 18950         |\n","|    policy_gradient_loss | -0.0005       |\n","|    value_loss           | 2.71e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3885000, episode_reward=21347.01 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.13e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3885000      |\n","| train/                  |              |\n","|    approx_kl            | 9.686773e-06 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.148       |\n","|    explained_variance   | 0.816        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.2e+03      |\n","|    n_updates            | 18960        |\n","|    policy_gradient_loss | -0.00017     |\n","|    value_loss           | 4.72e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1897    |\n","|    time_elapsed    | 11201   |\n","|    total_timesteps | 3885056 |\n","--------------------------------\n","--------------------------------------------\n","| time/                   |                |\n","|    fps                  | 346            |\n","|    iterations           | 1898           |\n","|    time_elapsed         | 11204          |\n","|    total_timesteps      | 3887104        |\n","| train/                  |                |\n","|    approx_kl            | 0.000118157885 |\n","|    clip_fraction        | 4.88e-05       |\n","|    clip_range           | 0.2            |\n","|    entropy_loss         | -0.117         |\n","|    explained_variance   | 0.63           |\n","|    learning_rate        | 0.001          |\n","|    loss                 | 8.91e+03       |\n","|    n_updates            | 18970          |\n","|    policy_gradient_loss | -0.000577      |\n","|    value_loss           | 4.03e+04       |\n","--------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1899         |\n","|    time_elapsed         | 11208        |\n","|    total_timesteps      | 3889152      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001299078 |\n","|    clip_fraction        | 0.000684     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.041       |\n","|    explained_variance   | 0.605        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.93e+04     |\n","|    n_updates            | 18980        |\n","|    policy_gradient_loss | -0.000375    |\n","|    value_loss           | 1e+05        |\n","------------------------------------------\n","Eval num_timesteps=3890000, episode_reward=20004.90 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2e+04         |\n","| time/                   |               |\n","|    total_timesteps      | 3890000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029169553 |\n","|    clip_fraction        | 0.00186       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.833         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.58e+04      |\n","|    n_updates            | 18990         |\n","|    policy_gradient_loss | -0.000762     |\n","|    value_loss           | 4.75e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1900    |\n","|    time_elapsed    | 11217   |\n","|    total_timesteps | 3891200 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1901          |\n","|    time_elapsed         | 11220         |\n","|    total_timesteps      | 3893248       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039688425 |\n","|    clip_fraction        | 0.00254       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.107        |\n","|    explained_variance   | 0.821         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.57e+03      |\n","|    n_updates            | 19000         |\n","|    policy_gradient_loss | -0.000595     |\n","|    value_loss           | 1.15e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3895000, episode_reward=19614.63 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 1.96e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3895000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00027218187 |\n","|    clip_fraction        | 0.000391      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.157        |\n","|    explained_variance   | 0.876         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.67e+04      |\n","|    n_updates            | 19010         |\n","|    policy_gradient_loss | -0.000283     |\n","|    value_loss           | 2.93e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1902    |\n","|    time_elapsed    | 11230   |\n","|    total_timesteps | 3895296 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1903         |\n","|    time_elapsed         | 11233        |\n","|    total_timesteps      | 3897344      |\n","| train/                  |              |\n","|    approx_kl            | 5.713472e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.126       |\n","|    explained_variance   | 0.68         |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.25e+04     |\n","|    n_updates            | 19020        |\n","|    policy_gradient_loss | -4.77e-05    |\n","|    value_loss           | 3.95e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1904          |\n","|    time_elapsed         | 11236         |\n","|    total_timesteps      | 3899392       |\n","| train/                  |               |\n","|    approx_kl            | 0.00058940204 |\n","|    clip_fraction        | 0.00264       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.696         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.57e+03      |\n","|    n_updates            | 19030         |\n","|    policy_gradient_loss | -0.000582     |\n","|    value_loss           | 2.42e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3900000, episode_reward=25100.64 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.51e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3900000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00013606137 |\n","|    clip_fraction        | 0.00186       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0433       |\n","|    explained_variance   | 0.548         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.02e+04      |\n","|    n_updates            | 19040         |\n","|    policy_gradient_loss | -0.000831     |\n","|    value_loss           | 1.05e+05      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1905    |\n","|    time_elapsed    | 11246   |\n","|    total_timesteps | 3901440 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1906         |\n","|    time_elapsed         | 11249        |\n","|    total_timesteps      | 3903488      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003994887 |\n","|    clip_fraction        | 0.00332      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.169       |\n","|    explained_variance   | 0.899        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 7.46e+03     |\n","|    n_updates            | 19050        |\n","|    policy_gradient_loss | -0.00109     |\n","|    value_loss           | 3.09e+04     |\n","------------------------------------------\n","Eval num_timesteps=3905000, episode_reward=25486.40 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.55e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3905000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011055067 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.11         |\n","|    explained_variance   | 0.682         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.4e+03       |\n","|    n_updates            | 19060         |\n","|    policy_gradient_loss | -0.000159     |\n","|    value_loss           | 2.74e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1907    |\n","|    time_elapsed    | 11259   |\n","|    total_timesteps | 3905536 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1908         |\n","|    time_elapsed         | 11262        |\n","|    total_timesteps      | 3907584      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001022841 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.166       |\n","|    explained_variance   | 0.819        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.02e+04     |\n","|    n_updates            | 19070        |\n","|    policy_gradient_loss | -0.000165    |\n","|    value_loss           | 2.93e+04     |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1909         |\n","|    time_elapsed         | 11266        |\n","|    total_timesteps      | 3909632      |\n","| train/                  |              |\n","|    approx_kl            | 9.060008e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.108       |\n","|    explained_variance   | 0.698        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.2e+04      |\n","|    n_updates            | 19080        |\n","|    policy_gradient_loss | -0.000404    |\n","|    value_loss           | 4.12e+04     |\n","------------------------------------------\n","Eval num_timesteps=3910000, episode_reward=27821.18 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.78e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3910000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00032900943 |\n","|    clip_fraction        | 0.00103       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.705         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.1e+03       |\n","|    n_updates            | 19090         |\n","|    policy_gradient_loss | -0.000352     |\n","|    value_loss           | 1.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1910    |\n","|    time_elapsed    | 11274   |\n","|    total_timesteps | 3911680 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1911         |\n","|    time_elapsed         | 11278        |\n","|    total_timesteps      | 3913728      |\n","| train/                  |              |\n","|    approx_kl            | 9.361122e-05 |\n","|    clip_fraction        | 4.88e-05     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0606      |\n","|    explained_variance   | 0.661        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.19e+05     |\n","|    n_updates            | 19100        |\n","|    policy_gradient_loss | -0.00011     |\n","|    value_loss           | 1.38e+05     |\n","------------------------------------------\n","Eval num_timesteps=3915000, episode_reward=27594.44 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.76e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3915000       |\n","| train/                  |               |\n","|    approx_kl            | 4.4778222e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.154        |\n","|    explained_variance   | 0.894         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.1e+03       |\n","|    n_updates            | 19110         |\n","|    policy_gradient_loss | -4.1e-05      |\n","|    value_loss           | 2.1e+04       |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1912    |\n","|    time_elapsed    | 11287   |\n","|    total_timesteps | 3915776 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1913          |\n","|    time_elapsed         | 11291         |\n","|    total_timesteps      | 3917824       |\n","| train/                  |               |\n","|    approx_kl            | 1.1876109e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.112        |\n","|    explained_variance   | 0.631         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.42e+03      |\n","|    n_updates            | 19120         |\n","|    policy_gradient_loss | -0.00014      |\n","|    value_loss           | 7.61e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1914         |\n","|    time_elapsed         | 11294        |\n","|    total_timesteps      | 3919872      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003305326 |\n","|    clip_fraction        | 0.00229      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.172       |\n","|    explained_variance   | 0.864        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 5.15e+03     |\n","|    n_updates            | 19130        |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 2.48e+04     |\n","------------------------------------------\n","Eval num_timesteps=3920000, episode_reward=26494.44 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.65e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3920000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00087421265 |\n","|    clip_fraction        | 0.00864       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.126        |\n","|    explained_variance   | 0.683         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.7e+04       |\n","|    n_updates            | 19140         |\n","|    policy_gradient_loss | -0.00184      |\n","|    value_loss           | 5.01e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1915    |\n","|    time_elapsed    | 11303   |\n","|    total_timesteps | 3921920 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1916         |\n","|    time_elapsed         | 11306        |\n","|    total_timesteps      | 3923968      |\n","| train/                  |              |\n","|    approx_kl            | 9.521897e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0977      |\n","|    explained_variance   | 0.722        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 2.86e+04     |\n","|    n_updates            | 19150        |\n","|    policy_gradient_loss | -0.000167    |\n","|    value_loss           | 6.65e+04     |\n","------------------------------------------\n","Eval num_timesteps=3925000, episode_reward=20972.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.1e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3925000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021308268 |\n","|    clip_fraction        | 0.000293      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0908       |\n","|    explained_variance   | 0.816         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.06e+04      |\n","|    n_updates            | 19160         |\n","|    policy_gradient_loss | -0.000404     |\n","|    value_loss           | 1e+05         |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1917    |\n","|    time_elapsed    | 11317   |\n","|    total_timesteps | 3926016 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1918          |\n","|    time_elapsed         | 11320         |\n","|    total_timesteps      | 3928064       |\n","| train/                  |               |\n","|    approx_kl            | 0.00021595616 |\n","|    clip_fraction        | 0.000342      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.125        |\n","|    explained_variance   | 0.74          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.66e+03      |\n","|    n_updates            | 19170         |\n","|    policy_gradient_loss | -0.000387     |\n","|    value_loss           | 2.26e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3930000, episode_reward=20281.19 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.03e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3930000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040563455 |\n","|    clip_fraction        | 0.00117       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.115        |\n","|    explained_variance   | 0.597         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 2.26e+04      |\n","|    n_updates            | 19180         |\n","|    policy_gradient_loss | -0.000759     |\n","|    value_loss           | 3.96e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1919    |\n","|    time_elapsed    | 11329   |\n","|    total_timesteps | 3930112 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1920          |\n","|    time_elapsed         | 11333         |\n","|    total_timesteps      | 3932160       |\n","| train/                  |               |\n","|    approx_kl            | 0.00026681245 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.185        |\n","|    explained_variance   | 0.865         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.26e+04      |\n","|    n_updates            | 19190         |\n","|    policy_gradient_loss | -0.000518     |\n","|    value_loss           | 3.56e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1921          |\n","|    time_elapsed         | 11336         |\n","|    total_timesteps      | 3934208       |\n","| train/                  |               |\n","|    approx_kl            | 0.00031466412 |\n","|    clip_fraction        | 0.000195      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0955       |\n","|    explained_variance   | 0.741         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.32e+03      |\n","|    n_updates            | 19200         |\n","|    policy_gradient_loss | -0.000306     |\n","|    value_loss           | 2.78e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3935000, episode_reward=20389.28 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.04e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3935000       |\n","| train/                  |               |\n","|    approx_kl            | 6.8692607e-06 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0876       |\n","|    explained_variance   | 0.639         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.34e+03      |\n","|    n_updates            | 19210         |\n","|    policy_gradient_loss | -2.85e-05     |\n","|    value_loss           | 6.37e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1922    |\n","|    time_elapsed    | 11346   |\n","|    total_timesteps | 3936256 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1923          |\n","|    time_elapsed         | 11349         |\n","|    total_timesteps      | 3938304       |\n","| train/                  |               |\n","|    approx_kl            | 0.00018539545 |\n","|    clip_fraction        | 0.000244      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.127        |\n","|    explained_variance   | 0.822         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.2e+04       |\n","|    n_updates            | 19220         |\n","|    policy_gradient_loss | 4.07e-05      |\n","|    value_loss           | 6.31e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3940000, episode_reward=26039.15 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.6e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3940000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037106944 |\n","|    clip_fraction        | 0.000977      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.091        |\n","|    explained_variance   | 0.676         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.19e+03      |\n","|    n_updates            | 19230         |\n","|    policy_gradient_loss | -0.000102     |\n","|    value_loss           | 2.39e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1924    |\n","|    time_elapsed    | 11358   |\n","|    total_timesteps | 3940352 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 346          |\n","|    iterations           | 1925         |\n","|    time_elapsed         | 11361        |\n","|    total_timesteps      | 3942400      |\n","| train/                  |              |\n","|    approx_kl            | 0.0009010429 |\n","|    clip_fraction        | 0.00557      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.142       |\n","|    explained_variance   | 0.623        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.06e+04     |\n","|    n_updates            | 19240        |\n","|    policy_gradient_loss | -0.00102     |\n","|    value_loss           | 3.65e+04     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1926          |\n","|    time_elapsed         | 11365         |\n","|    total_timesteps      | 3944448       |\n","| train/                  |               |\n","|    approx_kl            | 5.2606425e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.864         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.44e+03      |\n","|    n_updates            | 19250         |\n","|    policy_gradient_loss | -0.000136     |\n","|    value_loss           | 3.31e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3945000, episode_reward=26874.39 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.69e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3945000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003299656 |\n","|    clip_fraction        | 0.00083      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.119       |\n","|    explained_variance   | 0.714        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 8.64e+03     |\n","|    n_updates            | 19260        |\n","|    policy_gradient_loss | -0.000486    |\n","|    value_loss           | 3.82e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1927    |\n","|    time_elapsed    | 11375   |\n","|    total_timesteps | 3946496 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1928          |\n","|    time_elapsed         | 11379         |\n","|    total_timesteps      | 3948544       |\n","| train/                  |               |\n","|    approx_kl            | 2.7906994e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0594       |\n","|    explained_variance   | 0.643         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.92e+04      |\n","|    n_updates            | 19270         |\n","|    policy_gradient_loss | 5.71e-05      |\n","|    value_loss           | 1.22e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3950000, episode_reward=27684.93 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.77e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3950000       |\n","| train/                  |               |\n","|    approx_kl            | 1.5384256e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.134        |\n","|    explained_variance   | 0.843         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.4e+04       |\n","|    n_updates            | 19280         |\n","|    policy_gradient_loss | -0.000155     |\n","|    value_loss           | 7.41e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1929    |\n","|    time_elapsed    | 11388   |\n","|    total_timesteps | 3950592 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 346           |\n","|    iterations           | 1930          |\n","|    time_elapsed         | 11391         |\n","|    total_timesteps      | 3952640       |\n","| train/                  |               |\n","|    approx_kl            | 0.00074821565 |\n","|    clip_fraction        | 0.00791       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.124        |\n","|    explained_variance   | 0.662         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.27e+03      |\n","|    n_updates            | 19290         |\n","|    policy_gradient_loss | -0.00128      |\n","|    value_loss           | 2.58e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1931         |\n","|    time_elapsed         | 11394        |\n","|    total_timesteps      | 3954688      |\n","| train/                  |              |\n","|    approx_kl            | 8.795105e-05 |\n","|    clip_fraction        | 0.000781     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.143       |\n","|    explained_variance   | 0.716        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.89e+04     |\n","|    n_updates            | 19300        |\n","|    policy_gradient_loss | -0.000572    |\n","|    value_loss           | 3.79e+04     |\n","------------------------------------------\n","Eval num_timesteps=3955000, episode_reward=26318.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.63e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3955000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006557811 |\n","|    clip_fraction        | 0.0021       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.149       |\n","|    explained_variance   | 0.835        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.01e+04     |\n","|    n_updates            | 19310        |\n","|    policy_gradient_loss | -0.000657    |\n","|    value_loss           | 4.53e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1932    |\n","|    time_elapsed    | 11403   |\n","|    total_timesteps | 3956736 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1933         |\n","|    time_elapsed         | 11407        |\n","|    total_timesteps      | 3958784      |\n","| train/                  |              |\n","|    approx_kl            | 0.0003028378 |\n","|    clip_fraction        | 0.000195     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.122       |\n","|    explained_variance   | 0.684        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.64e+04     |\n","|    n_updates            | 19320        |\n","|    policy_gradient_loss | -0.000319    |\n","|    value_loss           | 3.02e+04     |\n","------------------------------------------\n","Eval num_timesteps=3960000, episode_reward=26965.84 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.7e+04       |\n","| time/                   |               |\n","|    total_timesteps      | 3960000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00024676902 |\n","|    clip_fraction        | 0.00112       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.0447       |\n","|    explained_variance   | 0.517         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 3.92e+04      |\n","|    n_updates            | 19330         |\n","|    policy_gradient_loss | -0.000573     |\n","|    value_loss           | 7.49e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1934    |\n","|    time_elapsed    | 11416   |\n","|    total_timesteps | 3960832 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1935          |\n","|    time_elapsed         | 11419         |\n","|    total_timesteps      | 3962880       |\n","| train/                  |               |\n","|    approx_kl            | 0.00014277225 |\n","|    clip_fraction        | 0.000146      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.814         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.39e+04      |\n","|    n_updates            | 19340         |\n","|    policy_gradient_loss | -0.000346     |\n","|    value_loss           | 6.39e+04      |\n","-------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1936          |\n","|    time_elapsed         | 11423         |\n","|    total_timesteps      | 3964928       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020837708 |\n","|    clip_fraction        | 0.000537      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.808         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.68e+03      |\n","|    n_updates            | 19350         |\n","|    policy_gradient_loss | -0.000271     |\n","|    value_loss           | 1e+04         |\n","-------------------------------------------\n","Eval num_timesteps=3965000, episode_reward=25412.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.54e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3965000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00046711793 |\n","|    clip_fraction        | 0.002         |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.164        |\n","|    explained_variance   | 0.86          |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.82e+03      |\n","|    n_updates            | 19360         |\n","|    policy_gradient_loss | -0.000787     |\n","|    value_loss           | 3.12e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1937    |\n","|    time_elapsed    | 11432   |\n","|    total_timesteps | 3966976 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1938          |\n","|    time_elapsed         | 11436         |\n","|    total_timesteps      | 3969024       |\n","| train/                  |               |\n","|    approx_kl            | 0.00037311748 |\n","|    clip_fraction        | 0.000879      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.135        |\n","|    explained_variance   | 0.671         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.38e+04      |\n","|    n_updates            | 19370         |\n","|    policy_gradient_loss | -0.000306     |\n","|    value_loss           | 4.94e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3970000, episode_reward=25745.03 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3970000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00040672722 |\n","|    clip_fraction        | 0.00317       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.12         |\n","|    explained_variance   | 0.638         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.05e+04      |\n","|    n_updates            | 19380         |\n","|    policy_gradient_loss | -0.000712     |\n","|    value_loss           | 3.24e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1939    |\n","|    time_elapsed    | 11445   |\n","|    total_timesteps | 3971072 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1940          |\n","|    time_elapsed         | 11448         |\n","|    total_timesteps      | 3973120       |\n","| train/                  |               |\n","|    approx_kl            | 0.00020730225 |\n","|    clip_fraction        | 0.000635      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.045        |\n","|    explained_variance   | 0.566         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.68e+04      |\n","|    n_updates            | 19390         |\n","|    policy_gradient_loss | -0.000844     |\n","|    value_loss           | 1.21e+05      |\n","-------------------------------------------\n","Eval num_timesteps=3975000, episode_reward=26318.51 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.63e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3975000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00025500273 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.175        |\n","|    explained_variance   | 0.859         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 9.12e+03      |\n","|    n_updates            | 19400         |\n","|    policy_gradient_loss | -0.00118      |\n","|    value_loss           | 3.81e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1941    |\n","|    time_elapsed    | 11457   |\n","|    total_timesteps | 3975168 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1942          |\n","|    time_elapsed         | 11461         |\n","|    total_timesteps      | 3977216       |\n","| train/                  |               |\n","|    approx_kl            | 0.00029198703 |\n","|    clip_fraction        | 0.00288       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.118        |\n","|    explained_variance   | 0.634         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 8.02e+03      |\n","|    n_updates            | 19410         |\n","|    policy_gradient_loss | -0.000724     |\n","|    value_loss           | 1.97e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1943         |\n","|    time_elapsed         | 11465        |\n","|    total_timesteps      | 3979264      |\n","| train/                  |              |\n","|    approx_kl            | 6.245263e-05 |\n","|    clip_fraction        | 0            |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.163       |\n","|    explained_variance   | 0.866        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 6.16e+03     |\n","|    n_updates            | 19420        |\n","|    policy_gradient_loss | -0.00028     |\n","|    value_loss           | 2.91e+04     |\n","------------------------------------------\n","Eval num_timesteps=3980000, episode_reward=22855.04 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.29e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3980000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0006156564 |\n","|    clip_fraction        | 0.00352      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.122       |\n","|    explained_variance   | 0.624        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.51e+04     |\n","|    n_updates            | 19430        |\n","|    policy_gradient_loss | -0.0012      |\n","|    value_loss           | 4.42e+04     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1944    |\n","|    time_elapsed    | 11473   |\n","|    total_timesteps | 3981312 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1945          |\n","|    time_elapsed         | 11477         |\n","|    total_timesteps      | 3983360       |\n","| train/                  |               |\n","|    approx_kl            | 0.00084574777 |\n","|    clip_fraction        | 0.00513       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.116        |\n","|    explained_variance   | 0.645         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 7.69e+03      |\n","|    n_updates            | 19440         |\n","|    policy_gradient_loss | -0.00131      |\n","|    value_loss           | 3.29e+04      |\n","-------------------------------------------\n","Eval num_timesteps=3985000, episode_reward=21546.89 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","------------------------------------------\n","| eval/                   |              |\n","|    mean_ep_length       | 1.97e+03     |\n","|    mean_reward          | 2.15e+04     |\n","| time/                   |              |\n","|    total_timesteps      | 3985000      |\n","| train/                  |              |\n","|    approx_kl            | 0.0001932398 |\n","|    clip_fraction        | 0.000732     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0565      |\n","|    explained_variance   | 0.653        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.4e+05      |\n","|    n_updates            | 19450        |\n","|    policy_gradient_loss | -0.000251    |\n","|    value_loss           | 1.51e+05     |\n","------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1946    |\n","|    time_elapsed    | 11486   |\n","|    total_timesteps | 3985408 |\n","--------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1947          |\n","|    time_elapsed         | 11489         |\n","|    total_timesteps      | 3987456       |\n","| train/                  |               |\n","|    approx_kl            | 0.00039494465 |\n","|    clip_fraction        | 0.00181       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.163        |\n","|    explained_variance   | 0.849         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 4.26e+03      |\n","|    n_updates            | 19460         |\n","|    policy_gradient_loss | -0.000903     |\n","|    value_loss           | 2.54e+04      |\n","-------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1948         |\n","|    time_elapsed         | 11493        |\n","|    total_timesteps      | 3989504      |\n","| train/                  |              |\n","|    approx_kl            | 0.0013717625 |\n","|    clip_fraction        | 0.0112       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.107       |\n","|    explained_variance   | 0.699        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 4.17e+03     |\n","|    n_updates            | 19470        |\n","|    policy_gradient_loss | -0.00198     |\n","|    value_loss           | 2.02e+04     |\n","------------------------------------------\n","Eval num_timesteps=3990000, episode_reward=25703.96 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.57e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3990000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00052224577 |\n","|    clip_fraction        | 0.000732      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.176        |\n","|    explained_variance   | 0.865         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.59e+03      |\n","|    n_updates            | 19480         |\n","|    policy_gradient_loss | -0.000433     |\n","|    value_loss           | 2.29e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1949    |\n","|    time_elapsed    | 11503   |\n","|    total_timesteps | 3991552 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1950         |\n","|    time_elapsed         | 11506        |\n","|    total_timesteps      | 3993600      |\n","| train/                  |              |\n","|    approx_kl            | 0.0011902284 |\n","|    clip_fraction        | 0.0121       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.118       |\n","|    explained_variance   | 0.604        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.2e+04      |\n","|    n_updates            | 19490        |\n","|    policy_gradient_loss | -0.00239     |\n","|    value_loss           | 4.27e+04     |\n","------------------------------------------\n","Eval num_timesteps=3995000, episode_reward=21560.05 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.16e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 3995000       |\n","| train/                  |               |\n","|    approx_kl            | 0.00011721198 |\n","|    clip_fraction        | 0.000439      |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.109        |\n","|    explained_variance   | 0.683         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 5.68e+04      |\n","|    n_updates            | 19500         |\n","|    policy_gradient_loss | -0.000751     |\n","|    value_loss           | 6.26e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 346     |\n","|    iterations      | 1951    |\n","|    time_elapsed    | 11515   |\n","|    total_timesteps | 3995648 |\n","--------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 347          |\n","|    iterations           | 1952         |\n","|    time_elapsed         | 11519        |\n","|    total_timesteps      | 3997696      |\n","| train/                  |              |\n","|    approx_kl            | 9.070002e-05 |\n","|    clip_fraction        | 0.000391     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.0773      |\n","|    explained_variance   | 0.727        |\n","|    learning_rate        | 0.001        |\n","|    loss                 | 1.43e+05     |\n","|    n_updates            | 19510        |\n","|    policy_gradient_loss | -0.000545    |\n","|    value_loss           | 1.37e+05     |\n","------------------------------------------\n","-------------------------------------------\n","| time/                   |               |\n","|    fps                  | 347           |\n","|    iterations           | 1953          |\n","|    time_elapsed         | 11522         |\n","|    total_timesteps      | 3999744       |\n","| train/                  |               |\n","|    approx_kl            | 0.00043757944 |\n","|    clip_fraction        | 0.00488       |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.145        |\n","|    explained_variance   | 0.778         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 6.5e+03       |\n","|    n_updates            | 19520         |\n","|    policy_gradient_loss | -0.00162      |\n","|    value_loss           | 1.91e+04      |\n","-------------------------------------------\n","Eval num_timesteps=4000000, episode_reward=21128.06 +/- 0.00\n","Episode length: 1969.00 +/- 0.00\n","-------------------------------------------\n","| eval/                   |               |\n","|    mean_ep_length       | 1.97e+03      |\n","|    mean_reward          | 2.11e+04      |\n","| time/                   |               |\n","|    total_timesteps      | 4000000       |\n","| train/                  |               |\n","|    approx_kl            | 2.4088047e-05 |\n","|    clip_fraction        | 0             |\n","|    clip_range           | 0.2           |\n","|    entropy_loss         | -0.108        |\n","|    explained_variance   | 0.734         |\n","|    learning_rate        | 0.001         |\n","|    loss                 | 1.26e+04      |\n","|    n_updates            | 19530         |\n","|    policy_gradient_loss | -0.000122     |\n","|    value_loss           | 2.97e+04      |\n","-------------------------------------------\n","--------------------------------\n","| time/              |         |\n","|    fps             | 347     |\n","|    iterations      | 1954    |\n","|    time_elapsed    | 11532   |\n","|    total_timesteps | 4001792 |\n","--------------------------------\n"]},{"data":{"text/plain":["<stable_baselines3.ppo.ppo.PPO at 0x139686330>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Callbacks for monitoring and saving\n","checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models/', name_prefix='ppo_forex')\n","env_maker = lambda: gym.make('forex-v0', df=forex_df, frame_bound=(30,2000), window_size=5)\n","eval_env = DummyVecEnv([env_maker])\n","eval_callback = EvalCallback(eval_env, best_model_save_path='./logs/', log_path='./logs/', eval_freq=5000, deterministic=True)\n","\n","# List of callbacks\n","callback = CallbackList([checkpoint_callback, eval_callback])\n","\n","# Train the model\n","# with mlflow.start_run():\n","model = PPO('MlpPolicy', env, verbose=1,\n","    learning_rate=0.001,      # Slightly lower learning rate for stability\n","# n_steps=1024,              # Keep as is, but can experiment with 1024 or 4096\n","# batch_size=64,             # Keep as is, but can experiment with 32 or 128\n","# n_epochs=10,               # Keep as is, but can experiment with 5 or 20\n","gamma=0.99,                # Higher discount factor to consider future rewards more\n","# gae_lambda=0.95,           # Keep as is, but can experiment with 0.9 to 1.0\n","# clip_range=0.2,            # Keep as is, but can experiment with 0.1 to 0.3\n","# ent_coef=0.02,             # Slightly higher entropy coefficient for more exploration\n","# vf_coef=0.5,               # Keep as is, but can experiment with 0.2 to 1.0\n","# max_grad_norm=0.5          # Keep as is, but can experiment with 0.5 to 1.0\n",") \n","# Set custom logger\n","# model.set_logger(loggers)\n","model.learn(total_timesteps=4000000,log_interval=1, callback=callback)\n"]},{"cell_type":"code","execution_count":138,"metadata":{"cell_id":"8f1e53184b954a79b9791a90f6f38366","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":1,"execution_start":1728997607969,"source_hash":"7130c40d"},"outputs":[],"source":["model_name = \"trader_usd_eur_ppo\""]},{"cell_type":"code","execution_count":139,"metadata":{"cell_id":"beb75bf0f8f54c849c21770edacfdb78","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":376,"execution_start":1728997608018,"source_hash":"b10d6c05"},"outputs":[],"source":["model.save(model_name)"]},{"cell_type":"markdown","metadata":{"cell_id":"4d6f94b59baa48f786b3f95f097759d3","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Evaluation"]},{"cell_type":"code","execution_count":140,"metadata":{"cell_id":"b152205229f648a78dfa5089fcf169b6","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":910,"execution_start":1728997608451,"source_hash":"f1a6733c"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:Updated profit: 0.9063634060332235\n","INFO:root:Updated profit: 0.9063634060332235\n","INFO:root:Updated profit: 0.6496175201611974\n","INFO:root:Updated profit: 0.6496175201611974\n","INFO:root:Updated profit: 2.2145532847261773\n","INFO:root:Updated profit: 2.2145532847261773\n","INFO:root:Updated profit: 0.4104901323867717\n","INFO:root:Updated profit: 0.4104901323867717\n","INFO:root:Updated profit: -0.04557949138932185\n","INFO:root:Updated profit: -0.04557949138932185\n","INFO:root:Updated profit: -0.06290844759741311\n","INFO:root:Updated profit: -0.06290844759741311\n","INFO:root:Updated profit: -0.12094557733826469\n","INFO:root:Updated profit: -0.12094557733826469\n","INFO:root:Updated profit: 0.0811583963055751\n","INFO:root:Updated profit: 0.0811583963055751\n","INFO:root:Updated profit: 0.01471315672720453\n"]},{"name":"stdout","output_type":"stream","text":["info: {'total_reward': 24344.456905156374, 'total_profit': 0.01471315672720453, 'position': <Positions.Short: 0>} [[1.9777821 1.6539327 1.2078769 1.1631104 1.7939239 1.4940124 1.191516 ]\n"," [1.9870995 1.6804731 1.2108783 1.1814321 1.8430374 1.504421  1.1852682]\n"," [2.043015  1.7053645 1.2132524 1.2935312 1.8957784 1.5118766 1.19212  ]\n"," [1.8940456 1.7261866 1.217502  0.6854907 1.9217918 1.539851  1.1072394]\n"," [1.8754545 1.7480514 1.2218282 0.6144437 1.9378791 1.5867299 1.016311 ]]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize the gym environment and your model as usual\n","env = gym.make('forex-v0', df=forex_df, frame_bound=(1500, 2000), window_size=5)\n","obs, _ = env.reset()\n","del model\n","\n","# Load the trained model\n","model = PPO.load(model_name)\n","\n","# Turn on interactive plotting\n","plt.ion()\n","\n","while True:\n","    action, _states = model.predict(obs)\n","    obs, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","    # env.render()\n","    # plt.pause(0.01)  # Pause to allow the plot to update\n","    if done:\n","        print(\"info:\", info, obs)\n","        break\n","\n","# Turn off interactive plotting and show the final plot\n","plt.cla()\n","env.unwrapped.render_all()\n","plt.show()"]},{"cell_type":"code","execution_count":141,"metadata":{"cell_id":"61804355b1e642a3bc71882b51012228","deepnote_cell_type":"code","execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","execution_millis":2341,"execution_start":1728997609406,"source_hash":"8410ce24"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'trader_usd_eur_dqn_2.zip'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[141], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrader_usd_eur_dqn_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize the environment\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# env = ForexEnv(df, window_size=50)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:680\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    678\u001b[0m     get_system_info()\n\u001b[0;32m--> 680\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:403\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[1;32m    377\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[1;32m    378\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/functools.py:907\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    905\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:240\u001b[0m, in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:291\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    285\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:272\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:264\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/miniconda3/envs/trading-env-playground/lib/python3.12/pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1012\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trader_usd_eur_dqn_2.zip'"]}],"source":["del model\n","\n","# Load the trained model\n","model = DQN.load(\"trader_usd_eur_dqn_2\")\n","\n","# Initialize the environment\n","# env = ForexEnv(df, window_size=50)\n","obs = env.reset()\n","\n","# Run the model to get predictions and interact with the environment\n","for i in range(len(df) - env.unwrapped.window_size - 1):\n","    # deterministic=True\n","    action, _states = model.predict(obs)\n","    obs, reward, done, _ = env.step(action)  # Extract only required values\n","    if done:\n","        break\n","\n","# After the loop, analyze the action distribution\n","# action_counts = {action: 0 for action in range(env.action_space.n)}\n","# for action in model.actions_taken:\n","#     action_counts[action] += 1\n","# print(\"Action distribution:\", action_counts)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2c5b476911c14de1bfbac4acc65a64c0","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","source_hash":null},"outputs":[],"source":["import oandapyV20\n","import oandapyV20.endpoints.pricing as pricing\n","import oandapyV20.endpoints.orders as orders\n","import oandapyV20.endpoints.instruments as instruments\n","import pandas as pd\n","import logging\n","from oandapyV20 import API\n","import json\n","from oandapyV20.exceptions import V20Error\n","from oandapyV20.endpoints.pricing import PricingStream\n","from oandapyV20.endpoints.pricing import PricingStream\n","from oandapyV20.endpoints.orders import OrderCreate\n","from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n","from oandapyV20.contrib.requests import MarketOrderRequest\n","from oandapyV20.contrib.requests import TakeProfitDetails, StopLossDetails"]},{"cell_type":"code","execution_count":0,"metadata":{"cell_id":"6deabd350bcf486cbcc72d5fba3382c6","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","source_hash":null},"outputs":[],"source":["# OANDA API credentials\n","access_token = \"0922675609ea57cff543c8c7a74bf72c-b080b89522fd436a7c5e3809137c48f1\"\n","account_id =\"101-004-29270068-001\"\n","client = API(access_token=access_token)"]},{"cell_type":"code","execution_count":0,"metadata":{"cell_id":"01f42f3773a447fcacba53f7dbe27688","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","source_hash":null},"outputs":[],"source":["import gym\n","import matplotlib.pyplot as plt\n","import logging\n","import pandas as pd\n","import numpy as np\n","from stable_baselines3 import A2C\n","from stable_baselines3.common.envs import DummyVecEnv\n","\n","# Initialize environment\n","env = gym.make('forex-v0', frame_bound=(100, 500), window_size=5)\n","env = DummyVecEnv([lambda: env])\n","\n","# Load pre-trained model\n","model = A2C.load('trader_usd_eur_a2c')\n","\n","# Setup logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n","\n","# Initialize historical data\n","data = {}\n","\n","# Function to fetch historical data (optional, depending on your setup)\n","def fetch_historical_data(instrument, count, granularity):\n","    params = {\"count\": count, \"granularity\": granularity}\n","    try:\n","        request = instruments.InstrumentsCandles(instrument=instrument, params=params)\n","        candles = client.request(request)[\"candles\"]\n","        df = pd.DataFrame([{'time': c['time'], 'close': c['mid']['c']} for c in candles])\n","        df['time'] = pd.to_datetime(df['time'])\n","        df.set_index('time', inplace=True)\n","        return df\n","  \n","    except Exception as e:\n","        logging.error(f\"Error fetching historical data for {instrument}: {e}\")\n","        return None\n","\n","# Function to place an order\n","def place_order(instrument, units, stop_loss_pips=50, take_profit_pips=100):\n","    try:\n","        price = float(data[instrument].iloc[-1][\"close\"])\n","        stop_loss_price = price - (stop_loss_pips * 0.0001 * units / abs(units))\n","        take_profit_price = price + (take_profit_pips * 0.0001 * units / abs(units))\n","\n","        order = {\n","            \"order\": {\n","                \"instrument\": instrument,\n","                \"units\": str(units),\n","                \"type\": \"MARKET\",\n","                \"positionFill\": \"DEFAULT\",\n","                \"stopLossOnFill\": {\n","                    \"price\": str(stop_loss_price)\n","                },\n","                \"takeProfitOnFill\": {\n","                    \"price\": str(take_profit_price)\n","                }\n","            }\n","        }\n","        request = OrderCreate(accountID=account_id, data=order)\n","        response = client.request(request)\n","        logging.info(f\"Order placed for {instrument}: {response}\")\n","\n","    except Exception as e:\n","        logging.error(f\"Error placing order for {instrument}: {e}\")\n","\n","# Stream data and apply model's prediction for trading\n","def stream_data_and_trade(instruments):\n","    params = {\"instruments\": \",\".join(instruments)}\n","    priceStream = PricingStream(accountID=account_id, params=params)\n","    try:\n","        for tick in client.request(priceStream):\n","            if tick['type'] == 'PRICE':\n","                instrument = tick['instrument']\n","                price = (float(tick['bids'][0]['price']) + float(tick['asks'][0]['price'])) / 2\n","\n","                if instrument not in data:\n","                    data[instrument] = fetch_historical_data(instrument, count=300, granularity=\"M30\")\n","                    if data[instrument] is None:\n","                        continue\n","\n","                df = data[instrument]\n","\n","                # Update the DataFrame with the new tick data\n","                new_row = pd.DataFrame({\"time\": [pd.to_datetime(tick['time'])], \"close\": [price]})\n","                new_row.set_index(\"time\", inplace=True)\n","                df = pd.concat([df, new_row])\n","                if len(df) > 300:\n","                    df = df.iloc[-300:]  # Keep only the last 300 rows\n","                data[instrument] = df\n","\n","                # Prepare observation for the model\n","                obs = df[\"close\"].values[-env.observation_space.shape[0]:]\n","                obs = obs[np.newaxis, ..., np.newaxis]  # Adjust shape for model input\n","\n","                # Model prediction\n","                action, _states = model.predict(obs)\n","\n","                # Translate model action to buy/sell decision\n","                units = 1000 if action == 1 else -1000 if action == 2 else 0  # Assuming 0: hold, 1: buy, 2: sell\n","\n","                if units != 0:\n","                    place_order(instrument, units)\n","\n","    except V20Error as e:\n","        logging.error(f\"Error streaming data: {e}\")\n","\n","# Start streaming data and trading  \"GBP_USD\", \"EUR_JPY\"\n","instruments = [\"EUR_USD\"]\n","stream_data_and_trade(instruments)\n","\n","# # Setup logging\n","# logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n","\n","# # Function to fetch historical data (optional, depending on your setup)\n","# def fetch_historical_data(instrument, count, granularity):\n","#     params = {\"count\": count, \"granularity\": granularity}\n","#     try:\n","#         request = instruments.InstrumentsCandles(instrument=instrument, params=params)\n","#         candles = client.request(request)[\"candles\"]\n","#         df = pd.DataFrame([{'time': c['time'], 'close': c['mid']['c']} for c in candles])\n","#         df['time'] = pd.to_datetime(df['time'])\n","#         df.set_index('time', inplace=True)\n","#         return df\n","  \n","#     except Exception as e:\n","#         logging.error(f\"Error fetching historical data for {instrument}: {e}\")\n","#         return None\n","\n","# # Function to place an order\n","# def place_order(instrument, units, stop_loss_pips=50, take_profit_pips=100):\n","#     try:\n","#         price = float(data[instrument].iloc[-1][\"close\"])\n","#         stop_loss_price = price - (stop_loss_pips * 0.0001 * units / abs(units))\n","#         take_profit_price = price + (take_profit_pips * 0.0001 * units / abs(units))\n","\n","#         order = {\n","#             \"order\": {\n","#                 \"instrument\": instrument,\n","#                 \"units\": str(units),\n","#                 \"type\": \"MARKET\",\n","#                 \"positionFill\": \"DEFAULT\",\n","#                 \"stopLossOnFill\": {\n","#                     \"price\": str(stop_loss_price)\n","#                 },\n","#                 \"takeProfitOnFill\": {\n","#                     \"price\": str(take_profit_price)\n","#                 }\n","#             }\n","#         }\n","#         request = OrderCreate(accountID=account_id, data=order)\n","#         response = client.request(request)\n","#         logging.info(f\"Order placed for {instrument}: {response}\")\n","\n","#     except Exception as e:\n","#         logging.error(f\"Error placing order for {instrument}: {e}\")\n","\n","# # Stream data and apply model's prediction for trading\n","# def stream_data_and_trade(instruments):\n","#     params = {\"instruments\": \",\".join(instruments)}\n","#     priceStream = PricingStream(accountID=account_id, params=params)\n","#     try:\n","#         for tick in client.request(priceStream):\n","#             if tick['type'] == 'PRICE':\n","#                 instrument = tick['instrument']\n","#                 price = (float(tick['bids'][0]['price']) + float(tick['asks'][0]['price'])) / 2\n","\n","#                 if instrument not in data:\n","#                     data[instrument] = fetch_historical_data(instrument, count=300, granularity=\"M30\")\n","#                     if data[instrument] is None:\n","#                         continue\n","\n","#                 df = data[instrument]\n","\n","#                 # Update the DataFrame with the new tick data\n","#                 new_row = pd.DataFrame({\"time\": [pd.to_datetime(tick['time'])], \"close\": [price]})\n","#                 new_row.set_index(\"time\", inplace=True)\n","#                 df = pd.concat([df, new_row])\n","#                 if len(df) > 300:\n","#                     df = df.iloc[-300:]  # Keep only the last 300 rows\n","#                 data[instrument] = df\n","\n","#                 # Prepare observation for the model\n","#                 obs = df[\"close\"].values[-env.observation_space.shape[0]:]\n","#                 obs = obs[np.newaxis, ..., np.newaxis]  # Adjust shape for model input\n","\n","#                 # Model prediction\n","#                 action, _states = model.predict(obs)\n","\n","#                 # Translate model action to buy/sell decision\n","#                 units = 1000 if action == 1 else -1000 if action == 2 else 0  # Assuming 0: hold, 1: buy, 2: sell\n","\n","#                 if units != 0:\n","#                     place_order(instrument, units)\n","\n","#     except V20Error as e:\n","#         logging.error(f\"Error streaming data: {e}\")\n","\n","# # Start streaming data and trading\n","# instruments = [\"EUR_USD\", \"GBP_USD\", \"EUR_JPY\"]\n","# stream_data_and_trade(instruments)\n"]},{"cell_type":"code","execution_count":0,"metadata":{"cell_id":"cdfa7d815670473eb5389e99e40cec25","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","source_hash":null},"outputs":[],"source":["# Setup logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n","\n","# Parameters\n","instruments_list = [\"DE30_EUR\", \"EUR_USD\", \"EUR_JPY\"]\n","params = {\"instruments\": \",\".join(instruments_list)}\n","short_window = 50\n","long_window = 200\n","# Initialize historical data\n","data = {}\n","\n","# Function to fetch historical data\n","def fetch_historical_data(instrument, count, granularity):\n","    params = {\"count\": count, \"granularity\": granularity}\n","    try:\n","        request = instruments.InstrumentsCandles(instrument=instrument, params=params)\n","        candles = client.request(request)[\"candles\"]\n","        print(candles)\n","  \n","  \n","    except Exception as e:\n","        logging.error(f\"Error fetching historical data for {instrument}: {e}\")\n","        return None\n","\n","# Function to apply the trading strategy\n","def apply_strategy(df, short_window, long_window):\n","    df[\"SMA_short\"] = df[\"close\"].rolling(window=short_window).mean()\n","    df[\"SMA_long\"] = df[\"close\"].rolling(window=long_window).mean()\n","    df[\"signal\"] = 0.0\n","    df.loc[df.index[short_window:], \"signal\"] = (df[\"SMA_short\"][short_window:] > df[\"SMA_long\"][short_window:]).astype(float)\n","    df[\"positions\"] = df[\"signal\"].diff()\n","    return df\n","\n","# Function to place an order\n","def place_order(instrument, units, stop_loss_pips=50, take_profit_pips=100):\n","    try:\n","        price = float(data[instrument].iloc[-1][\"close\"])\n","        stop_loss_price = price - (stop_loss_pips * 0.0001 * units / abs(units))\n","        take_profit_price = price + (take_profit_pips * 0.0001 * units / abs(units))\n","\n","        order = {\n","            \"order\": {\n","                \"instrument\": instrument,\n","                \"units\": str(units),\n","                \"type\": \"MARKET\",\n","                \"positionFill\": \"DEFAULT\",\n","                \"stopLossOnFill\": {\n","                    \"price\": str(stop_loss_price)\n","                },\n","                \"takeProfitOnFill\": {\n","                    \"price\": str(take_profit_price)\n","                }\n","            }\n","        }\n","        request = OrderCreate(accountID=account_id, data=order)\n","        response = client.request(request)\n","        logging.info(f\"Order placed for {instrument}: {response}\")\n","\n","    except Exception as e:\n","        logging.error(f\"Error placing order for {instrument}: {e}\")\n","        \n","# Stream data and apply strategy\n","def stream_data_and_trade(instruments):\n","    params = {\"instruments\": \",\".join(instruments)}\n","    priceStream = PricingStream(accountID=account_id, params=params)\n","    try:\n","        for tick in client.request(priceStream):\n","            if tick['type'] == 'PRICE':\n","                instrument = tick['instrument']\n","                price = (float(tick['bids'][0]['price']) + float(tick['asks'][0]['price'])) / 2\n","\n","                if instrument not in data:\n","                    data[instrument] = fetch_historical_data(instrument, count=300, granularity=\"M30\")\n","                    if data[instrument] is None:\n","                        continue\n","\n","                df = data[instrument]\n","\n","                # Update the DataFrame with the new tick data\n","                new_row = pd.DataFrame({\"time\": [pd.to_datetime(tick['time'])], \"close\": [price]})\n","                new_row.set_index(\"time\", inplace=True)\n","                df = pd.concat([df, new_row])\n","                if len(df)> 300:\n","                    df = df.iloc[-300:]  # Keep only the last 300 rows\n","                data[instrument] = df\n","\n","                # Apply trading strategy\n","                df = apply_strategy(df, short_window, long_window)\n","\n","                # Check for buy/sell signals\n","                last_row = df.iloc[-1]\n","                if last_row[\"positions\"] == 1:\n","                    place_order(instrument, 10)\n","                elif last_row[\"positions\"] == -1:\n","                    place_order(instrument, -10)\n","                else:\n","                    logging.info(f\"Order not placed for any instrument\")\n","\n","    except V20Error as e:\n","        logging.error(f\"Error streaming data: {e}\")\n","\n","\n","instruments = [\"EUR_USD\",\"GBP_USD\"]\n","# Start streaming data and trading\n","stream_data_and_trade(instruments)"]},{"cell_type":"code","execution_count":0,"metadata":{"cell_id":"2d37b14379684f889b74329aac83a086","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_context_id":"1af93267-b8b3-4955-be9a-6a1ca1fbef3b","source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3d45628e-a0f9-421e-94f2-273c0d2863ec' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"735f0e046c1c488d980d3f00b20f9cb6","kernelspec":{"display_name":"trading-env-playground","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
